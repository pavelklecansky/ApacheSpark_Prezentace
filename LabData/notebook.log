[I 12:09:13.491 NotebookApp] Using MathJax: /static/vendor/MathJax-2.5-latest/MathJax.js
[I 12:09:13.494 NotebookApp] Using existing profile dir: u'/home/notebook/.ipython/profile_default'
[I 12:09:13.513 NotebookApp] Writing notebook server cookie secret to /home/notebook/.ipython/profile_default/security/notebook_cookie_secret
[C 12:09:13.565 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using encryption. This is not recommended.
[C 12:09:13.565 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using authentication. This is highly insecure and not recommended.
[I 12:09:13.586 NotebookApp] Serving notebooks from local directory: /resources
[I 12:09:13.586 NotebookApp] 0 active kernels 
[I 12:09:13.586 NotebookApp] The IPython Notebook is running at: http://[all ip addresses on your system]:8888/
[I 12:09:13.586 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[W 12:09:13.586 NotebookApp] No web browser found: could not locate runnable browser.
[I 05:23:31.876 NotebookApp] Using MathJax: /static/vendor/MathJax-2.5-latest/MathJax.js
[I 05:23:31.878 NotebookApp] Using existing profile dir: u'/home/notebook/.ipython/profile_default'
[C 05:23:31.934 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using encryption. This is not recommended.
[C 05:23:31.935 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using authentication. This is highly insecure and not recommended.
[I 05:23:31.950 NotebookApp] Serving notebooks from local directory: /resources
[I 05:23:31.950 NotebookApp] 0 active kernels 
[I 05:23:31.951 NotebookApp] The IPython Notebook is running at: http://[all ip addresses on your system]:8888/
[I 05:23:31.951 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[W 05:23:31.951 NotebookApp] No web browser found: could not locate runnable browser.
[I 17:47:53.549 NotebookApp] Using MathJax: /static/vendor/MathJax-2.5-latest/MathJax.js
[I 17:47:53.551 NotebookApp] Using existing profile dir: u'/home/notebook/.ipython/profile_default'
[C 17:47:53.607 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using encryption. This is not recommended.
[C 17:47:53.607 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using authentication. This is highly insecure and not recommended.
[I 17:47:53.624 NotebookApp] Serving notebooks from local directory: /resources
[I 17:47:53.625 NotebookApp] 0 active kernels 
[I 17:47:53.625 NotebookApp] The IPython Notebook is running at: http://[all ip addresses on your system]:8888/
[I 17:47:53.625 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[W 17:47:53.625 NotebookApp] No web browser found: could not locate runnable browser.
[I 15:44:00.376 NotebookApp] Using MathJax: /static/vendor/MathJax-2.5-latest/MathJax.js
[I 15:44:00.379 NotebookApp] Using existing profile dir: u'/home/notebook/.ipython/profile_default'
[C 15:44:00.432 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using encryption. This is not recommended.
[C 15:44:00.432 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using authentication. This is highly insecure and not recommended.
[I 15:44:00.448 NotebookApp] Serving notebooks from local directory: /resources
[I 15:44:00.448 NotebookApp] 0 active kernels 
[I 15:44:00.448 NotebookApp] The IPython Notebook is running at: http://[all ip addresses on your system]:8888/
[I 15:44:00.448 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[W 15:44:00.449 NotebookApp] No web browser found: could not locate runnable browser.
[I 14:29:17.513 NotebookApp] Writing notebook-signing key to /home/notebook/.ipython/profile_default/security/notebook_secret
[W 14:29:17.514 NotebookApp] Notebook Tutorial #1 - Get Data0.ipynb is not trusted
[I 14:29:18.119 NotebookApp] Request start_kernel: kernel_id=None, kernel_name=python2, path="", **kwargs={}
[I 14:29:18.121 NotebookApp] Provisioning local kernel: python2
[I 14:29:18.511 NotebookApp] Kernel started: 12a23d72-5ba3-498c-88f5-bc362c8c5357
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/14 14:29:21 INFO SparkContext: Running Spark version 1.4.1
15/10/14 14:29:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/14 14:29:22 INFO SecurityManager: Changing view acls to: notebook
15/10/14 14:29:22 INFO SecurityManager: Changing modify acls to: notebook
15/10/14 14:29:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
15/10/14 14:29:23 INFO Slf4jLogger: Slf4jLogger started
15/10/14 14:29:23 INFO Remoting: Starting remoting
15/10/14 14:29:23 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.22:53333]
15/10/14 14:29:23 INFO Utils: Successfully started service 'sparkDriver' on port 53333.
15/10/14 14:29:23 INFO SparkEnv: Registering MapOutputTracker
15/10/14 14:29:23 INFO SparkEnv: Registering BlockManagerMaster
15/10/14 14:29:23 INFO DiskBlockManager: Created local directory at /tmp/spark-fe150378-7bad-42b6-876b-d14e2c193eb6/blockmgr-c142f2f1-ebb6-4612-945b-0a67d156230a
15/10/14 14:29:23 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/10/14 14:29:23 INFO HttpFileServer: HTTP File server directory is /tmp/spark-fe150378-7bad-42b6-876b-d14e2c193eb6/httpd-ed3f4ab0-7218-48bc-9d8a-3981b1cfe574
15/10/14 14:29:23 INFO HttpServer: Starting HTTP Server
15/10/14 14:29:24 INFO Utils: Successfully started service 'HTTP file server' on port 49932.
15/10/14 14:29:24 INFO SparkEnv: Registering OutputCommitCoordinator
15/10/14 14:29:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/10/14 14:29:24 INFO SparkUI: Started SparkUI at http://172.17.0.22:4040
15/10/14 14:29:24 INFO Executor: Starting executor ID driver on host localhost
15/10/14 14:29:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35726.
15/10/14 14:29:24 INFO NettyBlockTransferService: Server created on 35726
15/10/14 14:29:24 INFO BlockManagerMaster: Trying to register BlockManager
15/10/14 14:29:24 INFO BlockManagerMasterEndpoint: Registering block manager localhost:35726 with 265.4 MB RAM, BlockManagerId(driver, localhost, 35726)
15/10/14 14:29:24 INFO BlockManagerMaster: Registered BlockManager
[W 14:29:34.393 NotebookApp] Notebook Tutorial #1 - Get Data0.ipynb is not trusted
[I 14:29:34.445 NotebookApp] Saving file at /Tutorial #1 - Get Data0.ipynb
[W 15:33:37.041 NotebookApp] Notebook presentation.ipynb is not trusted
[I 15:33:37.580 NotebookApp] Request start_kernel: kernel_id=None, kernel_name=None, path="", **kwargs={}
[I 15:33:37.580 NotebookApp] Provisioning local kernel: None
[I 15:33:37.609 NotebookApp] Kernel started: 12cbbe53-badb-4eee-88e0-08f04221d2be
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/15 15:33:40 INFO SparkContext: Running Spark version 1.4.1
15/10/15 15:33:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/15 15:33:41 INFO SecurityManager: Changing view acls to: notebook
15/10/15 15:33:41 INFO SecurityManager: Changing modify acls to: notebook
15/10/15 15:33:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
15/10/15 15:33:42 INFO Slf4jLogger: Slf4jLogger started
15/10/15 15:33:42 INFO Remoting: Starting remoting
15/10/15 15:33:42 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.22:47412]
15/10/15 15:33:42 INFO Utils: Successfully started service 'sparkDriver' on port 47412.
15/10/15 15:33:42 INFO SparkEnv: Registering MapOutputTracker
15/10/15 15:33:42 INFO SparkEnv: Registering BlockManagerMaster
15/10/15 15:33:42 INFO DiskBlockManager: Created local directory at /tmp/spark-fc035223-3b43-43d1-8d7d-a22dda6b0d46/blockmgr-aad4e583-6a6c-479a-b021-a7e0390ea261
15/10/15 15:33:42 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/10/15 15:33:42 INFO HttpFileServer: HTTP File server directory is /tmp/spark-fc035223-3b43-43d1-8d7d-a22dda6b0d46/httpd-80730048-1dcb-4da2-8458-8bf3eba96046
15/10/15 15:33:42 INFO HttpServer: Starting HTTP Server
15/10/15 15:33:42 INFO Utils: Successfully started service 'HTTP file server' on port 33688.
15/10/15 15:33:42 INFO SparkEnv: Registering OutputCommitCoordinator
15/10/15 15:33:43 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/10/15 15:33:43 INFO Utils: Successfully started service 'SparkUI' on port 4041.
15/10/15 15:33:43 INFO SparkUI: Started SparkUI at http://172.17.0.22:4041
15/10/15 15:33:43 INFO Executor: Starting executor ID driver on host localhost
15/10/15 15:33:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 47915.
15/10/15 15:33:43 INFO NettyBlockTransferService: Server created on 47915
15/10/15 15:33:43 INFO BlockManagerMaster: Trying to register BlockManager
15/10/15 15:33:43 INFO BlockManagerMasterEndpoint: Registering block manager localhost:47915 with 265.4 MB RAM, BlockManagerId(driver, localhost, 47915)
15/10/15 15:33:43 INFO BlockManagerMaster: Registered BlockManager
[I 15:37:39.136 NotebookApp] Saving file at /presentation.ipynb
[W 15:37:39.136 NotebookApp] Saving untrusted notebook presentation.ipynb
[I 16:01:55.926 NotebookApp] Saving file at /presentation.ipynb
[W 16:01:55.926 NotebookApp] Saving untrusted notebook presentation.ipynb
[I 16:03:58.884 NotebookApp] Saving file at /presentation.ipynb
[W 16:03:58.884 NotebookApp] Saving untrusted notebook presentation.ipynb
[I 16:16:06.482 NotebookApp] Saving file at /presentation.ipynb
[W 16:16:06.482 NotebookApp] Saving untrusted notebook presentation.ipynb
[I 16:17:08.097 NotebookApp] Kernel interrupted: 12cbbe53-badb-4eee-88e0-08f04221d2be
[I 16:17:09.506 NotebookApp] Kernel interrupted: 12cbbe53-badb-4eee-88e0-08f04221d2be
[I 16:17:13.095 NotebookApp] Kernel interrupted: 12cbbe53-badb-4eee-88e0-08f04221d2be
[I 16:18:06.310 NotebookApp] Saving file at /presentation.ipynb
[W 16:18:06.310 NotebookApp] Saving untrusted notebook presentation.ipynb
[I 16:20:06.420 NotebookApp] Saving file at /presentation.ipynb
[W 16:20:06.420 NotebookApp] Saving untrusted notebook presentation.ipynb
[I 16:22:06.414 NotebookApp] Saving file at /presentation.ipynb
[W 16:22:06.415 NotebookApp] Saving untrusted notebook presentation.ipynb
[I 16:24:06.399 NotebookApp] Saving file at /presentation.ipynb
[W 16:24:06.399 NotebookApp] Saving untrusted notebook presentation.ipynb
[W 16:31:31.999 NotebookApp] WebSocket ping timeout after 119949 ms.
[W 17:39:02.460 NotebookApp] Notebook presentation.ipynb is not trusted
[W 17:39:02.972 NotebookApp] zmq message arrived on closed channel
[W 17:39:02.974 NotebookApp] zmq message arrived on closed channel
[W 17:40:32.344 NotebookApp] zmq message arrived on closed channel
[W 17:40:32.345 NotebookApp] zmq message arrived on closed channel
[W 17:50:59.807 NotebookApp] zmq message arrived on closed channel
[W 17:50:59.809 NotebookApp] zmq message arrived on closed channel
[W 21:46:29.786 NotebookApp] WebSocket ping timeout after 119982 ms.
[W 23:57:57.893 NotebookApp] WebSocket ping timeout after 90000 ms.
[W 00:24:31.376 NotebookApp] WebSocket ping timeout after 90000 ms.
[W 01:13:03.731 NotebookApp] WebSocket ping timeout after 119946 ms.
[W 02:43:09.449 NotebookApp] WebSocket ping timeout after 90001 ms.
[W 03:44:53.227 NotebookApp] WebSocket ping timeout after 119924 ms.
[W 09:48:40.685 NotebookApp] WebSocket ping timeout after 119918 ms.
[W 13:08:17.861 NotebookApp] Notebook Untitled.ipynb is not trusted
[I 13:08:17.970 NotebookApp] Request start_kernel: kernel_id=None, kernel_name=python2, path="", **kwargs={}
[I 13:08:17.970 NotebookApp] Provisioning local kernel: python2
[I 13:08:18.000 NotebookApp] Kernel started: fba3d4f2-e87c-461e-b434-374434e25aac
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/16 13:08:21 INFO SparkContext: Running Spark version 1.4.1
15/10/16 13:08:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/16 13:08:21 INFO SecurityManager: Changing view acls to: notebook
15/10/16 13:08:21 INFO SecurityManager: Changing modify acls to: notebook
15/10/16 13:08:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
15/10/16 13:08:22 INFO Slf4jLogger: Slf4jLogger started
15/10/16 13:08:22 INFO Remoting: Starting remoting
15/10/16 13:08:23 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.22:58378]
15/10/16 13:08:23 INFO Utils: Successfully started service 'sparkDriver' on port 58378.
15/10/16 13:08:23 INFO SparkEnv: Registering MapOutputTracker
15/10/16 13:08:23 INFO SparkEnv: Registering BlockManagerMaster
15/10/16 13:08:23 INFO DiskBlockManager: Created local directory at /tmp/spark-ca471293-a9b6-4761-b0c9-00799500af70/blockmgr-24ee1e5a-9311-4665-8ce7-56fc1f0601a0
15/10/16 13:08:23 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/10/16 13:08:23 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ca471293-a9b6-4761-b0c9-00799500af70/httpd-98632027-ee06-401b-a027-b7973b158023
15/10/16 13:08:23 INFO HttpServer: Starting HTTP Server
15/10/16 13:08:23 INFO Utils: Successfully started service 'HTTP file server' on port 58885.
15/10/16 13:08:23 INFO SparkEnv: Registering OutputCommitCoordinator
15/10/16 13:08:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/10/16 13:08:23 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
15/10/16 13:08:23 INFO Utils: Successfully started service 'SparkUI' on port 4042.
15/10/16 13:08:23 INFO SparkUI: Started SparkUI at http://172.17.0.22:4042
15/10/16 13:08:23 INFO Executor: Starting executor ID driver on host localhost
15/10/16 13:08:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34420.
15/10/16 13:08:23 INFO NettyBlockTransferService: Server created on 34420
15/10/16 13:08:23 INFO BlockManagerMaster: Trying to register BlockManager
15/10/16 13:08:23 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34420 with 265.4 MB RAM, BlockManagerId(driver, localhost, 34420)
15/10/16 13:08:23 INFO BlockManagerMaster: Registered BlockManager
[I 13:10:18.237 NotebookApp] Saving file at /Untitled.ipynb
[I 13:12:18.438 NotebookApp] Saving file at /Untitled.ipynb
[I 13:13:22.038 NotebookApp] Request restart_kernel: fba3d4f2-e87c-461e-b434-374434e25aac, <IPython.kernel.ioloop.manager.IOLoopKernelManager object at 0x7fd6315aea50>
15/10/16 13:13:22 INFO SparkUI: Stopped Spark web UI at http://172.17.0.22:4042
15/10/16 13:13:22 INFO DAGScheduler: Stopping DAGScheduler
15/10/16 13:13:22 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/10/16 13:13:22 INFO Utils: path = /tmp/spark-ca471293-a9b6-4761-b0c9-00799500af70/blockmgr-24ee1e5a-9311-4665-8ce7-56fc1f0601a0, already present as root for deletion.
15/10/16 13:13:22 INFO MemoryStore: MemoryStore cleared
15/10/16 13:13:22 INFO BlockManager: BlockManager stopped
15/10/16 13:13:22 INFO BlockManagerMaster: BlockManagerMaster stopped
15/10/16 13:13:22 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/10/16 13:13:22 INFO SparkContext: Successfully stopped SparkContext
15/10/16 13:13:22 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/10/16 13:13:22 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/10/16 13:13:22 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
15/10/16 13:13:22 INFO Utils: Shutdown hook called
15/10/16 13:13:22 INFO Utils: Deleting directory /tmp/spark-ca471293-a9b6-4761-b0c9-00799500af70/pyspark-2107622a-f8ad-4b5a-b456-f0e414fbed40
15/10/16 13:13:22 INFO Utils: Deleting directory /tmp/spark-ca471293-a9b6-4761-b0c9-00799500af70
[I 13:13:22.762 NotebookApp] Kernel restarted: fba3d4f2-e87c-461e-b434-374434e25aac
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/16 13:13:25 INFO SparkContext: Running Spark version 1.4.1
15/10/16 13:13:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/16 13:13:26 INFO SecurityManager: Changing view acls to: notebook
15/10/16 13:13:26 INFO SecurityManager: Changing modify acls to: notebook
15/10/16 13:13:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
15/10/16 13:13:27 INFO Slf4jLogger: Slf4jLogger started
15/10/16 13:13:27 INFO Remoting: Starting remoting
15/10/16 13:13:27 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.22:38668]
15/10/16 13:13:27 INFO Utils: Successfully started service 'sparkDriver' on port 38668.
15/10/16 13:13:27 INFO SparkEnv: Registering MapOutputTracker
15/10/16 13:13:27 INFO SparkEnv: Registering BlockManagerMaster
15/10/16 13:13:27 INFO DiskBlockManager: Created local directory at /tmp/spark-52bdb6b1-7781-4abd-9758-bfc0d2a578ec/blockmgr-e0992345-e860-44ea-aaca-50e75bd99684
15/10/16 13:13:27 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/10/16 13:13:27 INFO HttpFileServer: HTTP File server directory is /tmp/spark-52bdb6b1-7781-4abd-9758-bfc0d2a578ec/httpd-fe5e1d28-9663-460b-97fd-e2374b912583
15/10/16 13:13:27 INFO HttpServer: Starting HTTP Server
15/10/16 13:13:28 INFO Utils: Successfully started service 'HTTP file server' on port 36908.
15/10/16 13:13:28 INFO SparkEnv: Registering OutputCommitCoordinator
15/10/16 13:13:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/10/16 13:13:28 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
15/10/16 13:13:28 INFO Utils: Successfully started service 'SparkUI' on port 4042.
15/10/16 13:13:28 INFO SparkUI: Started SparkUI at http://172.17.0.22:4042
15/10/16 13:13:28 INFO Executor: Starting executor ID driver on host localhost
15/10/16 13:13:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44407.
15/10/16 13:13:28 INFO NettyBlockTransferService: Server created on 44407
15/10/16 13:13:28 INFO BlockManagerMaster: Trying to register BlockManager
15/10/16 13:13:28 INFO BlockManagerMasterEndpoint: Registering block manager localhost:44407 with 265.4 MB RAM, BlockManagerId(driver, localhost, 44407)
15/10/16 13:13:28 INFO BlockManagerMaster: Registered BlockManager
[I 13:14:18.299 NotebookApp] Saving file at /Untitled.ipynb
15/10/16 13:15:35 INFO HiveContext: Initializing execution hive, version 0.13.1
15/10/16 13:15:35 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
15/10/16 13:15:35 INFO ObjectStore: ObjectStore, initialize called
15/10/16 13:15:35 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
15/10/16 13:15:35 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
15/10/16 13:15:35 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)
15/10/16 13:15:35 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)
15/10/16 13:15:37 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
15/10/16 13:15:37 INFO MetaStoreDirectSql: MySQL check failed, assuming we are not on mysql: Lexical error at line 1, column 5.  Encountered: "@" (64), after : "".
15/10/16 13:15:38 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
15/10/16 13:15:38 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
15/10/16 13:15:39 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
15/10/16 13:15:39 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
15/10/16 13:15:39 INFO ObjectStore: Initialized ObjectStore
15/10/16 13:15:39 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 0.13.1aa
15/10/16 13:15:40 INFO HiveMetaStore: Added admin role in metastore
15/10/16 13:15:40 INFO HiveMetaStore: Added public role in metastore
15/10/16 13:15:40 INFO HiveMetaStore: No user is added in admin role, since config is empty
15/10/16 13:15:40 INFO SessionState: No Tez session required at this point. hive.execution.engine=mr.
15/10/16 13:15:41 INFO HiveContext: Initializing HiveMetastoreConnection version 0.13.1 using Spark classes.
15/10/16 13:15:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/16 13:15:41 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
15/10/16 13:15:41 INFO ObjectStore: ObjectStore, initialize called
15/10/16 13:15:42 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
15/10/16 13:15:42 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
15/10/16 13:15:42 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)
15/10/16 13:15:42 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)
15/10/16 13:15:43 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
15/10/16 13:15:43 INFO MetaStoreDirectSql: MySQL check failed, assuming we are not on mysql: Lexical error at line 1, column 5.  Encountered: "@" (64), after : "".
15/10/16 13:15:44 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
15/10/16 13:15:44 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
15/10/16 13:15:45 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
15/10/16 13:15:45 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
15/10/16 13:15:46 INFO ObjectStore: Initialized ObjectStore
15/10/16 13:15:46 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 0.13.1aa
15/10/16 13:15:46 INFO HiveMetaStore: Added admin role in metastore
15/10/16 13:15:46 INFO HiveMetaStore: Added public role in metastore
15/10/16 13:15:46 INFO HiveMetaStore: No user is added in admin role, since config is empty
15/10/16 13:15:46 INFO SessionState: No Tez session required at this point. hive.execution.engine=mr.
15/10/16 13:15:47 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:-2
15/10/16 13:15:47 INFO DAGScheduler: Got job 0 (showString at NativeMethodAccessorImpl.java:-2) with 1 output partitions (allowLocal=false)
15/10/16 13:15:47 INFO DAGScheduler: Final stage: ResultStage 0(showString at NativeMethodAccessorImpl.java:-2)
15/10/16 13:15:47 INFO DAGScheduler: Parents of final stage: List()
15/10/16 13:15:47 INFO DAGScheduler: Missing parents: List()
15/10/16 13:15:47 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at showString at NativeMethodAccessorImpl.java:-2), which has no missing parents
15/10/16 13:15:47 INFO MemoryStore: ensureFreeSpace(5304) called with curMem=0, maxMem=278302556
15/10/16 13:15:47 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.2 KB, free 265.4 MB)
15/10/16 13:15:47 INFO MemoryStore: ensureFreeSpace(2733) called with curMem=5304, maxMem=278302556
15/10/16 13:15:47 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.7 KB, free 265.4 MB)
15/10/16 13:15:47 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:44407 (size: 2.7 KB, free: 265.4 MB)
15/10/16 13:15:47 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:874
15/10/16 13:15:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at showString at NativeMethodAccessorImpl.java:-2)
15/10/16 13:15:47 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
15/10/16 13:15:47 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 1171 bytes)
15/10/16 13:15:47 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/10/16 13:15:47 INFO JDBCRDD: closed connection
15/10/16 13:15:47 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 4985 bytes result sent to driver
15/10/16 13:15:47 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 366 ms on localhost (1/1)
15/10/16 13:15:47 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/10/16 13:15:47 INFO DAGScheduler: ResultStage 0 (showString at NativeMethodAccessorImpl.java:-2) finished in 0.382 s
15/10/16 13:15:47 INFO DAGScheduler: Job 0 finished: showString at NativeMethodAccessorImpl.java:-2, took 0.569826 s
[I 13:16:18.370 NotebookApp] Saving file at /Untitled.ipynb
[I 13:18:18.364 NotebookApp] Saving file at /Untitled.ipynb
[I 13:20:18.402 NotebookApp] Saving file at /Untitled.ipynb
15/10/16 13:31:24 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:-2
15/10/16 13:31:24 INFO DAGScheduler: Got job 1 (showString at NativeMethodAccessorImpl.java:-2) with 1 output partitions (allowLocal=false)
15/10/16 13:31:24 INFO DAGScheduler: Final stage: ResultStage 1(showString at NativeMethodAccessorImpl.java:-2)
15/10/16 13:31:24 INFO DAGScheduler: Parents of final stage: List()
15/10/16 13:31:24 INFO DAGScheduler: Missing parents: List()
15/10/16 13:31:24 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[3] at showString at NativeMethodAccessorImpl.java:-2), which has no missing parents
15/10/16 13:31:24 INFO MemoryStore: ensureFreeSpace(5304) called with curMem=8037, maxMem=278302556
15/10/16 13:31:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 5.2 KB, free 265.4 MB)
15/10/16 13:31:24 INFO MemoryStore: ensureFreeSpace(2732) called with curMem=13341, maxMem=278302556
15/10/16 13:31:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.7 KB, free 265.4 MB)
15/10/16 13:31:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:44407 (size: 2.7 KB, free: 265.4 MB)
15/10/16 13:31:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:874
15/10/16 13:31:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at showString at NativeMethodAccessorImpl.java:-2)
15/10/16 13:31:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
15/10/16 13:31:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1171 bytes)
15/10/16 13:31:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
15/10/16 13:31:24 INFO JDBCRDD: closed connection
15/10/16 13:31:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 4995 bytes result sent to driver
15/10/16 13:31:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 308 ms on localhost (1/1)
15/10/16 13:31:24 INFO DAGScheduler: ResultStage 1 (showString at NativeMethodAccessorImpl.java:-2) finished in 0.310 s
15/10/16 13:31:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/10/16 13:31:24 INFO DAGScheduler: Job 1 finished: showString at NativeMethodAccessorImpl.java:-2, took 0.323202 s
[I 13:32:19.833 NotebookApp] Saving file at /Untitled.ipynb
[I 13:44:19.751 NotebookApp] Saving file at /Untitled.ipynb
[I 13:46:30.101 NotebookApp] Saving file at /Untitled.ipynb
[I 13:50:32.798 NotebookApp] Saving file at /Untitled.ipynb
[I 13:56:34.101 NotebookApp] Saving file at /Untitled.ipynb
[W 14:52:15.514 NotebookApp] Notebook Untitled0.ipynb is not trusted
[I 14:52:15.614 NotebookApp] Request start_kernel: kernel_id=None, kernel_name=python2, path="", **kwargs={}
[I 14:52:15.614 NotebookApp] Provisioning local kernel: python2
[I 14:52:15.643 NotebookApp] Kernel started: d815d372-19b2-4620-80b3-1126c94b76ff
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/16 14:52:18 INFO SparkContext: Running Spark version 1.4.1
15/10/16 14:52:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/16 14:52:19 INFO SecurityManager: Changing view acls to: notebook
15/10/16 14:52:19 INFO SecurityManager: Changing modify acls to: notebook
15/10/16 14:52:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
15/10/16 14:52:20 INFO Slf4jLogger: Slf4jLogger started
15/10/16 14:52:20 INFO Remoting: Starting remoting
15/10/16 14:52:20 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.22:43750]
15/10/16 14:52:20 INFO Utils: Successfully started service 'sparkDriver' on port 43750.
15/10/16 14:52:20 INFO SparkEnv: Registering MapOutputTracker
15/10/16 14:52:20 INFO SparkEnv: Registering BlockManagerMaster
15/10/16 14:52:20 INFO DiskBlockManager: Created local directory at /tmp/spark-682ea8cc-d28a-4715-be6e-9c2bdc684ba4/blockmgr-73dbe021-6e2b-43f9-9547-72004cf3a221
15/10/16 14:52:20 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/10/16 14:52:20 INFO HttpFileServer: HTTP File server directory is /tmp/spark-682ea8cc-d28a-4715-be6e-9c2bdc684ba4/httpd-a9ac31c5-fdd1-4437-a29f-771847924c71
15/10/16 14:52:20 INFO HttpServer: Starting HTTP Server
15/10/16 14:52:20 INFO Utils: Successfully started service 'HTTP file server' on port 54419.
15/10/16 14:52:20 INFO SparkEnv: Registering OutputCommitCoordinator
15/10/16 14:52:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/10/16 14:52:21 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
15/10/16 14:52:21 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
15/10/16 14:52:21 INFO Utils: Successfully started service 'SparkUI' on port 4043.
15/10/16 14:52:21 INFO SparkUI: Started SparkUI at http://172.17.0.22:4043
15/10/16 14:52:21 INFO Executor: Starting executor ID driver on host localhost
15/10/16 14:52:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54796.
15/10/16 14:52:21 INFO NettyBlockTransferService: Server created on 54796
15/10/16 14:52:21 INFO BlockManagerMaster: Trying to register BlockManager
15/10/16 14:52:21 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54796 with 265.4 MB RAM, BlockManagerId(driver, localhost, 54796)
15/10/16 14:52:21 INFO BlockManagerMaster: Registered BlockManager
[I 14:54:16.025 NotebookApp] Saving file at /Untitled0.ipynb
[I 14:56:15.996 NotebookApp] Saving file at /Untitled0.ipynb
[I 14:58:15.961 NotebookApp] Saving file at /Untitled0.ipynb
[I 15:00:16.003 NotebookApp] Saving file at /RedRock.ipynb
15/10/16 15:05:04 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:44407 in memory (size: 2.7 KB, free: 265.4 MB)
15/10/16 15:05:04 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:44407 in memory (size: 2.7 KB, free: 265.4 MB)
[I 15:06:39.589 NotebookApp] Saving file at /Untitled.ipynb
[W 15:21:41.764 NotebookApp] WebSocket ping timeout after 119954 ms.
[W 15:21:41.935 NotebookApp] WebSocket ping timeout after 119956 ms.
[W 15:21:51.950 NotebookApp] WebSocket ping timeout after 119960 ms.
[I 15:34:33.779 NotebookApp] Saving file at /RedRock.ipynb
[W 15:42:31.442 NotebookApp] zmq message arrived on closed channel
[W 15:42:31.443 NotebookApp] zmq message arrived on closed channel
[I 15:56:31.474 NotebookApp] Saving file at /RedRock.ipynb
[W 16:06:28.475 NotebookApp] zmq message arrived on closed channel
[W 16:06:28.476 NotebookApp] zmq message arrived on closed channel
[W 16:06:28.522 NotebookApp] zmq message arrived on closed channel
[W 16:06:30.872 NotebookApp] zmq message arrived on closed channel
[W 16:06:30.873 NotebookApp] zmq message arrived on closed channel
[I 16:06:31.463 NotebookApp] Saving file at /RedRock.ipynb
[W 16:06:32.970 NotebookApp] zmq message arrived on closed channel
[W 16:06:32.972 NotebookApp] zmq message arrived on closed channel
[I 16:08:31.474 NotebookApp] Saving file at /RedRock.ipynb
[W 16:11:34.069 NotebookApp] zmq message arrived on closed channel
[W 16:11:34.070 NotebookApp] zmq message arrived on closed channel
[W 16:11:36.180 NotebookApp] zmq message arrived on closed channel
[W 16:11:36.181 NotebookApp] zmq message arrived on closed channel
[I 16:12:33.440 NotebookApp] Saving file at /RedRock.ipynb
[W 16:14:27.808 NotebookApp] zmq message arrived on closed channel
[W 16:14:27.809 NotebookApp] zmq message arrived on closed channel
[W 16:14:28.901 NotebookApp] zmq message arrived on closed channel
[W 16:14:28.902 NotebookApp] zmq message arrived on closed channel
[I 16:14:33.752 NotebookApp] Saving file at /RedRock.ipynb
[W 16:14:37.695 NotebookApp] zmq message arrived on closed channel
[W 16:14:37.695 NotebookApp] zmq message arrived on closed channel
[W 16:14:39.776 NotebookApp] zmq message arrived on closed channel
[W 16:14:39.777 NotebookApp] zmq message arrived on closed channel
[I 16:16:33.776 NotebookApp] Saving file at /RedRock.ipynb
[W 17:28:01.401 NotebookApp] WebSocket ping timeout after 119960 ms.
[W 19:48:50.155 NotebookApp] WebSocket ping timeout after 119961 ms.
[W 21:30:12.489 NotebookApp] WebSocket ping timeout after 119979 ms.
[W 23:57:57.101 NotebookApp] WebSocket ping timeout after 90001 ms.
[W 02:42:32.416 NotebookApp] WebSocket ping timeout after 119958 ms.
[W 05:12:04.531 NotebookApp] WebSocket ping timeout after 119906 ms.
[W 06:09:14.793 NotebookApp] Notebook RedRock_HM_v3.ipynb is not trusted
[I 06:09:16.755 NotebookApp] Request start_kernel: kernel_id=None, kernel_name=python2, path="", **kwargs={}
[I 06:09:16.755 NotebookApp] Provisioning local kernel: python2
[I 06:09:16.791 NotebookApp] Kernel started: 00a2534c-99f1-478e-a86d-8dae5c34900f
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/21 06:09:19 INFO SparkContext: Running Spark version 1.4.1
15/10/21 06:09:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/21 06:09:20 INFO SecurityManager: Changing view acls to: notebook
15/10/21 06:09:20 INFO SecurityManager: Changing modify acls to: notebook
15/10/21 06:09:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
15/10/21 06:09:21 INFO Slf4jLogger: Slf4jLogger started
15/10/21 06:09:21 INFO Remoting: Starting remoting
15/10/21 06:09:21 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.22:43928]
15/10/21 06:09:21 INFO Utils: Successfully started service 'sparkDriver' on port 43928.
15/10/21 06:09:21 INFO SparkEnv: Registering MapOutputTracker
15/10/21 06:09:21 INFO SparkEnv: Registering BlockManagerMaster
15/10/21 06:09:21 INFO DiskBlockManager: Created local directory at /tmp/spark-228429ff-23c9-4471-88ae-9c5c26535d7a/blockmgr-ed90f7d7-7049-471a-8560-950825742016
15/10/21 06:09:21 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/10/21 06:09:21 INFO HttpFileServer: HTTP File server directory is /tmp/spark-228429ff-23c9-4471-88ae-9c5c26535d7a/httpd-3f3cd3ee-81f2-4ba5-be62-ccdb6d62cf52
15/10/21 06:09:21 INFO HttpServer: Starting HTTP Server
15/10/21 06:09:21 INFO Utils: Successfully started service 'HTTP file server' on port 39189.
15/10/21 06:09:21 INFO SparkEnv: Registering OutputCommitCoordinator
15/10/21 06:09:22 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/10/21 06:09:22 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
15/10/21 06:09:22 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
15/10/21 06:09:22 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
15/10/21 06:09:22 INFO Utils: Successfully started service 'SparkUI' on port 4044.
15/10/21 06:09:22 INFO SparkUI: Started SparkUI at http://172.17.0.22:4044
15/10/21 06:09:22 INFO Executor: Starting executor ID driver on host localhost
15/10/21 06:09:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34705.
15/10/21 06:09:22 INFO NettyBlockTransferService: Server created on 34705
15/10/21 06:09:22 INFO BlockManagerMaster: Trying to register BlockManager
15/10/21 06:09:22 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34705 with 265.4 MB RAM, BlockManagerId(driver, localhost, 34705)
15/10/21 06:09:22 INFO BlockManagerMaster: Registered BlockManager
--2015-10-21 06:10:05--  https://ibm.box.com/shared/static/pdeifd6iku04877aec39h71qtfgn3c84.csv
Resolving ibm.box.com (ibm.box.com)... 74.112.185.182, 74.112.184.85
Connecting to ibm.box.com (ibm.box.com)|74.112.185.182|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://ibm.app.box.com/shared/static/pdeifd6iku04877aec39h71qtfgn3c84.csv [following]
--2015-10-21 06:10:06--  https://ibm.app.box.com/shared/static/pdeifd6iku04877aec39h71qtfgn3c84.csv
Resolving ibm.app.box.com (ibm.app.box.com)... 74.112.184.87, 74.112.185.87
Connecting to ibm.app.box.com (ibm.app.box.com)|74.112.184.87|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://dl.boxcloud.com/d/1/w19ZVDnxNkDhmAbGB1Sp13MB9orJHIuk3Vv6Y_ScJqJ_oVNAbbs_kTETO36WLIG_edmK5um3mQZVm33NnOUIVynE3wSQejZpSJaWrwImdgK7H__lyUw0Hstea68L-UdXnLEmhcUTCnViarvsxxdKChBJ2q6NzYdfRrWCkaDHIo554ZZuKkVGz3RIz8QpZtUy9kZRz0wmry0zk_WiFRMjSAKtBqVBqQoJZsqwrFBW7MWwotNS02lXxOMEqTmap1iz_THDMu6TLNm_xD_K2Z4vbEawweFGDeOA8f_RncME-UVd7NskVcaNAGSXzPvpM2luSirbteRhBWaOERiaWqNCmjS-dqEFO2WEgwiwG0SiwWKXR1z9uHk05LCzSIMR1wHHMQ4L0NI05Oyt4nacqLrXGGPJLE-yrKwIo0QyPYigMIW1igYhZht0T7YKWNZykjn_pYnSb9F808bAbb1i3KyHzKl2u3hrZhMV0WbKIiqZ26musP1rkEQn2Nw44_nXJv9loa_89Jy98Zo-ZDAdn4-mL-2lYEVLOioKLZQ4hS6QD-HB-v74hvOXgrxVu8MEUhrpp_EgqjS5Is02VSZIEwYR-wARacsQKMbGoQNtacJunZkb5I_gqkEuBCrdr6ndnH_qupRaP1cc8ITRZ0szjcd9xBhmYFNsPGaBJeeYYnmeDrvPyc50PJTuM3N3AmS9QsbRF-w-Y3VZilu2O3Tbyu0tYirRDM_qgLzkXbuV40nIxJI6am3TzUdmZuejTsnx2USo7_SNwQb5SkZyPJ-wDWrE8XeaLtvIw6RIOjmz3_hZ5LbS53fOqu-90R7Sz6lAMmt3zbrCfPi-IDmNyl9lyDK_Q7bh4PjK7EcVFmXMj0Ok2ZDFnEdmZz9ApKrIEB4d06ImtKHy7mcc7WQXiLZE71IkLoJdCKDagzJWXL0mpqBD7aG0JjGBumeKEoj_9j8FYpLd042DbSuRYIP6-QGTWGlwWIuZ_0q4r_nssse4hXfoboGJMPkczTSSUQMLHtEAC50ddL-E_xnScfLP5HmCtTWCH0hGwJcwapqdlz-PJ8MAI0VtEixLGRJSgO5He9KYsODVtIo1WUkYGiXdZ9YYySTE4hsPSq9IwWco9zpm2pGUiS0pR6ET1Yw2vUUS-6yw7b6JwLtLnJItaKcudkRl7ibkhpEVkLynIGNQbCrYQbioGXwomyfDNjICg2tg2cL5t7fphw../download [following]
--2015-10-21 06:10:06--  https://dl.boxcloud.com/d/1/w19ZVDnxNkDhmAbGB1Sp13MB9orJHIuk3Vv6Y_ScJqJ_oVNAbbs_kTETO36WLIG_edmK5um3mQZVm33NnOUIVynE3wSQejZpSJaWrwImdgK7H__lyUw0Hstea68L-UdXnLEmhcUTCnViarvsxxdKChBJ2q6NzYdfRrWCkaDHIo554ZZuKkVGz3RIz8QpZtUy9kZRz0wmry0zk_WiFRMjSAKtBqVBqQoJZsqwrFBW7MWwotNS02lXxOMEqTmap1iz_THDMu6TLNm_xD_K2Z4vbEawweFGDeOA8f_RncME-UVd7NskVcaNAGSXzPvpM2luSirbteRhBWaOERiaWqNCmjS-dqEFO2WEgwiwG0SiwWKXR1z9uHk05LCzSIMR1wHHMQ4L0NI05Oyt4nacqLrXGGPJLE-yrKwIo0QyPYigMIW1igYhZht0T7YKWNZykjn_pYnSb9F808bAbb1i3KyHzKl2u3hrZhMV0WbKIiqZ26musP1rkEQn2Nw44_nXJv9loa_89Jy98Zo-ZDAdn4-mL-2lYEVLOioKLZQ4hS6QD-HB-v74hvOXgrxVu8MEUhrpp_EgqjS5Is02VSZIEwYR-wARacsQKMbGoQNtacJunZkb5I_gqkEuBCrdr6ndnH_qupRaP1cc8ITRZ0szjcd9xBhmYFNsPGaBJeeYYnmeDrvPyc50PJTuM3N3AmS9QsbRF-w-Y3VZilu2O3Tbyu0tYirRDM_qgLzkXbuV40nIxJI6am3TzUdmZuejTsnx2USo7_SNwQb5SkZyPJ-wDWrE8XeaLtvIw6RIOjmz3_hZ5LbS53fOqu-90R7Sz6lAMmt3zbrCfPi-IDmNyl9lyDK_Q7bh4PjK7EcVFmXMj0Ok2ZDFnEdmZz9ApKrIEB4d06ImtKHy7mcc7WQXiLZE71IkLoJdCKDagzJWXL0mpqBD7aG0JjGBumeKEoj_9j8FYpLd042DbSuRYIP6-QGTWGlwWIuZ_0q4r_nssse4hXfoboGJMPkczTSSUQMLHtEAC50ddL-E_xnScfLP5HmCtTWCH0hGwJcwapqdlz-PJ8MAI0VtEixLGRJSgO5He9KYsODVtIo1WUkYGiXdZ9YYySTE4hsPSq9IwWco9zpm2pGUiS0pR6ET1Yw2vUUS-6yw7b6JwLtLnJItaKcudkRl7ibkhpEVkLynIGNQbCrYQbioGXwomyfDNjICg2tg2cL5t7fphw../download
Resolving dl.boxcloud.com (dl.boxcloud.com)... 74.112.185.96, 74.112.184.96
Connecting to dl.boxcloud.com (dl.boxcloud.com)|74.112.185.96|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 113549 (111K) [text/csv]
Saving to: ‘tweetlocation.csv’

 0% [                                       ] 0           --.-K/s              68% [=========================>             ] 77,466       294KB/s             100%[======================================>] 113,549      345KB/s   in 0.3s   

2015-10-21 06:10:07 (345 KB/s) - ‘tweetlocation.csv’ saved [113549/113549]

--2015-10-21 06:10:08--  https://ibm.box.com/shared/static/wq8g26futqbq0cr2hymg03immnmonw9t.json
Resolving ibm.box.com (ibm.box.com)... 74.112.185.182, 74.112.184.85
Connecting to ibm.box.com (ibm.box.com)|74.112.185.182|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://ibm.app.box.com/shared/static/wq8g26futqbq0cr2hymg03immnmonw9t.json [following]
--2015-10-21 06:10:08--  https://ibm.app.box.com/shared/static/wq8g26futqbq0cr2hymg03immnmonw9t.json
Resolving ibm.app.box.com (ibm.app.box.com)... 74.112.185.87, 74.112.184.87
Connecting to ibm.app.box.com (ibm.app.box.com)|74.112.185.87|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://dl.boxcloud.com/d/1/IgYC8Y8pQga4l2_cc2jcaRzsN6HZu8Lhl0kjLJe7rrz2ietinecTAL8JMSgvyn7OgibrcdRzY1rGfQuBwe0nawH5Ypxb_G_F-05vyM2V16eMHpoR3ndojfsvb58Mu49UcyTVBIv7rPPHoIOuP-wFKRrFjSSZpg3DwRq-Za3qlA4VGh9X_EO-4gsUsTIOJ0i5p-ewMPABvpkFFDjUC3AZmNY0ZrQ0GVdRiADIoMzVkEoou8OdouMYEDBWZh3qQsQv-qDX-554Z8gvvi7-fNQkkZ7ufVin3C3uihExlcc5rTXuglyZMXTuMBrwurWpch19vqOWkrfl25-UFZYeAreDJGgyN24kXwPhUfiq281lU12TZcCiOJBBEgVXj86lhztkOlzZLJi04WFDXBetyIxwsdotzF_TcXwa-gscmSZZOettdQXuEuZc3zVbvC3dlA5DM_IbVYsc00F62hLsJ8toY-f_T1LTKAX-4lVDuGliakqu9oGl8DLA0y7NT2TGP2G-OyNnmW6l_iQ_giXH-GwJW1cp_8ZxJ8lVErUCONRM6CDcNe3mS8xwh7KFtIocgMRtudHQMK6qCPe9Z2_SMYOqOG1nP7vaN53L5CYz6xRL9RoCEWx_BMnbZ5Qe2xV7Ct1p1Zb6IgbykLVD3lXUUD5-oFKMLTXZ9l2-BslVkm-D_kgqmEb1yB7C3MAh3uDp9zYrTw0w9N-E4xv1C5VKuTq2f4874VkCWqFfrDK12KIRoyHaFVeafkgyvodAog91F-GsUynHAkXZI7TgJqzugKXT5ccGQbsvv77kMJ7juHEIH7vysL6yK2_x4tCoi98kADSFUUOQ53twF2UZ7C8E1LSiqYWBtUhdWFF5f68GRftZav4v2uduDCFpSnDZH-fwv1tLMMwkw2jMetodUoOhJX7e19y7ydv_9uNrSSelhmILq-3T_r8g27etAuD4hYByQCxfXQsNWa9UlF5HohNscEGky3Fgf6pGwquHLQUZnM9UTSpbOO-Hhm2gPwEQntTifWNriUbgzMH5JnggIwZgMQdzp5e3r_GP-NYKKaMpfUWqXY76wxk8onZxix5P7I4KQiGNaSi1NBChKjh990ovHjAnAPNDBjZ09SjMmOGnIEh6MASv-V6EGTDGNQz0ynV1CVnaEIOW9DKcTpl-ND6n8YQkn4upwjaWcuM6G3YAwQ6oqUAYWl05BzBTb3lRkMU7hQhu/download [following]
--2015-10-21 06:10:09--  https://dl.boxcloud.com/d/1/IgYC8Y8pQga4l2_cc2jcaRzsN6HZu8Lhl0kjLJe7rrz2ietinecTAL8JMSgvyn7OgibrcdRzY1rGfQuBwe0nawH5Ypxb_G_F-05vyM2V16eMHpoR3ndojfsvb58Mu49UcyTVBIv7rPPHoIOuP-wFKRrFjSSZpg3DwRq-Za3qlA4VGh9X_EO-4gsUsTIOJ0i5p-ewMPABvpkFFDjUC3AZmNY0ZrQ0GVdRiADIoMzVkEoou8OdouMYEDBWZh3qQsQv-qDX-554Z8gvvi7-fNQkkZ7ufVin3C3uihExlcc5rTXuglyZMXTuMBrwurWpch19vqOWkrfl25-UFZYeAreDJGgyN24kXwPhUfiq281lU12TZcCiOJBBEgVXj86lhztkOlzZLJi04WFDXBetyIxwsdotzF_TcXwa-gscmSZZOettdQXuEuZc3zVbvC3dlA5DM_IbVYsc00F62hLsJ8toY-f_T1LTKAX-4lVDuGliakqu9oGl8DLA0y7NT2TGP2G-OyNnmW6l_iQ_giXH-GwJW1cp_8ZxJ8lVErUCONRM6CDcNe3mS8xwh7KFtIocgMRtudHQMK6qCPe9Z2_SMYOqOG1nP7vaN53L5CYz6xRL9RoCEWx_BMnbZ5Qe2xV7Ct1p1Zb6IgbykLVD3lXUUD5-oFKMLTXZ9l2-BslVkm-D_kgqmEb1yB7C3MAh3uDp9zYrTw0w9N-E4xv1C5VKuTq2f4874VkCWqFfrDK12KIRoyHaFVeafkgyvodAog91F-GsUynHAkXZI7TgJqzugKXT5ccGQbsvv77kMJ7juHEIH7vysL6yK2_x4tCoi98kADSFUUOQ53twF2UZ7C8E1LSiqYWBtUhdWFF5f68GRftZav4v2uduDCFpSnDZH-fwv1tLMMwkw2jMetodUoOhJX7e19y7ydv_9uNrSSelhmILq-3T_r8g27etAuD4hYByQCxfXQsNWa9UlF5HohNscEGky3Fgf6pGwquHLQUZnM9UTSpbOO-Hhm2gPwEQntTifWNriUbgzMH5JnggIwZgMQdzp5e3r_GP-NYKKaMpfUWqXY76wxk8onZxix5P7I4KQiGNaSi1NBChKjh990ovHjAnAPNDBjZ09SjMmOGnIEh6MASv-V6EGTDGNQz0ynV1CVnaEIOW9DKcTpl-ND6n8YQkn4upwjaWcuM6G3YAwQ6oqUAYWl05BzBTb3lRkMU7hQhu/download
Resolving dl.boxcloud.com (dl.boxcloud.com)... 74.112.185.96, 74.112.184.96
Connecting to dl.boxcloud.com (dl.boxcloud.com)|74.112.185.96|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 1895828 (1.8M) [application/octet-stream]
Saving to: ‘zip3.json’

 0% [                                       ] 0           --.-K/s               4% [>                                      ] 77,465       287KB/s             11% [===>                                   ] 224,921      441KB/s             23% [========>                              ] 454,297      613KB/s             47% [=================>                     ] 896,665      947KB/s             84% [===============================>       ] 1,601,177   1.32MB/s             100%[======================================>] 1,895,828   1.48MB/s   in 1.2s   

2015-10-21 06:10:11 (1.48 MB/s) - ‘zip3.json’ saved [1895828/1895828]

[I 06:11:25.852 NotebookApp] Saving file at /RedRock_HM_v3.ipynb
Map: Tweet locations
[W 06:11:33.185 NotebookApp] Deprecated files/ URL: files/map.html
[I 06:11:33.186 NotebookApp] 302 GET /notebooks/files/map.html (172.17.0.29) 1.75ms
[I 06:13:33.654 NotebookApp] Saving file at /RedRock_HM_v3.ipynb
[I 06:17:33.675 NotebookApp] Saving file at /RedRock_HM_v3.ipynb
Map: Tweet locations
[W 06:17:42.511 NotebookApp] Deprecated files/ URL: files/map.html
[I 06:17:42.512 NotebookApp] 302 GET /notebooks/files/map.html (172.17.0.29) 1.47ms
[I 06:18:12.108 NotebookApp] Saving file at /RedRock_HM_v3.ipynb
[W 06:18:15.690 NotebookApp] Notebook Untitled0.ipynb is not trusted
[I 06:18:15.770 NotebookApp] Request start_kernel: kernel_id=None, kernel_name=python2, path="", **kwargs={}
[I 06:18:15.770 NotebookApp] Provisioning local kernel: python2
[I 06:18:15.818 NotebookApp] Kernel started: 67458258-930e-4921-94f9-f58353462d87
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/21 06:18:18 INFO SparkContext: Running Spark version 1.4.1
15/10/21 06:18:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/21 06:18:19 INFO SecurityManager: Changing view acls to: notebook
15/10/21 06:18:19 INFO SecurityManager: Changing modify acls to: notebook
15/10/21 06:18:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
15/10/21 06:18:20 INFO Slf4jLogger: Slf4jLogger started
15/10/21 06:18:20 INFO Remoting: Starting remoting
15/10/21 06:18:20 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.22:34767]
15/10/21 06:18:20 INFO Utils: Successfully started service 'sparkDriver' on port 34767.
15/10/21 06:18:20 INFO SparkEnv: Registering MapOutputTracker
15/10/21 06:18:20 INFO SparkEnv: Registering BlockManagerMaster
15/10/21 06:18:20 INFO DiskBlockManager: Created local directory at /tmp/spark-2673eda4-a8e0-485b-a32e-b50c3f74e350/blockmgr-5abb109b-5c36-4d13-ac93-7ad13e807555
15/10/21 06:18:20 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/10/21 06:18:20 INFO HttpFileServer: HTTP File server directory is /tmp/spark-2673eda4-a8e0-485b-a32e-b50c3f74e350/httpd-81687cf4-f5a6-4a97-8e52-a6096ad60235
15/10/21 06:18:20 INFO HttpServer: Starting HTTP Server
15/10/21 06:18:20 INFO Utils: Successfully started service 'HTTP file server' on port 47914.
15/10/21 06:18:20 INFO SparkEnv: Registering OutputCommitCoordinator
15/10/21 06:18:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/10/21 06:18:21 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
15/10/21 06:18:21 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
15/10/21 06:18:21 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
15/10/21 06:18:21 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
15/10/21 06:18:21 INFO Utils: Successfully started service 'SparkUI' on port 4045.
15/10/21 06:18:21 INFO SparkUI: Started SparkUI at http://172.17.0.22:4045
15/10/21 06:18:21 INFO Executor: Starting executor ID driver on host localhost
15/10/21 06:18:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58989.
15/10/21 06:18:21 INFO NettyBlockTransferService: Server created on 58989
15/10/21 06:18:21 INFO BlockManagerMaster: Trying to register BlockManager
15/10/21 06:18:21 INFO BlockManagerMasterEndpoint: Registering block manager localhost:58989 with 265.4 MB RAM, BlockManagerId(driver, localhost, 58989)
15/10/21 06:18:21 INFO BlockManagerMaster: Registered BlockManager
Map: Tweet locations
<IPython.core.display.HTML object>
Map: Tweet locations
[W 06:19:35.458 NotebookApp] Deprecated files/ URL: files/map.html
[I 06:19:35.459 NotebookApp] 302 GET /notebooks/files/map.html (172.17.0.29) 1.81ms
[I 06:20:15.912 NotebookApp] Saving file at /RedRock Update.ipynb
[I 06:22:16.115 NotebookApp] Saving file at /RedRock Update.ipynb
Map: Tweet locations
[W 06:26:36.433 NotebookApp] Deprecated files/ URL: files/map.html
[I 06:26:36.434 NotebookApp] 302 GET /notebooks/files/map.html (172.17.0.29) 1.53ms
[I 06:28:15.938 NotebookApp] Saving file at /RedRock Update.ipynb
[W 06:44:06.278 NotebookApp] Notebook presentation.ipynb is not trusted
[W 06:44:06.940 NotebookApp] zmq message arrived on closed channel
[W 06:44:06.940 NotebookApp] zmq message arrived on closed channel
[W 06:44:06.941 NotebookApp] zmq message arrived on closed channel
[W 06:44:06.941 NotebookApp] zmq message arrived on closed channel
[W 06:44:06.941 NotebookApp] zmq message arrived on closed channel
[W 06:44:06.942 NotebookApp] zmq message arrived on closed channel
[W 06:44:06.942 NotebookApp] zmq message arrived on closed channel
[W 06:44:06.943 NotebookApp] zmq message arrived on closed channel
[W 06:44:06.943 NotebookApp] zmq message arrived on closed channel
[W 06:44:06.943 NotebookApp] zmq message arrived on closed channel
[W 06:44:06.943 NotebookApp] zmq message arrived on closed channel
[W 06:44:06.944 NotebookApp] zmq message arrived on closed channel
[W 06:44:06.944 NotebookApp] zmq message arrived on closed channel
[W 06:44:06.944 NotebookApp] zmq message arrived on closed channel
[W 06:44:06.945 NotebookApp] zmq message arrived on closed channel
[W 06:44:06.945 NotebookApp] zmq message arrived on closed channel
[W 06:44:06.946 NotebookApp] zmq message arrived on closed channel
[W 06:44:06.946 NotebookApp] zmq message arrived on closed channel
[I 06:44:15.922 NotebookApp] Saving file at /RedRock Update.ipynb
[I 06:44:27.078 NotebookApp] Request shutdown_kernel: 12cbbe53-badb-4eee-88e0-08f04221d2be, <IPython.kernel.ioloop.manager.IOLoopKernelManager object at 0x7fd632bb8c10>
15/10/21 06:44:27 INFO SparkUI: Stopped Spark web UI at http://172.17.0.22:4041
15/10/21 06:44:27 INFO DAGScheduler: Stopping DAGScheduler
15/10/21 06:44:27 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/10/21 06:44:27 INFO Utils: path = /tmp/spark-fc035223-3b43-43d1-8d7d-a22dda6b0d46/blockmgr-aad4e583-6a6c-479a-b021-a7e0390ea261, already present as root for deletion.
15/10/21 06:44:27 INFO MemoryStore: MemoryStore cleared
15/10/21 06:44:27 INFO BlockManager: BlockManager stopped
15/10/21 06:44:27 INFO BlockManagerMaster: BlockManagerMaster stopped
15/10/21 06:44:27 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/10/21 06:44:27 INFO SparkContext: Successfully stopped SparkContext
15/10/21 06:44:27 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/10/21 06:44:27 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/10/21 06:44:27 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
15/10/21 06:44:27 INFO Utils: Shutdown hook called
15/10/21 06:44:27 INFO Utils: Deleting directory /tmp/spark-fc035223-3b43-43d1-8d7d-a22dda6b0d46
[I 06:44:27.681 NotebookApp] Kernel shutdown: 12cbbe53-badb-4eee-88e0-08f04221d2be
[W 06:44:27.685 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.685 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.685 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.685 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.686 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.686 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.686 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.686 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.686 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.687 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.687 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.687 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.687 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.688 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.688 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.688 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.688 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.688 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.689 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.689 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.689 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.689 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.689 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.690 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.690 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.690 NotebookApp] zmq message arrived on closed channel
[W 06:44:27.690 NotebookApp] zmq message arrived on closed channel
[I 06:44:41.422 NotebookApp] Request shutdown_kernel: 00a2534c-99f1-478e-a86d-8dae5c34900f, <IPython.kernel.ioloop.manager.IOLoopKernelManager object at 0x7fd631831b10>
15/10/21 06:44:41 INFO SparkUI: Stopped Spark web UI at http://172.17.0.22:4044
15/10/21 06:44:41 INFO DAGScheduler: Stopping DAGScheduler
15/10/21 06:44:41 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/10/21 06:44:41 INFO Utils: path = /tmp/spark-228429ff-23c9-4471-88ae-9c5c26535d7a/blockmgr-ed90f7d7-7049-471a-8560-950825742016, already present as root for deletion.
15/10/21 06:44:41 INFO MemoryStore: MemoryStore cleared
15/10/21 06:44:41 INFO BlockManager: BlockManager stopped
15/10/21 06:44:41 INFO BlockManagerMaster: BlockManagerMaster stopped
15/10/21 06:44:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/10/21 06:44:41 INFO SparkContext: Successfully stopped SparkContext
15/10/21 06:44:41 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/10/21 06:44:41 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/10/21 06:44:41 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
[I 06:44:42.442 NotebookApp] Kernel shutdown: 00a2534c-99f1-478e-a86d-8dae5c34900f
15/10/21 06:44:42 INFO Utils: Shutdown hook called
15/10/21 06:44:42 INFO Utils: Deleting directory /tmp/spark-228429ff-23c9-4471-88ae-9c5c26535d7a
[I 06:45:58.919 NotebookApp] Request start_kernel: kernel_id=None, kernel_name=python2, path="", **kwargs={}
[I 06:45:58.920 NotebookApp] Provisioning local kernel: python2
[I 06:45:58.969 NotebookApp] Kernel started: 18a89cff-0214-4ef7-94d1-a3a69acdfe11
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/21 06:46:01 INFO SparkContext: Running Spark version 1.4.1
15/10/21 06:46:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/21 06:46:02 INFO SecurityManager: Changing view acls to: notebook
15/10/21 06:46:02 INFO SecurityManager: Changing modify acls to: notebook
15/10/21 06:46:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
15/10/21 06:46:03 INFO Slf4jLogger: Slf4jLogger started
15/10/21 06:46:03 INFO Remoting: Starting remoting
15/10/21 06:46:03 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.22:44681]
15/10/21 06:46:03 INFO Utils: Successfully started service 'sparkDriver' on port 44681.
15/10/21 06:46:03 INFO SparkEnv: Registering MapOutputTracker
15/10/21 06:46:03 INFO SparkEnv: Registering BlockManagerMaster
15/10/21 06:46:03 INFO DiskBlockManager: Created local directory at /tmp/spark-03b183d8-7092-4253-9183-5738cd14ccf5/blockmgr-719b62d4-5020-486a-bf06-ff030c696f62
15/10/21 06:46:03 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/10/21 06:46:04 INFO HttpFileServer: HTTP File server directory is /tmp/spark-03b183d8-7092-4253-9183-5738cd14ccf5/httpd-ca2b9527-9689-44df-90b9-94eb76bf22c8
15/10/21 06:46:04 INFO HttpServer: Starting HTTP Server
15/10/21 06:46:04 INFO Utils: Successfully started service 'HTTP file server' on port 58880.
15/10/21 06:46:04 INFO SparkEnv: Registering OutputCommitCoordinator
15/10/21 06:46:04 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/10/21 06:46:04 INFO Utils: Successfully started service 'SparkUI' on port 4041.
15/10/21 06:46:04 INFO SparkUI: Started SparkUI at http://172.17.0.22:4041
15/10/21 06:46:04 INFO Executor: Starting executor ID driver on host localhost
15/10/21 06:46:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33807.
15/10/21 06:46:04 INFO NettyBlockTransferService: Server created on 33807
15/10/21 06:46:04 INFO BlockManagerMaster: Trying to register BlockManager
15/10/21 06:46:04 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33807 with 265.4 MB RAM, BlockManagerId(driver, localhost, 33807)
15/10/21 06:46:04 INFO BlockManagerMaster: Registered BlockManager
[I 06:46:05.846 NotebookApp] Request shutdown_kernel: 18a89cff-0214-4ef7-94d1-a3a69acdfe11, <IPython.kernel.ioloop.manager.IOLoopKernelManager object at 0x7fd63184d610>
15/10/21 06:46:06 INFO SparkUI: Stopped Spark web UI at http://172.17.0.22:4041
15/10/21 06:46:06 INFO DAGScheduler: Stopping DAGScheduler
15/10/21 06:46:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/10/21 06:46:06 INFO Utils: path = /tmp/spark-03b183d8-7092-4253-9183-5738cd14ccf5/blockmgr-719b62d4-5020-486a-bf06-ff030c696f62, already present as root for deletion.
15/10/21 06:46:06 INFO MemoryStore: MemoryStore cleared
15/10/21 06:46:06 INFO BlockManager: BlockManager stopped
15/10/21 06:46:06 INFO BlockManagerMaster: BlockManagerMaster stopped
15/10/21 06:46:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/10/21 06:46:06 INFO SparkContext: Successfully stopped SparkContext
15/10/21 06:46:06 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/10/21 06:46:06 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/10/21 06:46:06 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
15/10/21 06:46:06 INFO Utils: Shutdown hook called
15/10/21 06:46:06 INFO Utils: Deleting directory /tmp/spark-03b183d8-7092-4253-9183-5738cd14ccf5
[I 06:46:06.649 NotebookApp] Kernel shutdown: 18a89cff-0214-4ef7-94d1-a3a69acdfe11
[I 06:46:15.464 NotebookApp] Request start_kernel: kernel_id=None, kernel_name=python2, path="", **kwargs={}
[I 06:46:15.464 NotebookApp] Provisioning local kernel: python2
[I 06:46:15.510 NotebookApp] Kernel started: c7f66d04-76bc-4f9a-a9f8-a47936dc6ef0
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
[I 06:46:18.059 NotebookApp] Request shutdown_kernel: 67458258-930e-4921-94f9-f58353462d87, <IPython.kernel.ioloop.manager.IOLoopKernelManager object at 0x7fd63184d690>
15/10/21 06:46:18 INFO SparkUI: Stopped Spark web UI at http://172.17.0.22:4045
15/10/21 06:46:18 INFO DAGScheduler: Stopping DAGScheduler
15/10/21 06:46:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/10/21 06:46:18 INFO Utils: path = /tmp/spark-2673eda4-a8e0-485b-a32e-b50c3f74e350/blockmgr-5abb109b-5c36-4d13-ac93-7ad13e807555, already present as root for deletion.
15/10/21 06:46:18 INFO MemoryStore: MemoryStore cleared
15/10/21 06:46:18 INFO BlockManager: BlockManager stopped
15/10/21 06:46:18 INFO BlockManagerMaster: BlockManagerMaster stopped
15/10/21 06:46:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/10/21 06:46:18 INFO SparkContext: Successfully stopped SparkContext
15/10/21 06:46:18 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/10/21 06:46:18 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/10/21 06:46:18 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/21 06:46:18 INFO SparkContext: Running Spark version 1.4.1
15/10/21 06:46:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[I 06:46:19.078 NotebookApp] Kernel shutdown: 67458258-930e-4921-94f9-f58353462d87
15/10/21 06:46:19 INFO Utils: Shutdown hook called
15/10/21 06:46:19 INFO Utils: Deleting directory /tmp/spark-2673eda4-a8e0-485b-a32e-b50c3f74e350
15/10/21 06:46:19 INFO SecurityManager: Changing view acls to: notebook
15/10/21 06:46:19 INFO SecurityManager: Changing modify acls to: notebook
15/10/21 06:46:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
15/10/21 06:46:20 INFO Slf4jLogger: Slf4jLogger started
15/10/21 06:46:20 INFO Remoting: Starting remoting
15/10/21 06:46:20 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.22:34749]
15/10/21 06:46:20 INFO Utils: Successfully started service 'sparkDriver' on port 34749.
15/10/21 06:46:20 INFO SparkEnv: Registering MapOutputTracker
15/10/21 06:46:20 INFO SparkEnv: Registering BlockManagerMaster
15/10/21 06:46:20 INFO DiskBlockManager: Created local directory at /tmp/spark-0f142b40-8af5-41a7-b3fc-b03c2392bf8f/blockmgr-fb8c79d9-cb49-4e14-9eae-02211819594f
15/10/21 06:46:20 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/10/21 06:46:20 INFO HttpFileServer: HTTP File server directory is /tmp/spark-0f142b40-8af5-41a7-b3fc-b03c2392bf8f/httpd-72d3e35d-a6b4-427b-b7cd-7f40b45041ae
15/10/21 06:46:20 INFO HttpServer: Starting HTTP Server
15/10/21 06:46:20 INFO Utils: Successfully started service 'HTTP file server' on port 56995.
15/10/21 06:46:20 INFO SparkEnv: Registering OutputCommitCoordinator
15/10/21 06:46:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/10/21 06:46:20 INFO Utils: Successfully started service 'SparkUI' on port 4041.
15/10/21 06:46:20 INFO SparkUI: Started SparkUI at http://172.17.0.22:4041
15/10/21 06:46:21 INFO Executor: Starting executor ID driver on host localhost
15/10/21 06:46:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43363.
15/10/21 06:46:21 INFO NettyBlockTransferService: Server created on 43363
15/10/21 06:46:21 INFO BlockManagerMaster: Trying to register BlockManager
15/10/21 06:46:21 INFO BlockManagerMasterEndpoint: Registering block manager localhost:43363 with 265.4 MB RAM, BlockManagerId(driver, localhost, 43363)
15/10/21 06:46:21 INFO BlockManagerMaster: Registered BlockManager
15/10/21 06:48:09 INFO SparkContext: Starting job: reduce at <ipython-input-1-be560de4c7e1>:14
15/10/21 06:48:09 INFO DAGScheduler: Got job 0 (reduce at <ipython-input-1-be560de4c7e1>:14) with 2 output partitions (allowLocal=false)
15/10/21 06:48:09 INFO DAGScheduler: Final stage: ResultStage 0(reduce at <ipython-input-1-be560de4c7e1>:14)
15/10/21 06:48:09 INFO DAGScheduler: Parents of final stage: List()
15/10/21 06:48:09 INFO DAGScheduler: Missing parents: List()
15/10/21 06:48:09 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[1] at reduce at <ipython-input-1-be560de4c7e1>:14), which has no missing parents
15/10/21 06:48:09 INFO MemoryStore: ensureFreeSpace(4392) called with curMem=0, maxMem=278302556
15/10/21 06:48:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 4.3 KB, free 265.4 MB)
15/10/21 06:48:09 INFO MemoryStore: ensureFreeSpace(2771) called with curMem=4392, maxMem=278302556
15/10/21 06:48:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.7 KB, free 265.4 MB)
15/10/21 06:48:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:43363 (size: 2.7 KB, free: 265.4 MB)
15/10/21 06:48:09 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:874
15/10/21 06:48:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[1] at reduce at <ipython-input-1-be560de4c7e1>:14)
15/10/21 06:48:09 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/10/21 06:48:09 WARN TaskSetManager: Stage 0 contains a task of very large size (364 KB). The maximum recommended task size is 100 KB.
15/10/21 06:48:09 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 373750 bytes)
15/10/21 06:48:09 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 501553 bytes)
15/10/21 06:48:09 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/10/21 06:48:09 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/10/21 06:48:13 INFO PythonRDD: Times: total = 3709, boot = 3612, init = 10, finish = 87
15/10/21 06:48:13 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 701 bytes result sent to driver
15/10/21 06:48:13 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 3771 ms on localhost (1/2)
15/10/21 06:48:13 INFO PythonRDD: Times: total = 3757, boot = 3666, init = 3, finish = 88
15/10/21 06:48:13 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 701 bytes result sent to driver
15/10/21 06:48:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3838 ms on localhost (2/2)
15/10/21 06:48:13 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/10/21 06:48:13 INFO DAGScheduler: ResultStage 0 (reduce at <ipython-input-1-be560de4c7e1>:14) finished in 3.853 s
15/10/21 06:48:13 INFO DAGScheduler: Job 0 finished: reduce at <ipython-input-1-be560de4c7e1>:14, took 4.073024 s
[I 06:48:15.554 NotebookApp] Saving file at /Spark Code.ipynb
[I 06:49:54.058 NotebookApp] Request start_kernel: kernel_id=None, kernel_name=python2, path="", **kwargs={}
[I 06:49:54.058 NotebookApp] Provisioning local kernel: python2
[I 06:49:54.103 NotebookApp] Kernel started: d4389eab-b783-4abf-8ae5-ce3bebb2fbd5
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/21 06:49:57 INFO SparkContext: Running Spark version 1.4.1
[I 06:49:57.147 NotebookApp] Request shutdown_kernel: d4389eab-b783-4abf-8ae5-ce3bebb2fbd5, <IPython.kernel.ioloop.manager.IOLoopKernelManager object at 0x7fd63170c150>
15/10/21 06:49:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/21 06:49:57 INFO SecurityManager: Changing view acls to: notebook
15/10/21 06:49:57 INFO SecurityManager: Changing modify acls to: notebook
15/10/21 06:49:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
[I 06:49:58.159 NotebookApp] Kernel shutdown: d4389eab-b783-4abf-8ae5-ce3bebb2fbd5
15/10/21 06:49:58 INFO Utils: Shutdown hook called
[W 06:50:04.173 NotebookApp] Timeout waiting for kernel_info reply from d4389eab-b783-4abf-8ae5-ce3bebb2fbd5
[E 06:50:04.174 NotebookApp] Error opening stream: HTTP 404: Not Found (Kernel does not exist: d4389eab-b783-4abf-8ae5-ce3bebb2fbd5)
[I 06:50:19.858 NotebookApp] Saving file at /Spark Code.ipynb
15/10/21 06:51:28 INFO SparkContext: Starting job: reduce at <ipython-input-2-be560de4c7e1>:14
15/10/21 06:51:28 INFO DAGScheduler: Got job 1 (reduce at <ipython-input-2-be560de4c7e1>:14) with 2 output partitions (allowLocal=false)
15/10/21 06:51:28 INFO DAGScheduler: Final stage: ResultStage 1(reduce at <ipython-input-2-be560de4c7e1>:14)
15/10/21 06:51:28 INFO DAGScheduler: Parents of final stage: List()
15/10/21 06:51:28 INFO DAGScheduler: Missing parents: List()
15/10/21 06:51:28 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[3] at reduce at <ipython-input-2-be560de4c7e1>:14), which has no missing parents
15/10/21 06:51:28 INFO MemoryStore: ensureFreeSpace(4392) called with curMem=7163, maxMem=278302556
15/10/21 06:51:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.3 KB, free 265.4 MB)
15/10/21 06:51:28 INFO MemoryStore: ensureFreeSpace(2774) called with curMem=11555, maxMem=278302556
15/10/21 06:51:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.7 KB, free 265.4 MB)
15/10/21 06:51:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:43363 (size: 2.7 KB, free: 265.4 MB)
15/10/21 06:51:28 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:874
15/10/21 06:51:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[3] at reduce at <ipython-input-2-be560de4c7e1>:14)
15/10/21 06:51:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/10/21 06:51:28 WARN TaskSetManager: Stage 1 contains a task of very large size (364 KB). The maximum recommended task size is 100 KB.
15/10/21 06:51:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 373750 bytes)
15/10/21 06:51:28 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 501553 bytes)
15/10/21 06:51:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/10/21 06:51:28 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/10/21 06:51:28 INFO PythonRDD: Times: total = 149, boot = 59, init = 3, finish = 87
15/10/21 06:51:28 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 701 bytes result sent to driver
15/10/21 06:51:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 170 ms on localhost (1/2)
15/10/21 06:51:28 INFO PythonRDD: Times: total = 202, boot = 113, init = 2, finish = 87
15/10/21 06:51:28 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 701 bytes result sent to driver
15/10/21 06:51:28 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 266 ms on localhost (2/2)
15/10/21 06:51:28 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/10/21 06:51:28 INFO DAGScheduler: ResultStage 1 (reduce at <ipython-input-2-be560de4c7e1>:14) finished in 0.272 s
15/10/21 06:51:28 INFO DAGScheduler: Job 1 finished: reduce at <ipython-input-2-be560de4c7e1>:14, took 0.288274 s
15/10/21 06:51:28 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:43363 in memory (size: 2.7 KB, free: 265.4 MB)
[I 06:51:39.348 NotebookApp] Request start_kernel: kernel_id=None, kernel_name=python2, path="", **kwargs={}
[I 06:51:39.349 NotebookApp] Provisioning local kernel: python2
[I 06:51:39.394 NotebookApp] Kernel started: c3da83e4-da41-46b6-931e-b02641be0d98
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/21 06:51:42 INFO SparkContext: Running Spark version 1.4.1
15/10/21 06:51:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/21 06:51:43 INFO SecurityManager: Changing view acls to: notebook
15/10/21 06:51:43 INFO SecurityManager: Changing modify acls to: notebook
15/10/21 06:51:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
15/10/21 06:51:43 INFO Slf4jLogger: Slf4jLogger started
15/10/21 06:51:43 INFO Remoting: Starting remoting
15/10/21 06:51:44 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.22:58291]
15/10/21 06:51:44 INFO Utils: Successfully started service 'sparkDriver' on port 58291.
15/10/21 06:51:44 INFO SparkEnv: Registering MapOutputTracker
15/10/21 06:51:44 INFO SparkEnv: Registering BlockManagerMaster
15/10/21 06:51:44 INFO DiskBlockManager: Created local directory at /tmp/spark-087dfd65-e3af-498d-9d22-e35dd3d35ef5/blockmgr-22d08b29-3ede-43e5-b659-7938c320c115
15/10/21 06:51:44 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/10/21 06:51:44 INFO HttpFileServer: HTTP File server directory is /tmp/spark-087dfd65-e3af-498d-9d22-e35dd3d35ef5/httpd-c3af5d8f-93b1-4ea1-b4cd-d939821a87ee
15/10/21 06:51:44 INFO HttpServer: Starting HTTP Server
15/10/21 06:51:44 INFO Utils: Successfully started service 'HTTP file server' on port 33877.
15/10/21 06:51:44 INFO SparkEnv: Registering OutputCommitCoordinator
15/10/21 06:51:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/10/21 06:51:44 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
15/10/21 06:51:44 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
15/10/21 06:51:44 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
15/10/21 06:51:44 INFO Utils: Successfully started service 'SparkUI' on port 4044.
15/10/21 06:51:44 INFO SparkUI: Started SparkUI at http://172.17.0.22:4044
15/10/21 06:51:44 INFO Executor: Starting executor ID driver on host localhost
15/10/21 06:51:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60134.
15/10/21 06:51:45 INFO NettyBlockTransferService: Server created on 60134
15/10/21 06:51:45 INFO BlockManagerMaster: Trying to register BlockManager
15/10/21 06:51:45 INFO BlockManagerMasterEndpoint: Registering block manager localhost:60134 with 265.4 MB RAM, BlockManagerId(driver, localhost, 60134)
15/10/21 06:51:45 INFO BlockManagerMaster: Registered BlockManager
Map: Tweet locations
[W 06:51:54.197 NotebookApp] Deprecated files/ URL: files/map.html
[I 06:51:54.197 NotebookApp] 302 GET /notebooks/files/map.html (172.17.0.29) 1.69ms
[I 06:52:34.904 NotebookApp] Saving file at /Spark Code.ipynb
[I 06:53:10.736 NotebookApp] Request start_kernel: kernel_id=None, kernel_name=python2, path="", **kwargs={}
[I 06:53:10.737 NotebookApp] Provisioning local kernel: python2
[I 06:53:10.782 NotebookApp] Kernel started: 30fd377f-e20d-4e26-8333-7a1c861e3e3f
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/21 06:53:13 INFO SparkContext: Running Spark version 1.4.1
15/10/21 06:53:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/21 06:53:14 INFO SecurityManager: Changing view acls to: notebook
15/10/21 06:53:14 INFO SecurityManager: Changing modify acls to: notebook
15/10/21 06:53:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
15/10/21 06:53:15 INFO Slf4jLogger: Slf4jLogger started
15/10/21 06:53:15 INFO Remoting: Starting remoting
15/10/21 06:53:15 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.22:52949]
15/10/21 06:53:15 INFO Utils: Successfully started service 'sparkDriver' on port 52949.
15/10/21 06:53:15 INFO SparkEnv: Registering MapOutputTracker
15/10/21 06:53:15 INFO SparkEnv: Registering BlockManagerMaster
15/10/21 06:53:15 INFO DiskBlockManager: Created local directory at /tmp/spark-a0d30f27-58f2-4803-b7ce-2f437dce18c1/blockmgr-33399bc4-6281-42c6-b023-b7bcd4a56bc2
15/10/21 06:53:15 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/10/21 06:53:15 INFO HttpFileServer: HTTP File server directory is /tmp/spark-a0d30f27-58f2-4803-b7ce-2f437dce18c1/httpd-0637bf42-85e3-45a9-a395-9fadcb6744a4
15/10/21 06:53:15 INFO HttpServer: Starting HTTP Server
15/10/21 06:53:15 INFO Utils: Successfully started service 'HTTP file server' on port 43389.
15/10/21 06:53:15 INFO SparkEnv: Registering OutputCommitCoordinator
15/10/21 06:53:16 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/10/21 06:53:16 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
15/10/21 06:53:16 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
15/10/21 06:53:16 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
15/10/21 06:53:16 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
15/10/21 06:53:16 INFO Utils: Successfully started service 'SparkUI' on port 4045.
15/10/21 06:53:16 INFO SparkUI: Started SparkUI at http://172.17.0.22:4045
15/10/21 06:53:16 INFO Executor: Starting executor ID driver on host localhost
15/10/21 06:53:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42148.
15/10/21 06:53:16 INFO NettyBlockTransferService: Server created on 42148
15/10/21 06:53:16 INFO BlockManagerMaster: Trying to register BlockManager
15/10/21 06:53:16 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42148 with 265.4 MB RAM, BlockManagerId(driver, localhost, 42148)
15/10/21 06:53:16 INFO BlockManagerMaster: Registered BlockManager
[I 06:53:32.915 NotebookApp] Request start_kernel: kernel_id=None, kernel_name=python2, path="", **kwargs={}
[I 06:53:32.916 NotebookApp] Provisioning local kernel: python2
[I 06:53:32.961 NotebookApp] Kernel started: dd7acff1-b1b3-4bdc-821c-9bb42891498c
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/21 06:53:35 INFO SparkContext: Running Spark version 1.4.1
15/10/21 06:53:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/21 06:53:36 INFO SecurityManager: Changing view acls to: notebook
15/10/21 06:53:36 INFO SecurityManager: Changing modify acls to: notebook
15/10/21 06:53:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
15/10/21 06:53:37 INFO Slf4jLogger: Slf4jLogger started
15/10/21 06:53:37 INFO Remoting: Starting remoting
15/10/21 06:53:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.22:48625]
15/10/21 06:53:37 INFO Utils: Successfully started service 'sparkDriver' on port 48625.
15/10/21 06:53:37 INFO SparkEnv: Registering MapOutputTracker
15/10/21 06:53:37 INFO SparkEnv: Registering BlockManagerMaster
15/10/21 06:53:37 INFO DiskBlockManager: Created local directory at /tmp/spark-b42d68f2-0d81-418e-bccc-425aa078bfd3/blockmgr-822dc396-71cd-4fe2-893d-9f536687422a
15/10/21 06:53:37 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/10/21 06:53:37 INFO HttpFileServer: HTTP File server directory is /tmp/spark-b42d68f2-0d81-418e-bccc-425aa078bfd3/httpd-034f2b34-e002-40b1-9500-9409076170ec
15/10/21 06:53:37 INFO HttpServer: Starting HTTP Server
15/10/21 06:53:38 INFO Utils: Successfully started service 'HTTP file server' on port 55101.
15/10/21 06:53:38 INFO SparkEnv: Registering OutputCommitCoordinator
15/10/21 06:53:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/10/21 06:53:38 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
15/10/21 06:53:38 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
15/10/21 06:53:38 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
15/10/21 06:53:38 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
15/10/21 06:53:38 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
15/10/21 06:53:38 INFO Utils: Successfully started service 'SparkUI' on port 4046.
15/10/21 06:53:38 INFO SparkUI: Started SparkUI at http://172.17.0.22:4046
15/10/21 06:53:38 INFO Executor: Starting executor ID driver on host localhost
15/10/21 06:53:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53086.
15/10/21 06:53:38 INFO NettyBlockTransferService: Server created on 53086
15/10/21 06:53:38 INFO BlockManagerMaster: Trying to register BlockManager
15/10/21 06:53:38 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53086 with 265.4 MB RAM, BlockManagerId(driver, localhost, 53086)
15/10/21 06:53:38 INFO BlockManagerMaster: Registered BlockManager
[I 06:53:41.044 NotebookApp] Saving file at /RedRock Update.ipynb
[I 06:54:50.968 NotebookApp] Request start_kernel: kernel_id=None, kernel_name=python2, path="", **kwargs={}
[I 06:54:50.969 NotebookApp] Provisioning local kernel: python2
[I 06:54:51.014 NotebookApp] Kernel started: cdc7d048-052d-4fbb-b8ff-a143678d3fb7
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/21 06:54:54 INFO SparkContext: Running Spark version 1.4.1
15/10/21 06:54:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/21 06:54:54 INFO SecurityManager: Changing view acls to: notebook
15/10/21 06:54:54 INFO SecurityManager: Changing modify acls to: notebook
15/10/21 06:54:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
15/10/21 06:54:55 INFO Slf4jLogger: Slf4jLogger started
15/10/21 06:54:55 INFO Remoting: Starting remoting
15/10/21 06:54:55 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.22:34793]
15/10/21 06:54:55 INFO Utils: Successfully started service 'sparkDriver' on port 34793.
15/10/21 06:54:55 INFO SparkEnv: Registering MapOutputTracker
15/10/21 06:54:55 INFO SparkEnv: Registering BlockManagerMaster
15/10/21 06:54:55 INFO DiskBlockManager: Created local directory at /tmp/spark-3bf9d32b-7ee3-487a-b956-ad88489183bb/blockmgr-c7cde9d3-876b-4def-8d6b-103aab7c5654
15/10/21 06:54:55 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/10/21 06:54:56 INFO HttpFileServer: HTTP File server directory is /tmp/spark-3bf9d32b-7ee3-487a-b956-ad88489183bb/httpd-7dd197ab-d78a-45df-a99f-0cdd16edd456
15/10/21 06:54:56 INFO HttpServer: Starting HTTP Server
15/10/21 06:54:56 INFO Utils: Successfully started service 'HTTP file server' on port 44342.
15/10/21 06:54:56 INFO SparkEnv: Registering OutputCommitCoordinator
15/10/21 06:54:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/10/21 06:54:56 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
15/10/21 06:54:56 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
15/10/21 06:54:56 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
15/10/21 06:54:56 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
15/10/21 06:54:56 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
15/10/21 06:54:56 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.
15/10/21 06:54:56 INFO Utils: Successfully started service 'SparkUI' on port 4047.
15/10/21 06:54:56 INFO SparkUI: Started SparkUI at http://172.17.0.22:4047
15/10/21 06:54:56 INFO Executor: Starting executor ID driver on host localhost
15/10/21 06:54:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50977.
15/10/21 06:54:57 INFO NettyBlockTransferService: Server created on 50977
15/10/21 06:54:57 INFO BlockManagerMaster: Trying to register BlockManager
15/10/21 06:54:57 INFO BlockManagerMasterEndpoint: Registering block manager localhost:50977 with 265.4 MB RAM, BlockManagerId(driver, localhost, 50977)
15/10/21 06:54:57 INFO BlockManagerMaster: Registered BlockManager
[I 06:54:59.513 NotebookApp] Request shutdown_kernel: cdc7d048-052d-4fbb-b8ff-a143678d3fb7, <IPython.kernel.ioloop.manager.IOLoopKernelManager object at 0x7fd6317cb290>
15/10/21 06:54:59 INFO SparkUI: Stopped Spark web UI at http://172.17.0.22:4047
15/10/21 06:54:59 INFO DAGScheduler: Stopping DAGScheduler
15/10/21 06:54:59 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/10/21 06:54:59 INFO Utils: path = /tmp/spark-3bf9d32b-7ee3-487a-b956-ad88489183bb/blockmgr-c7cde9d3-876b-4def-8d6b-103aab7c5654, already present as root for deletion.
15/10/21 06:54:59 INFO MemoryStore: MemoryStore cleared
15/10/21 06:54:59 INFO BlockManager: BlockManager stopped
15/10/21 06:54:59 INFO BlockManagerMaster: BlockManagerMaster stopped
15/10/21 06:54:59 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/10/21 06:54:59 INFO SparkContext: Successfully stopped SparkContext
15/10/21 06:54:59 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/10/21 06:54:59 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/10/21 06:54:59 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
15/10/21 06:55:00 INFO Utils: Shutdown hook called
15/10/21 06:55:00 INFO Utils: Deleting directory /tmp/spark-3bf9d32b-7ee3-487a-b956-ad88489183bb
[I 06:55:00.524 NotebookApp] Kernel shutdown: cdc7d048-052d-4fbb-b8ff-a143678d3fb7
[I 06:55:05.136 NotebookApp] Saving file at /RedRock New Visualizations.ipynb
[W 06:55:15.252 NotebookApp] Notebook RedRock New Visualizations0.ipynb is not trusted
[I 06:55:15.489 NotebookApp] Request start_kernel: kernel_id=None, kernel_name=python2, path="", **kwargs={}
[I 06:55:15.489 NotebookApp] Provisioning local kernel: python2
[I 06:55:15.537 NotebookApp] Kernel started: 80963995-4989-4617-8e7b-32071eb71849
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/21 06:55:18 INFO SparkContext: Running Spark version 1.4.1
15/10/21 06:55:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/21 06:55:19 INFO SecurityManager: Changing view acls to: notebook
15/10/21 06:55:19 INFO SecurityManager: Changing modify acls to: notebook
15/10/21 06:55:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
15/10/21 06:55:20 INFO Slf4jLogger: Slf4jLogger started
15/10/21 06:55:20 INFO Remoting: Starting remoting
15/10/21 06:55:20 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.22:53265]
15/10/21 06:55:20 INFO Utils: Successfully started service 'sparkDriver' on port 53265.
15/10/21 06:55:20 INFO SparkEnv: Registering MapOutputTracker
15/10/21 06:55:20 INFO SparkEnv: Registering BlockManagerMaster
15/10/21 06:55:20 INFO DiskBlockManager: Created local directory at /tmp/spark-a5859c75-a576-49b2-a2a0-a673e1a2738a/blockmgr-80f6b3de-e725-45a4-8df9-34bf5a8b291e
15/10/21 06:55:20 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/10/21 06:55:20 INFO HttpFileServer: HTTP File server directory is /tmp/spark-a5859c75-a576-49b2-a2a0-a673e1a2738a/httpd-a749eee4-3bc1-429a-94d0-d221f2f3738a
15/10/21 06:55:20 INFO HttpServer: Starting HTTP Server
15/10/21 06:55:20 INFO Utils: Successfully started service 'HTTP file server' on port 50410.
15/10/21 06:55:20 INFO SparkEnv: Registering OutputCommitCoordinator
15/10/21 06:55:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/10/21 06:55:20 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
15/10/21 06:55:21 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
15/10/21 06:55:21 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
15/10/21 06:55:21 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
15/10/21 06:55:21 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
15/10/21 06:55:21 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.
15/10/21 06:55:21 INFO Utils: Successfully started service 'SparkUI' on port 4047.
15/10/21 06:55:21 INFO SparkUI: Started SparkUI at http://172.17.0.22:4047
15/10/21 06:55:21 INFO Executor: Starting executor ID driver on host localhost
15/10/21 06:55:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45478.
15/10/21 06:55:21 INFO NettyBlockTransferService: Server created on 45478
15/10/21 06:55:21 INFO BlockManagerMaster: Trying to register BlockManager
15/10/21 06:55:21 INFO BlockManagerMasterEndpoint: Registering block manager localhost:45478 with 265.4 MB RAM, BlockManagerId(driver, localhost, 45478)
15/10/21 06:55:21 INFO BlockManagerMaster: Registered BlockManager
[I 06:55:22.523 NotebookApp] Request shutdown_kernel: 80963995-4989-4617-8e7b-32071eb71849, <IPython.kernel.ioloop.manager.IOLoopKernelManager object at 0x7fd6317d2dd0>
15/10/21 06:55:22 INFO SparkUI: Stopped Spark web UI at http://172.17.0.22:4047
15/10/21 06:55:22 INFO DAGScheduler: Stopping DAGScheduler
15/10/21 06:55:22 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/10/21 06:55:22 INFO Utils: path = /tmp/spark-a5859c75-a576-49b2-a2a0-a673e1a2738a/blockmgr-80f6b3de-e725-45a4-8df9-34bf5a8b291e, already present as root for deletion.
15/10/21 06:55:22 INFO MemoryStore: MemoryStore cleared
15/10/21 06:55:22 INFO BlockManager: BlockManager stopped
15/10/21 06:55:22 INFO BlockManagerMaster: BlockManagerMaster stopped
15/10/21 06:55:22 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/10/21 06:55:22 INFO SparkContext: Successfully stopped SparkContext
15/10/21 06:55:22 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/10/21 06:55:22 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/10/21 06:55:22 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
[I 06:55:23.536 NotebookApp] Kernel shutdown: 80963995-4989-4617-8e7b-32071eb71849
15/10/21 06:55:23 INFO Utils: Shutdown hook called
15/10/21 06:55:23 INFO Utils: Deleting directory /tmp/spark-a5859c75-a576-49b2-a2a0-a673e1a2738a/pyspark-6db0c8fd-094a-4f08-bd68-dff219e65350
15/10/21 06:55:23 INFO Utils: Deleting directory /tmp/spark-a5859c75-a576-49b2-a2a0-a673e1a2738a
[W 06:55:34.748 NotebookApp] Notebook RedRock New Visualizations.ipynb is not trusted
[I 06:55:35.016 NotebookApp] Request start_kernel: kernel_id=None, kernel_name=python2, path="", **kwargs={}
[I 06:55:35.017 NotebookApp] Provisioning local kernel: python2
[I 06:55:35.065 NotebookApp] Kernel started: 06958e6a-4426-4eee-b258-033a73784328
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/21 06:55:38 INFO SparkContext: Running Spark version 1.4.1
15/10/21 06:55:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/21 06:55:38 INFO SecurityManager: Changing view acls to: notebook
15/10/21 06:55:38 INFO SecurityManager: Changing modify acls to: notebook
15/10/21 06:55:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
[I 06:55:38.794 NotebookApp] Request shutdown_kernel: 06958e6a-4426-4eee-b258-033a73784328, <IPython.kernel.ioloop.manager.IOLoopKernelManager object at 0x7fd6316124d0>
15/10/21 06:55:39 INFO Slf4jLogger: Slf4jLogger started
15/10/21 06:55:39 INFO Remoting: Starting remoting
[I 06:55:39.806 NotebookApp] Kernel shutdown: 06958e6a-4426-4eee-b258-033a73784328
15/10/21 06:55:39 INFO Utils: Shutdown hook called
[W 06:55:45.167 NotebookApp] Timeout waiting for kernel_info reply from 06958e6a-4426-4eee-b258-033a73784328
[E 06:55:45.168 NotebookApp] Error opening stream: HTTP 404: Not Found (Kernel does not exist: 06958e6a-4426-4eee-b258-033a73784328)
Map: Tweet locations
[W 06:57:03.995 NotebookApp] Deprecated files/ URL: files/map.html
[I 06:57:03.995 NotebookApp] 302 GET /notebooks/files/map.html (172.17.0.29) 1.55ms
[I 06:58:03.216 NotebookApp] Saving file at /RedRock Original.ipynb
15/10/21 07:03:54 INFO SparkContext: Starting job: reduce at <ipython-input-3-be560de4c7e1>:14
15/10/21 07:03:54 INFO DAGScheduler: Got job 2 (reduce at <ipython-input-3-be560de4c7e1>:14) with 2 output partitions (allowLocal=false)
15/10/21 07:03:54 INFO DAGScheduler: Final stage: ResultStage 2(reduce at <ipython-input-3-be560de4c7e1>:14)
15/10/21 07:03:54 INFO DAGScheduler: Parents of final stage: List()
15/10/21 07:03:54 INFO DAGScheduler: Missing parents: List()
15/10/21 07:03:54 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[5] at reduce at <ipython-input-3-be560de4c7e1>:14), which has no missing parents
15/10/21 07:03:54 INFO MemoryStore: ensureFreeSpace(4392) called with curMem=7166, maxMem=278302556
15/10/21 07:03:54 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.3 KB, free 265.4 MB)
15/10/21 07:03:54 INFO MemoryStore: ensureFreeSpace(2774) called with curMem=11558, maxMem=278302556
15/10/21 07:03:54 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.7 KB, free 265.4 MB)
15/10/21 07:03:54 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:43363 (size: 2.7 KB, free: 265.4 MB)
15/10/21 07:03:54 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:874
15/10/21 07:03:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[5] at reduce at <ipython-input-3-be560de4c7e1>:14)
15/10/21 07:03:54 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/10/21 07:03:54 WARN TaskSetManager: Stage 2 contains a task of very large size (364 KB). The maximum recommended task size is 100 KB.
15/10/21 07:03:54 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 373750 bytes)
15/10/21 07:03:54 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 501553 bytes)
15/10/21 07:03:54 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/10/21 07:03:54 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/10/21 07:03:55 INFO PythonRDD: Times: total = 154, boot = 61, init = 5, finish = 88
15/10/21 07:03:55 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 701 bytes result sent to driver
15/10/21 07:03:55 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 173 ms on localhost (1/2)
15/10/21 07:03:55 INFO PythonRDD: Times: total = 205, boot = 115, init = 3, finish = 87
15/10/21 07:03:55 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 701 bytes result sent to driver
15/10/21 07:03:55 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 219 ms on localhost (2/2)
15/10/21 07:03:55 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/10/21 07:03:55 INFO DAGScheduler: ResultStage 2 (reduce at <ipython-input-3-be560de4c7e1>:14) finished in 0.224 s
15/10/21 07:03:55 INFO DAGScheduler: Job 2 finished: reduce at <ipython-input-3-be560de4c7e1>:14, took 0.239392 s
[I 07:05:46.248 NotebookApp] Saving file at /Spark Code.ipynb
[W 07:14:51.412 NotebookApp] Notebook RedRock New Visualizations.ipynb is not trusted
[I 07:14:51.650 NotebookApp] Request start_kernel: kernel_id=None, kernel_name=python2, path="", **kwargs={}
[I 07:14:51.650 NotebookApp] Provisioning local kernel: python2
[I 07:14:51.697 NotebookApp] Kernel started: e5b46672-62e4-414d-a53c-36167c8a4c14
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/21 07:14:54 INFO SparkContext: Running Spark version 1.4.1
15/10/21 07:14:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/21 07:14:55 INFO SecurityManager: Changing view acls to: notebook
15/10/21 07:14:55 INFO SecurityManager: Changing modify acls to: notebook
15/10/21 07:14:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
15/10/21 07:14:56 INFO Slf4jLogger: Slf4jLogger started
15/10/21 07:14:56 INFO Remoting: Starting remoting
15/10/21 07:14:56 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.22:45827]
15/10/21 07:14:56 INFO Utils: Successfully started service 'sparkDriver' on port 45827.
15/10/21 07:14:56 INFO SparkEnv: Registering MapOutputTracker
15/10/21 07:14:56 INFO SparkEnv: Registering BlockManagerMaster
15/10/21 07:14:56 INFO DiskBlockManager: Created local directory at /tmp/spark-0f1efbbf-1336-4e53-b9e1-c3a0b791b808/blockmgr-573c0859-eb51-466c-99b6-84c3311f512c
15/10/21 07:14:56 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/10/21 07:14:56 INFO HttpFileServer: HTTP File server directory is /tmp/spark-0f1efbbf-1336-4e53-b9e1-c3a0b791b808/httpd-4a3e389d-7784-4587-95d4-46cd1d001fca
15/10/21 07:14:56 INFO HttpServer: Starting HTTP Server
15/10/21 07:14:56 INFO Utils: Successfully started service 'HTTP file server' on port 50657.
15/10/21 07:14:56 INFO SparkEnv: Registering OutputCommitCoordinator
15/10/21 07:14:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/10/21 07:14:57 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
15/10/21 07:14:57 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
15/10/21 07:14:57 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
15/10/21 07:14:57 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
15/10/21 07:14:57 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
15/10/21 07:14:57 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.
15/10/21 07:14:57 INFO Utils: Successfully started service 'SparkUI' on port 4047.
15/10/21 07:14:57 INFO SparkUI: Started SparkUI at http://172.17.0.22:4047
15/10/21 07:14:57 INFO Executor: Starting executor ID driver on host localhost
15/10/21 07:14:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53959.
15/10/21 07:14:57 INFO NettyBlockTransferService: Server created on 53959
15/10/21 07:14:57 INFO BlockManagerMaster: Trying to register BlockManager
15/10/21 07:14:57 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53959 with 265.4 MB RAM, BlockManagerId(driver, localhost, 53959)
15/10/21 07:14:57 INFO BlockManagerMaster: Registered BlockManager
Map: Tweet locations
[W 07:15:13.320 NotebookApp] Deprecated files/ URL: files/map.html
[I 07:15:13.321 NotebookApp] 302 GET /notebooks/files/map.html (172.17.0.29) 1.81ms
[I 07:17:07.557 NotebookApp] Saving file at /RedRock Original.ipynb
Map: Tweet locations
[W 07:17:30.806 NotebookApp] Deprecated files/ URL: files/map.html
[I 07:17:30.807 NotebookApp] 302 GET /notebooks/files/map.html (172.17.0.29) 1.51ms
Map: Tweet locations
[W 07:18:17.701 NotebookApp] Deprecated files/ URL: files/map.html
[I 07:18:17.702 NotebookApp] 302 GET /notebooks/files/map.html (172.17.0.29) 1.64ms
Map: Tweet locations
[W 07:18:54.991 NotebookApp] Deprecated files/ URL: files/map.html
[I 07:18:54.991 NotebookApp] 302 GET /notebooks/files/map.html (172.17.0.29) 1.49ms
[I 07:19:07.464 NotebookApp] Saving file at /RedRock Original.ipynb
[I 07:21:15.304 NotebookApp] Saving file at /RedRock Original.ipynb
[W 07:56:23.029 NotebookApp] Notebook Untitled0.ipynb is not trusted
[I 07:56:23.149 NotebookApp] Request start_kernel: kernel_id=None, kernel_name=spark, path="", **kwargs={}
[I 07:56:23.151 NotebookApp] Provisioning local kernel: spark
[I 07:56:23.203 NotebookApp] Kernel started: e85064b7-a07a-452b-8f29-ac7f2b8cb557
15/10/21 07:56:24 [INFO] c.i.s.SparkKernel$$anon$1 - Kernel version: 0.1.2-SNAPSHOT
15/10/21 07:56:24 [INFO] c.i.s.SparkKernel$$anon$1 - Scala version: 2.10.4
15/10/21 07:56:24 [INFO] c.i.s.SparkKernel$$anon$1 - ZeroMQ (JeroMQ) version: 3.2.2
15/10/21 07:56:24 [INFO] c.i.s.SparkKernel$$anon$1 - Initializing internal actor system
15/10/21 07:56:25 [INFO] c.i.s.SparkKernel$$anon$1 - Connection Profile: {
  "stdin_port" : 55814,
  "control_port" : 40818,
  "hb_port" : 48665,
  "shell_port" : 56781,
  "iopub_port" : 43101,
  "ip" : "127.0.0.1",
  "transport" : "tcp",
  "signature_scheme" : "hmac-sha256",
  "key" : "7167b175-9bd6-458c-bd35-838b82a02104"
}
15/10/21 07:56:25 [INFO] c.i.s.SparkKernel$$anon$1 - Constructing interpreter with 4 threads and with arguments: 
15/10/21 07:56:25 [INFO] c.i.s.k.p.v.r.KernelMessageRelay - Not ready for messages! Stashing until ready!
15/10/21 07:56:25 [WARN] o.a.h.u.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/21 07:56:26 [INFO] o.s.j.s.Server - jetty-8.y.z-SNAPSHOT
15/10/21 07:56:26 [INFO] o.s.j.s.AbstractConnector - Started SocketConnector@0.0.0.0:45021
15/10/21 07:56:30 [INFO] c.i.s.SparkKernel$$anon$1 - Using local[*] as Spark Master
15/10/21 07:56:30 [INFO] c.i.s.SparkKernel$$anon$1 - Using IBM Spark Kernel as Spark application name
15/10/21 07:56:30 [WARN] c.i.s.SparkKernel$$anon$1 - Locked to Scala interpreter with SparkIMain until decoupled!
15/10/21 07:56:30 [WARN] c.i.s.SparkKernel$$anon$1 - Unable to control initialization of REPL class server!
15/10/21 07:56:30 [INFO] c.i.s.SparkKernel$$anon$1 - REPL Class Server Uri: http://172.17.0.22:45021
15/10/21 07:56:30 [INFO] Remoting - Starting remoting
15/10/21 07:56:30 [INFO] Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.22:39281]
15/10/21 07:56:30 [INFO] o.s.j.s.Server - jetty-8.y.z-SNAPSHOT
15/10/21 07:56:31 [INFO] o.s.j.s.AbstractConnector - Started SocketConnector@0.0.0.0:40168
15/10/21 07:56:31 [INFO] o.s.j.s.Server - jetty-8.y.z-SNAPSHOT
15/10/21 07:56:31 [WARN] o.s.j.u.c.AbstractLifeCycle - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:445)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply$mcV$sp(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.global.StreamState$.withStreams(StreamState.scala:80)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.reallyInitializeSparkContext(ComponentInitialization.scala:186)
	at com.ibm.spark.SparkKernel$$anon$1.reallyInitializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeSparkContext(ComponentInitialization.scala:164)
	at com.ibm.spark.SparkKernel$$anon$1.initializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeComponents(ComponentInitialization.scala:79)
	at com.ibm.spark.SparkKernel$$anon$1.initializeComponents(SparkKernel.scala:34)
	at com.ibm.spark.boot.KernelBootstrap.initialize(KernelBootstrap.scala:79)
	at com.ibm.spark.SparkKernel$delayedInit$body.apply(SparkKernel.scala:39)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at com.ibm.spark.SparkKernel$.main(SparkKernel.scala:23)
	at com.ibm.spark.SparkKernel.main(SparkKernel.scala)
15/10/21 07:56:31 [WARN] o.s.j.u.c.AbstractLifeCycle - FAILED org.spark-project.jetty.server.Server@6391b9c: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:445)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply$mcV$sp(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.global.StreamState$.withStreams(StreamState.scala:80)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.reallyInitializeSparkContext(ComponentInitialization.scala:186)
	at com.ibm.spark.SparkKernel$$anon$1.reallyInitializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeSparkContext(ComponentInitialization.scala:164)
	at com.ibm.spark.SparkKernel$$anon$1.initializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeComponents(ComponentInitialization.scala:79)
	at com.ibm.spark.SparkKernel$$anon$1.initializeComponents(SparkKernel.scala:34)
	at com.ibm.spark.boot.KernelBootstrap.initialize(KernelBootstrap.scala:79)
	at com.ibm.spark.SparkKernel$delayedInit$body.apply(SparkKernel.scala:39)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at com.ibm.spark.SparkKernel$.main(SparkKernel.scala:23)
	at com.ibm.spark.SparkKernel.main(SparkKernel.scala)
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
15/10/21 07:56:31 [WARN] o.a.s.u.Utils - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/10/21 07:56:31 [INFO] o.s.j.s.Server - jetty-8.y.z-SNAPSHOT
15/10/21 07:56:31 [WARN] o.s.j.u.c.AbstractLifeCycle - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:445)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply$mcV$sp(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.global.StreamState$.withStreams(StreamState.scala:80)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.reallyInitializeSparkContext(ComponentInitialization.scala:186)
	at com.ibm.spark.SparkKernel$$anon$1.reallyInitializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeSparkContext(ComponentInitialization.scala:164)
	at com.ibm.spark.SparkKernel$$anon$1.initializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeComponents(ComponentInitialization.scala:79)
	at com.ibm.spark.SparkKernel$$anon$1.initializeComponents(SparkKernel.scala:34)
	at com.ibm.spark.boot.KernelBootstrap.initialize(KernelBootstrap.scala:79)
	at com.ibm.spark.SparkKernel$delayedInit$body.apply(SparkKernel.scala:39)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at com.ibm.spark.SparkKernel$.main(SparkKernel.scala:23)
	at com.ibm.spark.SparkKernel.main(SparkKernel.scala)
15/10/21 07:56:31 [WARN] o.s.j.u.c.AbstractLifeCycle - FAILED org.spark-project.jetty.server.Server@2de2a1ad: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:445)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply$mcV$sp(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.global.StreamState$.withStreams(StreamState.scala:80)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.reallyInitializeSparkContext(ComponentInitialization.scala:186)
	at com.ibm.spark.SparkKernel$$anon$1.reallyInitializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeSparkContext(ComponentInitialization.scala:164)
	at com.ibm.spark.SparkKernel$$anon$1.initializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeComponents(ComponentInitialization.scala:79)
	at com.ibm.spark.SparkKernel$$anon$1.initializeComponents(SparkKernel.scala:34)
	at com.ibm.spark.boot.KernelBootstrap.initialize(KernelBootstrap.scala:79)
	at com.ibm.spark.SparkKernel$delayedInit$body.apply(SparkKernel.scala:39)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at com.ibm.spark.SparkKernel$.main(SparkKernel.scala:23)
	at com.ibm.spark.SparkKernel.main(SparkKernel.scala)
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
15/10/21 07:56:31 [WARN] o.a.s.u.Utils - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
15/10/21 07:56:31 [INFO] o.s.j.s.Server - jetty-8.y.z-SNAPSHOT
15/10/21 07:56:31 [WARN] o.s.j.u.c.AbstractLifeCycle - FAILED SelectChannelConnector@0.0.0.0:4042: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:445)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply$mcV$sp(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.global.StreamState$.withStreams(StreamState.scala:80)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.reallyInitializeSparkContext(ComponentInitialization.scala:186)
	at com.ibm.spark.SparkKernel$$anon$1.reallyInitializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeSparkContext(ComponentInitialization.scala:164)
	at com.ibm.spark.SparkKernel$$anon$1.initializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeComponents(ComponentInitialization.scala:79)
	at com.ibm.spark.SparkKernel$$anon$1.initializeComponents(SparkKernel.scala:34)
	at com.ibm.spark.boot.KernelBootstrap.initialize(KernelBootstrap.scala:79)
	at com.ibm.spark.SparkKernel$delayedInit$body.apply(SparkKernel.scala:39)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at com.ibm.spark.SparkKernel$.main(SparkKernel.scala:23)
	at com.ibm.spark.SparkKernel.main(SparkKernel.scala)
15/10/21 07:56:31 [WARN] o.s.j.u.c.AbstractLifeCycle - FAILED org.spark-project.jetty.server.Server@5ceaf435: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:445)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply$mcV$sp(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.global.StreamState$.withStreams(StreamState.scala:80)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.reallyInitializeSparkContext(ComponentInitialization.scala:186)
	at com.ibm.spark.SparkKernel$$anon$1.reallyInitializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeSparkContext(ComponentInitialization.scala:164)
	at com.ibm.spark.SparkKernel$$anon$1.initializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeComponents(ComponentInitialization.scala:79)
	at com.ibm.spark.SparkKernel$$anon$1.initializeComponents(SparkKernel.scala:34)
	at com.ibm.spark.boot.KernelBootstrap.initialize(KernelBootstrap.scala:79)
	at com.ibm.spark.SparkKernel$delayedInit$body.apply(SparkKernel.scala:39)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at com.ibm.spark.SparkKernel$.main(SparkKernel.scala:23)
	at com.ibm.spark.SparkKernel.main(SparkKernel.scala)
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
15/10/21 07:56:31 [WARN] o.a.s.u.Utils - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
15/10/21 07:56:31 [INFO] o.s.j.s.Server - jetty-8.y.z-SNAPSHOT
15/10/21 07:56:31 [WARN] o.s.j.u.c.AbstractLifeCycle - FAILED SelectChannelConnector@0.0.0.0:4043: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:445)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply$mcV$sp(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.global.StreamState$.withStreams(StreamState.scala:80)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.reallyInitializeSparkContext(ComponentInitialization.scala:186)
	at com.ibm.spark.SparkKernel$$anon$1.reallyInitializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeSparkContext(ComponentInitialization.scala:164)
	at com.ibm.spark.SparkKernel$$anon$1.initializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeComponents(ComponentInitialization.scala:79)
	at com.ibm.spark.SparkKernel$$anon$1.initializeComponents(SparkKernel.scala:34)
	at com.ibm.spark.boot.KernelBootstrap.initialize(KernelBootstrap.scala:79)
	at com.ibm.spark.SparkKernel$delayedInit$body.apply(SparkKernel.scala:39)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at com.ibm.spark.SparkKernel$.main(SparkKernel.scala:23)
	at com.ibm.spark.SparkKernel.main(SparkKernel.scala)
15/10/21 07:56:31 [WARN] o.s.j.u.c.AbstractLifeCycle - FAILED org.spark-project.jetty.server.Server@28b59438: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:445)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply$mcV$sp(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.global.StreamState$.withStreams(StreamState.scala:80)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.reallyInitializeSparkContext(ComponentInitialization.scala:186)
	at com.ibm.spark.SparkKernel$$anon$1.reallyInitializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeSparkContext(ComponentInitialization.scala:164)
	at com.ibm.spark.SparkKernel$$anon$1.initializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeComponents(ComponentInitialization.scala:79)
	at com.ibm.spark.SparkKernel$$anon$1.initializeComponents(SparkKernel.scala:34)
	at com.ibm.spark.boot.KernelBootstrap.initialize(KernelBootstrap.scala:79)
	at com.ibm.spark.SparkKernel$delayedInit$body.apply(SparkKernel.scala:39)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at com.ibm.spark.SparkKernel$.main(SparkKernel.scala:23)
	at com.ibm.spark.SparkKernel.main(SparkKernel.scala)
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
15/10/21 07:56:31 [WARN] o.a.s.u.Utils - Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
15/10/21 07:56:31 [INFO] o.s.j.s.Server - jetty-8.y.z-SNAPSHOT
15/10/21 07:56:31 [WARN] o.s.j.u.c.AbstractLifeCycle - FAILED SelectChannelConnector@0.0.0.0:4044: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:445)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply$mcV$sp(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.global.StreamState$.withStreams(StreamState.scala:80)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.reallyInitializeSparkContext(ComponentInitialization.scala:186)
	at com.ibm.spark.SparkKernel$$anon$1.reallyInitializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeSparkContext(ComponentInitialization.scala:164)
	at com.ibm.spark.SparkKernel$$anon$1.initializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeComponents(ComponentInitialization.scala:79)
	at com.ibm.spark.SparkKernel$$anon$1.initializeComponents(SparkKernel.scala:34)
	at com.ibm.spark.boot.KernelBootstrap.initialize(KernelBootstrap.scala:79)
	at com.ibm.spark.SparkKernel$delayedInit$body.apply(SparkKernel.scala:39)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at com.ibm.spark.SparkKernel$.main(SparkKernel.scala:23)
	at com.ibm.spark.SparkKernel.main(SparkKernel.scala)
15/10/21 07:56:31 [WARN] o.s.j.u.c.AbstractLifeCycle - FAILED org.spark-project.jetty.server.Server@7856b513: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:445)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply$mcV$sp(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.global.StreamState$.withStreams(StreamState.scala:80)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.reallyInitializeSparkContext(ComponentInitialization.scala:186)
	at com.ibm.spark.SparkKernel$$anon$1.reallyInitializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeSparkContext(ComponentInitialization.scala:164)
	at com.ibm.spark.SparkKernel$$anon$1.initializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeComponents(ComponentInitialization.scala:79)
	at com.ibm.spark.SparkKernel$$anon$1.initializeComponents(SparkKernel.scala:34)
	at com.ibm.spark.boot.KernelBootstrap.initialize(KernelBootstrap.scala:79)
	at com.ibm.spark.SparkKernel$delayedInit$body.apply(SparkKernel.scala:39)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at com.ibm.spark.SparkKernel$.main(SparkKernel.scala:23)
	at com.ibm.spark.SparkKernel.main(SparkKernel.scala)
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
15/10/21 07:56:31 [WARN] o.a.s.u.Utils - Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
15/10/21 07:56:31 [INFO] o.s.j.s.Server - jetty-8.y.z-SNAPSHOT
15/10/21 07:56:31 [WARN] o.s.j.u.c.AbstractLifeCycle - FAILED SelectChannelConnector@0.0.0.0:4045: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:445)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply$mcV$sp(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.global.StreamState$.withStreams(StreamState.scala:80)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.reallyInitializeSparkContext(ComponentInitialization.scala:186)
	at com.ibm.spark.SparkKernel$$anon$1.reallyInitializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeSparkContext(ComponentInitialization.scala:164)
	at com.ibm.spark.SparkKernel$$anon$1.initializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeComponents(ComponentInitialization.scala:79)
	at com.ibm.spark.SparkKernel$$anon$1.initializeComponents(SparkKernel.scala:34)
	at com.ibm.spark.boot.KernelBootstrap.initialize(KernelBootstrap.scala:79)
	at com.ibm.spark.SparkKernel$delayedInit$body.apply(SparkKernel.scala:39)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at com.ibm.spark.SparkKernel$.main(SparkKernel.scala:23)
	at com.ibm.spark.SparkKernel.main(SparkKernel.scala)
15/10/21 07:56:31 [WARN] o.s.j.u.c.AbstractLifeCycle - FAILED org.spark-project.jetty.server.Server@51e5a36c: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:445)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply$mcV$sp(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.global.StreamState$.withStreams(StreamState.scala:80)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.reallyInitializeSparkContext(ComponentInitialization.scala:186)
	at com.ibm.spark.SparkKernel$$anon$1.reallyInitializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeSparkContext(ComponentInitialization.scala:164)
	at com.ibm.spark.SparkKernel$$anon$1.initializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeComponents(ComponentInitialization.scala:79)
	at com.ibm.spark.SparkKernel$$anon$1.initializeComponents(SparkKernel.scala:34)
	at com.ibm.spark.boot.KernelBootstrap.initialize(KernelBootstrap.scala:79)
	at com.ibm.spark.SparkKernel$delayedInit$body.apply(SparkKernel.scala:39)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at com.ibm.spark.SparkKernel$.main(SparkKernel.scala:23)
	at com.ibm.spark.SparkKernel.main(SparkKernel.scala)
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
15/10/21 07:56:31 [WARN] o.a.s.u.Utils - Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
15/10/21 07:56:31 [INFO] o.s.j.s.Server - jetty-8.y.z-SNAPSHOT
15/10/21 07:56:31 [WARN] o.s.j.u.c.AbstractLifeCycle - FAILED SelectChannelConnector@0.0.0.0:4046: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:445)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply$mcV$sp(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.global.StreamState$.withStreams(StreamState.scala:80)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.reallyInitializeSparkContext(ComponentInitialization.scala:186)
	at com.ibm.spark.SparkKernel$$anon$1.reallyInitializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeSparkContext(ComponentInitialization.scala:164)
	at com.ibm.spark.SparkKernel$$anon$1.initializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeComponents(ComponentInitialization.scala:79)
	at com.ibm.spark.SparkKernel$$anon$1.initializeComponents(SparkKernel.scala:34)
	at com.ibm.spark.boot.KernelBootstrap.initialize(KernelBootstrap.scala:79)
	at com.ibm.spark.SparkKernel$delayedInit$body.apply(SparkKernel.scala:39)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at com.ibm.spark.SparkKernel$.main(SparkKernel.scala:23)
	at com.ibm.spark.SparkKernel.main(SparkKernel.scala)
15/10/21 07:56:31 [WARN] o.s.j.u.c.AbstractLifeCycle - FAILED org.spark-project.jetty.server.Server@65d53974: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:445)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply$mcV$sp(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.global.StreamState$.withStreams(StreamState.scala:80)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.reallyInitializeSparkContext(ComponentInitialization.scala:186)
	at com.ibm.spark.SparkKernel$$anon$1.reallyInitializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeSparkContext(ComponentInitialization.scala:164)
	at com.ibm.spark.SparkKernel$$anon$1.initializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeComponents(ComponentInitialization.scala:79)
	at com.ibm.spark.SparkKernel$$anon$1.initializeComponents(SparkKernel.scala:34)
	at com.ibm.spark.boot.KernelBootstrap.initialize(KernelBootstrap.scala:79)
	at com.ibm.spark.SparkKernel$delayedInit$body.apply(SparkKernel.scala:39)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at com.ibm.spark.SparkKernel$.main(SparkKernel.scala:23)
	at com.ibm.spark.SparkKernel.main(SparkKernel.scala)
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
15/10/21 07:56:31 [WARN] o.a.s.u.Utils - Service 'SparkUI' could not bind on port 4046. Attempting port 4047.
15/10/21 07:56:31 [INFO] o.s.j.s.Server - jetty-8.y.z-SNAPSHOT
15/10/21 07:56:31 [WARN] o.s.j.u.c.AbstractLifeCycle - FAILED SelectChannelConnector@0.0.0.0:4047: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:445)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply$mcV$sp(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.global.StreamState$.withStreams(StreamState.scala:80)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.reallyInitializeSparkContext(ComponentInitialization.scala:186)
	at com.ibm.spark.SparkKernel$$anon$1.reallyInitializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeSparkContext(ComponentInitialization.scala:164)
	at com.ibm.spark.SparkKernel$$anon$1.initializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeComponents(ComponentInitialization.scala:79)
	at com.ibm.spark.SparkKernel$$anon$1.initializeComponents(SparkKernel.scala:34)
	at com.ibm.spark.boot.KernelBootstrap.initialize(KernelBootstrap.scala:79)
	at com.ibm.spark.SparkKernel$delayedInit$body.apply(SparkKernel.scala:39)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at com.ibm.spark.SparkKernel$.main(SparkKernel.scala:23)
	at com.ibm.spark.SparkKernel.main(SparkKernel.scala)
15/10/21 07:56:31 [WARN] o.s.j.u.c.AbstractLifeCycle - FAILED org.spark-project.jetty.server.Server@44069e8f: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:445)
	at sun.nio.ch.Net.bind(Net.java:437)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:228)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.ui.JettyUtils$$anonfun$2.apply(JettyUtils.scala:238)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1991)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1982)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:238)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:117)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:448)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:448)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply$mcV$sp(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$$anonfun$reallyInitializeSparkContext$1.apply(ComponentInitialization.scala:187)
	at com.ibm.spark.global.StreamState$.withStreams(StreamState.scala:80)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.reallyInitializeSparkContext(ComponentInitialization.scala:186)
	at com.ibm.spark.SparkKernel$$anon$1.reallyInitializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeSparkContext(ComponentInitialization.scala:164)
	at com.ibm.spark.SparkKernel$$anon$1.initializeSparkContext(SparkKernel.scala:34)
	at com.ibm.spark.boot.layer.StandardComponentInitialization$class.initializeComponents(ComponentInitialization.scala:79)
	at com.ibm.spark.SparkKernel$$anon$1.initializeComponents(SparkKernel.scala:34)
	at com.ibm.spark.boot.KernelBootstrap.initialize(KernelBootstrap.scala:79)
	at com.ibm.spark.SparkKernel$delayedInit$body.apply(SparkKernel.scala:39)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at com.ibm.spark.SparkKernel$.main(SparkKernel.scala:23)
	at com.ibm.spark.SparkKernel.main(SparkKernel.scala)
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/api,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/static,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/executors,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/environment,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/storage,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/stages,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
15/10/21 07:56:31 [INFO] o.s.j.s.h.ContextHandler - stopped o.s.j.s.ServletContextHandler{/jobs,null}
15/10/21 07:56:31 [WARN] o.a.s.u.Utils - Service 'SparkUI' could not bind on port 4047. Attempting port 4048.
15/10/21 07:56:31 [INFO] o.s.j.s.Server - jetty-8.y.z-SNAPSHOT
15/10/21 07:56:31 [INFO] o.s.j.s.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4048
15/10/21 07:56:31 [INFO] c.i.s.k.p.v.r.KernelMessageRelay - Not ready for messages! Stashing until ready!
[W 07:56:33.342 NotebookApp] Timeout waiting for kernel_info reply from e85064b7-a07a-452b-8f29-ac7f2b8cb557
15/10/21 07:56:33 [INFO] c.i.s.k.p.v.r.KernelMessageRelay - Not ready for messages! Stashing until ready!
15/10/21 07:56:35 [INFO] c.i.s.SparkKernel$$anon$1 - Running in local mode! Not adding self as dependency!
15/10/21 07:56:35 [WARN] c.i.s.SparkKernel$$anon$1 - No external magics provided to MagicLoader!
15/10/21 07:56:35 [INFO] c.i.s.SparkKernel$$anon$1 - Marking relay as ready for receiving messages
15/10/21 07:56:35 [INFO] c.i.s.k.p.v.r.KernelMessageRelay - Unstashing all messages received!
15/10/21 07:56:35 [INFO] c.i.s.k.p.v.r.KernelMessageRelay - Relay is now fully ready to receive messages!
res0: org.apache.spark.SparkContext = org.apache.spark.SparkContext@176734ca
[I 07:58:23.242 NotebookApp] Saving file at /Untitled0.ipynb
<console>:13: error: not found: value ?
              ?sc
              ^
<console>:13: error: not found: value ?
              ?
              ^
<console>:13: error: not found: value ??
              ??
              ^
<console>:13: error: not found: value ??
              ?? spark
              ^
readme: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[2] at textFile at <console>:14
org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/tmp/README.md
	at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:251)
	at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:270)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:207)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:219)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:217)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:217)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:32)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:219)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:217)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:217)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1781)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1099)
	at $iwC$$iwC$$iwC$$iwC.<init>(<console>:17)
	at $iwC$$iwC$$iwC.<init>(<console>:22)
	at $iwC$$iwC.<init>(<console>:24)
	at $iwC.<init>(<console>:26)
	at <init>(<console>:28)
	at .<init>(<console>:32)
	at .<clinit>(<console>)
	at .<init>(<console>:7)
	at .<clinit>(<console>)
	at $print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	at com.ibm.spark.interpreter.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:296)
	at com.ibm.spark.interpreter.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:291)
	at com.ibm.spark.global.StreamState$.withStreams(StreamState.scala:80)
	at com.ibm.spark.interpreter.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:290)
	at com.ibm.spark.interpreter.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:290)
	at com.ibm.spark.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

lastException: Throwable = null
[I 08:00:23.949 NotebookApp] Saving file at /Untitled0.ipynb
<console>:1: error: ';' expected but 'with' found.
       Run bash commands with an !
                         ^
<console>:13: error: not found: value ls
              !ls
               ^
[I 08:02:23.966 NotebookApp] Saving file at /Untitled0.ipynb
[I 08:04:23.948 NotebookApp] Saving file at /Untitled0.ipynb
[I 08:06:24.012 NotebookApp] Saving file at /Untitled0.ipynb
[I 08:10:23.923 NotebookApp] Saving file at /Untitled0.ipynb
[I 08:12:25.764 NotebookApp] Saving file at /Untitled0.ipynb
<console>:3: error: ';' expected but ':' found.
       https://raw.githubusercontent.com/apache/spark/master/README.md
            ^
[I 08:14:25.806 NotebookApp] Saving file at /Untitled0.ipynb
[I 08:16:25.724 NotebookApp] Saving file at /Untitled0.ipynb
[I 08:18:25.889 NotebookApp] Saving file at /Untitled0.ipynb
readme: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[4] at textFile at <console>:14
res7: Long = 98
res8: String = # Apache Spark
[I 08:20:25.752 NotebookApp] Saving file at /Untitled0.ipynb
res9: String = 1.4.1
res10: String = 1.4.1
[I 08:22:25.748 NotebookApp] Saving file at /Untitled0.ipynb
linesWithSpark: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[5] at filter at <console>:16
res11: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[5] at filter at <console>:16
res12: Long = 18
[I 08:24:10.225 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 08:33:46.208 NotebookApp] WebSocket ping timeout after 119959 ms.
[W 08:33:58.266 NotebookApp] WebSocket ping timeout after 119984 ms.
[W 08:34:03.344 NotebookApp] WebSocket ping timeout after 119931 ms.
[W 08:34:07.407 NotebookApp] WebSocket ping timeout after 119900 ms.
[W 08:42:10.693 NotebookApp] WebSocket ping timeout after 90000 ms.
[W 08:42:16.318 NotebookApp] WebSocket ping timeout after 90000 ms.
[W 08:42:22.324 NotebookApp] WebSocket ping timeout after 90000 ms.
[W 09:43:57.034 NotebookApp] WebSocket ping timeout after 119876 ms.
[W 09:44:01.636 NotebookApp] WebSocket ping timeout after 119953 ms.
[W 09:44:03.358 NotebookApp] WebSocket ping timeout after 119950 ms.
[W 09:44:09.213 NotebookApp] WebSocket ping timeout after 119968 ms.
15/10/21 10:39:55 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:43363 in memory (size: 2.7 KB, free: 265.4 MB)
15/10/21 10:39:55 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:43363 in memory (size: 2.7 KB, free: 265.4 MB)
[W 11:44:10.550 NotebookApp] WebSocket ping timeout after 90000 ms.
[W 11:44:13.660 NotebookApp] WebSocket ping timeout after 90000 ms.
[W 11:44:15.573 NotebookApp] WebSocket ping timeout after 90000 ms.
[W 11:44:22.341 NotebookApp] WebSocket ping timeout after 90000 ms.
[W 12:44:53.416 NotebookApp] WebSocket ping timeout after 90000 ms.
[W 12:44:56.615 NotebookApp] WebSocket ping timeout after 90000 ms.
[W 12:44:58.638 NotebookApp] WebSocket ping timeout after 90000 ms.
[W 12:45:06.314 NotebookApp] WebSocket ping timeout after 90000 ms.
[W 15:43:42.178 NotebookApp] zmq message arrived on closed channel
[W 15:43:42.178 NotebookApp] zmq message arrived on closed channel
[W 15:43:42.179 NotebookApp] zmq message arrived on closed channel
[W 15:43:42.179 NotebookApp] zmq message arrived on closed channel
[W 15:43:42.181 NotebookApp] zmq message arrived on closed channel
[W 15:43:42.182 NotebookApp] zmq message arrived on closed channel
[W 15:43:42.182 NotebookApp] zmq message arrived on closed channel
[W 15:43:42.183 NotebookApp] zmq message arrived on closed channel
[W 15:43:52.556 NotebookApp] Notebook Untitled0.ipynb is not trusted
[I 15:43:52.634 NotebookApp] Request start_kernel: kernel_id=None, kernel_name=python2, path="", **kwargs={}
[I 15:43:52.635 NotebookApp] Provisioning local kernel: python2
[I 15:43:52.681 NotebookApp] Kernel started: 66656a3b-1fea-4dac-b8a8-45cef547f01d
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/21 15:43:55 INFO SparkContext: Running Spark version 1.4.1
15/10/21 15:43:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/21 15:43:56 INFO SecurityManager: Changing view acls to: notebook
15/10/21 15:43:56 INFO SecurityManager: Changing modify acls to: notebook
15/10/21 15:43:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
15/10/21 15:43:57 INFO Slf4jLogger: Slf4jLogger started
15/10/21 15:43:57 INFO Remoting: Starting remoting
15/10/21 15:43:57 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.22:39173]
15/10/21 15:43:57 INFO Utils: Successfully started service 'sparkDriver' on port 39173.
15/10/21 15:43:57 INFO SparkEnv: Registering MapOutputTracker
15/10/21 15:43:57 INFO SparkEnv: Registering BlockManagerMaster
15/10/21 15:43:57 INFO DiskBlockManager: Created local directory at /tmp/spark-6e54b9ef-eeee-4cb9-bdd3-c91f0bfba6e8/blockmgr-586c41e5-996a-4a68-87a5-5b736a9618b6
15/10/21 15:43:57 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/10/21 15:43:57 INFO HttpFileServer: HTTP File server directory is /tmp/spark-6e54b9ef-eeee-4cb9-bdd3-c91f0bfba6e8/httpd-4b254c9b-ffb8-4603-bf57-49661e22248d
15/10/21 15:43:57 INFO HttpServer: Starting HTTP Server
15/10/21 15:43:57 INFO Utils: Successfully started service 'HTTP file server' on port 34732.
15/10/21 15:43:57 INFO SparkEnv: Registering OutputCommitCoordinator
15/10/21 15:43:58 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/10/21 15:43:58 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
15/10/21 15:43:58 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
15/10/21 15:43:58 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
15/10/21 15:43:58 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
15/10/21 15:43:58 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
15/10/21 15:43:58 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.
15/10/21 15:43:58 WARN Utils: Service 'SparkUI' could not bind on port 4047. Attempting port 4048.
15/10/21 15:43:58 WARN Utils: Service 'SparkUI' could not bind on port 4048. Attempting port 4049.
15/10/21 15:43:58 INFO Utils: Successfully started service 'SparkUI' on port 4049.
15/10/21 15:43:58 INFO SparkUI: Started SparkUI at http://172.17.0.22:4049
15/10/21 15:43:58 INFO Executor: Starting executor ID driver on host localhost
15/10/21 15:43:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54908.
15/10/21 15:43:58 INFO NettyBlockTransferService: Server created on 54908
15/10/21 15:43:58 INFO BlockManagerMaster: Trying to register BlockManager
15/10/21 15:43:58 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54908 with 265.4 MB RAM, BlockManagerId(driver, localhost, 54908)
15/10/21 15:43:58 INFO BlockManagerMaster: Registered BlockManager
15/10/21 15:45:05 INFO MemoryStore: ensureFreeSpace(157248) called with curMem=0, maxMem=278302556
15/10/21 15:45:05 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 153.6 KB, free 265.3 MB)
15/10/21 15:45:05 INFO MemoryStore: ensureFreeSpace(14257) called with curMem=157248, maxMem=278302556
15/10/21 15:45:05 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 13.9 KB, free 265.2 MB)
15/10/21 15:45:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54908 (size: 13.9 KB, free: 265.4 MB)
15/10/21 15:45:05 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2
15/10/21 15:45:17 INFO FileInputFormat: Total input paths to process : 1
15/10/21 15:45:17 INFO SparkContext: Starting job: count at <ipython-input-3-98a3501d210e>:1
15/10/21 15:45:17 INFO DAGScheduler: Got job 0 (count at <ipython-input-3-98a3501d210e>:1) with 2 output partitions (allowLocal=false)
15/10/21 15:45:17 INFO DAGScheduler: Final stage: ResultStage 0(count at <ipython-input-3-98a3501d210e>:1)
15/10/21 15:45:17 INFO DAGScheduler: Parents of final stage: List()
15/10/21 15:45:17 INFO DAGScheduler: Missing parents: List()
15/10/21 15:45:17 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at <ipython-input-3-98a3501d210e>:1), which has no missing parents
15/10/21 15:45:17 INFO MemoryStore: ensureFreeSpace(6024) called with curMem=171505, maxMem=278302556
15/10/21 15:45:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 5.9 KB, free 265.2 MB)
15/10/21 15:45:17 INFO MemoryStore: ensureFreeSpace(3554) called with curMem=177529, maxMem=278302556
15/10/21 15:45:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.5 KB, free 265.2 MB)
15/10/21 15:45:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54908 (size: 3.5 KB, free: 265.4 MB)
15/10/21 15:45:17 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:874
15/10/21 15:45:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at <ipython-input-3-98a3501d210e>:1)
15/10/21 15:45:17 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/10/21 15:45:17 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 15:45:17 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 15:45:17 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/10/21 15:45:17 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/10/21 15:45:21 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 15:45:21 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
15/10/21 15:45:21 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
15/10/21 15:45:21 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
15/10/21 15:45:21 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
15/10/21 15:45:21 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
15/10/21 15:45:21 INFO PythonRDD: Times: total = 3722, boot = 3672, init = 49, finish = 1
15/10/21 15:45:21 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 15:45:21 INFO PythonRDD: Times: total = 3794, boot = 3732, init = 61, finish = 1
15/10/21 15:45:21 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1870 bytes result sent to driver
15/10/21 15:45:21 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1870 bytes result sent to driver
15/10/21 15:45:21 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3878 ms on localhost (1/2)
15/10/21 15:45:21 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 3867 ms on localhost (2/2)
15/10/21 15:45:21 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/10/21 15:45:21 INFO DAGScheduler: ResultStage 0 (count at <ipython-input-3-98a3501d210e>:1) finished in 3.898 s
15/10/21 15:45:21 INFO DAGScheduler: Job 0 finished: count at <ipython-input-3-98a3501d210e>:1, took 3.982962 s
[I 15:45:53.199 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[I 15:53:53.903 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
15/10/21 15:58:27 INFO SparkContext: Starting job: runJob at PythonRDD.scala:366
15/10/21 15:58:27 INFO DAGScheduler: Got job 1 (runJob at PythonRDD.scala:366) with 1 output partitions (allowLocal=true)
15/10/21 15:58:27 INFO DAGScheduler: Final stage: ResultStage 1(runJob at PythonRDD.scala:366)
15/10/21 15:58:27 INFO DAGScheduler: Parents of final stage: List()
15/10/21 15:58:27 INFO DAGScheduler: Missing parents: List()
15/10/21 15:58:27 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[3] at RDD at PythonRDD.scala:43), which has no missing parents
15/10/21 15:58:27 INFO MemoryStore: ensureFreeSpace(5136) called with curMem=181083, maxMem=278302556
15/10/21 15:58:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.0 KB, free 265.2 MB)
15/10/21 15:58:27 INFO MemoryStore: ensureFreeSpace(3075) called with curMem=186219, maxMem=278302556
15/10/21 15:58:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.0 KB, free 265.2 MB)
15/10/21 15:58:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:54908 (size: 3.0 KB, free: 265.4 MB)
15/10/21 15:58:27 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:874
15/10/21 15:58:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (PythonRDD[3] at RDD at PythonRDD.scala:43)
15/10/21 15:58:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
15/10/21 15:58:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 15:58:27 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/10/21 15:58:27 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 15:58:27 INFO PythonRDD: Times: total = 68, boot = 62, init = 6, finish = 0
15/10/21 15:58:27 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1889 bytes result sent to driver
15/10/21 15:58:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 84 ms on localhost (1/1)
15/10/21 15:58:27 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/10/21 15:58:27 INFO DAGScheduler: ResultStage 1 (runJob at PythonRDD.scala:366) finished in 0.084 s
15/10/21 15:58:27 INFO DAGScheduler: Job 1 finished: runJob at PythonRDD.scala:366, took 0.100814 s
15/10/21 15:58:32 INFO SparkContext: Starting job: count at <ipython-input-5-af61aa398f2b>:3
15/10/21 15:58:32 INFO DAGScheduler: Got job 2 (count at <ipython-input-5-af61aa398f2b>:3) with 2 output partitions (allowLocal=false)
15/10/21 15:58:32 INFO DAGScheduler: Final stage: ResultStage 2(count at <ipython-input-5-af61aa398f2b>:3)
15/10/21 15:58:32 INFO DAGScheduler: Parents of final stage: List()
15/10/21 15:58:32 INFO DAGScheduler: Missing parents: List()
15/10/21 15:58:32 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[4] at count at <ipython-input-5-af61aa398f2b>:3), which has no missing parents
15/10/21 15:58:32 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=189294, maxMem=278302556
15/10/21 15:58:32 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 15:58:32 INFO MemoryStore: ensureFreeSpace(3804) called with curMem=195686, maxMem=278302556
15/10/21 15:58:32 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 15:58:32 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 15:58:32 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:874
15/10/21 15:58:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[4] at count at <ipython-input-5-af61aa398f2b>:3)
15/10/21 15:58:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/10/21 15:58:32 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 3, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 15:58:32 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 15:58:32 INFO Executor: Running task 0.0 in stage 2.0 (TID 3)
15/10/21 15:58:32 INFO Executor: Running task 1.0 in stage 2.0 (TID 4)
15/10/21 15:58:32 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 15:58:32 INFO PythonRDD: Times: total = 73, boot = 64, init = 9, finish = 0
15/10/21 15:58:32 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 15:58:32 INFO Executor: Finished task 0.0 in stage 2.0 (TID 3). 1870 bytes result sent to driver
15/10/21 15:58:32 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 3) in 140 ms on localhost (1/2)
15/10/21 15:58:32 INFO PythonRDD: Times: total = 130, boot = 124, init = 5, finish = 1
15/10/21 15:58:32 INFO Executor: Finished task 1.0 in stage 2.0 (TID 4). 1870 bytes result sent to driver
15/10/21 15:58:32 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 4) in 144 ms on localhost (2/2)
15/10/21 15:58:32 INFO DAGScheduler: ResultStage 2 (count at <ipython-input-5-af61aa398f2b>:3) finished in 0.146 s
15/10/21 15:58:32 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/10/21 15:58:32 INFO DAGScheduler: Job 2 finished: count at <ipython-input-5-af61aa398f2b>:3, took 0.163987 s
[W 15:59:20.188 NotebookApp] zmq message arrived on closed channel
[W 15:59:20.188 NotebookApp] zmq message arrived on closed channel
[W 15:59:20.188 NotebookApp] zmq message arrived on closed channel
[W 15:59:20.189 NotebookApp] zmq message arrived on closed channel
[W 15:59:20.189 NotebookApp] zmq message arrived on closed channel
[W 15:59:20.189 NotebookApp] zmq message arrived on closed channel
[W 15:59:20.190 NotebookApp] zmq message arrived on closed channel
[W 15:59:20.190 NotebookApp] zmq message arrived on closed channel
res13: Int = 14
[W 15:59:21.686 NotebookApp] zmq message arrived on closed channel
[W 15:59:21.686 NotebookApp] zmq message arrived on closed channel
[W 15:59:21.687 NotebookApp] zmq message arrived on closed channel
[W 15:59:21.687 NotebookApp] zmq message arrived on closed channel
[W 15:59:21.688 NotebookApp] zmq message arrived on closed channel
[W 15:59:21.689 NotebookApp] zmq message arrived on closed channel
[W 15:59:21.689 NotebookApp] zmq message arrived on closed channel
[W 15:59:21.689 NotebookApp] zmq message arrived on closed channel
[I 15:59:43.747 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 15:59:46.856 NotebookApp] zmq message arrived on closed channel
[W 15:59:46.857 NotebookApp] zmq message arrived on closed channel
[W 15:59:46.857 NotebookApp] zmq message arrived on closed channel
[W 15:59:46.858 NotebookApp] zmq message arrived on closed channel
[W 15:59:46.858 NotebookApp] zmq message arrived on closed channel
[W 15:59:46.858 NotebookApp] zmq message arrived on closed channel
[W 15:59:46.859 NotebookApp] zmq message arrived on closed channel
[W 15:59:46.859 NotebookApp] zmq message arrived on closed channel
import java.lang.Math
[W 15:59:47.012 NotebookApp] zmq message arrived on closed channel
[W 15:59:47.013 NotebookApp] zmq message arrived on closed channel
[W 15:59:47.013 NotebookApp] zmq message arrived on closed channel
[W 15:59:47.014 NotebookApp] zmq message arrived on closed channel
[W 15:59:47.822 NotebookApp] zmq message arrived on closed channel
[W 15:59:47.822 NotebookApp] zmq message arrived on closed channel
[W 15:59:47.823 NotebookApp] zmq message arrived on closed channel
[W 15:59:47.823 NotebookApp] zmq message arrived on closed channel
[W 15:59:47.824 NotebookApp] zmq message arrived on closed channel
[W 15:59:47.824 NotebookApp] zmq message arrived on closed channel
[W 15:59:47.824 NotebookApp] zmq message arrived on closed channel
[W 15:59:47.825 NotebookApp] zmq message arrived on closed channel
res14: Int = 14
[W 15:59:48.159 NotebookApp] zmq message arrived on closed channel
[W 15:59:48.160 NotebookApp] zmq message arrived on closed channel
[W 15:59:48.161 NotebookApp] zmq message arrived on closed channel
[W 15:59:48.161 NotebookApp] zmq message arrived on closed channel
[W 15:59:48.161 NotebookApp] zmq message arrived on closed channel
[W 15:59:48.161 NotebookApp] zmq message arrived on closed channel
[W 15:59:48.162 NotebookApp] zmq message arrived on closed channel
[W 15:59:48.163 NotebookApp] zmq message arrived on closed channel
[I 15:59:53.730 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[W 15:59:56.368 NotebookApp] zmq message arrived on closed channel
[W 15:59:56.368 NotebookApp] zmq message arrived on closed channel
[W 15:59:56.368 NotebookApp] zmq message arrived on closed channel
[W 15:59:56.369 NotebookApp] zmq message arrived on closed channel
[W 15:59:56.370 NotebookApp] zmq message arrived on closed channel
[W 15:59:56.370 NotebookApp] zmq message arrived on closed channel
[W 15:59:56.370 NotebookApp] zmq message arrived on closed channel
[W 15:59:56.370 NotebookApp] zmq message arrived on closed channel
wordCounts: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[11] at reduceByKey at <console>:17
[W 15:59:57.125 NotebookApp] zmq message arrived on closed channel
[W 15:59:57.125 NotebookApp] zmq message arrived on closed channel
[W 15:59:57.125 NotebookApp] zmq message arrived on closed channel
[W 15:59:57.126 NotebookApp] zmq message arrived on closed channel
[W 16:00:01.331 NotebookApp] zmq message arrived on closed channel
[W 16:00:01.331 NotebookApp] zmq message arrived on closed channel
[W 16:00:01.332 NotebookApp] zmq message arrived on closed channel
[W 16:00:01.332 NotebookApp] zmq message arrived on closed channel
[W 16:00:01.333 NotebookApp] zmq message arrived on closed channel
[W 16:00:01.333 NotebookApp] zmq message arrived on closed channel
[W 16:00:01.333 NotebookApp] zmq message arrived on closed channel
[W 16:00:01.334 NotebookApp] zmq message arrived on closed channel
res15: Array[(String, Int)] = Array((package,1), (this,1), (Version"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version),1), (Because,1), (Python,2), (cluster.,1), (its,1), ([run,1), (general,2), (have,1), (pre-built,1), (locally.,1), (locally,2), (changed,1), (sc.parallelize(1,1), (only,1), (several,1), (This,2), (basic,1), (Configuration,1), (learning,,1), (documentation,3), (YARN,,1), (graph,1), (Hive,2), (first,1), (["Specifying,1), ("yarn",1), (page](http://spark.apache.org/documentation.html),1), ([params]`.,1), (application,1), ([project,2), (prefer,1), (SparkPi,2), (<http://spark.apache.org/>,1), (engine,1), (version,1), (file,1), (documentation,,1), (MASTER,1), (example,3), (distribution.,1), (are,1), (params,1), (scala>,1), (DataFrames,,1), ...[W 16:00:01.901 NotebookApp] zmq message arrived on closed channel
[W 16:00:01.901 NotebookApp] zmq message arrived on closed channel
[W 16:00:01.902 NotebookApp] zmq message arrived on closed channel
[W 16:00:01.902 NotebookApp] zmq message arrived on closed channel
<console>:1: error: ';' expected but '.' found.
       print wordCounts.collect()
                       ^
[W 16:00:15.117 NotebookApp] zmq message arrived on closed channel
[W 16:00:15.117 NotebookApp] zmq message arrived on closed channel
[W 16:00:15.118 NotebookApp] zmq message arrived on closed channel
[W 16:00:15.118 NotebookApp] zmq message arrived on closed channel
[W 16:00:15.119 NotebookApp] zmq message arrived on closed channel
[W 16:00:15.119 NotebookApp] zmq message arrived on closed channel
[W 16:00:15.119 NotebookApp] zmq message arrived on closed channel
[W 16:00:15.119 NotebookApp] zmq message arrived on closed channel
[W 16:00:15.122 NotebookApp] zmq message arrived on closed channel
[W 16:00:15.122 NotebookApp] zmq message arrived on closed channel
[W 16:00:15.123 NotebookApp] zmq message arrived on closed channel
[W 16:00:15.123 NotebookApp] zmq message arrived on closed channel
[W 16:00:15.124 NotebookApp] zmq message arrived on closed channel
[W 16:00:15.124 NotebookApp] zmq message arrived on closed channel
[W 16:00:15.125 NotebookApp] zmq message arrived on closed channel
[W 16:00:15.125 NotebookApp] zmq message arrived on closed channel
[W 16:00:19.120 NotebookApp] zmq message arrived on closed channel
[W 16:00:19.120 NotebookApp] zmq message arrived on closed channel
[W 16:00:19.121 NotebookApp] zmq message arrived on closed channel
[W 16:00:19.121 NotebookApp] zmq message arrived on closed channel
[W 16:00:19.122 NotebookApp] zmq message arrived on closed channel
[W 16:00:19.122 NotebookApp] zmq message arrived on closed channel
[W 16:00:19.122 NotebookApp] zmq message arrived on closed channel
[W 16:00:19.122 NotebookApp] zmq message arrived on closed channel
<console>:22: error: not found: value a
val $ires14 = a
              ^
<console>:19: error: not found: value a
       a=wordCounts.collect()
       ^
[W 16:00:19.164 NotebookApp] zmq message arrived on closed channel
[W 16:00:19.164 NotebookApp] zmq message arrived on closed channel
[W 16:00:19.165 NotebookApp] zmq message arrived on closed channel
[W 16:00:19.165 NotebookApp] zmq message arrived on closed channel
[W 16:00:19.166 NotebookApp] zmq message arrived on closed channel
[W 16:00:19.166 NotebookApp] zmq message arrived on closed channel
[W 16:00:19.166 NotebookApp] zmq message arrived on closed channel
[W 16:00:19.167 NotebookApp] zmq message arrived on closed channel
[W 16:00:23.225 NotebookApp] zmq message arrived on closed channel
[W 16:00:23.225 NotebookApp] zmq message arrived on closed channel
[W 16:00:23.226 NotebookApp] zmq message arrived on closed channel
[W 16:00:23.226 NotebookApp] zmq message arrived on closed channel
[W 16:00:23.226 NotebookApp] zmq message arrived on closed channel
[W 16:00:23.227 NotebookApp] zmq message arrived on closed channel
[W 16:00:23.227 NotebookApp] zmq message arrived on closed channel
[W 16:00:23.227 NotebookApp] zmq message arrived on closed channel
a: Array[(String, Int)] = Array((package,1), (this,1), (Version"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version),1), (Because,1), (Python,2), (cluster.,1), (its,1), ([run,1), (general,2), (have,1), (pre-built,1), (locally.,1), (locally,2), (changed,1), (sc.parallelize(1,1), (only,1), (several,1), (This,2), (basic,1), (Configuration,1), (learning,,1), (documentation,3), (YARN,,1), (graph,1), (Hive,2), (first,1), (["Specifying,1), ("yarn",1), (page](http://spark.apache.org/documentation.html),1), ([params]`.,1), (application,1), ([project,2), (prefer,1), (SparkPi,2), (<http://spark.apache.org/>,1), (engine,1), (version,1), (file,1), (documentation,,1), (MASTER,1), (example,3), (distribution.,1), (are,1), (params,1), (scala>,1), (DataFrames,,1), (pro...[W 16:00:23.497 NotebookApp] zmq message arrived on closed channel
[W 16:00:23.497 NotebookApp] zmq message arrived on closed channel
[W 16:00:23.498 NotebookApp] zmq message arrived on closed channel
[W 16:00:23.498 NotebookApp] zmq message arrived on closed channel
[W 16:00:26.238 NotebookApp] zmq message arrived on closed channel
[W 16:00:26.239 NotebookApp] zmq message arrived on closed channel
[W 16:00:26.239 NotebookApp] zmq message arrived on closed channel
[W 16:00:26.239 NotebookApp] zmq message arrived on closed channel
[W 16:00:26.240 NotebookApp] zmq message arrived on closed channel
[W 16:00:26.240 NotebookApp] zmq message arrived on closed channel
[W 16:00:26.241 NotebookApp] zmq message arrived on closed channel
[W 16:00:26.241 NotebookApp] zmq message arrived on closed channel
res16: Array[(String, Int)] = Array((package,1), (this,1), (Version"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version),1), (Because,1), (Python,2), (cluster.,1), (its,1), ([run,1), (general,2), (have,1), (pre-built,1), (locally.,1), (locally,2), (changed,1), (sc.parallelize(1,1), (only,1), (several,1), (This,2), (basic,1), (Configuration,1), (learning,,1), (documentation,3), (YARN,,1), (graph,1), (Hive,2), (first,1), (["Specifying,1), ("yarn",1), (page](http://spark.apache.org/documentation.html),1), ([params]`.,1), (application,1), ([project,2), (prefer,1), (SparkPi,2), (<http://spark.apache.org/>,1), (engine,1), (version,1), (file,1), (documentation,,1), (MASTER,1), (example,3), (distribution.,1), (are,1), (params,1), (scala>,1), (DataFrames,,1), ...[W 16:00:26.429 NotebookApp] zmq message arrived on closed channel
[W 16:00:26.429 NotebookApp] zmq message arrived on closed channel
[W 16:00:26.430 NotebookApp] zmq message arrived on closed channel
[W 16:00:26.430 NotebookApp] zmq message arrived on closed channel
[W 16:00:36.684 NotebookApp] zmq message arrived on closed channel
[W 16:00:36.684 NotebookApp] zmq message arrived on closed channel
[W 16:00:36.685 NotebookApp] zmq message arrived on closed channel
[W 16:00:36.685 NotebookApp] zmq message arrived on closed channel
[W 16:00:36.865 NotebookApp] zmq message arrived on closed channel
[W 16:00:36.865 NotebookApp] zmq message arrived on closed channel
[W 16:00:36.865 NotebookApp] zmq message arrived on closed channel
[W 16:00:36.866 NotebookApp] zmq message arrived on closed channel
[W 16:00:36.999 NotebookApp] zmq message arrived on closed channel
[W 16:00:37.000 NotebookApp] zmq message arrived on closed channel
[W 16:00:37.000 NotebookApp] zmq message arrived on closed channel
[W 16:00:37.000 NotebookApp] zmq message arrived on closed channel
[W 16:00:37.184 NotebookApp] zmq message arrived on closed channel
[W 16:00:37.184 NotebookApp] zmq message arrived on closed channel
[W 16:00:37.185 NotebookApp] zmq message arrived on closed channel
[W 16:00:37.185 NotebookApp] zmq message arrived on closed channel
[W 16:00:38.265 NotebookApp] zmq message arrived on closed channel
[W 16:00:38.265 NotebookApp] zmq message arrived on closed channel
[W 16:00:38.266 NotebookApp] zmq message arrived on closed channel
[W 16:00:38.266 NotebookApp] zmq message arrived on closed channel
[W 16:00:38.585 NotebookApp] zmq message arrived on closed channel
[W 16:00:38.585 NotebookApp] zmq message arrived on closed channel
[W 16:00:38.586 NotebookApp] zmq message arrived on closed channel
[W 16:00:38.586 NotebookApp] zmq message arrived on closed channel
[W 16:00:45.566 NotebookApp] zmq message arrived on closed channel
[W 16:00:45.566 NotebookApp] zmq message arrived on closed channel
[W 16:00:45.567 NotebookApp] zmq message arrived on closed channel
[W 16:00:45.567 NotebookApp] zmq message arrived on closed channel
[W 16:00:45.568 NotebookApp] zmq message arrived on closed channel
[W 16:00:45.568 NotebookApp] zmq message arrived on closed channel
[W 16:00:45.568 NotebookApp] zmq message arrived on closed channel
[W 16:00:45.569 NotebookApp] zmq message arrived on closed channel
res17: Long = 267
[W 16:00:45.772 NotebookApp] zmq message arrived on closed channel
[W 16:00:45.772 NotebookApp] zmq message arrived on closed channel
[W 16:00:45.772 NotebookApp] zmq message arrived on closed channel
[W 16:00:45.773 NotebookApp] zmq message arrived on closed channel
[W 16:00:45.774 NotebookApp] zmq message arrived on closed channel
[W 16:00:45.774 NotebookApp] zmq message arrived on closed channel
[W 16:00:45.775 NotebookApp] zmq message arrived on closed channel
[W 16:00:45.775 NotebookApp] zmq message arrived on closed channel
[W 16:01:07.410 NotebookApp] zmq message arrived on closed channel
[W 16:01:07.411 NotebookApp] zmq message arrived on closed channel
[W 16:01:07.411 NotebookApp] zmq message arrived on closed channel
[W 16:01:07.411 NotebookApp] zmq message arrived on closed channel
[W 16:01:07.412 NotebookApp] zmq message arrived on closed channel
[W 16:01:07.412 NotebookApp] zmq message arrived on closed channel
[W 16:01:07.412 NotebookApp] zmq message arrived on closed channel
[W 16:01:07.413 NotebookApp] zmq message arrived on closed channel
res18: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[11] at reduceByKey at <console>:17
[W 16:01:07.582 NotebookApp] zmq message arrived on closed channel
[W 16:01:07.583 NotebookApp] zmq message arrived on closed channel
[W 16:01:07.583 NotebookApp] zmq message arrived on closed channel
[W 16:01:07.584 NotebookApp] zmq message arrived on closed channel
[W 16:01:12.769 NotebookApp] zmq message arrived on closed channel
[W 16:01:12.770 NotebookApp] zmq message arrived on closed channel
[W 16:01:12.770 NotebookApp] zmq message arrived on closed channel
[W 16:01:12.770 NotebookApp] zmq message arrived on closed channel
[W 16:01:13.121 NotebookApp] zmq message arrived on closed channel
[W 16:01:13.121 NotebookApp] zmq message arrived on closed channel
[W 16:01:13.122 NotebookApp] zmq message arrived on closed channel
[W 16:01:13.122 NotebookApp] zmq message arrived on closed channel
[W 16:01:13.761 NotebookApp] zmq message arrived on closed channel
[W 16:01:13.761 NotebookApp] zmq message arrived on closed channel
[W 16:01:13.762 NotebookApp] zmq message arrived on closed channel
[W 16:01:13.762 NotebookApp] zmq message arrived on closed channel
[W 16:01:14.107 NotebookApp] zmq message arrived on closed channel
[W 16:01:14.107 NotebookApp] zmq message arrived on closed channel
[W 16:01:14.107 NotebookApp] zmq message arrived on closed channel
[W 16:01:14.108 NotebookApp] zmq message arrived on closed channel
[W 16:01:16.341 NotebookApp] zmq message arrived on closed channel
[W 16:01:16.342 NotebookApp] zmq message arrived on closed channel
[W 16:01:16.342 NotebookApp] zmq message arrived on closed channel
[W 16:01:16.342 NotebookApp] zmq message arrived on closed channel
[W 16:01:16.343 NotebookApp] zmq message arrived on closed channel
[W 16:01:16.343 NotebookApp] zmq message arrived on closed channel
[W 16:01:16.343 NotebookApp] zmq message arrived on closed channel
[W 16:01:16.344 NotebookApp] zmq message arrived on closed channel
res19: Array[(String, Int)] = Array((package,1), (this,1), (Version"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version),1), (Because,1), (Python,2), (cluster.,1), (its,1), ([run,1), (general,2), (have,1), (pre-built,1), (locally.,1), (locally,2), (changed,1), (sc.parallelize(1,1), (only,1), (several,1), (This,2), (basic,1), (Configuration,1), (learning,,1), (documentation,3), (YARN,,1), (graph,1), (Hive,2), (first,1), (["Specifying,1), ("yarn",1), (page](http://spark.apache.org/documentation.html),1), ([params]`.,1), (application,1), ([project,2), (prefer,1), (SparkPi,2), (<http://spark.apache.org/>,1), (engine,1), (version,1), (file,1), (documentation,,1), (MASTER,1), (example,3), (distribution.,1), (are,1), (params,1), (scala>,1), (DataFrames,,1), ...[W 16:01:16.585 NotebookApp] zmq message arrived on closed channel
[W 16:01:16.585 NotebookApp] zmq message arrived on closed channel
[W 16:01:16.586 NotebookApp] zmq message arrived on closed channel
[W 16:01:16.586 NotebookApp] zmq message arrived on closed channel
[W 16:01:19.039 NotebookApp] zmq message arrived on closed channel
[W 16:01:19.039 NotebookApp] zmq message arrived on closed channel
[W 16:01:19.040 NotebookApp] zmq message arrived on closed channel
[W 16:01:19.040 NotebookApp] zmq message arrived on closed channel
[W 16:01:19.213 NotebookApp] zmq message arrived on closed channel
[W 16:01:19.214 NotebookApp] zmq message arrived on closed channel
[W 16:01:19.215 NotebookApp] zmq message arrived on closed channel
[W 16:01:19.215 NotebookApp] zmq message arrived on closed channel
[W 16:01:19.286 NotebookApp] zmq message arrived on closed channel
[W 16:01:19.286 NotebookApp] zmq message arrived on closed channel
[W 16:01:19.287 NotebookApp] zmq message arrived on closed channel
[W 16:01:19.287 NotebookApp] zmq message arrived on closed channel
[W 16:01:19.451 NotebookApp] zmq message arrived on closed channel
[W 16:01:19.452 NotebookApp] zmq message arrived on closed channel
[W 16:01:19.452 NotebookApp] zmq message arrived on closed channel
[W 16:01:19.452 NotebookApp] zmq message arrived on closed channel
[W 16:01:20.839 NotebookApp] zmq message arrived on closed channel
[W 16:01:20.839 NotebookApp] zmq message arrived on closed channel
[W 16:01:20.840 NotebookApp] zmq message arrived on closed channel
[W 16:01:20.840 NotebookApp] zmq message arrived on closed channel
[W 16:01:20.841 NotebookApp] zmq message arrived on closed channel
[W 16:01:20.841 NotebookApp] zmq message arrived on closed channel
[W 16:01:20.841 NotebookApp] zmq message arrived on closed channel
[W 16:01:20.841 NotebookApp] zmq message arrived on closed channel
res20: String = [Lscala.Tuple2;@d97869f
[W 16:01:21.072 NotebookApp] zmq message arrived on closed channel
[W 16:01:21.073 NotebookApp] zmq message arrived on closed channel
[W 16:01:21.073 NotebookApp] zmq message arrived on closed channel
[W 16:01:21.074 NotebookApp] zmq message arrived on closed channel
[W 16:01:21.074 NotebookApp] zmq message arrived on closed channel
[W 16:01:21.074 NotebookApp] zmq message arrived on closed channel
[W 16:01:21.075 NotebookApp] zmq message arrived on closed channel
[W 16:01:21.075 NotebookApp] zmq message arrived on closed channel
[I 16:01:45.158 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 16:02:15.686 NotebookApp] zmq message arrived on closed channel
[W 16:02:15.686 NotebookApp] zmq message arrived on closed channel
[W 16:02:15.687 NotebookApp] zmq message arrived on closed channel
[W 16:02:15.687 NotebookApp] zmq message arrived on closed channel
[W 16:02:15.688 NotebookApp] zmq message arrived on closed channel
[W 16:02:15.688 NotebookApp] zmq message arrived on closed channel
[W 16:02:15.688 NotebookApp] zmq message arrived on closed channel
[W 16:02:15.689 NotebookApp] zmq message arrived on closed channel
[W 16:02:15.969 NotebookApp] zmq message arrived on closed channel
[W 16:02:15.969 NotebookApp] zmq message arrived on closed channel
[W 16:02:15.970 NotebookApp] zmq message arrived on closed channel
[W 16:02:15.970 NotebookApp] zmq message arrived on closed channel
[W 16:02:15.971 NotebookApp] zmq message arrived on closed channel
[W 16:02:15.971 NotebookApp] zmq message arrived on closed channel
[W 16:02:15.971 NotebookApp] zmq message arrived on closed channel
[W 16:02:15.971 NotebookApp] zmq message arrived on closed channel
[W 16:02:55.466 NotebookApp] zmq message arrived on closed channel
[W 16:02:55.466 NotebookApp] zmq message arrived on closed channel
[W 16:02:55.467 NotebookApp] zmq message arrived on closed channel
[W 16:02:55.467 NotebookApp] zmq message arrived on closed channel
[W 16:02:55.468 NotebookApp] zmq message arrived on closed channel
[W 16:02:55.468 NotebookApp] zmq message arrived on closed channel
[W 16:02:55.468 NotebookApp] zmq message arrived on closed channel
[W 16:02:55.469 NotebookApp] zmq message arrived on closed channel
[W 16:02:55.799 NotebookApp] zmq message arrived on closed channel
[W 16:02:55.799 NotebookApp] zmq message arrived on closed channel
[W 16:02:55.799 NotebookApp] zmq message arrived on closed channel
[W 16:02:55.800 NotebookApp] zmq message arrived on closed channel
[W 16:02:55.803 NotebookApp] zmq message arrived on closed channel
[W 16:02:55.803 NotebookApp] zmq message arrived on closed channel
[W 16:02:55.803 NotebookApp] zmq message arrived on closed channel
[W 16:02:55.804 NotebookApp] zmq message arrived on closed channel
[W 16:02:55.808 NotebookApp] zmq message arrived on closed channel
[W 16:02:55.808 NotebookApp] zmq message arrived on closed channel
[W 16:02:55.808 NotebookApp] zmq message arrived on closed channel
[W 16:02:55.809 NotebookApp] zmq message arrived on closed channel
[I 16:03:45.220 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
<console>:1: error: illegal start of definition
       #wordCounts.collect() foreach println
       ^
[W 16:04:01.365 NotebookApp] zmq message arrived on closed channel
[W 16:04:01.366 NotebookApp] zmq message arrived on closed channel
[W 16:04:01.366 NotebookApp] zmq message arrived on closed channel
[W 16:04:01.367 NotebookApp] zmq message arrived on closed channel
[W 16:04:01.367 NotebookApp] zmq message arrived on closed channel
[W 16:04:01.368 NotebookApp] zmq message arrived on closed channel
[W 16:04:01.368 NotebookApp] zmq message arrived on closed channel
[W 16:04:01.368 NotebookApp] zmq message arrived on closed channel
[W 16:04:01.369 NotebookApp] zmq message arrived on closed channel
[W 16:04:01.369 NotebookApp] zmq message arrived on closed channel
[W 16:04:01.370 NotebookApp] zmq message arrived on closed channel
[W 16:04:01.370 NotebookApp] zmq message arrived on closed channel
[W 16:04:01.373 NotebookApp] zmq message arrived on closed channel
[W 16:04:01.373 NotebookApp] zmq message arrived on closed channel
[W 16:04:01.373 NotebookApp] zmq message arrived on closed channel
[W 16:04:01.373 NotebookApp] zmq message arrived on closed channel
[W 16:04:10.652 NotebookApp] zmq message arrived on closed channel
[W 16:04:10.652 NotebookApp] zmq message arrived on closed channel
[W 16:04:10.652 NotebookApp] zmq message arrived on closed channel
[W 16:04:10.652 NotebookApp] zmq message arrived on closed channel
[W 16:04:10.653 NotebookApp] zmq message arrived on closed channel
[W 16:04:10.654 NotebookApp] zmq message arrived on closed channel
[W 16:04:10.654 NotebookApp] zmq message arrived on closed channel
[W 16:04:10.654 NotebookApp] zmq message arrived on closed channel
[W 16:04:10.892 NotebookApp] zmq message arrived on closed channel
[W 16:04:10.893 NotebookApp] zmq message arrived on closed channel
[W 16:04:10.894 NotebookApp] zmq message arrived on closed channel
[W 16:04:10.894 NotebookApp] zmq message arrived on closed channel
[W 16:04:10.894 NotebookApp] zmq message arrived on closed channel
[W 16:04:10.894 NotebookApp] zmq message arrived on closed channel
[W 16:04:10.895 NotebookApp] zmq message arrived on closed channel
[W 16:04:10.895 NotebookApp] zmq message arrived on closed channel
[W 16:04:10.896 NotebookApp] zmq message arrived on closed channel
[W 16:04:10.896 NotebookApp] zmq message arrived on closed channel
[W 16:04:10.896 NotebookApp] zmq message arrived on closed channel
[W 16:04:10.896 NotebookApp] zmq message arrived on closed channel
[W 16:04:18.352 NotebookApp] zmq message arrived on closed channel
[W 16:04:18.352 NotebookApp] zmq message arrived on closed channel
[W 16:04:18.352 NotebookApp] zmq message arrived on closed channel
[W 16:04:18.353 NotebookApp] zmq message arrived on closed channel
[W 16:04:18.353 NotebookApp] zmq message arrived on closed channel
[W 16:04:18.354 NotebookApp] zmq message arrived on closed channel
[W 16:04:18.354 NotebookApp] zmq message arrived on closed channel
[W 16:04:18.354 NotebookApp] zmq message arrived on closed channel
[W 16:04:18.573 NotebookApp] zmq message arrived on closed channel
[W 16:04:18.573 NotebookApp] zmq message arrived on closed channel
[W 16:04:18.573 NotebookApp] zmq message arrived on closed channel
[W 16:04:18.574 NotebookApp] zmq message arrived on closed channel
[W 16:04:18.581 NotebookApp] zmq message arrived on closed channel
[W 16:04:18.581 NotebookApp] zmq message arrived on closed channel
[W 16:04:18.581 NotebookApp] zmq message arrived on closed channel
[W 16:04:18.582 NotebookApp] zmq message arrived on closed channel
[W 16:04:25.983 NotebookApp] zmq message arrived on closed channel
[W 16:04:25.983 NotebookApp] zmq message arrived on closed channel
[W 16:04:25.983 NotebookApp] zmq message arrived on closed channel
[W 16:04:25.984 NotebookApp] zmq message arrived on closed channel
[W 16:04:25.985 NotebookApp] zmq message arrived on closed channel
[W 16:04:25.985 NotebookApp] zmq message arrived on closed channel
[W 16:04:25.985 NotebookApp] zmq message arrived on closed channel
[W 16:04:25.986 NotebookApp] zmq message arrived on closed channel
[W 16:04:26.275 NotebookApp] zmq message arrived on closed channel
[W 16:04:26.276 NotebookApp] zmq message arrived on closed channel
[W 16:04:26.276 NotebookApp] zmq message arrived on closed channel
[W 16:04:26.277 NotebookApp] zmq message arrived on closed channel
[W 16:04:26.277 NotebookApp] zmq message arrived on closed channel
[W 16:04:26.277 NotebookApp] zmq message arrived on closed channel
[W 16:04:26.278 NotebookApp] zmq message arrived on closed channel
[W 16:04:26.278 NotebookApp] zmq message arrived on closed channel
[W 16:04:26.278 NotebookApp] zmq message arrived on closed channel
[W 16:04:26.278 NotebookApp] zmq message arrived on closed channel
[W 16:04:26.279 NotebookApp] zmq message arrived on closed channel
[W 16:04:26.279 NotebookApp] zmq message arrived on closed channel
[W 16:05:02.797 NotebookApp] zmq message arrived on closed channel
[W 16:05:02.798 NotebookApp] zmq message arrived on closed channel
[W 16:05:02.798 NotebookApp] zmq message arrived on closed channel
[W 16:05:02.798 NotebookApp] zmq message arrived on closed channel
[W 16:05:02.799 NotebookApp] zmq message arrived on closed channel
[W 16:05:02.799 NotebookApp] zmq message arrived on closed channel
[W 16:05:02.800 NotebookApp] zmq message arrived on closed channel
[W 16:05:02.800 NotebookApp] zmq message arrived on closed channel
[W 16:05:03.083 NotebookApp] zmq message arrived on closed channel
[W 16:05:03.084 NotebookApp] zmq message arrived on closed channel
[W 16:05:03.084 NotebookApp] zmq message arrived on closed channel
[W 16:05:03.085 NotebookApp] zmq message arrived on closed channel
[W 16:05:03.085 NotebookApp] zmq message arrived on closed channel
[W 16:05:03.086 NotebookApp] zmq message arrived on closed channel
[W 16:05:03.086 NotebookApp] zmq message arrived on closed channel
[W 16:05:03.087 NotebookApp] zmq message arrived on closed channel
[W 16:05:03.087 NotebookApp] zmq message arrived on closed channel
[W 16:05:03.088 NotebookApp] zmq message arrived on closed channel
[W 16:05:03.088 NotebookApp] zmq message arrived on closed channel
[W 16:05:03.088 NotebookApp] zmq message arrived on closed channel
15/10/21 16:05:40 INFO SparkContext: Starting job: reduce at <ipython-input-6-1df081d8b441>:1
15/10/21 16:05:40 INFO DAGScheduler: Got job 3 (reduce at <ipython-input-6-1df081d8b441>:1) with 2 output partitions (allowLocal=false)
15/10/21 16:05:40 INFO DAGScheduler: Final stage: ResultStage 3(reduce at <ipython-input-6-1df081d8b441>:1)
15/10/21 16:05:40 INFO DAGScheduler: Parents of final stage: List()
15/10/21 16:05:40 INFO DAGScheduler: Missing parents: List()
15/10/21 16:05:40 INFO DAGScheduler: Submitting ResultStage 3 (PythonRDD[5] at reduce at <ipython-input-6-1df081d8b441>:1), which has no missing parents
15/10/21 16:05:40 INFO MemoryStore: ensureFreeSpace(5976) called with curMem=199490, maxMem=278302556
15/10/21 16:05:40 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 5.8 KB, free 265.2 MB)
15/10/21 16:05:40 INFO MemoryStore: ensureFreeSpace(3575) called with curMem=205466, maxMem=278302556
15/10/21 16:05:40 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.5 KB, free 265.2 MB)
15/10/21 16:05:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:54908 (size: 3.5 KB, free: 265.4 MB)
15/10/21 16:05:40 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:874
15/10/21 16:05:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (PythonRDD[5] at reduce at <ipython-input-6-1df081d8b441>:1)
15/10/21 16:05:40 INFO TaskSchedulerImpl: Adding task set 3.0 with 2 tasks
15/10/21 16:05:40 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 5, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:05:40 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 6, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:05:40 INFO Executor: Running task 0.0 in stage 3.0 (TID 5)
15/10/21 16:05:40 INFO Executor: Running task 1.0 in stage 3.0 (TID 6)
15/10/21 16:05:40 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 16:05:40 INFO PythonRDD: Times: total = 68, boot = 62, init = 5, finish = 1
15/10/21 16:05:40 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 16:05:40 INFO Executor: Finished task 0.0 in stage 3.0 (TID 5). 1870 bytes result sent to driver
15/10/21 16:05:40 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 5) in 136 ms on localhost (1/2)
15/10/21 16:05:40 INFO PythonRDD: Times: total = 127, boot = 121, init = 5, finish = 1
15/10/21 16:05:40 INFO Executor: Finished task 1.0 in stage 3.0 (TID 6). 1870 bytes result sent to driver
15/10/21 16:05:40 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 6) in 142 ms on localhost (2/2)
15/10/21 16:05:40 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
15/10/21 16:05:40 INFO DAGScheduler: ResultStage 3 (reduce at <ipython-input-6-1df081d8b441>:1) finished in 0.144 s
15/10/21 16:05:40 INFO DAGScheduler: Job 3 finished: reduce at <ipython-input-6-1df081d8b441>:1, took 0.160646 s
[I 16:05:45.135 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[I 16:05:56.210 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
15/10/21 16:06:26 INFO SparkContext: Starting job: reduce at <ipython-input-8-7ec28932a355>:1
15/10/21 16:06:26 INFO DAGScheduler: Got job 4 (reduce at <ipython-input-8-7ec28932a355>:1) with 2 output partitions (allowLocal=false)
15/10/21 16:06:26 INFO DAGScheduler: Final stage: ResultStage 4(reduce at <ipython-input-8-7ec28932a355>:1)
15/10/21 16:06:26 INFO DAGScheduler: Parents of final stage: List()
15/10/21 16:06:26 INFO DAGScheduler: Missing parents: List()
15/10/21 16:06:26 INFO DAGScheduler: Submitting ResultStage 4 (PythonRDD[6] at reduce at <ipython-input-8-7ec28932a355>:1), which has no missing parents
15/10/21 16:06:26 INFO MemoryStore: ensureFreeSpace(5992) called with curMem=209041, maxMem=278302556
15/10/21 16:06:26 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 5.9 KB, free 265.2 MB)
15/10/21 16:06:26 INFO MemoryStore: ensureFreeSpace(3605) called with curMem=215033, maxMem=278302556
15/10/21 16:06:26 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.5 KB, free 265.2 MB)
15/10/21 16:06:26 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:54908 (size: 3.5 KB, free: 265.4 MB)
15/10/21 16:06:26 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:874
15/10/21 16:06:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (PythonRDD[6] at reduce at <ipython-input-8-7ec28932a355>:1)
15/10/21 16:06:26 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks
15/10/21 16:06:26 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 7, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:06:26 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 8, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:06:26 INFO Executor: Running task 0.0 in stage 4.0 (TID 7)
15/10/21 16:06:26 INFO Executor: Running task 1.0 in stage 4.0 (TID 8)
15/10/21 16:06:26 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 16:06:26 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 16:06:26 INFO PythonRDD: Times: total = 39, boot = -45033, init = 45072, finish = 0
15/10/21 16:06:26 INFO PythonRDD: Times: total = 39, boot = -45095, init = 45134, finish = 0
15/10/21 16:06:26 INFO Executor: Finished task 0.0 in stage 4.0 (TID 7). 1870 bytes result sent to driver
15/10/21 16:06:26 INFO Executor: Finished task 1.0 in stage 4.0 (TID 8). 1870 bytes result sent to driver
15/10/21 16:06:26 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 7) in 57 ms on localhost (1/2)
15/10/21 16:06:26 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 8) in 56 ms on localhost (2/2)
15/10/21 16:06:26 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
15/10/21 16:06:26 INFO DAGScheduler: ResultStage 4 (reduce at <ipython-input-8-7ec28932a355>:1) finished in 0.058 s
15/10/21 16:06:26 INFO DAGScheduler: Job 4 finished: reduce at <ipython-input-8-7ec28932a355>:1, took 0.075159 s
15/10/21 16:06:40 INFO SparkContext: Starting job: collect at <ipython-input-10-be52ca2d5e05>:1
15/10/21 16:06:40 INFO DAGScheduler: Registering RDD 8 (reduceByKey at <ipython-input-9-fa54d2c9e6e8>:1)
15/10/21 16:06:40 INFO DAGScheduler: Got job 5 (collect at <ipython-input-10-be52ca2d5e05>:1) with 2 output partitions (allowLocal=false)
15/10/21 16:06:40 INFO DAGScheduler: Final stage: ResultStage 6(collect at <ipython-input-10-be52ca2d5e05>:1)
15/10/21 16:06:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
15/10/21 16:06:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
15/10/21 16:06:40 INFO DAGScheduler: Submitting ShuffleMapStage 5 (PairwiseRDD[8] at reduceByKey at <ipython-input-9-fa54d2c9e6e8>:1), which has no missing parents
15/10/21 16:06:41 INFO MemoryStore: ensureFreeSpace(8552) called with curMem=218638, maxMem=278302556
15/10/21 16:06:41 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 8.4 KB, free 265.2 MB)
15/10/21 16:06:41 INFO MemoryStore: ensureFreeSpace(5258) called with curMem=227190, maxMem=278302556
15/10/21 16:06:41 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.1 KB, free 265.2 MB)
15/10/21 16:06:41 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:54908 (size: 5.1 KB, free: 265.4 MB)
15/10/21 16:06:41 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:874
15/10/21 16:06:41 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 5 (PairwiseRDD[8] at reduceByKey at <ipython-input-9-fa54d2c9e6e8>:1)
15/10/21 16:06:41 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks
15/10/21 16:06:41 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 9, localhost, PROCESS_LOCAL, 1387 bytes)
15/10/21 16:06:41 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 10, localhost, PROCESS_LOCAL, 1387 bytes)
15/10/21 16:06:41 INFO Executor: Running task 0.0 in stage 5.0 (TID 9)
15/10/21 16:06:41 INFO Executor: Running task 1.0 in stage 5.0 (TID 10)
15/10/21 16:06:41 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 16:06:41 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 16:06:41 INFO PythonRDD: Times: total = 42, boot = -14908, init = 14948, finish = 2
15/10/21 16:06:41 INFO PythonRDD: Times: total = 42, boot = -14908, init = 14948, finish = 2
15/10/21 16:06:41 INFO Executor: Finished task 1.0 in stage 5.0 (TID 10). 2064 bytes result sent to driver
15/10/21 16:06:41 INFO Executor: Finished task 0.0 in stage 5.0 (TID 9). 2064 bytes result sent to driver
15/10/21 16:06:41 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 10) in 125 ms on localhost (1/2)
15/10/21 16:06:41 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 9) in 128 ms on localhost (2/2)
15/10/21 16:06:41 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
15/10/21 16:06:41 INFO DAGScheduler: ShuffleMapStage 5 (reduceByKey at <ipython-input-9-fa54d2c9e6e8>:1) finished in 0.131 s
15/10/21 16:06:41 INFO DAGScheduler: looking for newly runnable stages
15/10/21 16:06:41 INFO DAGScheduler: running: Set()
15/10/21 16:06:41 INFO DAGScheduler: waiting: Set(ResultStage 6)
15/10/21 16:06:41 INFO DAGScheduler: failed: Set()
15/10/21 16:06:41 INFO DAGScheduler: Missing parents for ResultStage 6: List()
15/10/21 16:06:41 INFO DAGScheduler: Submitting ResultStage 6 (PythonRDD[11] at collect at <ipython-input-10-be52ca2d5e05>:1), which is now runnable
15/10/21 16:06:41 INFO MemoryStore: ensureFreeSpace(5128) called with curMem=232448, maxMem=278302556
15/10/21 16:06:41 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 5.0 KB, free 265.2 MB)
15/10/21 16:06:41 INFO MemoryStore: ensureFreeSpace(3085) called with curMem=237576, maxMem=278302556
15/10/21 16:06:41 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.0 KB, free 265.2 MB)
15/10/21 16:06:41 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:54908 (size: 3.0 KB, free: 265.4 MB)
15/10/21 16:06:41 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:874
15/10/21 16:06:41 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 6 (PythonRDD[11] at collect at <ipython-input-10-be52ca2d5e05>:1)
15/10/21 16:06:41 INFO TaskSchedulerImpl: Adding task set 6.0 with 2 tasks
15/10/21 16:06:41 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 11, localhost, PROCESS_LOCAL, 1165 bytes)
15/10/21 16:06:41 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 12, localhost, PROCESS_LOCAL, 1165 bytes)
15/10/21 16:06:41 INFO Executor: Running task 0.0 in stage 6.0 (TID 11)
15/10/21 16:06:41 INFO Executor: Running task 1.0 in stage 6.0 (TID 12)
15/10/21 16:06:41 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/10/21 16:06:41 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/10/21 16:06:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
15/10/21 16:06:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
15/10/21 16:06:41 INFO PythonRDD: Times: total = 42, boot = -82, init = 123, finish = 1
15/10/21 16:06:41 INFO PythonRDD: Times: total = 42, boot = -82, init = 123, finish = 1
15/10/21 16:06:41 INFO Executor: Finished task 0.0 in stage 6.0 (TID 11). 3685 bytes result sent to driver
15/10/21 16:06:41 INFO Executor: Finished task 1.0 in stage 6.0 (TID 12). 3461 bytes result sent to driver
15/10/21 16:06:41 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 11) in 57 ms on localhost (1/2)
15/10/21 16:06:41 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 12) in 55 ms on localhost (2/2)
15/10/21 16:06:41 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
15/10/21 16:06:41 INFO DAGScheduler: ResultStage 6 (collect at <ipython-input-10-be52ca2d5e05>:1) finished in 0.058 s
15/10/21 16:06:41 INFO DAGScheduler: Job 5 finished: collect at <ipython-input-10-be52ca2d5e05>:1, took 0.245653 s
[I 16:07:56.417 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
15/10/21 16:08:33 INFO SparkContext: Starting job: count at <ipython-input-12-200488fe0ca6>:2
15/10/21 16:08:33 INFO DAGScheduler: Got job 6 (count at <ipython-input-12-200488fe0ca6>:2) with 2 output partitions (allowLocal=false)
15/10/21 16:08:33 INFO DAGScheduler: Final stage: ResultStage 7(count at <ipython-input-12-200488fe0ca6>:2)
15/10/21 16:08:33 INFO DAGScheduler: Parents of final stage: List()
15/10/21 16:08:33 INFO DAGScheduler: Missing parents: List()
15/10/21 16:08:33 INFO DAGScheduler: Submitting ResultStage 7 (PythonRDD[13] at count at <ipython-input-12-200488fe0ca6>:2), which has no missing parents
15/10/21 16:08:33 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=240661, maxMem=278302556
15/10/21 16:08:33 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 16:08:33 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=247669, maxMem=278302556
15/10/21 16:08:33 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 16:08:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 16:08:33 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:874
15/10/21 16:08:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 7 (PythonRDD[13] at count at <ipython-input-12-200488fe0ca6>:2)
15/10/21 16:08:33 INFO TaskSchedulerImpl: Adding task set 7.0 with 2 tasks
15/10/21 16:08:33 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 13, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:08:33 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 14, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:08:33 INFO Executor: Running task 0.0 in stage 7.0 (TID 13)
15/10/21 16:08:33 INFO Executor: Running task 1.0 in stage 7.0 (TID 14)
15/10/21 16:08:33 INFO CacheManager: Partition rdd_12_0 not found, computing it
15/10/21 16:08:33 INFO CacheManager: Partition rdd_12_1 not found, computing it
15/10/21 16:08:33 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 16:08:33 INFO PythonRDD: Times: total = 109, boot = 103, init = 5, finish = 1
15/10/21 16:08:33 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 16:08:33 INFO MemoryStore: ensureFreeSpace(682) called with curMem=251624, maxMem=278302556
15/10/21 16:08:33 INFO MemoryStore: Block rdd_12_0 stored as bytes in memory (estimated size 682.0 B, free 265.2 MB)
15/10/21 16:08:33 INFO BlockManagerInfo: Added rdd_12_0 in memory on localhost:54908 (size: 682.0 B, free: 265.4 MB)
15/10/21 16:08:33 INFO PythonRDD: Times: total = 232, boot = 62, init = 169, finish = 1
15/10/21 16:08:33 INFO PythonRDD: Times: total = 113, boot = 108, init = 4, finish = 1
15/10/21 16:08:33 INFO MemoryStore: ensureFreeSpace(497) called with curMem=252306, maxMem=278302556
15/10/21 16:08:33 INFO MemoryStore: Block rdd_12_1 stored as bytes in memory (estimated size 497.0 B, free 265.2 MB)
15/10/21 16:08:33 INFO Executor: Finished task 0.0 in stage 7.0 (TID 13). 2450 bytes result sent to driver
15/10/21 16:08:33 INFO BlockManagerInfo: Added rdd_12_1 in memory on localhost:54908 (size: 497.0 B, free: 265.4 MB)
15/10/21 16:08:33 INFO PythonRDD: Times: total = 237, boot = 116, init = 121, finish = 0
15/10/21 16:08:33 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 13) in 249 ms on localhost (1/2)
15/10/21 16:08:33 INFO Executor: Finished task 1.0 in stage 7.0 (TID 14). 2450 bytes result sent to driver
15/10/21 16:08:33 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 14) in 253 ms on localhost (2/2)
15/10/21 16:08:33 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
15/10/21 16:08:33 INFO DAGScheduler: ResultStage 7 (count at <ipython-input-12-200488fe0ca6>:2) finished in 0.255 s
15/10/21 16:08:33 INFO DAGScheduler: Job 6 finished: count at <ipython-input-12-200488fe0ca6>:2, took 0.272262 s
15/10/21 16:08:33 INFO SparkContext: Starting job: count at <ipython-input-12-200488fe0ca6>:3
15/10/21 16:08:33 INFO DAGScheduler: Got job 7 (count at <ipython-input-12-200488fe0ca6>:3) with 2 output partitions (allowLocal=false)
15/10/21 16:08:33 INFO DAGScheduler: Final stage: ResultStage 8(count at <ipython-input-12-200488fe0ca6>:3)
15/10/21 16:08:33 INFO DAGScheduler: Parents of final stage: List()
15/10/21 16:08:33 INFO DAGScheduler: Missing parents: List()
15/10/21 16:08:33 INFO DAGScheduler: Submitting ResultStage 8 (PythonRDD[14] at count at <ipython-input-12-200488fe0ca6>:3), which has no missing parents
15/10/21 16:08:33 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=252803, maxMem=278302556
15/10/21 16:08:33 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 16:08:33 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=259811, maxMem=278302556
15/10/21 16:08:33 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 16:08:33 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 16:08:33 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:874
15/10/21 16:08:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 8 (PythonRDD[14] at count at <ipython-input-12-200488fe0ca6>:3)
15/10/21 16:08:33 INFO TaskSchedulerImpl: Adding task set 8.0 with 2 tasks
15/10/21 16:08:33 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 15, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:08:33 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 16, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:08:33 INFO Executor: Running task 1.0 in stage 8.0 (TID 16)
15/10/21 16:08:33 INFO Executor: Running task 0.0 in stage 8.0 (TID 15)
15/10/21 16:08:33 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 16:08:33 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 16:08:33 INFO PythonRDD: Times: total = 40, boot = 10, init = 30, finish = 0
15/10/21 16:08:33 INFO PythonRDD: Times: total = 40, boot = -44, init = 84, finish = 0
15/10/21 16:08:33 INFO Executor: Finished task 0.0 in stage 8.0 (TID 15). 1870 bytes result sent to driver
15/10/21 16:08:33 INFO Executor: Finished task 1.0 in stage 8.0 (TID 16). 1870 bytes result sent to driver
15/10/21 16:08:33 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 15) in 54 ms on localhost (1/2)
15/10/21 16:08:33 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 16) in 53 ms on localhost (2/2)
15/10/21 16:08:33 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
15/10/21 16:08:33 INFO DAGScheduler: ResultStage 8 (count at <ipython-input-12-200488fe0ca6>:3) finished in 0.055 s
15/10/21 16:08:33 INFO DAGScheduler: Job 7 finished: count at <ipython-input-12-200488fe0ca6>:3, took 0.074187 s
15/10/21 16:08:52 INFO SparkContext: Starting job: count at <ipython-input-13-5b1ea19347b0>:2
15/10/21 16:08:52 INFO DAGScheduler: Got job 8 (count at <ipython-input-13-5b1ea19347b0>:2) with 2 output partitions (allowLocal=false)
15/10/21 16:08:52 INFO DAGScheduler: Final stage: ResultStage 9(count at <ipython-input-13-5b1ea19347b0>:2)
15/10/21 16:08:52 INFO DAGScheduler: Parents of final stage: List()
15/10/21 16:08:52 INFO DAGScheduler: Missing parents: List()
15/10/21 16:08:52 INFO DAGScheduler: Submitting ResultStage 9 (PythonRDD[15] at count at <ipython-input-13-5b1ea19347b0>:2), which has no missing parents
15/10/21 16:08:52 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=263766, maxMem=278302556
15/10/21 16:08:52 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 16:08:52 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=270774, maxMem=278302556
15/10/21 16:08:52 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 16:08:52 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 16:08:52 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:874
15/10/21 16:08:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 9 (PythonRDD[15] at count at <ipython-input-13-5b1ea19347b0>:2)
15/10/21 16:08:52 INFO TaskSchedulerImpl: Adding task set 9.0 with 2 tasks
15/10/21 16:08:52 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 17, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:08:52 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 18, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:08:52 INFO Executor: Running task 0.0 in stage 9.0 (TID 17)
15/10/21 16:08:52 INFO Executor: Running task 1.0 in stage 9.0 (TID 18)
15/10/21 16:08:52 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 16:08:52 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 16:08:52 INFO PythonRDD: Times: total = 39, boot = -18779, init = 18818, finish = 0
15/10/21 16:08:52 INFO PythonRDD: Times: total = 39, boot = -18781, init = 18820, finish = 0
15/10/21 16:08:52 INFO Executor: Finished task 1.0 in stage 9.0 (TID 18). 1870 bytes result sent to driver
15/10/21 16:08:52 INFO Executor: Finished task 0.0 in stage 9.0 (TID 17). 1870 bytes result sent to driver
15/10/21 16:08:52 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 18) in 52 ms on localhost (1/2)
15/10/21 16:08:52 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 17) in 53 ms on localhost (2/2)
15/10/21 16:08:52 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
15/10/21 16:08:52 INFO DAGScheduler: ResultStage 9 (count at <ipython-input-13-5b1ea19347b0>:2) finished in 0.055 s
15/10/21 16:08:52 INFO DAGScheduler: Job 8 finished: count at <ipython-input-13-5b1ea19347b0>:2, took 0.069617 s
15/10/21 16:08:53 INFO SparkContext: Starting job: count at <ipython-input-14-0c6978752e26>:1
15/10/21 16:08:53 INFO DAGScheduler: Got job 9 (count at <ipython-input-14-0c6978752e26>:1) with 2 output partitions (allowLocal=false)
15/10/21 16:08:53 INFO DAGScheduler: Final stage: ResultStage 10(count at <ipython-input-14-0c6978752e26>:1)
15/10/21 16:08:53 INFO DAGScheduler: Parents of final stage: List()
15/10/21 16:08:53 INFO DAGScheduler: Missing parents: List()
15/10/21 16:08:53 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[16] at count at <ipython-input-14-0c6978752e26>:1), which has no missing parents
15/10/21 16:08:53 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=274729, maxMem=278302556
15/10/21 16:08:53 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 16:08:53 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=281737, maxMem=278302556
15/10/21 16:08:53 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 16:08:53 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 16:08:53 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:874
15/10/21 16:08:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 10 (PythonRDD[16] at count at <ipython-input-14-0c6978752e26>:1)
15/10/21 16:08:53 INFO TaskSchedulerImpl: Adding task set 10.0 with 2 tasks
15/10/21 16:08:53 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 19, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:08:53 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 20, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:08:53 INFO Executor: Running task 1.0 in stage 10.0 (TID 20)
15/10/21 16:08:53 INFO Executor: Running task 0.0 in stage 10.0 (TID 19)
15/10/21 16:08:53 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 16:08:53 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 16:08:53 INFO PythonRDD: Times: total = 41, boot = -20330, init = 20371, finish = 0
15/10/21 16:08:53 INFO PythonRDD: Times: total = 41, boot = -20330, init = 20371, finish = 0
15/10/21 16:08:53 INFO Executor: Finished task 0.0 in stage 10.0 (TID 19). 1870 bytes result sent to driver
15/10/21 16:08:53 INFO Executor: Finished task 1.0 in stage 10.0 (TID 20). 1870 bytes result sent to driver
15/10/21 16:08:53 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 19) in 55 ms on localhost (1/2)
15/10/21 16:08:53 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 20) in 54 ms on localhost (2/2)
15/10/21 16:08:53 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
15/10/21 16:08:53 INFO DAGScheduler: ResultStage 10 (count at <ipython-input-14-0c6978752e26>:1) finished in 0.056 s
15/10/21 16:08:53 INFO DAGScheduler: Job 9 finished: count at <ipython-input-14-0c6978752e26>:1, took 0.071979 s
15/10/21 16:09:47 INFO SparkContext: Starting job: count at <ipython-input-17-3ab3328dbde5>:3
15/10/21 16:09:47 INFO DAGScheduler: Got job 10 (count at <ipython-input-17-3ab3328dbde5>:3) with 2 output partitions (allowLocal=false)
15/10/21 16:09:47 INFO DAGScheduler: Final stage: ResultStage 11(count at <ipython-input-17-3ab3328dbde5>:3)
15/10/21 16:09:47 INFO DAGScheduler: Parents of final stage: List()
15/10/21 16:09:47 INFO DAGScheduler: Missing parents: List()
15/10/21 16:09:47 INFO DAGScheduler: Submitting ResultStage 11 (PythonRDD[17] at count at <ipython-input-17-3ab3328dbde5>:3), which has no missing parents
15/10/21 16:09:47 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=285692, maxMem=278302556
15/10/21 16:09:47 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 16:09:47 INFO MemoryStore: ensureFreeSpace(3953) called with curMem=292700, maxMem=278302556
15/10/21 16:09:47 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 16:09:47 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 16:09:47 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:874
15/10/21 16:09:47 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 11 (PythonRDD[17] at count at <ipython-input-17-3ab3328dbde5>:3)
15/10/21 16:09:47 INFO TaskSchedulerImpl: Adding task set 11.0 with 2 tasks
15/10/21 16:09:47 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 21, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:09:47 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 22, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:09:47 INFO Executor: Running task 1.0 in stage 11.0 (TID 22)
15/10/21 16:09:47 INFO Executor: Running task 0.0 in stage 11.0 (TID 21)
15/10/21 16:09:47 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 16:09:47 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 16:09:47 INFO PythonRDD: Times: total = 37, boot = -55194, init = 55231, finish = 0
15/10/21 16:09:47 INFO Executor: Finished task 1.0 in stage 11.0 (TID 22). 1870 bytes result sent to driver
15/10/21 16:09:47 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 22) in 48 ms on localhost (1/2)
15/10/21 16:09:47 INFO PythonRDD: Times: total = 45, boot = -55195, init = 55240, finish = 0
15/10/21 16:09:47 INFO Executor: Finished task 0.0 in stage 11.0 (TID 21). 1870 bytes result sent to driver
15/10/21 16:09:47 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 21) in 57 ms on localhost (2/2)
15/10/21 16:09:47 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
15/10/21 16:09:47 INFO DAGScheduler: ResultStage 11 (count at <ipython-input-17-3ab3328dbde5>:3) finished in 0.057 s
15/10/21 16:09:47 INFO DAGScheduler: Job 10 finished: count at <ipython-input-17-3ab3328dbde5>:3, took 0.073367 s
[I 16:09:56.698 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
15/10/21 16:10:01 INFO SparkContext: Starting job: count at <ipython-input-18-3ceff9534ef9>:3
15/10/21 16:10:01 INFO DAGScheduler: Got job 11 (count at <ipython-input-18-3ceff9534ef9>:3) with 2 output partitions (allowLocal=false)
15/10/21 16:10:01 INFO DAGScheduler: Final stage: ResultStage 12(count at <ipython-input-18-3ceff9534ef9>:3)
15/10/21 16:10:01 INFO DAGScheduler: Parents of final stage: List()
15/10/21 16:10:01 INFO DAGScheduler: Missing parents: List()
15/10/21 16:10:01 INFO DAGScheduler: Submitting ResultStage 12 (PythonRDD[18] at count at <ipython-input-18-3ceff9534ef9>:3), which has no missing parents
15/10/21 16:10:01 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=296653, maxMem=278302556
15/10/21 16:10:01 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 16:10:01 INFO MemoryStore: ensureFreeSpace(3953) called with curMem=303661, maxMem=278302556
15/10/21 16:10:01 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 16:10:01 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 16:10:01 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:874
15/10/21 16:10:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 12 (PythonRDD[18] at count at <ipython-input-18-3ceff9534ef9>:3)
15/10/21 16:10:01 INFO TaskSchedulerImpl: Adding task set 12.0 with 2 tasks
15/10/21 16:10:01 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 23, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:10:01 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 24, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:10:01 INFO Executor: Running task 0.0 in stage 12.0 (TID 23)
15/10/21 16:10:01 INFO Executor: Running task 1.0 in stage 12.0 (TID 24)
15/10/21 16:10:01 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 16:10:01 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 16:10:02 INFO PythonRDD: Times: total = 40, boot = -68095, init = 68135, finish = 0
15/10/21 16:10:02 INFO PythonRDD: Times: total = 40, boot = -68095, init = 68135, finish = 0
15/10/21 16:10:02 INFO Executor: Finished task 0.0 in stage 12.0 (TID 23). 1870 bytes result sent to driver
15/10/21 16:10:02 INFO Executor: Finished task 1.0 in stage 12.0 (TID 24). 1870 bytes result sent to driver
15/10/21 16:10:02 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 23) in 52 ms on localhost (1/2)
15/10/21 16:10:02 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 24) in 52 ms on localhost (2/2)
15/10/21 16:10:02 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
15/10/21 16:10:02 INFO DAGScheduler: ResultStage 12 (count at <ipython-input-18-3ceff9534ef9>:3) finished in 0.054 s
15/10/21 16:10:02 INFO DAGScheduler: Job 11 finished: count at <ipython-input-18-3ceff9534ef9>:3, took 0.069605 s
15/10/21 16:10:19 INFO SparkContext: Starting job: count at <ipython-input-19-954b403175aa>:3
15/10/21 16:10:19 INFO DAGScheduler: Got job 12 (count at <ipython-input-19-954b403175aa>:3) with 2 output partitions (allowLocal=false)
15/10/21 16:10:19 INFO DAGScheduler: Final stage: ResultStage 13(count at <ipython-input-19-954b403175aa>:3)
15/10/21 16:10:19 INFO DAGScheduler: Parents of final stage: List()
15/10/21 16:10:19 INFO DAGScheduler: Missing parents: List()
15/10/21 16:10:19 INFO DAGScheduler: Submitting ResultStage 13 (PythonRDD[19] at count at <ipython-input-19-954b403175aa>:3), which has no missing parents
15/10/21 16:10:19 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=307614, maxMem=278302556
15/10/21 16:10:19 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 16:10:19 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=314622, maxMem=278302556
15/10/21 16:10:19 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 16:10:19 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 16:10:19 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:874
15/10/21 16:10:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 13 (PythonRDD[19] at count at <ipython-input-19-954b403175aa>:3)
15/10/21 16:10:19 INFO TaskSchedulerImpl: Adding task set 13.0 with 2 tasks
15/10/21 16:10:19 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 25, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:10:19 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 26, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:10:19 INFO Executor: Running task 1.0 in stage 13.0 (TID 26)
15/10/21 16:10:19 INFO Executor: Running task 0.0 in stage 13.0 (TID 25)
15/10/21 16:10:19 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 16:10:19 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 16:10:19 INFO PythonRDD: Times: total = 40, boot = -32307, init = 32347, finish = 0
15/10/21 16:10:19 INFO PythonRDD: Times: total = 39, boot = -32300, init = 32339, finish = 0
15/10/21 16:10:19 INFO Executor: Finished task 1.0 in stage 13.0 (TID 26). 1870 bytes result sent to driver
15/10/21 16:10:19 INFO Executor: Finished task 0.0 in stage 13.0 (TID 25). 1870 bytes result sent to driver
15/10/21 16:10:19 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 26) in 51 ms on localhost (1/2)
15/10/21 16:10:19 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 25) in 53 ms on localhost (2/2)
15/10/21 16:10:19 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
15/10/21 16:10:19 INFO DAGScheduler: ResultStage 13 (count at <ipython-input-19-954b403175aa>:3) finished in 0.053 s
15/10/21 16:10:19 INFO DAGScheduler: Job 12 finished: count at <ipython-input-19-954b403175aa>:3, took 0.068028 s
15/10/21 16:11:03 INFO PythonRDD: Removing RDD 12 from persistence list
15/10/21 16:11:03 INFO BlockManager: Removing RDD 12
15/10/21 16:11:06 INFO SparkContext: Starting job: count at <ipython-input-21-954b403175aa>:3
15/10/21 16:11:06 INFO DAGScheduler: Got job 13 (count at <ipython-input-21-954b403175aa>:3) with 2 output partitions (allowLocal=false)
15/10/21 16:11:06 INFO DAGScheduler: Final stage: ResultStage 14(count at <ipython-input-21-954b403175aa>:3)
15/10/21 16:11:06 INFO DAGScheduler: Parents of final stage: List()
15/10/21 16:11:06 INFO DAGScheduler: Missing parents: List()
15/10/21 16:11:06 INFO DAGScheduler: Submitting ResultStage 14 (PythonRDD[20] at count at <ipython-input-21-954b403175aa>:3), which has no missing parents
15/10/21 16:11:06 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=317398, maxMem=278302556
15/10/21 16:11:06 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 16:11:06 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=324406, maxMem=278302556
15/10/21 16:11:06 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 16:11:06 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 16:11:06 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:874
15/10/21 16:11:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 14 (PythonRDD[20] at count at <ipython-input-21-954b403175aa>:3)
15/10/21 16:11:06 INFO TaskSchedulerImpl: Adding task set 14.0 with 2 tasks
15/10/21 16:11:06 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 27, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:11:06 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 28, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:11:06 INFO Executor: Running task 0.0 in stage 14.0 (TID 27)
15/10/21 16:11:06 INFO Executor: Running task 1.0 in stage 14.0 (TID 28)
15/10/21 16:11:06 INFO CacheManager: Partition rdd_12_0 not found, computing it
15/10/21 16:11:06 INFO CacheManager: Partition rdd_12_1 not found, computing it
15/10/21 16:11:06 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 16:11:06 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 16:11:06 INFO PythonRDD: Times: total = 38, boot = -46394, init = 46432, finish = 0
15/10/21 16:11:06 INFO PythonRDD: Times: total = 39, boot = -46393, init = 46432, finish = 0
15/10/21 16:11:06 INFO MemoryStore: ensureFreeSpace(497) called with curMem=328361, maxMem=278302556
15/10/21 16:11:06 INFO MemoryStore: Block rdd_12_1 stored as bytes in memory (estimated size 497.0 B, free 265.1 MB)
15/10/21 16:11:06 INFO MemoryStore: ensureFreeSpace(682) called with curMem=328858, maxMem=278302556
15/10/21 16:11:06 INFO BlockManagerInfo: Added rdd_12_1 in memory on localhost:54908 (size: 497.0 B, free: 265.3 MB)
15/10/21 16:11:06 INFO MemoryStore: Block rdd_12_0 stored as bytes in memory (estimated size 682.0 B, free 265.1 MB)
15/10/21 16:11:06 INFO PythonRDD: Times: total = 45, boot = -64256, init = 64301, finish = 0
15/10/21 16:11:06 INFO BlockManagerInfo: Added rdd_12_0 in memory on localhost:54908 (size: 682.0 B, free: 265.3 MB)
15/10/21 16:11:06 INFO PythonRDD: Times: total = 47, boot = -64256, init = 64303, finish = 0
15/10/21 16:11:06 INFO Executor: Finished task 1.0 in stage 14.0 (TID 28). 2450 bytes result sent to driver
15/10/21 16:11:06 INFO Executor: Finished task 0.0 in stage 14.0 (TID 27). 2450 bytes result sent to driver
15/10/21 16:11:06 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 28) in 57 ms on localhost (1/2)
15/10/21 16:11:06 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 27) in 58 ms on localhost (2/2)
15/10/21 16:11:06 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
15/10/21 16:11:06 INFO DAGScheduler: ResultStage 14 (count at <ipython-input-21-954b403175aa>:3) finished in 0.060 s
15/10/21 16:11:06 INFO DAGScheduler: Job 13 finished: count at <ipython-input-21-954b403175aa>:3, took 0.075695 s
15/10/21 16:11:17 INFO SparkContext: Starting job: count at <ipython-input-22-d1479026ea1a>:2
15/10/21 16:11:17 INFO DAGScheduler: Got job 14 (count at <ipython-input-22-d1479026ea1a>:2) with 2 output partitions (allowLocal=false)
15/10/21 16:11:17 INFO DAGScheduler: Final stage: ResultStage 15(count at <ipython-input-22-d1479026ea1a>:2)
15/10/21 16:11:17 INFO DAGScheduler: Parents of final stage: List()
15/10/21 16:11:17 INFO DAGScheduler: Missing parents: List()
15/10/21 16:11:17 INFO DAGScheduler: Submitting ResultStage 15 (PythonRDD[21] at count at <ipython-input-22-d1479026ea1a>:2), which has no missing parents
15/10/21 16:11:17 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=329540, maxMem=278302556
15/10/21 16:11:17 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 16:11:17 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=336548, maxMem=278302556
15/10/21 16:11:17 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 16:11:17 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 16:11:17 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:874
15/10/21 16:11:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 15 (PythonRDD[21] at count at <ipython-input-22-d1479026ea1a>:2)
15/10/21 16:11:17 INFO TaskSchedulerImpl: Adding task set 15.0 with 2 tasks
15/10/21 16:11:17 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 29, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:11:17 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 30, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:11:17 INFO Executor: Running task 0.0 in stage 15.0 (TID 29)
15/10/21 16:11:17 INFO Executor: Running task 1.0 in stage 15.0 (TID 30)
15/10/21 16:11:17 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 16:11:17 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 16:11:17 INFO PythonRDD: Times: total = 39, boot = -11348, init = 11387, finish = 0
15/10/21 16:11:17 INFO PythonRDD: Times: total = 40, boot = -11350, init = 11390, finish = 0
15/10/21 16:11:17 INFO Executor: Finished task 1.0 in stage 15.0 (TID 30). 1870 bytes result sent to driver
15/10/21 16:11:17 INFO Executor: Finished task 0.0 in stage 15.0 (TID 29). 1870 bytes result sent to driver
15/10/21 16:11:17 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 30) in 50 ms on localhost (1/2)
15/10/21 16:11:17 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 29) in 52 ms on localhost (2/2)
15/10/21 16:11:17 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
15/10/21 16:11:17 INFO DAGScheduler: ResultStage 15 (count at <ipython-input-22-d1479026ea1a>:2) finished in 0.053 s
15/10/21 16:11:17 INFO DAGScheduler: Job 14 finished: count at <ipython-input-22-d1479026ea1a>:2, took 0.068377 s
15/10/21 16:11:20 INFO SparkContext: Starting job: count at <ipython-input-23-d1479026ea1a>:2
15/10/21 16:11:20 INFO DAGScheduler: Got job 15 (count at <ipython-input-23-d1479026ea1a>:2) with 2 output partitions (allowLocal=false)
15/10/21 16:11:20 INFO DAGScheduler: Final stage: ResultStage 16(count at <ipython-input-23-d1479026ea1a>:2)
15/10/21 16:11:20 INFO DAGScheduler: Parents of final stage: List()
15/10/21 16:11:20 INFO DAGScheduler: Missing parents: List()
15/10/21 16:11:20 INFO DAGScheduler: Submitting ResultStage 16 (PythonRDD[22] at count at <ipython-input-23-d1479026ea1a>:2), which has no missing parents
15/10/21 16:11:20 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=340503, maxMem=278302556
15/10/21 16:11:20 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 16:11:20 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=347511, maxMem=278302556
15/10/21 16:11:20 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 16:11:20 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 16:11:20 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:874
15/10/21 16:11:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 16 (PythonRDD[22] at count at <ipython-input-23-d1479026ea1a>:2)
15/10/21 16:11:20 INFO TaskSchedulerImpl: Adding task set 16.0 with 2 tasks
15/10/21 16:11:20 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 16:11:20 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 31, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:11:20 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 32, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:11:20 INFO Executor: Running task 0.0 in stage 16.0 (TID 31)
15/10/21 16:11:20 INFO Executor: Running task 1.0 in stage 16.0 (TID 32)
15/10/21 16:11:20 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 16:11:20 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 16:11:20 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 16:11:20 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 16:11:20 INFO BlockManagerInfo: Removed broadcast_13_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 16:11:20 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 16:11:20 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 16:11:20 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 16:11:20 INFO BlockManagerInfo: Removed broadcast_9_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 16:11:20 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 16:11:20 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:54908 in memory (size: 3.0 KB, free: 265.4 MB)
15/10/21 16:11:20 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:54908 in memory (size: 5.1 KB, free: 265.4 MB)
15/10/21 16:11:20 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:54908 in memory (size: 3.5 KB, free: 265.4 MB)
15/10/21 16:11:20 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:54908 in memory (size: 3.5 KB, free: 265.4 MB)
15/10/21 16:11:20 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 16:11:20 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:54908 in memory (size: 3.0 KB, free: 265.4 MB)
15/10/21 16:11:20 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:54908 in memory (size: 3.5 KB, free: 265.4 MB)
15/10/21 16:11:20 INFO PythonRDD: Times: total = 39, boot = -14508, init = 14547, finish = 0
15/10/21 16:11:20 INFO PythonRDD: Times: total = 38, boot = -14508, init = 14546, finish = 0
15/10/21 16:11:20 INFO Executor: Finished task 1.0 in stage 16.0 (TID 32). 1870 bytes result sent to driver
15/10/21 16:11:20 INFO Executor: Finished task 0.0 in stage 16.0 (TID 31). 1870 bytes result sent to driver
15/10/21 16:11:20 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 32) in 50 ms on localhost (1/2)
15/10/21 16:11:20 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 31) in 51 ms on localhost (2/2)
15/10/21 16:11:20 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
15/10/21 16:11:20 INFO DAGScheduler: ResultStage 16 (count at <ipython-input-23-d1479026ea1a>:2) finished in 0.052 s
15/10/21 16:11:20 INFO DAGScheduler: Job 15 finished: count at <ipython-input-23-d1479026ea1a>:2, took 0.089403 s
15/10/21 16:11:23 INFO SparkContext: Starting job: count at <ipython-input-24-d1479026ea1a>:2
15/10/21 16:11:23 INFO DAGScheduler: Got job 16 (count at <ipython-input-24-d1479026ea1a>:2) with 2 output partitions (allowLocal=false)
15/10/21 16:11:23 INFO DAGScheduler: Final stage: ResultStage 17(count at <ipython-input-24-d1479026ea1a>:2)
15/10/21 16:11:23 INFO DAGScheduler: Parents of final stage: List()
15/10/21 16:11:23 INFO DAGScheduler: Missing parents: List()
15/10/21 16:11:23 INFO DAGScheduler: Submitting ResultStage 17 (PythonRDD[23] at count at <ipython-input-24-d1479026ea1a>:2), which has no missing parents
15/10/21 16:11:23 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=183647, maxMem=278302556
15/10/21 16:11:23 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 16:11:23 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=190655, maxMem=278302556
15/10/21 16:11:23 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 16:11:23 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 16:11:23 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:874
15/10/21 16:11:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 17 (PythonRDD[23] at count at <ipython-input-24-d1479026ea1a>:2)
15/10/21 16:11:23 INFO TaskSchedulerImpl: Adding task set 17.0 with 2 tasks
15/10/21 16:11:23 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 33, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:11:23 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 34, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:11:23 INFO Executor: Running task 0.0 in stage 17.0 (TID 33)
15/10/21 16:11:23 INFO Executor: Running task 1.0 in stage 17.0 (TID 34)
15/10/21 16:11:23 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 16:11:23 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 16:11:23 INFO PythonRDD: Times: total = 39, boot = -5692, init = 5731, finish = 0
15/10/21 16:11:23 INFO PythonRDD: Times: total = 40, boot = -5692, init = 5732, finish = 0
15/10/21 16:11:23 INFO Executor: Finished task 1.0 in stage 17.0 (TID 34). 1870 bytes result sent to driver
15/10/21 16:11:23 INFO Executor: Finished task 0.0 in stage 17.0 (TID 33). 1870 bytes result sent to driver
15/10/21 16:11:23 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 34) in 50 ms on localhost (1/2)
15/10/21 16:11:23 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 33) in 51 ms on localhost (2/2)
15/10/21 16:11:23 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
15/10/21 16:11:23 INFO DAGScheduler: ResultStage 17 (count at <ipython-input-24-d1479026ea1a>:2) finished in 0.053 s
15/10/21 16:11:23 INFO DAGScheduler: Job 16 finished: count at <ipython-input-24-d1479026ea1a>:2, took 0.067366 s
15/10/21 16:11:25 INFO PythonRDD: Removing RDD 12 from persistence list
15/10/21 16:11:25 INFO BlockManager: Removing RDD 12
15/10/21 16:11:27 INFO SparkContext: Starting job: count at <ipython-input-26-d1479026ea1a>:2
15/10/21 16:11:27 INFO DAGScheduler: Got job 17 (count at <ipython-input-26-d1479026ea1a>:2) with 2 output partitions (allowLocal=false)
15/10/21 16:11:27 INFO DAGScheduler: Final stage: ResultStage 18(count at <ipython-input-26-d1479026ea1a>:2)
15/10/21 16:11:27 INFO DAGScheduler: Parents of final stage: List()
15/10/21 16:11:27 INFO DAGScheduler: Missing parents: List()
15/10/21 16:11:27 INFO DAGScheduler: Submitting ResultStage 18 (PythonRDD[24] at count at <ipython-input-26-d1479026ea1a>:2), which has no missing parents
15/10/21 16:11:27 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=193431, maxMem=278302556
15/10/21 16:11:27 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 16:11:27 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=200439, maxMem=278302556
15/10/21 16:11:27 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 16:11:27 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 16:11:27 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:874
15/10/21 16:11:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 18 (PythonRDD[24] at count at <ipython-input-26-d1479026ea1a>:2)
15/10/21 16:11:27 INFO TaskSchedulerImpl: Adding task set 18.0 with 2 tasks
15/10/21 16:11:27 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 35, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:11:27 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 36, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:11:27 INFO Executor: Running task 0.0 in stage 18.0 (TID 35)
15/10/21 16:11:27 INFO Executor: Running task 1.0 in stage 18.0 (TID 36)
15/10/21 16:11:27 INFO CacheManager: Partition rdd_12_0 not found, computing it
15/10/21 16:11:27 INFO CacheManager: Partition rdd_12_1 not found, computing it
15/10/21 16:11:27 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 16:11:27 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 16:11:27 INFO PythonRDD: Times: total = 39, boot = -4091, init = 4130, finish = 0
15/10/21 16:11:27 INFO PythonRDD: Times: total = 39, boot = -4091, init = 4130, finish = 0
15/10/21 16:11:27 INFO MemoryStore: ensureFreeSpace(497) called with curMem=204394, maxMem=278302556
15/10/21 16:11:27 INFO MemoryStore: Block rdd_12_1 stored as bytes in memory (estimated size 497.0 B, free 265.2 MB)
15/10/21 16:11:27 INFO MemoryStore: ensureFreeSpace(682) called with curMem=204891, maxMem=278302556
15/10/21 16:11:27 INFO MemoryStore: Block rdd_12_0 stored as bytes in memory (estimated size 682.0 B, free 265.2 MB)
15/10/21 16:11:27 INFO BlockManagerInfo: Added rdd_12_1 in memory on localhost:54908 (size: 497.0 B, free: 265.4 MB)
15/10/21 16:11:27 INFO PythonRDD: Times: total = 45, boot = -6686, init = 6731, finish = 0
15/10/21 16:11:27 INFO BlockManagerInfo: Added rdd_12_0 in memory on localhost:54908 (size: 682.0 B, free: 265.4 MB)
15/10/21 16:11:27 INFO PythonRDD: Times: total = 47, boot = -6685, init = 6732, finish = 0
15/10/21 16:11:27 INFO Executor: Finished task 1.0 in stage 18.0 (TID 36). 2450 bytes result sent to driver
15/10/21 16:11:27 INFO Executor: Finished task 0.0 in stage 18.0 (TID 35). 2450 bytes result sent to driver
15/10/21 16:11:27 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 36) in 59 ms on localhost (1/2)
15/10/21 16:11:27 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 35) in 61 ms on localhost (2/2)
15/10/21 16:11:27 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
15/10/21 16:11:27 INFO DAGScheduler: ResultStage 18 (count at <ipython-input-26-d1479026ea1a>:2) finished in 0.062 s
15/10/21 16:11:27 INFO DAGScheduler: Job 17 finished: count at <ipython-input-26-d1479026ea1a>:2, took 0.079816 s
15/10/21 16:11:29 INFO SparkContext: Starting job: count at <ipython-input-27-d1479026ea1a>:2
15/10/21 16:11:29 INFO DAGScheduler: Got job 18 (count at <ipython-input-27-d1479026ea1a>:2) with 2 output partitions (allowLocal=false)
15/10/21 16:11:29 INFO DAGScheduler: Final stage: ResultStage 19(count at <ipython-input-27-d1479026ea1a>:2)
15/10/21 16:11:29 INFO DAGScheduler: Parents of final stage: List()
15/10/21 16:11:29 INFO DAGScheduler: Missing parents: List()
15/10/21 16:11:29 INFO DAGScheduler: Submitting ResultStage 19 (PythonRDD[25] at count at <ipython-input-27-d1479026ea1a>:2), which has no missing parents
15/10/21 16:11:29 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=205573, maxMem=278302556
15/10/21 16:11:29 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 16:11:29 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=212581, maxMem=278302556
15/10/21 16:11:29 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 16:11:29 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 16:11:29 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:874
15/10/21 16:11:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 19 (PythonRDD[25] at count at <ipython-input-27-d1479026ea1a>:2)
15/10/21 16:11:29 INFO TaskSchedulerImpl: Adding task set 19.0 with 2 tasks
15/10/21 16:11:29 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 37, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:11:29 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 38, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 16:11:29 INFO Executor: Running task 0.0 in stage 19.0 (TID 37)
15/10/21 16:11:29 INFO Executor: Running task 1.0 in stage 19.0 (TID 38)
15/10/21 16:11:29 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 16:11:29 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 16:11:29 INFO PythonRDD: Times: total = 41, boot = -1957, init = 1998, finish = 0
15/10/21 16:11:29 INFO Executor: Finished task 0.0 in stage 19.0 (TID 37). 1870 bytes result sent to driver
15/10/21 16:11:29 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 37) in 51 ms on localhost (1/2)
15/10/21 16:11:29 INFO PythonRDD: Times: total = 44, boot = -1959, init = 2003, finish = 0
15/10/21 16:11:29 INFO Executor: Finished task 1.0 in stage 19.0 (TID 38). 1870 bytes result sent to driver
15/10/21 16:11:29 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 38) in 54 ms on localhost (2/2)
15/10/21 16:11:29 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
15/10/21 16:11:29 INFO DAGScheduler: ResultStage 19 (count at <ipython-input-27-d1479026ea1a>:2) finished in 0.056 s
15/10/21 16:11:29 INFO DAGScheduler: Job 18 finished: count at <ipython-input-27-d1479026ea1a>:2, took 0.073540 s
[I 16:11:56.649 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
15/10/21 16:13:16 INFO PythonRDD: Removing RDD 12 from persistence list
15/10/21 16:13:16 INFO BlockManager: Removing RDD 12
15/10/21 16:13:18 INFO PythonRDD: Removing RDD 12 from persistence list
15/10/21 16:13:18 INFO BlockManager: Removing RDD 12
15/10/21 16:13:21 INFO PythonRDD: Removing RDD 12 from persistence list
15/10/21 16:13:21 INFO BlockManager: Removing RDD 12
[I 16:13:56.381 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[I 16:16:03.135 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[I 16:55:41.657 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[I 16:57:42.438 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
15/10/21 16:58:23 INFO PythonRDD: Removing RDD 12 from persistence list
15/10/21 16:58:23 INFO BlockManager: Removing RDD 12
[I 16:59:41.808 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
15/10/21 17:00:00 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:00 INFO DAGScheduler: Got job 19 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:00 INFO DAGScheduler: Final stage: ResultStage 20(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:00 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:00 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:00 INFO DAGScheduler: Submitting ResultStage 20 (PythonRDD[26] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:00 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=215357, maxMem=278302556
15/10/21 17:00:00 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:00 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=221749, maxMem=278302556
15/10/21 17:00:00 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:00 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:00 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 20 (PythonRDD[26] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:00 INFO TaskSchedulerImpl: Adding task set 20.0 with 2 tasks
15/10/21 17:00:00 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 39, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:00 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 40, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:00 INFO Executor: Running task 0.0 in stage 20.0 (TID 39)
15/10/21 17:00:00 INFO Executor: Running task 1.0 in stage 20.0 (TID 40)
15/10/21 17:00:01 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:01 INFO PythonRDD: Times: total = 67, boot = 61, init = 6, finish = 0
15/10/21 17:00:01 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:01 INFO Executor: Finished task 0.0 in stage 20.0 (TID 39). 1870 bytes result sent to driver
15/10/21 17:00:01 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 39) in 130 ms on localhost (1/2)
15/10/21 17:00:01 INFO PythonRDD: Times: total = 126, boot = 120, init = 5, finish = 1
15/10/21 17:00:01 INFO Executor: Finished task 1.0 in stage 20.0 (TID 40). 1870 bytes result sent to driver
15/10/21 17:00:01 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 40) in 136 ms on localhost (2/2)
15/10/21 17:00:01 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
15/10/21 17:00:01 INFO DAGScheduler: ResultStage 20 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.138 s
15/10/21 17:00:01 INFO DAGScheduler: Job 19 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.152332 s
15/10/21 17:00:04 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:04 INFO DAGScheduler: Got job 20 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:04 INFO DAGScheduler: Final stage: ResultStage 21(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:04 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:04 INFO DAGScheduler: Submitting ResultStage 21 (PythonRDD[27] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=225554, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=231946, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:04 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 21 (PythonRDD[27] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Adding task set 21.0 with 2 tasks
15/10/21 17:00:04 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 41, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 42, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO Executor: Running task 0.0 in stage 21.0 (TID 41)
15/10/21 17:00:04 INFO Executor: Running task 1.0 in stage 21.0 (TID 42)
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:04 INFO PythonRDD: Times: total = 38, boot = -2907, init = 2945, finish = 0
15/10/21 17:00:04 INFO PythonRDD: Times: total = 38, boot = -2966, init = 3004, finish = 0
15/10/21 17:00:04 INFO Executor: Finished task 1.0 in stage 21.0 (TID 42). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO Executor: Finished task 0.0 in stage 21.0 (TID 41). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 42) in 48 ms on localhost (1/2)
15/10/21 17:00:04 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 41) in 50 ms on localhost (2/2)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
15/10/21 17:00:04 INFO DAGScheduler: ResultStage 21 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.050 s
15/10/21 17:00:04 INFO DAGScheduler: Job 20 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.064397 s
15/10/21 17:00:04 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:04 INFO DAGScheduler: Got job 21 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:04 INFO DAGScheduler: Final stage: ResultStage 22(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:04 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:04 INFO DAGScheduler: Submitting ResultStage 22 (PythonRDD[28] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=235751, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=242143, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:04 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 22 (PythonRDD[28] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Adding task set 22.0 with 2 tasks
15/10/21 17:00:04 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 43, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 44, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO Executor: Running task 1.0 in stage 22.0 (TID 44)
15/10/21 17:00:04 INFO Executor: Running task 0.0 in stage 22.0 (TID 43)
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:04 INFO PythonRDD: Times: total = 38, boot = -21, init = 59, finish = 0
15/10/21 17:00:04 INFO PythonRDD: Times: total = 38, boot = -21, init = 59, finish = 0
15/10/21 17:00:04 INFO Executor: Finished task 1.0 in stage 22.0 (TID 44). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO Executor: Finished task 0.0 in stage 22.0 (TID 43). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 44) in 48 ms on localhost (1/2)
15/10/21 17:00:04 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 43) in 49 ms on localhost (2/2)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
15/10/21 17:00:04 INFO DAGScheduler: ResultStage 22 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.049 s
15/10/21 17:00:04 INFO DAGScheduler: Job 21 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.062500 s
15/10/21 17:00:04 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:04 INFO DAGScheduler: Got job 22 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:04 INFO DAGScheduler: Final stage: ResultStage 23(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:04 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:04 INFO DAGScheduler: Submitting ResultStage 23 (PythonRDD[29] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=245948, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=252340, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:04 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 23 (PythonRDD[29] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Adding task set 23.0 with 2 tasks
15/10/21 17:00:04 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 45, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 46, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO Executor: Running task 1.0 in stage 23.0 (TID 46)
15/10/21 17:00:04 INFO Executor: Running task 0.0 in stage 23.0 (TID 45)
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:04 INFO PythonRDD: Times: total = 37, boot = -19, init = 56, finish = 0
15/10/21 17:00:04 INFO Executor: Finished task 1.0 in stage 23.0 (TID 46). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 46) in 46 ms on localhost (1/2)
15/10/21 17:00:04 INFO PythonRDD: Times: total = 41, boot = -19, init = 60, finish = 0
15/10/21 17:00:04 INFO Executor: Finished task 0.0 in stage 23.0 (TID 45). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 45) in 51 ms on localhost (2/2)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
15/10/21 17:00:04 INFO DAGScheduler: ResultStage 23 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.051 s
15/10/21 17:00:04 INFO DAGScheduler: Job 22 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.063507 s
15/10/21 17:00:04 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:04 INFO DAGScheduler: Got job 23 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:04 INFO DAGScheduler: Final stage: ResultStage 24(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:04 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:04 INFO DAGScheduler: Submitting ResultStage 24 (PythonRDD[30] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=256145, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=262537, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:04 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 24 (PythonRDD[30] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Adding task set 24.0 with 2 tasks
15/10/21 17:00:04 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 47, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 48, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO Executor: Running task 0.0 in stage 24.0 (TID 47)
15/10/21 17:00:04 INFO Executor: Running task 1.0 in stage 24.0 (TID 48)
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:04 INFO PythonRDD: Times: total = 39, boot = -21, init = 60, finish = 0
15/10/21 17:00:04 INFO PythonRDD: Times: total = 40, boot = -26, init = 66, finish = 0
15/10/21 17:00:04 INFO Executor: Finished task 1.0 in stage 24.0 (TID 48). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO Executor: Finished task 0.0 in stage 24.0 (TID 47). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 48) in 49 ms on localhost (1/2)
15/10/21 17:00:04 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 47) in 50 ms on localhost (2/2)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
15/10/21 17:00:04 INFO DAGScheduler: ResultStage 24 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.051 s
15/10/21 17:00:04 INFO DAGScheduler: Job 23 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.063512 s
15/10/21 17:00:04 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:04 INFO DAGScheduler: Got job 24 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:04 INFO DAGScheduler: Final stage: ResultStage 25(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:04 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:04 INFO DAGScheduler: Submitting ResultStage 25 (PythonRDD[31] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=266342, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=272734, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:04 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 25 (PythonRDD[31] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Adding task set 25.0 with 2 tasks
15/10/21 17:00:04 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 49, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 50, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO Executor: Running task 0.0 in stage 25.0 (TID 49)
15/10/21 17:00:04 INFO Executor: Running task 1.0 in stage 25.0 (TID 50)
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:04 INFO PythonRDD: Times: total = 40, boot = -22, init = 62, finish = 0
15/10/21 17:00:04 INFO PythonRDD: Times: total = 40, boot = -22, init = 62, finish = 0
15/10/21 17:00:04 INFO Executor: Finished task 0.0 in stage 25.0 (TID 49). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO Executor: Finished task 1.0 in stage 25.0 (TID 50). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 49) in 50 ms on localhost (1/2)
15/10/21 17:00:04 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 50) in 50 ms on localhost (2/2)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
15/10/21 17:00:04 INFO DAGScheduler: ResultStage 25 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.051 s
15/10/21 17:00:04 INFO DAGScheduler: Job 24 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.062936 s
15/10/21 17:00:04 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:04 INFO DAGScheduler: Got job 25 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:04 INFO DAGScheduler: Final stage: ResultStage 26(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:04 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:04 INFO DAGScheduler: Submitting ResultStage 26 (PythonRDD[32] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=276539, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=282931, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:04 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 26 (PythonRDD[32] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Adding task set 26.0 with 2 tasks
15/10/21 17:00:04 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 51, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 52, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO Executor: Running task 0.0 in stage 26.0 (TID 51)
15/10/21 17:00:04 INFO Executor: Running task 1.0 in stage 26.0 (TID 52)
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:04 INFO PythonRDD: Times: total = 40, boot = -23, init = 63, finish = 0
15/10/21 17:00:04 INFO PythonRDD: Times: total = 40, boot = -20, init = 60, finish = 0
15/10/21 17:00:04 INFO Executor: Finished task 1.0 in stage 26.0 (TID 52). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO Executor: Finished task 0.0 in stage 26.0 (TID 51). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 52) in 49 ms on localhost (1/2)
15/10/21 17:00:04 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 51) in 51 ms on localhost (2/2)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
15/10/21 17:00:04 INFO DAGScheduler: ResultStage 26 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.051 s
15/10/21 17:00:04 INFO DAGScheduler: Job 25 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.063353 s
15/10/21 17:00:04 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:04 INFO DAGScheduler: Got job 26 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:04 INFO DAGScheduler: Final stage: ResultStage 27(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:04 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:04 INFO DAGScheduler: Submitting ResultStage 27 (PythonRDD[33] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=286736, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=293128, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:04 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 27 (PythonRDD[33] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Adding task set 27.0 with 2 tasks
15/10/21 17:00:04 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 53, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 54, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO Executor: Running task 1.0 in stage 27.0 (TID 54)
15/10/21 17:00:04 INFO Executor: Running task 0.0 in stage 27.0 (TID 53)
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:04 INFO PythonRDD: Times: total = 38, boot = -18, init = 56, finish = 0
15/10/21 17:00:04 INFO PythonRDD: Times: total = 37, boot = -19, init = 56, finish = 0
15/10/21 17:00:04 INFO Executor: Finished task 1.0 in stage 27.0 (TID 54). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO Executor: Finished task 0.0 in stage 27.0 (TID 53). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 54) in 46 ms on localhost (1/2)
15/10/21 17:00:04 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 53) in 48 ms on localhost (2/2)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
15/10/21 17:00:04 INFO DAGScheduler: ResultStage 27 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.048 s
15/10/21 17:00:04 INFO DAGScheduler: Job 26 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.059767 s
15/10/21 17:00:04 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:04 INFO DAGScheduler: Got job 27 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:04 INFO DAGScheduler: Final stage: ResultStage 28(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:04 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:04 INFO DAGScheduler: Submitting ResultStage 28 (PythonRDD[34] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=296933, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=303325, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:04 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 28 (PythonRDD[34] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Adding task set 28.0 with 2 tasks
15/10/21 17:00:04 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 55, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO TaskSetManager: Starting task 1.0 in stage 28.0 (TID 56, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO Executor: Running task 1.0 in stage 28.0 (TID 56)
15/10/21 17:00:04 INFO Executor: Running task 0.0 in stage 28.0 (TID 55)
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:04 INFO PythonRDD: Times: total = 40, boot = -19, init = 59, finish = 0
15/10/21 17:00:04 INFO PythonRDD: Times: total = 40, boot = -18, init = 58, finish = 0
15/10/21 17:00:04 INFO Executor: Finished task 1.0 in stage 28.0 (TID 56). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO Executor: Finished task 0.0 in stage 28.0 (TID 55). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO TaskSetManager: Finished task 1.0 in stage 28.0 (TID 56) in 48 ms on localhost (1/2)
15/10/21 17:00:04 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 55) in 50 ms on localhost (2/2)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
15/10/21 17:00:04 INFO DAGScheduler: ResultStage 28 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.050 s
15/10/21 17:00:04 INFO DAGScheduler: Job 27 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.060966 s
15/10/21 17:00:04 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:04 INFO DAGScheduler: Got job 28 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:04 INFO DAGScheduler: Final stage: ResultStage 29(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:04 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:04 INFO DAGScheduler: Submitting ResultStage 29 (PythonRDD[35] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=307130, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=313522, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:04 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 29 (PythonRDD[35] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Adding task set 29.0 with 2 tasks
15/10/21 17:00:04 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 57, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 58, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO Executor: Running task 1.0 in stage 29.0 (TID 58)
15/10/21 17:00:04 INFO Executor: Running task 0.0 in stage 29.0 (TID 57)
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:04 INFO PythonRDD: Times: total = 40, boot = -24, init = 64, finish = 0
15/10/21 17:00:04 INFO PythonRDD: Times: total = 40, boot = -24, init = 64, finish = 0
15/10/21 17:00:04 INFO Executor: Finished task 1.0 in stage 29.0 (TID 58). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO Executor: Finished task 0.0 in stage 29.0 (TID 57). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 58) in 48 ms on localhost (1/2)
15/10/21 17:00:04 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 57) in 49 ms on localhost (2/2)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
15/10/21 17:00:04 INFO DAGScheduler: ResultStage 29 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.051 s
15/10/21 17:00:04 INFO DAGScheduler: Job 28 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.062388 s
15/10/21 17:00:04 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:04 INFO DAGScheduler: Got job 29 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:04 INFO DAGScheduler: Final stage: ResultStage 30(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:04 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:04 INFO DAGScheduler: Submitting ResultStage 30 (PythonRDD[36] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=317327, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=323719, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:04 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 30 (PythonRDD[36] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Adding task set 30.0 with 2 tasks
15/10/21 17:00:04 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 59, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 60, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO Executor: Running task 0.0 in stage 30.0 (TID 59)
15/10/21 17:00:04 INFO Executor: Running task 1.0 in stage 30.0 (TID 60)
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:04 INFO PythonRDD: Times: total = 38, boot = -17, init = 55, finish = 0
15/10/21 17:00:04 INFO Executor: Finished task 0.0 in stage 30.0 (TID 59). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 59) in 44 ms on localhost (1/2)
15/10/21 17:00:04 INFO PythonRDD: Times: total = 41, boot = -18, init = 59, finish = 0
15/10/21 17:00:04 INFO Executor: Finished task 1.0 in stage 30.0 (TID 60). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 60) in 49 ms on localhost (2/2)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
15/10/21 17:00:04 INFO DAGScheduler: ResultStage 30 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.050 s
15/10/21 17:00:04 INFO DAGScheduler: Job 29 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.061833 s
15/10/21 17:00:04 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:04 INFO DAGScheduler: Got job 30 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:04 INFO DAGScheduler: Final stage: ResultStage 31(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:04 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:04 INFO DAGScheduler: Submitting ResultStage 31 (PythonRDD[37] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=327524, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=333916, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:04 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:04 INFO BlockManagerInfo: Removed broadcast_31_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 31 (PythonRDD[37] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Adding task set 31.0 with 2 tasks
15/10/21 17:00:04 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 61, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 62, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO Executor: Running task 0.0 in stage 31.0 (TID 61)
15/10/21 17:00:04 INFO Executor: Running task 1.0 in stage 31.0 (TID 62)
15/10/21 17:00:04 INFO BlockManagerInfo: Removed broadcast_30_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Removed broadcast_29_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:04 INFO BlockManagerInfo: Removed broadcast_28_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Removed broadcast_27_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Removed broadcast_26_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Removed broadcast_25_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Removed broadcast_24_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Removed broadcast_23_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Removed broadcast_22_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Removed broadcast_21_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Removed broadcast_20_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Removed broadcast_19_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Removed broadcast_18_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Removed broadcast_17_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:04 INFO PythonRDD: Times: total = 39, boot = -31, init = 70, finish = 0
15/10/21 17:00:04 INFO PythonRDD: Times: total = 39, boot = -36, init = 75, finish = 0
15/10/21 17:00:04 INFO Executor: Finished task 1.0 in stage 31.0 (TID 62). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO Executor: Finished task 0.0 in stage 31.0 (TID 61). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 62) in 45 ms on localhost (1/2)
15/10/21 17:00:04 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 61) in 46 ms on localhost (2/2)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
15/10/21 17:00:04 INFO DAGScheduler: ResultStage 31 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:04 INFO DAGScheduler: Job 30 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.074362 s
15/10/21 17:00:04 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:04 INFO DAGScheduler: Got job 31 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:04 INFO DAGScheduler: Final stage: ResultStage 32(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:04 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:04 INFO DAGScheduler: Submitting ResultStage 32 (PythonRDD[38] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=181702, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=188094, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:04 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 32 (PythonRDD[38] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Adding task set 32.0 with 2 tasks
15/10/21 17:00:04 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 63, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 64, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO Executor: Running task 0.0 in stage 32.0 (TID 63)
15/10/21 17:00:04 INFO Executor: Running task 1.0 in stage 32.0 (TID 64)
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:04 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:04 INFO PythonRDD: Times: total = 38, boot = -16, init = 54, finish = 0
15/10/21 17:00:04 INFO PythonRDD: Times: total = 39, boot = -15, init = 54, finish = 0
15/10/21 17:00:04 INFO Executor: Finished task 1.0 in stage 32.0 (TID 64). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO Executor: Finished task 0.0 in stage 32.0 (TID 63). 1870 bytes result sent to driver
15/10/21 17:00:04 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 64) in 44 ms on localhost (1/2)
15/10/21 17:00:04 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 63) in 46 ms on localhost (2/2)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
15/10/21 17:00:04 INFO DAGScheduler: ResultStage 32 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:04 INFO DAGScheduler: Job 31 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.056670 s
15/10/21 17:00:04 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:04 INFO DAGScheduler: Got job 32 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:04 INFO DAGScheduler: Final stage: ResultStage 33(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:04 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:04 INFO DAGScheduler: Submitting ResultStage 33 (PythonRDD[39] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=191899, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:04 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=198291, maxMem=278302556
15/10/21 17:00:04 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:04 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:04 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:04 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 33 (PythonRDD[39] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:04 INFO TaskSchedulerImpl: Adding task set 33.0 with 2 tasks
15/10/21 17:00:04 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 65, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 66, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:04 INFO Executor: Running task 0.0 in stage 33.0 (TID 65)
15/10/21 17:00:04 INFO Executor: Running task 1.0 in stage 33.0 (TID 66)
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:05 INFO PythonRDD: Times: total = 38, boot = -16, init = 54, finish = 0
15/10/21 17:00:05 INFO PythonRDD: Times: total = 38, boot = -16, init = 54, finish = 0
15/10/21 17:00:05 INFO Executor: Finished task 1.0 in stage 33.0 (TID 66). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO Executor: Finished task 0.0 in stage 33.0 (TID 65). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 66) in 44 ms on localhost (1/2)
15/10/21 17:00:05 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 65) in 46 ms on localhost (2/2)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
15/10/21 17:00:05 INFO DAGScheduler: ResultStage 33 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:05 INFO DAGScheduler: Job 32 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.056485 s
15/10/21 17:00:05 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:05 INFO DAGScheduler: Got job 33 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:05 INFO DAGScheduler: Final stage: ResultStage 34(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:05 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:05 INFO DAGScheduler: Submitting ResultStage 34 (PythonRDD[40] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=202096, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(3804) called with curMem=208488, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:05 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:05 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 34 (PythonRDD[40] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Adding task set 34.0 with 2 tasks
15/10/21 17:00:05 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 67, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO TaskSetManager: Starting task 1.0 in stage 34.0 (TID 68, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO Executor: Running task 0.0 in stage 34.0 (TID 67)
15/10/21 17:00:05 INFO Executor: Running task 1.0 in stage 34.0 (TID 68)
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:05 INFO PythonRDD: Times: total = 39, boot = -16, init = 55, finish = 0
15/10/21 17:00:05 INFO PythonRDD: Times: total = 39, boot = -16, init = 55, finish = 0
15/10/21 17:00:05 INFO Executor: Finished task 1.0 in stage 34.0 (TID 68). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO Executor: Finished task 0.0 in stage 34.0 (TID 67). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO TaskSetManager: Finished task 1.0 in stage 34.0 (TID 68) in 46 ms on localhost (1/2)
15/10/21 17:00:05 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 67) in 47 ms on localhost (2/2)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
15/10/21 17:00:05 INFO DAGScheduler: ResultStage 34 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.048 s
15/10/21 17:00:05 INFO DAGScheduler: Job 33 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.058833 s
15/10/21 17:00:05 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:05 INFO DAGScheduler: Got job 34 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:05 INFO DAGScheduler: Final stage: ResultStage 35(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:05 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:05 INFO DAGScheduler: Submitting ResultStage 35 (PythonRDD[41] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=212292, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=218684, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:05 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:05 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 35 (PythonRDD[41] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Adding task set 35.0 with 2 tasks
15/10/21 17:00:05 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 69, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO TaskSetManager: Starting task 1.0 in stage 35.0 (TID 70, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO Executor: Running task 0.0 in stage 35.0 (TID 69)
15/10/21 17:00:05 INFO Executor: Running task 1.0 in stage 35.0 (TID 70)
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:05 INFO PythonRDD: Times: total = 40, boot = -16, init = 56, finish = 0
15/10/21 17:00:05 INFO PythonRDD: Times: total = 41, boot = -15, init = 56, finish = 0
15/10/21 17:00:05 INFO Executor: Finished task 1.0 in stage 35.0 (TID 70). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO Executor: Finished task 0.0 in stage 35.0 (TID 69). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO TaskSetManager: Finished task 1.0 in stage 35.0 (TID 70) in 46 ms on localhost (1/2)
15/10/21 17:00:05 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 69) in 48 ms on localhost (2/2)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
15/10/21 17:00:05 INFO DAGScheduler: ResultStage 35 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.048 s
15/10/21 17:00:05 INFO DAGScheduler: Job 34 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.059827 s
15/10/21 17:00:05 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:05 INFO DAGScheduler: Got job 35 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:05 INFO DAGScheduler: Final stage: ResultStage 36(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:05 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:05 INFO DAGScheduler: Submitting ResultStage 36 (PythonRDD[42] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=222489, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=228881, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:05 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:05 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 36 (PythonRDD[42] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Adding task set 36.0 with 2 tasks
15/10/21 17:00:05 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 71, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO TaskSetManager: Starting task 1.0 in stage 36.0 (TID 72, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO Executor: Running task 0.0 in stage 36.0 (TID 71)
15/10/21 17:00:05 INFO Executor: Running task 1.0 in stage 36.0 (TID 72)
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:05 INFO PythonRDD: Times: total = 38, boot = -17, init = 55, finish = 0
15/10/21 17:00:05 INFO Executor: Finished task 0.0 in stage 36.0 (TID 71). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 71) in 45 ms on localhost (1/2)
15/10/21 17:00:05 INFO PythonRDD: Times: total = 41, boot = -16, init = 57, finish = 0
15/10/21 17:00:05 INFO Executor: Finished task 1.0 in stage 36.0 (TID 72). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO TaskSetManager: Finished task 1.0 in stage 36.0 (TID 72) in 47 ms on localhost (2/2)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
15/10/21 17:00:05 INFO DAGScheduler: ResultStage 36 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.048 s
15/10/21 17:00:05 INFO DAGScheduler: Job 35 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.060175 s
15/10/21 17:00:05 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:05 INFO DAGScheduler: Got job 36 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:05 INFO DAGScheduler: Final stage: ResultStage 37(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:05 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:05 INFO DAGScheduler: Submitting ResultStage 37 (PythonRDD[43] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=232686, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=239078, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:05 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:05 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 37 (PythonRDD[43] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Adding task set 37.0 with 2 tasks
15/10/21 17:00:05 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 73, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 74, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO Executor: Running task 0.0 in stage 37.0 (TID 73)
15/10/21 17:00:05 INFO Executor: Running task 1.0 in stage 37.0 (TID 74)
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:05 INFO PythonRDD: Times: total = 38, boot = -14, init = 52, finish = 0
15/10/21 17:00:05 INFO PythonRDD: Times: total = 38, boot = -18, init = 56, finish = 0
15/10/21 17:00:05 INFO Executor: Finished task 1.0 in stage 37.0 (TID 74). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO Executor: Finished task 0.0 in stage 37.0 (TID 73). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 74) in 44 ms on localhost (1/2)
15/10/21 17:00:05 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 73) in 45 ms on localhost (2/2)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
15/10/21 17:00:05 INFO DAGScheduler: ResultStage 37 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:05 INFO DAGScheduler: Job 36 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.057014 s
15/10/21 17:00:05 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:05 INFO DAGScheduler: Got job 37 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:05 INFO DAGScheduler: Final stage: ResultStage 38(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:05 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:05 INFO DAGScheduler: Submitting ResultStage 38 (PythonRDD[44] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=242883, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=249275, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:05 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:05 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 38 (PythonRDD[44] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Adding task set 38.0 with 2 tasks
15/10/21 17:00:05 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 75, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 76, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO Executor: Running task 0.0 in stage 38.0 (TID 75)
15/10/21 17:00:05 INFO Executor: Running task 1.0 in stage 38.0 (TID 76)
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:05 INFO PythonRDD: Times: total = 38, boot = -15, init = 53, finish = 0
15/10/21 17:00:05 INFO Executor: Finished task 1.0 in stage 38.0 (TID 76). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 76) in 43 ms on localhost (1/2)
15/10/21 17:00:05 INFO PythonRDD: Times: total = 41, boot = -18, init = 59, finish = 0
15/10/21 17:00:05 INFO Executor: Finished task 0.0 in stage 38.0 (TID 75). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 75) in 48 ms on localhost (2/2)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
15/10/21 17:00:05 INFO DAGScheduler: ResultStage 38 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.049 s
15/10/21 17:00:05 INFO DAGScheduler: Job 37 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.060094 s
15/10/21 17:00:05 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:05 INFO DAGScheduler: Got job 38 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:05 INFO DAGScheduler: Final stage: ResultStage 39(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:05 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:05 INFO DAGScheduler: Submitting ResultStage 39 (PythonRDD[45] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=253080, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=259472, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:05 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:05 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 39 (PythonRDD[45] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Adding task set 39.0 with 2 tasks
15/10/21 17:00:05 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 77, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 78, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO Executor: Running task 1.0 in stage 39.0 (TID 78)
15/10/21 17:00:05 INFO Executor: Running task 0.0 in stage 39.0 (TID 77)
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:05 INFO PythonRDD: Times: total = 39, boot = -11, init = 50, finish = 0
15/10/21 17:00:05 INFO PythonRDD: Times: total = 39, boot = -14, init = 53, finish = 0
15/10/21 17:00:05 INFO Executor: Finished task 0.0 in stage 39.0 (TID 77). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO Executor: Finished task 1.0 in stage 39.0 (TID 78). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 77) in 45 ms on localhost (1/2)
15/10/21 17:00:05 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 78) in 45 ms on localhost (2/2)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
15/10/21 17:00:05 INFO DAGScheduler: ResultStage 39 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:05 INFO DAGScheduler: Job 38 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.056285 s
15/10/21 17:00:05 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:05 INFO DAGScheduler: Got job 39 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:05 INFO DAGScheduler: Final stage: ResultStage 40(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:05 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:05 INFO DAGScheduler: Submitting ResultStage 40 (PythonRDD[46] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=263277, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=269669, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:05 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:05 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 40 (PythonRDD[46] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Adding task set 40.0 with 2 tasks
15/10/21 17:00:05 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 79, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 80, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO Executor: Running task 0.0 in stage 40.0 (TID 79)
15/10/21 17:00:05 INFO Executor: Running task 1.0 in stage 40.0 (TID 80)
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:05 INFO PythonRDD: Times: total = 38, boot = -17, init = 55, finish = 0
15/10/21 17:00:05 INFO PythonRDD: Times: total = 38, boot = -15, init = 53, finish = 0
15/10/21 17:00:05 INFO Executor: Finished task 0.0 in stage 40.0 (TID 79). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO Executor: Finished task 1.0 in stage 40.0 (TID 80). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 79) in 44 ms on localhost (1/2)
15/10/21 17:00:05 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 80) in 45 ms on localhost (2/2)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
15/10/21 17:00:05 INFO DAGScheduler: ResultStage 40 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:05 INFO DAGScheduler: Job 39 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.057137 s
15/10/21 17:00:05 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:05 INFO DAGScheduler: Got job 40 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:05 INFO DAGScheduler: Final stage: ResultStage 41(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:05 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:05 INFO DAGScheduler: Submitting ResultStage 41 (PythonRDD[47] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=273474, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=279866, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:05 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:05 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 41 (PythonRDD[47] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Adding task set 41.0 with 2 tasks
15/10/21 17:00:05 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 81, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO TaskSetManager: Starting task 1.0 in stage 41.0 (TID 82, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO Executor: Running task 0.0 in stage 41.0 (TID 81)
15/10/21 17:00:05 INFO Executor: Running task 1.0 in stage 41.0 (TID 82)
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:05 INFO PythonRDD: Times: total = 39, boot = -16, init = 55, finish = 0
15/10/21 17:00:05 INFO PythonRDD: Times: total = 39, boot = -17, init = 56, finish = 0
15/10/21 17:00:05 INFO Executor: Finished task 1.0 in stage 41.0 (TID 82). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO Executor: Finished task 0.0 in stage 41.0 (TID 81). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO TaskSetManager: Finished task 1.0 in stage 41.0 (TID 82) in 45 ms on localhost (1/2)
15/10/21 17:00:05 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 81) in 46 ms on localhost (2/2)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
15/10/21 17:00:05 INFO DAGScheduler: ResultStage 41 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:00:05 INFO DAGScheduler: Job 40 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.057470 s
15/10/21 17:00:05 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:05 INFO DAGScheduler: Got job 41 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:05 INFO DAGScheduler: Final stage: ResultStage 42(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:05 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:05 INFO DAGScheduler: Submitting ResultStage 42 (PythonRDD[48] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=283671, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=290063, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:05 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:05 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 42 (PythonRDD[48] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Adding task set 42.0 with 2 tasks
15/10/21 17:00:05 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 83, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO TaskSetManager: Starting task 1.0 in stage 42.0 (TID 84, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO Executor: Running task 0.0 in stage 42.0 (TID 83)
15/10/21 17:00:05 INFO Executor: Running task 1.0 in stage 42.0 (TID 84)
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:05 INFO PythonRDD: Times: total = 39, boot = -16, init = 55, finish = 0
15/10/21 17:00:05 INFO PythonRDD: Times: total = 39, boot = -18, init = 57, finish = 0
15/10/21 17:00:05 INFO Executor: Finished task 0.0 in stage 42.0 (TID 83). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO Executor: Finished task 1.0 in stage 42.0 (TID 84). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 83) in 45 ms on localhost (1/2)
15/10/21 17:00:05 INFO TaskSetManager: Finished task 1.0 in stage 42.0 (TID 84) in 45 ms on localhost (2/2)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
15/10/21 17:00:05 INFO DAGScheduler: ResultStage 42 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:05 INFO DAGScheduler: Job 41 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.056965 s
15/10/21 17:00:05 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:05 INFO DAGScheduler: Got job 42 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:05 INFO DAGScheduler: Final stage: ResultStage 43(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:05 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:05 INFO DAGScheduler: Submitting ResultStage 43 (PythonRDD[49] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=293868, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=300260, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:05 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:05 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 43 (PythonRDD[49] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Adding task set 43.0 with 2 tasks
15/10/21 17:00:05 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 85, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO TaskSetManager: Starting task 1.0 in stage 43.0 (TID 86, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO Executor: Running task 1.0 in stage 43.0 (TID 86)
15/10/21 17:00:05 INFO Executor: Running task 0.0 in stage 43.0 (TID 85)
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:05 INFO PythonRDD: Times: total = 40, boot = -16, init = 56, finish = 0
15/10/21 17:00:05 INFO PythonRDD: Times: total = 39, boot = -16, init = 55, finish = 0
15/10/21 17:00:05 INFO Executor: Finished task 1.0 in stage 43.0 (TID 86). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO Executor: Finished task 0.0 in stage 43.0 (TID 85). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO TaskSetManager: Finished task 1.0 in stage 43.0 (TID 86) in 45 ms on localhost (1/2)
15/10/21 17:00:05 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 85) in 46 ms on localhost (2/2)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
15/10/21 17:00:05 INFO DAGScheduler: ResultStage 43 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:00:05 INFO DAGScheduler: Job 42 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.057376 s
15/10/21 17:00:05 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:05 INFO DAGScheduler: Got job 43 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:05 INFO DAGScheduler: Final stage: ResultStage 44(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:05 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:05 INFO DAGScheduler: Submitting ResultStage 44 (PythonRDD[50] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=304065, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=310457, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:05 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:05 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 44 (PythonRDD[50] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Adding task set 44.0 with 2 tasks
15/10/21 17:00:05 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 87, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO TaskSetManager: Starting task 1.0 in stage 44.0 (TID 88, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO Executor: Running task 0.0 in stage 44.0 (TID 87)
15/10/21 17:00:05 INFO Executor: Running task 1.0 in stage 44.0 (TID 88)
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:05 INFO PythonRDD: Times: total = 38, boot = -18, init = 56, finish = 0
15/10/21 17:00:05 INFO PythonRDD: Times: total = 39, boot = -17, init = 56, finish = 0
15/10/21 17:00:05 INFO Executor: Finished task 1.0 in stage 44.0 (TID 88). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO Executor: Finished task 0.0 in stage 44.0 (TID 87). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO TaskSetManager: Finished task 1.0 in stage 44.0 (TID 88) in 44 ms on localhost (1/2)
15/10/21 17:00:05 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 87) in 45 ms on localhost (2/2)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
15/10/21 17:00:05 INFO DAGScheduler: ResultStage 44 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:05 INFO DAGScheduler: Job 43 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.057552 s
15/10/21 17:00:05 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:05 INFO DAGScheduler: Got job 44 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:05 INFO DAGScheduler: Final stage: ResultStage 45(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:05 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:05 INFO DAGScheduler: Submitting ResultStage 45 (PythonRDD[51] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=314262, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=320654, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:05 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:05 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 45 (PythonRDD[51] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Adding task set 45.0 with 2 tasks
15/10/21 17:00:05 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 89, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 90, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO Executor: Running task 0.0 in stage 45.0 (TID 89)
15/10/21 17:00:05 INFO Executor: Running task 1.0 in stage 45.0 (TID 90)
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:05 INFO PythonRDD: Times: total = 39, boot = -17, init = 56, finish = 0
15/10/21 17:00:05 INFO Executor: Finished task 0.0 in stage 45.0 (TID 89). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 89) in 45 ms on localhost (1/2)
15/10/21 17:00:05 INFO PythonRDD: Times: total = 42, boot = -16, init = 58, finish = 0
15/10/21 17:00:05 INFO Executor: Finished task 1.0 in stage 45.0 (TID 90). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 90) in 48 ms on localhost (2/2)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
15/10/21 17:00:05 INFO DAGScheduler: ResultStage 45 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.050 s
15/10/21 17:00:05 INFO DAGScheduler: Job 44 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.060325 s
15/10/21 17:00:05 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:05 INFO DAGScheduler: Got job 45 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:05 INFO DAGScheduler: Final stage: ResultStage 46(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:05 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:05 INFO DAGScheduler: Submitting ResultStage 46 (PythonRDD[52] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=324459, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:05 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=330851, maxMem=278302556
15/10/21 17:00:05 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:05 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:05 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 46 (PythonRDD[52] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Adding task set 46.0 with 2 tasks
15/10/21 17:00:05 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 91, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO TaskSetManager: Starting task 1.0 in stage 46.0 (TID 92, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:05 INFO Executor: Running task 0.0 in stage 46.0 (TID 91)
15/10/21 17:00:05 INFO Executor: Running task 1.0 in stage 46.0 (TID 92)
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:05 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:05 INFO PythonRDD: Times: total = 38, boot = -17, init = 55, finish = 0
15/10/21 17:00:05 INFO PythonRDD: Times: total = 38, boot = -18, init = 56, finish = 0
15/10/21 17:00:05 INFO Executor: Finished task 0.0 in stage 46.0 (TID 91). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO Executor: Finished task 1.0 in stage 46.0 (TID 92). 1870 bytes result sent to driver
15/10/21 17:00:05 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 91) in 44 ms on localhost (1/2)
15/10/21 17:00:05 INFO TaskSetManager: Finished task 1.0 in stage 46.0 (TID 92) in 44 ms on localhost (2/2)
15/10/21 17:00:05 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
15/10/21 17:00:05 INFO DAGScheduler: ResultStage 46 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:05 INFO DAGScheduler: Job 45 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.056829 s
15/10/21 17:00:06 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:06 INFO DAGScheduler: Got job 46 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:06 INFO DAGScheduler: Final stage: ResultStage 47(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:06 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:06 INFO DAGScheduler: Submitting ResultStage 47 (PythonRDD[53] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=334656, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=341048, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:06 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 47 (PythonRDD[53] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Adding task set 47.0 with 2 tasks
15/10/21 17:00:06 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 93, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO TaskSetManager: Starting task 1.0 in stage 47.0 (TID 94, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO Executor: Running task 1.0 in stage 47.0 (TID 94)
15/10/21 17:00:06 INFO Executor: Running task 0.0 in stage 47.0 (TID 93)
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:06 INFO PythonRDD: Times: total = 40, boot = -10, init = 50, finish = 0
15/10/21 17:00:06 INFO PythonRDD: Times: total = 39, boot = -11, init = 50, finish = 0
15/10/21 17:00:06 INFO Executor: Finished task 1.0 in stage 47.0 (TID 94). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO Executor: Finished task 0.0 in stage 47.0 (TID 93). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO TaskSetManager: Finished task 1.0 in stage 47.0 (TID 94) in 44 ms on localhost (1/2)
15/10/21 17:00:06 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 93) in 45 ms on localhost (2/2)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
15/10/21 17:00:06 INFO DAGScheduler: ResultStage 47 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:06 INFO DAGScheduler: Job 46 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.055033 s
15/10/21 17:00:06 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:06 INFO DAGScheduler: Got job 47 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:06 INFO DAGScheduler: Final stage: ResultStage 48(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:06 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:06 INFO DAGScheduler: Submitting ResultStage 48 (PythonRDD[54] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=344853, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=351245, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:06 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 48 (PythonRDD[54] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Adding task set 48.0 with 2 tasks
15/10/21 17:00:06 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 95, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 96, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO Executor: Running task 0.0 in stage 48.0 (TID 95)
15/10/21 17:00:06 INFO Executor: Running task 1.0 in stage 48.0 (TID 96)
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:06 INFO PythonRDD: Times: total = 39, boot = -16, init = 55, finish = 0
15/10/21 17:00:06 INFO PythonRDD: Times: total = 39, boot = -15, init = 54, finish = 0
15/10/21 17:00:06 INFO Executor: Finished task 0.0 in stage 48.0 (TID 95). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO Executor: Finished task 1.0 in stage 48.0 (TID 96). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 95) in 45 ms on localhost (1/2)
15/10/21 17:00:06 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 96) in 44 ms on localhost (2/2)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
15/10/21 17:00:06 INFO DAGScheduler: ResultStage 48 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:06 INFO DAGScheduler: Job 47 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.056342 s
15/10/21 17:00:06 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:06 INFO DAGScheduler: Got job 48 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:06 INFO DAGScheduler: Final stage: ResultStage 49(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:06 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:06 INFO DAGScheduler: Submitting ResultStage 49 (PythonRDD[55] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=355050, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=361442, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:06 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 49 (PythonRDD[55] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Adding task set 49.0 with 2 tasks
15/10/21 17:00:06 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 97, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO TaskSetManager: Starting task 1.0 in stage 49.0 (TID 98, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO Executor: Running task 0.0 in stage 49.0 (TID 97)
15/10/21 17:00:06 INFO Executor: Running task 1.0 in stage 49.0 (TID 98)
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:06 INFO PythonRDD: Times: total = 39, boot = -14, init = 53, finish = 0
15/10/21 17:00:06 INFO PythonRDD: Times: total = 39, boot = -14, init = 53, finish = 0
15/10/21 17:00:06 INFO Executor: Finished task 1.0 in stage 49.0 (TID 98). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO Executor: Finished task 0.0 in stage 49.0 (TID 97). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO TaskSetManager: Finished task 1.0 in stage 49.0 (TID 98) in 44 ms on localhost (1/2)
15/10/21 17:00:06 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 97) in 44 ms on localhost (2/2)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
15/10/21 17:00:06 INFO DAGScheduler: ResultStage 49 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:06 INFO DAGScheduler: Job 48 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.056487 s
15/10/21 17:00:06 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:06 INFO DAGScheduler: Got job 49 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:06 INFO DAGScheduler: Final stage: ResultStage 50(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:06 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:06 INFO DAGScheduler: Submitting ResultStage 50 (PythonRDD[56] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=365247, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=371639, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:06 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:06 INFO BlockManagerInfo: Removed broadcast_50_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 50 (PythonRDD[56] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Adding task set 50.0 with 2 tasks
15/10/21 17:00:06 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 99, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO TaskSetManager: Starting task 1.0 in stage 50.0 (TID 100, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO Executor: Running task 0.0 in stage 50.0 (TID 99)
15/10/21 17:00:06 INFO BlockManagerInfo: Removed broadcast_49_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:06 INFO Executor: Running task 1.0 in stage 50.0 (TID 100)
15/10/21 17:00:06 INFO BlockManagerInfo: Removed broadcast_48_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:06 INFO BlockManagerInfo: Removed broadcast_47_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Removed broadcast_46_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Removed broadcast_45_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Removed broadcast_44_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Removed broadcast_43_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Removed broadcast_42_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Removed broadcast_41_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Removed broadcast_40_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Removed broadcast_39_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Removed broadcast_38_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Removed broadcast_37_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Removed broadcast_36_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Removed broadcast_35_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Removed broadcast_34_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Removed broadcast_33_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Removed broadcast_32_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:06 INFO PythonRDD: Times: total = 39, boot = -35, init = 74, finish = 0
15/10/21 17:00:06 INFO PythonRDD: Times: total = 39, boot = -35, init = 74, finish = 0
15/10/21 17:00:06 INFO Executor: Finished task 1.0 in stage 50.0 (TID 100). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO Executor: Finished task 0.0 in stage 50.0 (TID 99). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO TaskSetManager: Finished task 1.0 in stage 50.0 (TID 100) in 44 ms on localhost (1/2)
15/10/21 17:00:06 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 99) in 45 ms on localhost (2/2)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
15/10/21 17:00:06 INFO DAGScheduler: ResultStage 50 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:06 INFO DAGScheduler: Job 49 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.077326 s
15/10/21 17:00:06 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:06 INFO DAGScheduler: Got job 50 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:06 INFO DAGScheduler: Final stage: ResultStage 51(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:06 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:06 INFO DAGScheduler: Submitting ResultStage 51 (PythonRDD[57] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=181702, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=188094, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:06 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 51 (PythonRDD[57] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Adding task set 51.0 with 2 tasks
15/10/21 17:00:06 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 101, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 102, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO Executor: Running task 0.0 in stage 51.0 (TID 101)
15/10/21 17:00:06 INFO Executor: Running task 1.0 in stage 51.0 (TID 102)
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:06 INFO PythonRDD: Times: total = 38, boot = -12, init = 50, finish = 0
15/10/21 17:00:06 INFO PythonRDD: Times: total = 38, boot = -12, init = 50, finish = 0
15/10/21 17:00:06 INFO Executor: Finished task 1.0 in stage 51.0 (TID 102). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO Executor: Finished task 0.0 in stage 51.0 (TID 101). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 102) in 43 ms on localhost (1/2)
15/10/21 17:00:06 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 101) in 43 ms on localhost (2/2)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
15/10/21 17:00:06 INFO DAGScheduler: ResultStage 51 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:06 INFO DAGScheduler: Job 50 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053468 s
15/10/21 17:00:06 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:06 INFO DAGScheduler: Got job 51 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:06 INFO DAGScheduler: Final stage: ResultStage 52(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:06 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:06 INFO DAGScheduler: Submitting ResultStage 52 (PythonRDD[58] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=191899, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=198291, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:06 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 52 (PythonRDD[58] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Adding task set 52.0 with 2 tasks
15/10/21 17:00:06 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 103, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO TaskSetManager: Starting task 1.0 in stage 52.0 (TID 104, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO Executor: Running task 0.0 in stage 52.0 (TID 103)
15/10/21 17:00:06 INFO Executor: Running task 1.0 in stage 52.0 (TID 104)
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:06 INFO PythonRDD: Times: total = 39, boot = -13, init = 52, finish = 0
15/10/21 17:00:06 INFO PythonRDD: Times: total = 39, boot = -13, init = 52, finish = 0
15/10/21 17:00:06 INFO Executor: Finished task 1.0 in stage 52.0 (TID 104). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO Executor: Finished task 0.0 in stage 52.0 (TID 103). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO TaskSetManager: Finished task 1.0 in stage 52.0 (TID 104) in 43 ms on localhost (1/2)
15/10/21 17:00:06 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 103) in 44 ms on localhost (2/2)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
15/10/21 17:00:06 INFO DAGScheduler: ResultStage 52 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:06 INFO DAGScheduler: Job 51 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.054561 s
15/10/21 17:00:06 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:06 INFO DAGScheduler: Got job 52 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:06 INFO DAGScheduler: Final stage: ResultStage 53(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:06 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:06 INFO DAGScheduler: Submitting ResultStage 53 (PythonRDD[59] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=202096, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=208488, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:06 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 53 (PythonRDD[59] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Adding task set 53.0 with 2 tasks
15/10/21 17:00:06 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 105, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO TaskSetManager: Starting task 1.0 in stage 53.0 (TID 106, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO Executor: Running task 0.0 in stage 53.0 (TID 105)
15/10/21 17:00:06 INFO Executor: Running task 1.0 in stage 53.0 (TID 106)
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:06 INFO PythonRDD: Times: total = 38, boot = -14, init = 52, finish = 0
15/10/21 17:00:06 INFO PythonRDD: Times: total = 38, boot = -15, init = 53, finish = 0
15/10/21 17:00:06 INFO Executor: Finished task 1.0 in stage 53.0 (TID 106). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO Executor: Finished task 0.0 in stage 53.0 (TID 105). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO TaskSetManager: Finished task 1.0 in stage 53.0 (TID 106) in 43 ms on localhost (1/2)
15/10/21 17:00:06 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 105) in 44 ms on localhost (2/2)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
15/10/21 17:00:06 INFO DAGScheduler: ResultStage 53 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:06 INFO DAGScheduler: Job 52 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053735 s
15/10/21 17:00:06 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:06 INFO DAGScheduler: Got job 53 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:06 INFO DAGScheduler: Final stage: ResultStage 54(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:06 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:06 INFO DAGScheduler: Submitting ResultStage 54 (PythonRDD[60] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=212293, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=218685, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:06 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 54 (PythonRDD[60] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Adding task set 54.0 with 2 tasks
15/10/21 17:00:06 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 107, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 108, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO Executor: Running task 0.0 in stage 54.0 (TID 107)
15/10/21 17:00:06 INFO Executor: Running task 1.0 in stage 54.0 (TID 108)
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:06 INFO PythonRDD: Times: total = 41, boot = -15, init = 56, finish = 0
15/10/21 17:00:06 INFO Executor: Finished task 0.0 in stage 54.0 (TID 107). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 107) in 46 ms on localhost (1/2)
15/10/21 17:00:06 INFO PythonRDD: Times: total = 45, boot = -14, init = 59, finish = 0
15/10/21 17:00:06 INFO Executor: Finished task 1.0 in stage 54.0 (TID 108). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 108) in 50 ms on localhost (2/2)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
15/10/21 17:00:06 INFO DAGScheduler: ResultStage 54 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.050 s
15/10/21 17:00:06 INFO DAGScheduler: Job 53 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.060364 s
15/10/21 17:00:06 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:06 INFO DAGScheduler: Got job 54 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:06 INFO DAGScheduler: Final stage: ResultStage 55(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:06 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:06 INFO DAGScheduler: Submitting ResultStage 55 (PythonRDD[61] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=222490, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=228882, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:06 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 55 (PythonRDD[61] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Adding task set 55.0 with 2 tasks
15/10/21 17:00:06 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 109, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 110, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO Executor: Running task 1.0 in stage 55.0 (TID 110)
15/10/21 17:00:06 INFO Executor: Running task 0.0 in stage 55.0 (TID 109)
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:06 INFO PythonRDD: Times: total = 39, boot = -13, init = 52, finish = 0
15/10/21 17:00:06 INFO PythonRDD: Times: total = 38, boot = -12, init = 50, finish = 0
15/10/21 17:00:06 INFO Executor: Finished task 1.0 in stage 55.0 (TID 110). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO Executor: Finished task 0.0 in stage 55.0 (TID 109). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO TaskSetManager: Finished task 1.0 in stage 55.0 (TID 110) in 44 ms on localhost (1/2)
15/10/21 17:00:06 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 109) in 44 ms on localhost (2/2)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
15/10/21 17:00:06 INFO DAGScheduler: ResultStage 55 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:06 INFO DAGScheduler: Job 54 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.054351 s
15/10/21 17:00:06 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:06 INFO DAGScheduler: Got job 55 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:06 INFO DAGScheduler: Final stage: ResultStage 56(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:06 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:06 INFO DAGScheduler: Submitting ResultStage 56 (PythonRDD[62] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=232687, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=239079, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:06 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 56 (PythonRDD[62] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Adding task set 56.0 with 2 tasks
15/10/21 17:00:06 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 111, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO TaskSetManager: Starting task 1.0 in stage 56.0 (TID 112, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO Executor: Running task 1.0 in stage 56.0 (TID 112)
15/10/21 17:00:06 INFO Executor: Running task 0.0 in stage 56.0 (TID 111)
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:06 INFO PythonRDD: Times: total = 39, boot = -11, init = 50, finish = 0
15/10/21 17:00:06 INFO PythonRDD: Times: total = 38, boot = -12, init = 50, finish = 0
15/10/21 17:00:06 INFO Executor: Finished task 1.0 in stage 56.0 (TID 112). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO Executor: Finished task 0.0 in stage 56.0 (TID 111). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO TaskSetManager: Finished task 1.0 in stage 56.0 (TID 112) in 43 ms on localhost (1/2)
15/10/21 17:00:06 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 111) in 44 ms on localhost (2/2)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
15/10/21 17:00:06 INFO DAGScheduler: ResultStage 56 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:06 INFO DAGScheduler: Job 55 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.054534 s
15/10/21 17:00:06 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:06 INFO DAGScheduler: Got job 56 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:06 INFO DAGScheduler: Final stage: ResultStage 57(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:06 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:06 INFO DAGScheduler: Submitting ResultStage 57 (PythonRDD[63] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=242884, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=249276, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:06 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 57 (PythonRDD[63] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Adding task set 57.0 with 2 tasks
15/10/21 17:00:06 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 113, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 114, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO Executor: Running task 0.0 in stage 57.0 (TID 113)
15/10/21 17:00:06 INFO Executor: Running task 1.0 in stage 57.0 (TID 114)
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:06 INFO PythonRDD: Times: total = 41, boot = -11, init = 52, finish = 0
15/10/21 17:00:06 INFO PythonRDD: Times: total = 41, boot = -11, init = 52, finish = 0
15/10/21 17:00:06 INFO Executor: Finished task 1.0 in stage 57.0 (TID 114). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO Executor: Finished task 0.0 in stage 57.0 (TID 113). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 114) in 46 ms on localhost (1/2)
15/10/21 17:00:06 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 113) in 46 ms on localhost (2/2)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
15/10/21 17:00:06 INFO DAGScheduler: ResultStage 57 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:00:06 INFO DAGScheduler: Job 56 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.057040 s
15/10/21 17:00:06 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:06 INFO DAGScheduler: Got job 57 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:06 INFO DAGScheduler: Final stage: ResultStage 58(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:06 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:06 INFO DAGScheduler: Submitting ResultStage 58 (PythonRDD[64] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=253081, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=259473, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:06 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 58 (PythonRDD[64] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Adding task set 58.0 with 2 tasks
15/10/21 17:00:06 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 115, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO TaskSetManager: Starting task 1.0 in stage 58.0 (TID 116, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO Executor: Running task 0.0 in stage 58.0 (TID 115)
15/10/21 17:00:06 INFO Executor: Running task 1.0 in stage 58.0 (TID 116)
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:06 INFO PythonRDD: Times: total = 38, boot = -11, init = 49, finish = 0
15/10/21 17:00:06 INFO PythonRDD: Times: total = 38, boot = -11, init = 49, finish = 0
15/10/21 17:00:06 INFO Executor: Finished task 0.0 in stage 58.0 (TID 115). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO Executor: Finished task 1.0 in stage 58.0 (TID 116). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 115) in 43 ms on localhost (1/2)
15/10/21 17:00:06 INFO TaskSetManager: Finished task 1.0 in stage 58.0 (TID 116) in 44 ms on localhost (2/2)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
15/10/21 17:00:06 INFO DAGScheduler: ResultStage 58 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:06 INFO DAGScheduler: Job 57 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053402 s
15/10/21 17:00:06 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:06 INFO DAGScheduler: Got job 58 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:06 INFO DAGScheduler: Final stage: ResultStage 59(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:06 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:06 INFO DAGScheduler: Submitting ResultStage 59 (PythonRDD[65] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=263278, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=269670, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:06 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 59 (PythonRDD[65] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Adding task set 59.0 with 2 tasks
15/10/21 17:00:06 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 117, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO TaskSetManager: Starting task 1.0 in stage 59.0 (TID 118, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO Executor: Running task 1.0 in stage 59.0 (TID 118)
15/10/21 17:00:06 INFO Executor: Running task 0.0 in stage 59.0 (TID 117)
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:06 INFO PythonRDD: Times: total = 40, boot = -11, init = 51, finish = 0
15/10/21 17:00:06 INFO PythonRDD: Times: total = 40, boot = -13, init = 53, finish = 0
15/10/21 17:00:06 INFO Executor: Finished task 0.0 in stage 59.0 (TID 117). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO Executor: Finished task 1.0 in stage 59.0 (TID 118). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 117) in 45 ms on localhost (1/2)
15/10/21 17:00:06 INFO TaskSetManager: Finished task 1.0 in stage 59.0 (TID 118) in 45 ms on localhost (2/2)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
15/10/21 17:00:06 INFO DAGScheduler: ResultStage 59 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:00:06 INFO DAGScheduler: Job 58 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.056512 s
15/10/21 17:00:06 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:06 INFO DAGScheduler: Got job 59 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:06 INFO DAGScheduler: Final stage: ResultStage 60(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:06 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:06 INFO DAGScheduler: Submitting ResultStage 60 (PythonRDD[66] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=273475, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:06 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=279867, maxMem=278302556
15/10/21 17:00:06 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:06 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:06 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 60 (PythonRDD[66] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Adding task set 60.0 with 2 tasks
15/10/21 17:00:06 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 119, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO TaskSetManager: Starting task 1.0 in stage 60.0 (TID 120, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:06 INFO Executor: Running task 0.0 in stage 60.0 (TID 119)
15/10/21 17:00:06 INFO Executor: Running task 1.0 in stage 60.0 (TID 120)
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:06 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:06 INFO PythonRDD: Times: total = 41, boot = -12, init = 53, finish = 0
15/10/21 17:00:06 INFO PythonRDD: Times: total = 41, boot = -15, init = 56, finish = 0
15/10/21 17:00:06 INFO Executor: Finished task 0.0 in stage 60.0 (TID 119). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO Executor: Finished task 1.0 in stage 60.0 (TID 120). 1870 bytes result sent to driver
15/10/21 17:00:06 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 119) in 46 ms on localhost (1/2)
15/10/21 17:00:06 INFO TaskSetManager: Finished task 1.0 in stage 60.0 (TID 120) in 46 ms on localhost (2/2)
15/10/21 17:00:06 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
15/10/21 17:00:06 INFO DAGScheduler: ResultStage 60 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.048 s
15/10/21 17:00:06 INFO DAGScheduler: Job 59 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.056678 s
15/10/21 17:00:07 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:07 INFO DAGScheduler: Got job 60 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:07 INFO DAGScheduler: Final stage: ResultStage 61(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:07 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:07 INFO DAGScheduler: Submitting ResultStage 61 (PythonRDD[67] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=283672, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=290064, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:07 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 61 (PythonRDD[67] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Adding task set 61.0 with 2 tasks
15/10/21 17:00:07 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 121, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO TaskSetManager: Starting task 1.0 in stage 61.0 (TID 122, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO Executor: Running task 0.0 in stage 61.0 (TID 121)
15/10/21 17:00:07 INFO Executor: Running task 1.0 in stage 61.0 (TID 122)
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:07 INFO PythonRDD: Times: total = 40, boot = -11, init = 51, finish = 0
15/10/21 17:00:07 INFO PythonRDD: Times: total = 40, boot = -15, init = 55, finish = 0
15/10/21 17:00:07 INFO Executor: Finished task 1.0 in stage 61.0 (TID 122). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO Executor: Finished task 0.0 in stage 61.0 (TID 121). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO TaskSetManager: Finished task 1.0 in stage 61.0 (TID 122) in 45 ms on localhost (1/2)
15/10/21 17:00:07 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 121) in 46 ms on localhost (2/2)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
15/10/21 17:00:07 INFO DAGScheduler: ResultStage 61 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:00:07 INFO DAGScheduler: Job 60 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.056263 s
15/10/21 17:00:07 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:07 INFO DAGScheduler: Got job 61 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:07 INFO DAGScheduler: Final stage: ResultStage 62(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:07 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:07 INFO DAGScheduler: Submitting ResultStage 62 (PythonRDD[68] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=293869, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=300261, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:07 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 62 (PythonRDD[68] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Adding task set 62.0 with 2 tasks
15/10/21 17:00:07 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 123, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO TaskSetManager: Starting task 1.0 in stage 62.0 (TID 124, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO Executor: Running task 0.0 in stage 62.0 (TID 123)
15/10/21 17:00:07 INFO Executor: Running task 1.0 in stage 62.0 (TID 124)
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:07 INFO PythonRDD: Times: total = 37, boot = -13, init = 50, finish = 0
15/10/21 17:00:07 INFO Executor: Finished task 0.0 in stage 62.0 (TID 123). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 123) in 43 ms on localhost (1/2)
15/10/21 17:00:07 INFO PythonRDD: Times: total = 41, boot = -15, init = 56, finish = 0
15/10/21 17:00:07 INFO Executor: Finished task 1.0 in stage 62.0 (TID 124). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO TaskSetManager: Finished task 1.0 in stage 62.0 (TID 124) in 46 ms on localhost (2/2)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
15/10/21 17:00:07 INFO DAGScheduler: ResultStage 62 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:00:07 INFO DAGScheduler: Job 61 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.056576 s
15/10/21 17:00:07 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:07 INFO DAGScheduler: Got job 62 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:07 INFO DAGScheduler: Final stage: ResultStage 63(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:07 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:07 INFO DAGScheduler: Submitting ResultStage 63 (PythonRDD[69] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=304066, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=310458, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:07 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 63 (PythonRDD[69] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Adding task set 63.0 with 2 tasks
15/10/21 17:00:07 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 125, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO TaskSetManager: Starting task 1.0 in stage 63.0 (TID 126, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO Executor: Running task 0.0 in stage 63.0 (TID 125)
15/10/21 17:00:07 INFO Executor: Running task 1.0 in stage 63.0 (TID 126)
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:07 INFO PythonRDD: Times: total = 41, boot = -12, init = 53, finish = 0
15/10/21 17:00:07 INFO PythonRDD: Times: total = 41, boot = -16, init = 57, finish = 0
15/10/21 17:00:07 INFO Executor: Finished task 1.0 in stage 63.0 (TID 126). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO Executor: Finished task 0.0 in stage 63.0 (TID 125). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO TaskSetManager: Finished task 1.0 in stage 63.0 (TID 126) in 46 ms on localhost (1/2)
15/10/21 17:00:07 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 125) in 46 ms on localhost (2/2)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
15/10/21 17:00:07 INFO DAGScheduler: ResultStage 63 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.048 s
15/10/21 17:00:07 INFO DAGScheduler: Job 62 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.057738 s
15/10/21 17:00:07 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:07 INFO DAGScheduler: Got job 63 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:07 INFO DAGScheduler: Final stage: ResultStage 64(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:07 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:07 INFO DAGScheduler: Submitting ResultStage 64 (PythonRDD[70] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=314263, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=320655, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:07 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 64 (PythonRDD[70] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Adding task set 64.0 with 2 tasks
15/10/21 17:00:07 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 127, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO TaskSetManager: Starting task 1.0 in stage 64.0 (TID 128, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO Executor: Running task 0.0 in stage 64.0 (TID 127)
15/10/21 17:00:07 INFO Executor: Running task 1.0 in stage 64.0 (TID 128)
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:07 INFO PythonRDD: Times: total = 39, boot = -15, init = 54, finish = 0
15/10/21 17:00:07 INFO PythonRDD: Times: total = 39, boot = -16, init = 55, finish = 0
15/10/21 17:00:07 INFO Executor: Finished task 1.0 in stage 64.0 (TID 128). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO Executor: Finished task 0.0 in stage 64.0 (TID 127). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO TaskSetManager: Finished task 1.0 in stage 64.0 (TID 128) in 44 ms on localhost (1/2)
15/10/21 17:00:07 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 127) in 45 ms on localhost (2/2)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
15/10/21 17:00:07 INFO DAGScheduler: ResultStage 64 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:07 INFO DAGScheduler: Job 63 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.055862 s
15/10/21 17:00:07 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:07 INFO DAGScheduler: Got job 64 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:07 INFO DAGScheduler: Final stage: ResultStage 65(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:07 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:07 INFO DAGScheduler: Submitting ResultStage 65 (PythonRDD[71] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=324460, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=330852, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:07 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 65 (PythonRDD[71] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Adding task set 65.0 with 2 tasks
15/10/21 17:00:07 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 129, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO TaskSetManager: Starting task 1.0 in stage 65.0 (TID 130, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO Executor: Running task 0.0 in stage 65.0 (TID 129)
15/10/21 17:00:07 INFO Executor: Running task 1.0 in stage 65.0 (TID 130)
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:07 INFO PythonRDD: Times: total = 38, boot = -10, init = 48, finish = 0
15/10/21 17:00:07 INFO Executor: Finished task 0.0 in stage 65.0 (TID 129). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 129) in 43 ms on localhost (1/2)
15/10/21 17:00:07 INFO PythonRDD: Times: total = 41, boot = -12, init = 53, finish = 0
15/10/21 17:00:07 INFO Executor: Finished task 1.0 in stage 65.0 (TID 130). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO TaskSetManager: Finished task 1.0 in stage 65.0 (TID 130) in 47 ms on localhost (2/2)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
15/10/21 17:00:07 INFO DAGScheduler: ResultStage 65 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:00:07 INFO DAGScheduler: Job 64 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.057226 s
15/10/21 17:00:07 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:07 INFO DAGScheduler: Got job 65 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:07 INFO DAGScheduler: Final stage: ResultStage 66(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:07 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:07 INFO DAGScheduler: Submitting ResultStage 66 (PythonRDD[72] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=334657, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=341049, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:07 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 66 (PythonRDD[72] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Adding task set 66.0 with 2 tasks
15/10/21 17:00:07 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 131, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO TaskSetManager: Starting task 1.0 in stage 66.0 (TID 132, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO Executor: Running task 0.0 in stage 66.0 (TID 131)
15/10/21 17:00:07 INFO Executor: Running task 1.0 in stage 66.0 (TID 132)
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:07 INFO PythonRDD: Times: total = 41, boot = -12, init = 53, finish = 0
15/10/21 17:00:07 INFO PythonRDD: Times: total = 41, boot = -16, init = 57, finish = 0
15/10/21 17:00:07 INFO Executor: Finished task 1.0 in stage 66.0 (TID 132). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO Executor: Finished task 0.0 in stage 66.0 (TID 131). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO TaskSetManager: Finished task 1.0 in stage 66.0 (TID 132) in 46 ms on localhost (1/2)
15/10/21 17:00:07 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 131) in 46 ms on localhost (2/2)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
15/10/21 17:00:07 INFO DAGScheduler: ResultStage 66 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:07 INFO DAGScheduler: Job 65 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.057034 s
15/10/21 17:00:07 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:07 INFO DAGScheduler: Got job 66 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:07 INFO DAGScheduler: Final stage: ResultStage 67(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:07 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:07 INFO DAGScheduler: Submitting ResultStage 67 (PythonRDD[73] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=344854, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=351246, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:07 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 67 (PythonRDD[73] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Adding task set 67.0 with 2 tasks
15/10/21 17:00:07 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 133, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO TaskSetManager: Starting task 1.0 in stage 67.0 (TID 134, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO Executor: Running task 0.0 in stage 67.0 (TID 133)
15/10/21 17:00:07 INFO Executor: Running task 1.0 in stage 67.0 (TID 134)
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:07 INFO PythonRDD: Times: total = 41, boot = -13, init = 54, finish = 0
15/10/21 17:00:07 INFO PythonRDD: Times: total = 41, boot = -12, init = 53, finish = 0
15/10/21 17:00:07 INFO Executor: Finished task 0.0 in stage 67.0 (TID 133). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO Executor: Finished task 1.0 in stage 67.0 (TID 134). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 133) in 46 ms on localhost (1/2)
15/10/21 17:00:07 INFO TaskSetManager: Finished task 1.0 in stage 67.0 (TID 134) in 46 ms on localhost (2/2)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
15/10/21 17:00:07 INFO DAGScheduler: ResultStage 67 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:00:07 INFO DAGScheduler: Job 66 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.057352 s
15/10/21 17:00:07 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:07 INFO DAGScheduler: Got job 67 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:07 INFO DAGScheduler: Final stage: ResultStage 68(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:07 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:07 INFO DAGScheduler: Submitting ResultStage 68 (PythonRDD[74] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=355051, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=361443, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:07 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 68 (PythonRDD[74] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Adding task set 68.0 with 2 tasks
15/10/21 17:00:07 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 135, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO TaskSetManager: Starting task 1.0 in stage 68.0 (TID 136, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO Executor: Running task 0.0 in stage 68.0 (TID 135)
15/10/21 17:00:07 INFO Executor: Running task 1.0 in stage 68.0 (TID 136)
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:07 INFO PythonRDD: Times: total = 38, boot = -12, init = 50, finish = 0
15/10/21 17:00:07 INFO PythonRDD: Times: total = 38, boot = -12, init = 50, finish = 0
15/10/21 17:00:07 INFO Executor: Finished task 1.0 in stage 68.0 (TID 136). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO Executor: Finished task 0.0 in stage 68.0 (TID 135). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO TaskSetManager: Finished task 1.0 in stage 68.0 (TID 136) in 43 ms on localhost (1/2)
15/10/21 17:00:07 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 135) in 43 ms on localhost (2/2)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
15/10/21 17:00:07 INFO DAGScheduler: ResultStage 68 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:07 INFO DAGScheduler: Job 67 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053532 s
15/10/21 17:00:07 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:07 INFO DAGScheduler: Got job 68 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:07 INFO DAGScheduler: Final stage: ResultStage 69(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:07 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:07 INFO DAGScheduler: Submitting ResultStage 69 (PythonRDD[75] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=365248, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=371640, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:07 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:07 INFO BlockManagerInfo: Removed broadcast_69_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 69 (PythonRDD[75] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Adding task set 69.0 with 2 tasks
15/10/21 17:00:07 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 137, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 138, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO BlockManagerInfo: Removed broadcast_68_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:07 INFO Executor: Running task 1.0 in stage 69.0 (TID 138)
15/10/21 17:00:07 INFO Executor: Running task 0.0 in stage 69.0 (TID 137)
15/10/21 17:00:07 INFO BlockManagerInfo: Removed broadcast_67_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:07 INFO BlockManagerInfo: Removed broadcast_66_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Removed broadcast_65_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Removed broadcast_64_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Removed broadcast_63_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Removed broadcast_62_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Removed broadcast_61_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Removed broadcast_60_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Removed broadcast_59_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Removed broadcast_58_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Removed broadcast_57_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Removed broadcast_56_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Removed broadcast_55_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Removed broadcast_54_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Removed broadcast_53_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Removed broadcast_52_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Removed broadcast_51_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:07 INFO PythonRDD: Times: total = 39, boot = -33, init = 72, finish = 0
15/10/21 17:00:07 INFO PythonRDD: Times: total = 40, boot = -32, init = 72, finish = 0
15/10/21 17:00:07 INFO Executor: Finished task 1.0 in stage 69.0 (TID 138). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO Executor: Finished task 0.0 in stage 69.0 (TID 137). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 138) in 45 ms on localhost (1/2)
15/10/21 17:00:07 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 137) in 45 ms on localhost (2/2)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
15/10/21 17:00:07 INFO DAGScheduler: ResultStage 69 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:07 INFO DAGScheduler: Job 68 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.076700 s
15/10/21 17:00:07 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:07 INFO DAGScheduler: Got job 69 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:07 INFO DAGScheduler: Final stage: ResultStage 70(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:07 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:07 INFO DAGScheduler: Submitting ResultStage 70 (PythonRDD[76] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=181702, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=188094, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:07 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 70 (PythonRDD[76] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Adding task set 70.0 with 2 tasks
15/10/21 17:00:07 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 139, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO TaskSetManager: Starting task 1.0 in stage 70.0 (TID 140, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO Executor: Running task 0.0 in stage 70.0 (TID 139)
15/10/21 17:00:07 INFO Executor: Running task 1.0 in stage 70.0 (TID 140)
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:07 INFO PythonRDD: Times: total = 38, boot = -11, init = 49, finish = 0
15/10/21 17:00:07 INFO PythonRDD: Times: total = 38, boot = -11, init = 49, finish = 0
15/10/21 17:00:07 INFO Executor: Finished task 0.0 in stage 70.0 (TID 139). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO Executor: Finished task 1.0 in stage 70.0 (TID 140). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 139) in 43 ms on localhost (1/2)
15/10/21 17:00:07 INFO TaskSetManager: Finished task 1.0 in stage 70.0 (TID 140) in 43 ms on localhost (2/2)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
15/10/21 17:00:07 INFO DAGScheduler: ResultStage 70 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:07 INFO DAGScheduler: Job 69 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053645 s
15/10/21 17:00:07 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:07 INFO DAGScheduler: Got job 70 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:07 INFO DAGScheduler: Final stage: ResultStage 71(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:07 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:07 INFO DAGScheduler: Submitting ResultStage 71 (PythonRDD[77] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=191899, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=198291, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:07 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 71 (PythonRDD[77] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Adding task set 71.0 with 2 tasks
15/10/21 17:00:07 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 141, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 142, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO Executor: Running task 0.0 in stage 71.0 (TID 141)
15/10/21 17:00:07 INFO Executor: Running task 1.0 in stage 71.0 (TID 142)
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:07 INFO PythonRDD: Times: total = 39, boot = -11, init = 50, finish = 0
15/10/21 17:00:07 INFO PythonRDD: Times: total = 38, boot = -12, init = 50, finish = 0
15/10/21 17:00:07 INFO Executor: Finished task 1.0 in stage 71.0 (TID 142). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO Executor: Finished task 0.0 in stage 71.0 (TID 141). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 142) in 43 ms on localhost (1/2)
15/10/21 17:00:07 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 141) in 44 ms on localhost (2/2)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
15/10/21 17:00:07 INFO DAGScheduler: ResultStage 71 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:07 INFO DAGScheduler: Job 70 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053454 s
15/10/21 17:00:07 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:07 INFO DAGScheduler: Got job 71 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:07 INFO DAGScheduler: Final stage: ResultStage 72(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:07 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:07 INFO DAGScheduler: Submitting ResultStage 72 (PythonRDD[78] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=202096, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=208488, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:07 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 72 (PythonRDD[78] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Adding task set 72.0 with 2 tasks
15/10/21 17:00:07 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 143, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO TaskSetManager: Starting task 1.0 in stage 72.0 (TID 144, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO Executor: Running task 1.0 in stage 72.0 (TID 144)
15/10/21 17:00:07 INFO Executor: Running task 0.0 in stage 72.0 (TID 143)
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:07 INFO PythonRDD: Times: total = 39, boot = -11, init = 50, finish = 0
15/10/21 17:00:07 INFO PythonRDD: Times: total = 38, boot = -12, init = 50, finish = 0
15/10/21 17:00:07 INFO Executor: Finished task 1.0 in stage 72.0 (TID 144). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO Executor: Finished task 0.0 in stage 72.0 (TID 143). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO TaskSetManager: Finished task 1.0 in stage 72.0 (TID 144) in 43 ms on localhost (1/2)
15/10/21 17:00:07 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 143) in 43 ms on localhost (2/2)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
15/10/21 17:00:07 INFO DAGScheduler: ResultStage 72 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:07 INFO DAGScheduler: Job 71 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053715 s
15/10/21 17:00:07 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:07 INFO DAGScheduler: Got job 72 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:07 INFO DAGScheduler: Final stage: ResultStage 73(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:07 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:07 INFO DAGScheduler: Submitting ResultStage 73 (PythonRDD[79] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=212293, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=218685, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:07 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 73 (PythonRDD[79] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Adding task set 73.0 with 2 tasks
15/10/21 17:00:07 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 145, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO TaskSetManager: Starting task 1.0 in stage 73.0 (TID 146, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO Executor: Running task 0.0 in stage 73.0 (TID 145)
15/10/21 17:00:07 INFO Executor: Running task 1.0 in stage 73.0 (TID 146)
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:07 INFO PythonRDD: Times: total = 40, boot = -8, init = 48, finish = 0
15/10/21 17:00:07 INFO PythonRDD: Times: total = 39, boot = -9, init = 48, finish = 0
15/10/21 17:00:07 INFO Executor: Finished task 1.0 in stage 73.0 (TID 146). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO Executor: Finished task 0.0 in stage 73.0 (TID 145). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO TaskSetManager: Finished task 1.0 in stage 73.0 (TID 146) in 44 ms on localhost (1/2)
15/10/21 17:00:07 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 145) in 44 ms on localhost (2/2)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
15/10/21 17:00:07 INFO DAGScheduler: ResultStage 73 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:07 INFO DAGScheduler: Job 72 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.054481 s
15/10/21 17:00:07 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:07 INFO DAGScheduler: Got job 73 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:07 INFO DAGScheduler: Final stage: ResultStage 74(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:07 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:07 INFO DAGScheduler: Submitting ResultStage 74 (PythonRDD[80] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=222490, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:07 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=228882, maxMem=278302556
15/10/21 17:00:07 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:07 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:07 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:07 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 74 (PythonRDD[80] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Adding task set 74.0 with 2 tasks
15/10/21 17:00:07 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 147, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO TaskSetManager: Starting task 1.0 in stage 74.0 (TID 148, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:07 INFO Executor: Running task 0.0 in stage 74.0 (TID 147)
15/10/21 17:00:07 INFO Executor: Running task 1.0 in stage 74.0 (TID 148)
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:07 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:07 INFO PythonRDD: Times: total = 37, boot = -13, init = 50, finish = 0
15/10/21 17:00:07 INFO PythonRDD: Times: total = 37, boot = -12, init = 49, finish = 0
15/10/21 17:00:07 INFO Executor: Finished task 1.0 in stage 74.0 (TID 148). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO Executor: Finished task 0.0 in stage 74.0 (TID 147). 1870 bytes result sent to driver
15/10/21 17:00:07 INFO TaskSetManager: Finished task 1.0 in stage 74.0 (TID 148) in 42 ms on localhost (1/2)
15/10/21 17:00:07 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 147) in 42 ms on localhost (2/2)
15/10/21 17:00:07 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
15/10/21 17:00:07 INFO DAGScheduler: ResultStage 74 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:07 INFO DAGScheduler: Job 73 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053020 s
15/10/21 17:00:08 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:08 INFO DAGScheduler: Got job 74 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:08 INFO DAGScheduler: Final stage: ResultStage 75(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:08 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:08 INFO DAGScheduler: Submitting ResultStage 75 (PythonRDD[81] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=232687, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=239079, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:08 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 75 (PythonRDD[81] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Adding task set 75.0 with 2 tasks
15/10/21 17:00:08 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 149, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO TaskSetManager: Starting task 1.0 in stage 75.0 (TID 150, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO Executor: Running task 0.0 in stage 75.0 (TID 149)
15/10/21 17:00:08 INFO Executor: Running task 1.0 in stage 75.0 (TID 150)
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:08 INFO PythonRDD: Times: total = 39, boot = -10, init = 49, finish = 0
15/10/21 17:00:08 INFO PythonRDD: Times: total = 38, boot = -12, init = 50, finish = 0
15/10/21 17:00:08 INFO Executor: Finished task 1.0 in stage 75.0 (TID 150). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO Executor: Finished task 0.0 in stage 75.0 (TID 149). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO TaskSetManager: Finished task 1.0 in stage 75.0 (TID 150) in 43 ms on localhost (1/2)
15/10/21 17:00:08 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 149) in 44 ms on localhost (2/2)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
15/10/21 17:00:08 INFO DAGScheduler: ResultStage 75 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:08 INFO DAGScheduler: Job 74 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053015 s
15/10/21 17:00:08 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:08 INFO DAGScheduler: Got job 75 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:08 INFO DAGScheduler: Final stage: ResultStage 76(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:08 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:08 INFO DAGScheduler: Submitting ResultStage 76 (PythonRDD[82] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=242884, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=249276, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:08 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 76 (PythonRDD[82] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Adding task set 76.0 with 2 tasks
15/10/21 17:00:08 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 151, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO TaskSetManager: Starting task 1.0 in stage 76.0 (TID 152, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO Executor: Running task 1.0 in stage 76.0 (TID 152)
15/10/21 17:00:08 INFO Executor: Running task 0.0 in stage 76.0 (TID 151)
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:08 INFO PythonRDD: Times: total = 39, boot = -11, init = 50, finish = 0
15/10/21 17:00:08 INFO PythonRDD: Times: total = 39, boot = -10, init = 49, finish = 0
15/10/21 17:00:08 INFO Executor: Finished task 1.0 in stage 76.0 (TID 152). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO Executor: Finished task 0.0 in stage 76.0 (TID 151). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO TaskSetManager: Finished task 1.0 in stage 76.0 (TID 152) in 44 ms on localhost (1/2)
15/10/21 17:00:08 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 151) in 44 ms on localhost (2/2)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
15/10/21 17:00:08 INFO DAGScheduler: ResultStage 76 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:08 INFO DAGScheduler: Job 75 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.054132 s
15/10/21 17:00:08 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:08 INFO DAGScheduler: Got job 76 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:08 INFO DAGScheduler: Final stage: ResultStage 77(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:08 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:08 INFO DAGScheduler: Submitting ResultStage 77 (PythonRDD[83] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=253081, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=259473, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:08 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 77 (PythonRDD[83] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Adding task set 77.0 with 2 tasks
15/10/21 17:00:08 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 153, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 154, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO Executor: Running task 0.0 in stage 77.0 (TID 153)
15/10/21 17:00:08 INFO Executor: Running task 1.0 in stage 77.0 (TID 154)
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:08 INFO PythonRDD: Times: total = 38, boot = -9, init = 47, finish = 0
15/10/21 17:00:08 INFO PythonRDD: Times: total = 38, boot = -9, init = 47, finish = 0
15/10/21 17:00:08 INFO Executor: Finished task 0.0 in stage 77.0 (TID 153). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO Executor: Finished task 1.0 in stage 77.0 (TID 154). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 153) in 43 ms on localhost (1/2)
15/10/21 17:00:08 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 154) in 42 ms on localhost (2/2)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
15/10/21 17:00:08 INFO DAGScheduler: ResultStage 77 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:08 INFO DAGScheduler: Job 76 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053421 s
15/10/21 17:00:08 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:08 INFO DAGScheduler: Got job 77 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:08 INFO DAGScheduler: Final stage: ResultStage 78(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:08 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:08 INFO DAGScheduler: Submitting ResultStage 78 (PythonRDD[84] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=263278, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=269670, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:08 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 78 (PythonRDD[84] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Adding task set 78.0 with 2 tasks
15/10/21 17:00:08 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 155, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 156, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO Executor: Running task 1.0 in stage 78.0 (TID 156)
15/10/21 17:00:08 INFO Executor: Running task 0.0 in stage 78.0 (TID 155)
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:08 INFO PythonRDD: Times: total = 38, boot = -11, init = 49, finish = 0
15/10/21 17:00:08 INFO PythonRDD: Times: total = 38, boot = -11, init = 49, finish = 0
15/10/21 17:00:08 INFO Executor: Finished task 0.0 in stage 78.0 (TID 155). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO Executor: Finished task 1.0 in stage 78.0 (TID 156). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 155) in 43 ms on localhost (1/2)
15/10/21 17:00:08 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 156) in 42 ms on localhost (2/2)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
15/10/21 17:00:08 INFO DAGScheduler: ResultStage 78 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:08 INFO DAGScheduler: Job 77 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053808 s
15/10/21 17:00:08 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:08 INFO DAGScheduler: Got job 78 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:08 INFO DAGScheduler: Final stage: ResultStage 79(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:08 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:08 INFO DAGScheduler: Submitting ResultStage 79 (PythonRDD[85] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=273475, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=279867, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:08 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 79 (PythonRDD[85] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Adding task set 79.0 with 2 tasks
15/10/21 17:00:08 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 157, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 158, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO Executor: Running task 0.0 in stage 79.0 (TID 157)
15/10/21 17:00:08 INFO Executor: Running task 1.0 in stage 79.0 (TID 158)
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:08 INFO PythonRDD: Times: total = 41, boot = -11, init = 52, finish = 0
15/10/21 17:00:08 INFO PythonRDD: Times: total = 41, boot = -11, init = 52, finish = 0
15/10/21 17:00:08 INFO Executor: Finished task 1.0 in stage 79.0 (TID 158). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO Executor: Finished task 0.0 in stage 79.0 (TID 157). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 158) in 45 ms on localhost (1/2)
15/10/21 17:00:08 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 157) in 46 ms on localhost (2/2)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
15/10/21 17:00:08 INFO DAGScheduler: ResultStage 79 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:08 INFO DAGScheduler: Job 78 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.056478 s
15/10/21 17:00:08 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:08 INFO DAGScheduler: Got job 79 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:08 INFO DAGScheduler: Final stage: ResultStage 80(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:08 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:08 INFO DAGScheduler: Submitting ResultStage 80 (PythonRDD[86] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=283672, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=290064, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:08 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 80 (PythonRDD[86] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Adding task set 80.0 with 2 tasks
15/10/21 17:00:08 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 159, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO TaskSetManager: Starting task 1.0 in stage 80.0 (TID 160, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO Executor: Running task 0.0 in stage 80.0 (TID 159)
15/10/21 17:00:08 INFO Executor: Running task 1.0 in stage 80.0 (TID 160)
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:08 INFO PythonRDD: Times: total = 39, boot = -12, init = 51, finish = 0
15/10/21 17:00:08 INFO Executor: Finished task 0.0 in stage 80.0 (TID 159). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 159) in 42 ms on localhost (1/2)
15/10/21 17:00:08 INFO PythonRDD: Times: total = 42, boot = -10, init = 52, finish = 0
15/10/21 17:00:08 INFO Executor: Finished task 1.0 in stage 80.0 (TID 160). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO TaskSetManager: Finished task 1.0 in stage 80.0 (TID 160) in 46 ms on localhost (2/2)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
15/10/21 17:00:08 INFO DAGScheduler: ResultStage 80 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:00:08 INFO DAGScheduler: Job 79 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.057174 s
15/10/21 17:00:08 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:08 INFO DAGScheduler: Got job 80 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:08 INFO DAGScheduler: Final stage: ResultStage 81(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:08 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:08 INFO DAGScheduler: Submitting ResultStage 81 (PythonRDD[87] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=293869, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=300261, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:08 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 81 (PythonRDD[87] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Adding task set 81.0 with 2 tasks
15/10/21 17:00:08 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 161, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 162, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO Executor: Running task 0.0 in stage 81.0 (TID 161)
15/10/21 17:00:08 INFO Executor: Running task 1.0 in stage 81.0 (TID 162)
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:08 INFO PythonRDD: Times: total = 40, boot = -12, init = 52, finish = 0
15/10/21 17:00:08 INFO PythonRDD: Times: total = 40, boot = -9, init = 49, finish = 0
15/10/21 17:00:08 INFO Executor: Finished task 0.0 in stage 81.0 (TID 161). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO Executor: Finished task 1.0 in stage 81.0 (TID 162). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 161) in 44 ms on localhost (1/2)
15/10/21 17:00:08 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 162) in 44 ms on localhost (2/2)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
15/10/21 17:00:08 INFO DAGScheduler: ResultStage 81 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:08 INFO DAGScheduler: Job 80 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.054954 s
15/10/21 17:00:08 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:08 INFO DAGScheduler: Got job 81 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:08 INFO DAGScheduler: Final stage: ResultStage 82(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:08 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:08 INFO DAGScheduler: Submitting ResultStage 82 (PythonRDD[88] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=304066, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=310458, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:08 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 82 (PythonRDD[88] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Adding task set 82.0 with 2 tasks
15/10/21 17:00:08 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 163, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO TaskSetManager: Starting task 1.0 in stage 82.0 (TID 164, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO Executor: Running task 0.0 in stage 82.0 (TID 163)
15/10/21 17:00:08 INFO Executor: Running task 1.0 in stage 82.0 (TID 164)
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:08 INFO PythonRDD: Times: total = 38, boot = -11, init = 49, finish = 0
15/10/21 17:00:08 INFO PythonRDD: Times: total = 39, boot = -11, init = 50, finish = 0
15/10/21 17:00:08 INFO Executor: Finished task 1.0 in stage 82.0 (TID 164). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO Executor: Finished task 0.0 in stage 82.0 (TID 163). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO TaskSetManager: Finished task 1.0 in stage 82.0 (TID 164) in 43 ms on localhost (1/2)
15/10/21 17:00:08 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 163) in 44 ms on localhost (2/2)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
15/10/21 17:00:08 INFO DAGScheduler: ResultStage 82 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:08 INFO DAGScheduler: Job 81 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053706 s
15/10/21 17:00:08 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:08 INFO DAGScheduler: Got job 82 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:08 INFO DAGScheduler: Final stage: ResultStage 83(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:08 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:08 INFO DAGScheduler: Submitting ResultStage 83 (PythonRDD[89] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=314263, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=320655, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:08 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 83 (PythonRDD[89] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Adding task set 83.0 with 2 tasks
15/10/21 17:00:08 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 165, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO TaskSetManager: Starting task 1.0 in stage 83.0 (TID 166, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO Executor: Running task 0.0 in stage 83.0 (TID 165)
15/10/21 17:00:08 INFO Executor: Running task 1.0 in stage 83.0 (TID 166)
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:08 INFO PythonRDD: Times: total = 38, boot = -13, init = 51, finish = 0
15/10/21 17:00:08 INFO PythonRDD: Times: total = 38, boot = -13, init = 51, finish = 0
15/10/21 17:00:08 INFO Executor: Finished task 1.0 in stage 83.0 (TID 166). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO Executor: Finished task 0.0 in stage 83.0 (TID 165). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO TaskSetManager: Finished task 1.0 in stage 83.0 (TID 166) in 43 ms on localhost (1/2)
15/10/21 17:00:08 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 165) in 43 ms on localhost (2/2)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
15/10/21 17:00:08 INFO DAGScheduler: ResultStage 83 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:08 INFO DAGScheduler: Job 82 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053004 s
15/10/21 17:00:08 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:08 INFO DAGScheduler: Got job 83 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:08 INFO DAGScheduler: Final stage: ResultStage 84(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:08 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:08 INFO DAGScheduler: Submitting ResultStage 84 (PythonRDD[90] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=324460, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=330852, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:08 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 84 (PythonRDD[90] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Adding task set 84.0 with 2 tasks
15/10/21 17:00:08 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 167, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO TaskSetManager: Starting task 1.0 in stage 84.0 (TID 168, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO Executor: Running task 0.0 in stage 84.0 (TID 167)
15/10/21 17:00:08 INFO Executor: Running task 1.0 in stage 84.0 (TID 168)
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:08 INFO PythonRDD: Times: total = 38, boot = -10, init = 48, finish = 0
15/10/21 17:00:08 INFO PythonRDD: Times: total = 38, boot = -13, init = 51, finish = 0
15/10/21 17:00:08 INFO Executor: Finished task 1.0 in stage 84.0 (TID 168). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO Executor: Finished task 0.0 in stage 84.0 (TID 167). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO TaskSetManager: Finished task 1.0 in stage 84.0 (TID 168) in 42 ms on localhost (1/2)
15/10/21 17:00:08 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 167) in 43 ms on localhost (2/2)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
15/10/21 17:00:08 INFO DAGScheduler: ResultStage 84 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:08 INFO DAGScheduler: Job 83 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053239 s
15/10/21 17:00:08 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:08 INFO DAGScheduler: Got job 84 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:08 INFO DAGScheduler: Final stage: ResultStage 85(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:08 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:08 INFO DAGScheduler: Submitting ResultStage 85 (PythonRDD[91] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=334657, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=341049, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:08 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 85 (PythonRDD[91] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Adding task set 85.0 with 2 tasks
15/10/21 17:00:08 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 169, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO TaskSetManager: Starting task 1.0 in stage 85.0 (TID 170, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO Executor: Running task 1.0 in stage 85.0 (TID 170)
15/10/21 17:00:08 INFO Executor: Running task 0.0 in stage 85.0 (TID 169)
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:08 INFO PythonRDD: Times: total = 38, boot = -11, init = 49, finish = 0
15/10/21 17:00:08 INFO Executor: Finished task 1.0 in stage 85.0 (TID 170). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO TaskSetManager: Finished task 1.0 in stage 85.0 (TID 170) in 42 ms on localhost (1/2)
15/10/21 17:00:08 INFO PythonRDD: Times: total = 41, boot = -10, init = 51, finish = 0
15/10/21 17:00:08 INFO Executor: Finished task 0.0 in stage 85.0 (TID 169). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 169) in 46 ms on localhost (2/2)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
15/10/21 17:00:08 INFO DAGScheduler: ResultStage 85 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:00:08 INFO DAGScheduler: Job 84 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.056140 s
15/10/21 17:00:08 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:08 INFO DAGScheduler: Got job 85 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:08 INFO DAGScheduler: Final stage: ResultStage 86(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:08 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:08 INFO DAGScheduler: Submitting ResultStage 86 (PythonRDD[92] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=344854, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=351246, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:08 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 86 (PythonRDD[92] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Adding task set 86.0 with 2 tasks
15/10/21 17:00:08 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 171, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO TaskSetManager: Starting task 1.0 in stage 86.0 (TID 172, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO Executor: Running task 0.0 in stage 86.0 (TID 171)
15/10/21 17:00:08 INFO Executor: Running task 1.0 in stage 86.0 (TID 172)
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:08 INFO PythonRDD: Times: total = 38, boot = -9, init = 47, finish = 0
15/10/21 17:00:08 INFO PythonRDD: Times: total = 38, boot = -17, init = 55, finish = 0
15/10/21 17:00:08 INFO Executor: Finished task 1.0 in stage 86.0 (TID 172). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO Executor: Finished task 0.0 in stage 86.0 (TID 171). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO TaskSetManager: Finished task 1.0 in stage 86.0 (TID 172) in 42 ms on localhost (1/2)
15/10/21 17:00:08 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 171) in 43 ms on localhost (2/2)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
15/10/21 17:00:08 INFO DAGScheduler: ResultStage 86 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:08 INFO DAGScheduler: Job 85 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053496 s
15/10/21 17:00:08 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:08 INFO DAGScheduler: Got job 86 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:08 INFO DAGScheduler: Final stage: ResultStage 87(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:08 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:08 INFO DAGScheduler: Submitting ResultStage 87 (PythonRDD[93] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=355051, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=361443, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:08 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 87 (PythonRDD[93] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Adding task set 87.0 with 2 tasks
15/10/21 17:00:08 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 173, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO TaskSetManager: Starting task 1.0 in stage 87.0 (TID 174, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO Executor: Running task 0.0 in stage 87.0 (TID 173)
15/10/21 17:00:08 INFO Executor: Running task 1.0 in stage 87.0 (TID 174)
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:08 INFO BlockManagerInfo: Removed broadcast_87_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Removed broadcast_86_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Removed broadcast_85_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Removed broadcast_84_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Removed broadcast_83_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:08 INFO PythonRDD: Times: total = 37, boot = -11, init = 48, finish = 0
15/10/21 17:00:08 INFO Executor: Finished task 0.0 in stage 87.0 (TID 173). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 173) in 42 ms on localhost (1/2)
15/10/21 17:00:08 INFO BlockManagerInfo: Removed broadcast_82_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:08 INFO PythonRDD: Times: total = 41, boot = -10, init = 51, finish = 0
15/10/21 17:00:08 INFO BlockManagerInfo: Removed broadcast_81_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:08 INFO Executor: Finished task 1.0 in stage 87.0 (TID 174). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO TaskSetManager: Finished task 1.0 in stage 87.0 (TID 174) in 45 ms on localhost (2/2)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
15/10/21 17:00:08 INFO DAGScheduler: ResultStage 87 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:08 INFO DAGScheduler: Job 86 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.055456 s
15/10/21 17:00:08 INFO BlockManagerInfo: Removed broadcast_80_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Removed broadcast_79_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Removed broadcast_78_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Removed broadcast_77_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Removed broadcast_76_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Removed broadcast_75_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Removed broadcast_74_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:08 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:08 INFO DAGScheduler: Got job 87 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:08 INFO DAGScheduler: Final stage: ResultStage 88(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:08 INFO BlockManagerInfo: Removed broadcast_73_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:08 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:08 INFO DAGScheduler: Submitting ResultStage 88 (PythonRDD[94] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:08 INFO BlockManagerInfo: Removed broadcast_72_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=202096, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Removed broadcast_71_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=198291, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Removed broadcast_70_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:08 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 88 (PythonRDD[94] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Adding task set 88.0 with 2 tasks
15/10/21 17:00:08 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 175, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO TaskSetManager: Starting task 1.0 in stage 88.0 (TID 176, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO Executor: Running task 0.0 in stage 88.0 (TID 175)
15/10/21 17:00:08 INFO Executor: Running task 1.0 in stage 88.0 (TID 176)
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:08 INFO PythonRDD: Times: total = 39, boot = -14, init = 53, finish = 0
15/10/21 17:00:08 INFO PythonRDD: Times: total = 38, boot = -12, init = 50, finish = 0
15/10/21 17:00:08 INFO Executor: Finished task 1.0 in stage 88.0 (TID 176). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO Executor: Finished task 0.0 in stage 88.0 (TID 175). 1870 bytes result sent to driver
15/10/21 17:00:08 INFO TaskSetManager: Finished task 1.0 in stage 88.0 (TID 176) in 43 ms on localhost (1/2)
15/10/21 17:00:08 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 175) in 43 ms on localhost (2/2)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
15/10/21 17:00:08 INFO DAGScheduler: ResultStage 88 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:08 INFO DAGScheduler: Job 87 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053102 s
15/10/21 17:00:08 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:08 INFO DAGScheduler: Got job 88 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:08 INFO DAGScheduler: Final stage: ResultStage 89(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:08 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:08 INFO DAGScheduler: Submitting ResultStage 89 (PythonRDD[95] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=191899, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:08 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=198291, maxMem=278302556
15/10/21 17:00:08 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:08 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:08 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:08 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 89 (PythonRDD[95] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:08 INFO TaskSchedulerImpl: Adding task set 89.0 with 2 tasks
15/10/21 17:00:08 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 177, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO TaskSetManager: Starting task 1.0 in stage 89.0 (TID 178, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:08 INFO Executor: Running task 0.0 in stage 89.0 (TID 177)
15/10/21 17:00:08 INFO Executor: Running task 1.0 in stage 89.0 (TID 178)
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:08 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:09 INFO PythonRDD: Times: total = 39, boot = -10, init = 49, finish = 0
15/10/21 17:00:09 INFO PythonRDD: Times: total = 39, boot = -12, init = 51, finish = 0
15/10/21 17:00:09 INFO Executor: Finished task 1.0 in stage 89.0 (TID 178). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO Executor: Finished task 0.0 in stage 89.0 (TID 177). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO TaskSetManager: Finished task 1.0 in stage 89.0 (TID 178) in 43 ms on localhost (1/2)
15/10/21 17:00:09 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 177) in 44 ms on localhost (2/2)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
15/10/21 17:00:09 INFO DAGScheduler: ResultStage 89 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:09 INFO DAGScheduler: Job 88 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.054400 s
15/10/21 17:00:09 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:09 INFO DAGScheduler: Got job 89 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:09 INFO DAGScheduler: Final stage: ResultStage 90(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:09 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:09 INFO DAGScheduler: Submitting ResultStage 90 (PythonRDD[96] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=202096, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=208488, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:09 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:09 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 90 (PythonRDD[96] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Adding task set 90.0 with 2 tasks
15/10/21 17:00:09 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 179, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO TaskSetManager: Starting task 1.0 in stage 90.0 (TID 180, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO Executor: Running task 0.0 in stage 90.0 (TID 179)
15/10/21 17:00:09 INFO Executor: Running task 1.0 in stage 90.0 (TID 180)
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:09 INFO PythonRDD: Times: total = 39, boot = -11, init = 50, finish = 0
15/10/21 17:00:09 INFO PythonRDD: Times: total = 39, boot = -11, init = 50, finish = 0
15/10/21 17:00:09 INFO Executor: Finished task 1.0 in stage 90.0 (TID 180). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO Executor: Finished task 0.0 in stage 90.0 (TID 179). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO TaskSetManager: Finished task 1.0 in stage 90.0 (TID 180) in 43 ms on localhost (1/2)
15/10/21 17:00:09 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 179) in 44 ms on localhost (2/2)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
15/10/21 17:00:09 INFO DAGScheduler: ResultStage 90 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:09 INFO DAGScheduler: Job 89 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.052974 s
15/10/21 17:00:09 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:09 INFO DAGScheduler: Got job 90 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:09 INFO DAGScheduler: Final stage: ResultStage 91(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:09 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:09 INFO DAGScheduler: Submitting ResultStage 91 (PythonRDD[97] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=212293, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=218685, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:09 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:09 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 91 (PythonRDD[97] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Adding task set 91.0 with 2 tasks
15/10/21 17:00:09 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 181, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO TaskSetManager: Starting task 1.0 in stage 91.0 (TID 182, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO Executor: Running task 0.0 in stage 91.0 (TID 181)
15/10/21 17:00:09 INFO Executor: Running task 1.0 in stage 91.0 (TID 182)
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:09 INFO PythonRDD: Times: total = 39, boot = -10, init = 49, finish = 0
15/10/21 17:00:09 INFO PythonRDD: Times: total = 39, boot = -10, init = 49, finish = 0
15/10/21 17:00:09 INFO Executor: Finished task 0.0 in stage 91.0 (TID 181). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO Executor: Finished task 1.0 in stage 91.0 (TID 182). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 181) in 44 ms on localhost (1/2)
15/10/21 17:00:09 INFO TaskSetManager: Finished task 1.0 in stage 91.0 (TID 182) in 44 ms on localhost (2/2)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
15/10/21 17:00:09 INFO DAGScheduler: ResultStage 91 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:09 INFO DAGScheduler: Job 90 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.054210 s
15/10/21 17:00:09 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:09 INFO DAGScheduler: Got job 91 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:09 INFO DAGScheduler: Final stage: ResultStage 92(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:09 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:09 INFO DAGScheduler: Submitting ResultStage 92 (PythonRDD[98] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=222490, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=228882, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:09 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:09 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 92 (PythonRDD[98] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Adding task set 92.0 with 2 tasks
15/10/21 17:00:09 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 183, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO TaskSetManager: Starting task 1.0 in stage 92.0 (TID 184, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO Executor: Running task 0.0 in stage 92.0 (TID 183)
15/10/21 17:00:09 INFO Executor: Running task 1.0 in stage 92.0 (TID 184)
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:09 INFO PythonRDD: Times: total = 38, boot = -15, init = 53, finish = 0
15/10/21 17:00:09 INFO PythonRDD: Times: total = 38, boot = -13, init = 51, finish = 0
15/10/21 17:00:09 INFO Executor: Finished task 1.0 in stage 92.0 (TID 184). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO Executor: Finished task 0.0 in stage 92.0 (TID 183). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO TaskSetManager: Finished task 1.0 in stage 92.0 (TID 184) in 42 ms on localhost (1/2)
15/10/21 17:00:09 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 183) in 43 ms on localhost (2/2)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
15/10/21 17:00:09 INFO DAGScheduler: ResultStage 92 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:09 INFO DAGScheduler: Job 91 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.052312 s
15/10/21 17:00:09 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:09 INFO DAGScheduler: Got job 92 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:09 INFO DAGScheduler: Final stage: ResultStage 93(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:09 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:09 INFO DAGScheduler: Submitting ResultStage 93 (PythonRDD[99] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=232687, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=239079, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:09 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:09 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 93 (PythonRDD[99] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Adding task set 93.0 with 2 tasks
15/10/21 17:00:09 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 185, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO TaskSetManager: Starting task 1.0 in stage 93.0 (TID 186, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO Executor: Running task 0.0 in stage 93.0 (TID 185)
15/10/21 17:00:09 INFO Executor: Running task 1.0 in stage 93.0 (TID 186)
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:09 INFO PythonRDD: Times: total = 38, boot = -13, init = 51, finish = 0
15/10/21 17:00:09 INFO Executor: Finished task 1.0 in stage 93.0 (TID 186). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO TaskSetManager: Finished task 1.0 in stage 93.0 (TID 186) in 42 ms on localhost (1/2)
15/10/21 17:00:09 INFO PythonRDD: Times: total = 42, boot = -13, init = 55, finish = 0
15/10/21 17:00:09 INFO Executor: Finished task 0.0 in stage 93.0 (TID 185). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 185) in 46 ms on localhost (2/2)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
15/10/21 17:00:09 INFO DAGScheduler: ResultStage 93 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:00:09 INFO DAGScheduler: Job 92 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.055747 s
15/10/21 17:00:09 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:09 INFO DAGScheduler: Got job 93 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:09 INFO DAGScheduler: Final stage: ResultStage 94(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:09 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:09 INFO DAGScheduler: Submitting ResultStage 94 (PythonRDD[100] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=242884, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=249276, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:09 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:09 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 94 (PythonRDD[100] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Adding task set 94.0 with 2 tasks
15/10/21 17:00:09 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 187, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO TaskSetManager: Starting task 1.0 in stage 94.0 (TID 188, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO Executor: Running task 0.0 in stage 94.0 (TID 187)
15/10/21 17:00:09 INFO Executor: Running task 1.0 in stage 94.0 (TID 188)
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:09 INFO PythonRDD: Times: total = 38, boot = -14, init = 52, finish = 0
15/10/21 17:00:09 INFO PythonRDD: Times: total = 38, boot = -15, init = 53, finish = 0
15/10/21 17:00:09 INFO Executor: Finished task 1.0 in stage 94.0 (TID 188). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO Executor: Finished task 0.0 in stage 94.0 (TID 187). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO TaskSetManager: Finished task 1.0 in stage 94.0 (TID 188) in 42 ms on localhost (1/2)
15/10/21 17:00:09 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 187) in 43 ms on localhost (2/2)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
15/10/21 17:00:09 INFO DAGScheduler: ResultStage 94 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:09 INFO DAGScheduler: Job 93 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.052034 s
15/10/21 17:00:09 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:09 INFO DAGScheduler: Got job 94 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:09 INFO DAGScheduler: Final stage: ResultStage 95(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:09 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:09 INFO DAGScheduler: Submitting ResultStage 95 (PythonRDD[101] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=253081, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=259473, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:09 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:09 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 95 (PythonRDD[101] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Adding task set 95.0 with 2 tasks
15/10/21 17:00:09 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 189, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO TaskSetManager: Starting task 1.0 in stage 95.0 (TID 190, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO Executor: Running task 1.0 in stage 95.0 (TID 190)
15/10/21 17:00:09 INFO Executor: Running task 0.0 in stage 95.0 (TID 189)
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:09 INFO PythonRDD: Times: total = 40, boot = -8, init = 48, finish = 0
15/10/21 17:00:09 INFO PythonRDD: Times: total = 39, boot = -9, init = 48, finish = 0
15/10/21 17:00:09 INFO Executor: Finished task 1.0 in stage 95.0 (TID 190). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO Executor: Finished task 0.0 in stage 95.0 (TID 189). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO TaskSetManager: Finished task 1.0 in stage 95.0 (TID 190) in 44 ms on localhost (1/2)
15/10/21 17:00:09 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 189) in 44 ms on localhost (2/2)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
15/10/21 17:00:09 INFO DAGScheduler: ResultStage 95 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:09 INFO DAGScheduler: Job 94 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053122 s
15/10/21 17:00:09 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:09 INFO DAGScheduler: Got job 95 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:09 INFO DAGScheduler: Final stage: ResultStage 96(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:09 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:09 INFO DAGScheduler: Submitting ResultStage 96 (PythonRDD[102] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=263278, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=269670, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:09 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:09 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 96 (PythonRDD[102] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Adding task set 96.0 with 2 tasks
15/10/21 17:00:09 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 191, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO TaskSetManager: Starting task 1.0 in stage 96.0 (TID 192, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO Executor: Running task 0.0 in stage 96.0 (TID 191)
15/10/21 17:00:09 INFO Executor: Running task 1.0 in stage 96.0 (TID 192)
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:09 INFO PythonRDD: Times: total = 39, boot = -9, init = 48, finish = 0
15/10/21 17:00:09 INFO PythonRDD: Times: total = 39, boot = -12, init = 51, finish = 0
15/10/21 17:00:09 INFO Executor: Finished task 1.0 in stage 96.0 (TID 192). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO Executor: Finished task 0.0 in stage 96.0 (TID 191). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO TaskSetManager: Finished task 1.0 in stage 96.0 (TID 192) in 43 ms on localhost (1/2)
15/10/21 17:00:09 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 191) in 43 ms on localhost (2/2)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
15/10/21 17:00:09 INFO DAGScheduler: ResultStage 96 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:09 INFO DAGScheduler: Job 95 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053265 s
15/10/21 17:00:09 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:09 INFO DAGScheduler: Got job 96 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:09 INFO DAGScheduler: Final stage: ResultStage 97(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:09 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:09 INFO DAGScheduler: Submitting ResultStage 97 (PythonRDD[103] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=273475, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=279867, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:09 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:09 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 97 (PythonRDD[103] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Adding task set 97.0 with 2 tasks
15/10/21 17:00:09 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 193, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO TaskSetManager: Starting task 1.0 in stage 97.0 (TID 194, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO Executor: Running task 0.0 in stage 97.0 (TID 193)
15/10/21 17:00:09 INFO Executor: Running task 1.0 in stage 97.0 (TID 194)
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:09 INFO PythonRDD: Times: total = 37, boot = -13, init = 50, finish = 0
15/10/21 17:00:09 INFO Executor: Finished task 0.0 in stage 97.0 (TID 193). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 193) in 42 ms on localhost (1/2)
15/10/21 17:00:09 INFO PythonRDD: Times: total = 41, boot = -11, init = 52, finish = 0
15/10/21 17:00:09 INFO Executor: Finished task 1.0 in stage 97.0 (TID 194). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO TaskSetManager: Finished task 1.0 in stage 97.0 (TID 194) in 44 ms on localhost (2/2)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
15/10/21 17:00:09 INFO DAGScheduler: ResultStage 97 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:09 INFO DAGScheduler: Job 96 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.055666 s
15/10/21 17:00:09 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:09 INFO DAGScheduler: Got job 97 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:09 INFO DAGScheduler: Final stage: ResultStage 98(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:09 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:09 INFO DAGScheduler: Submitting ResultStage 98 (PythonRDD[104] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=283672, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=290064, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:09 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:09 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 98 (PythonRDD[104] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Adding task set 98.0 with 2 tasks
15/10/21 17:00:09 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 195, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO TaskSetManager: Starting task 1.0 in stage 98.0 (TID 196, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO Executor: Running task 0.0 in stage 98.0 (TID 195)
15/10/21 17:00:09 INFO Executor: Running task 1.0 in stage 98.0 (TID 196)
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:09 INFO PythonRDD: Times: total = 39, boot = -11, init = 50, finish = 0
15/10/21 17:00:09 INFO PythonRDD: Times: total = 39, boot = -14, init = 53, finish = 0
15/10/21 17:00:09 INFO Executor: Finished task 1.0 in stage 98.0 (TID 196). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO Executor: Finished task 0.0 in stage 98.0 (TID 195). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO TaskSetManager: Finished task 1.0 in stage 98.0 (TID 196) in 43 ms on localhost (1/2)
15/10/21 17:00:09 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 195) in 43 ms on localhost (2/2)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
15/10/21 17:00:09 INFO DAGScheduler: ResultStage 98 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:09 INFO DAGScheduler: Job 97 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053310 s
15/10/21 17:00:09 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:09 INFO DAGScheduler: Got job 98 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:09 INFO DAGScheduler: Final stage: ResultStage 99(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:09 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:09 INFO DAGScheduler: Submitting ResultStage 99 (PythonRDD[105] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=293869, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=300261, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:09 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:09 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 99 (PythonRDD[105] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Adding task set 99.0 with 2 tasks
15/10/21 17:00:09 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 197, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO TaskSetManager: Starting task 1.0 in stage 99.0 (TID 198, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO Executor: Running task 1.0 in stage 99.0 (TID 198)
15/10/21 17:00:09 INFO Executor: Running task 0.0 in stage 99.0 (TID 197)
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:09 INFO PythonRDD: Times: total = 38, boot = -10, init = 48, finish = 0
15/10/21 17:00:09 INFO PythonRDD: Times: total = 37, boot = -11, init = 48, finish = 0
15/10/21 17:00:09 INFO Executor: Finished task 1.0 in stage 99.0 (TID 198). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO Executor: Finished task 0.0 in stage 99.0 (TID 197). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO TaskSetManager: Finished task 1.0 in stage 99.0 (TID 198) in 41 ms on localhost (1/2)
15/10/21 17:00:09 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 197) in 42 ms on localhost (2/2)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
15/10/21 17:00:09 INFO DAGScheduler: ResultStage 99 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.042 s
15/10/21 17:00:09 INFO DAGScheduler: Job 98 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.051943 s
15/10/21 17:00:09 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:09 INFO DAGScheduler: Got job 99 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:09 INFO DAGScheduler: Final stage: ResultStage 100(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:09 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:09 INFO DAGScheduler: Submitting ResultStage 100 (PythonRDD[106] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=304066, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=310458, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:09 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:09 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 100 (PythonRDD[106] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Adding task set 100.0 with 2 tasks
15/10/21 17:00:09 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 199, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO TaskSetManager: Starting task 1.0 in stage 100.0 (TID 200, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO Executor: Running task 1.0 in stage 100.0 (TID 200)
15/10/21 17:00:09 INFO Executor: Running task 0.0 in stage 100.0 (TID 199)
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:09 INFO PythonRDD: Times: total = 37, boot = -8, init = 45, finish = 0
15/10/21 17:00:09 INFO Executor: Finished task 1.0 in stage 100.0 (TID 200). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO TaskSetManager: Finished task 1.0 in stage 100.0 (TID 200) in 40 ms on localhost (1/2)
15/10/21 17:00:09 INFO PythonRDD: Times: total = 41, boot = -8, init = 49, finish = 0
15/10/21 17:00:09 INFO Executor: Finished task 0.0 in stage 100.0 (TID 199). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 199) in 45 ms on localhost (2/2)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
15/10/21 17:00:09 INFO DAGScheduler: ResultStage 100 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:09 INFO DAGScheduler: Job 99 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053478 s
15/10/21 17:00:09 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:09 INFO DAGScheduler: Got job 100 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:09 INFO DAGScheduler: Final stage: ResultStage 101(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:09 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:09 INFO DAGScheduler: Submitting ResultStage 101 (PythonRDD[107] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=314263, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=320655, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:09 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:09 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 101 (PythonRDD[107] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Adding task set 101.0 with 2 tasks
15/10/21 17:00:09 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 201, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO TaskSetManager: Starting task 1.0 in stage 101.0 (TID 202, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO Executor: Running task 0.0 in stage 101.0 (TID 201)
15/10/21 17:00:09 INFO Executor: Running task 1.0 in stage 101.0 (TID 202)
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:09 INFO PythonRDD: Times: total = 37, boot = -12, init = 49, finish = 0
15/10/21 17:00:09 INFO Executor: Finished task 0.0 in stage 101.0 (TID 201). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 201) in 41 ms on localhost (1/2)
15/10/21 17:00:09 INFO PythonRDD: Times: total = 41, boot = -7, init = 48, finish = 0
15/10/21 17:00:09 INFO Executor: Finished task 1.0 in stage 101.0 (TID 202). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO TaskSetManager: Finished task 1.0 in stage 101.0 (TID 202) in 44 ms on localhost (2/2)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
15/10/21 17:00:09 INFO DAGScheduler: ResultStage 101 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:09 INFO DAGScheduler: Job 100 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.054205 s
15/10/21 17:00:09 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:09 INFO DAGScheduler: Got job 101 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:09 INFO DAGScheduler: Final stage: ResultStage 102(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:09 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:09 INFO DAGScheduler: Submitting ResultStage 102 (PythonRDD[108] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=324460, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=330852, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:09 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:09 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 102 (PythonRDD[108] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Adding task set 102.0 with 2 tasks
15/10/21 17:00:09 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 203, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO TaskSetManager: Starting task 1.0 in stage 102.0 (TID 204, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO Executor: Running task 1.0 in stage 102.0 (TID 204)
15/10/21 17:00:09 INFO Executor: Running task 0.0 in stage 102.0 (TID 203)
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:09 INFO PythonRDD: Times: total = 41, boot = -10, init = 51, finish = 0
15/10/21 17:00:09 INFO PythonRDD: Times: total = 41, boot = -12, init = 53, finish = 0
15/10/21 17:00:09 INFO Executor: Finished task 0.0 in stage 102.0 (TID 203). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO Executor: Finished task 1.0 in stage 102.0 (TID 204). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 203) in 45 ms on localhost (1/2)
15/10/21 17:00:09 INFO TaskSetManager: Finished task 1.0 in stage 102.0 (TID 204) in 45 ms on localhost (2/2)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
15/10/21 17:00:09 INFO DAGScheduler: ResultStage 102 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:09 INFO DAGScheduler: Job 101 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053965 s
15/10/21 17:00:09 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:09 INFO DAGScheduler: Got job 102 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:09 INFO DAGScheduler: Final stage: ResultStage 103(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:09 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:09 INFO DAGScheduler: Submitting ResultStage 103 (PythonRDD[109] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=334657, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:09 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=341049, maxMem=278302556
15/10/21 17:00:09 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:09 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:09 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 103 (PythonRDD[109] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Adding task set 103.0 with 2 tasks
15/10/21 17:00:09 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 205, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO TaskSetManager: Starting task 1.0 in stage 103.0 (TID 206, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:09 INFO Executor: Running task 0.0 in stage 103.0 (TID 205)
15/10/21 17:00:09 INFO Executor: Running task 1.0 in stage 103.0 (TID 206)
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:09 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:09 INFO PythonRDD: Times: total = 38, boot = -9, init = 47, finish = 0
15/10/21 17:00:09 INFO PythonRDD: Times: total = 38, boot = -12, init = 50, finish = 0
15/10/21 17:00:09 INFO Executor: Finished task 1.0 in stage 103.0 (TID 206). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO Executor: Finished task 0.0 in stage 103.0 (TID 205). 1870 bytes result sent to driver
15/10/21 17:00:09 INFO TaskSetManager: Finished task 1.0 in stage 103.0 (TID 206) in 42 ms on localhost (1/2)
15/10/21 17:00:09 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 205) in 43 ms on localhost (2/2)
15/10/21 17:00:09 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
15/10/21 17:00:09 INFO DAGScheduler: ResultStage 103 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:09 INFO DAGScheduler: Job 102 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.052878 s
15/10/21 17:00:10 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:10 INFO DAGScheduler: Got job 103 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:10 INFO DAGScheduler: Final stage: ResultStage 104(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:10 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:10 INFO DAGScheduler: Submitting ResultStage 104 (PythonRDD[110] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=344854, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=351246, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:10 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 104 (PythonRDD[110] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Adding task set 104.0 with 2 tasks
15/10/21 17:00:10 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 207, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO TaskSetManager: Starting task 1.0 in stage 104.0 (TID 208, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO Executor: Running task 0.0 in stage 104.0 (TID 207)
15/10/21 17:00:10 INFO Executor: Running task 1.0 in stage 104.0 (TID 208)
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:10 INFO PythonRDD: Times: total = 38, boot = -15, init = 53, finish = 0
15/10/21 17:00:10 INFO Executor: Finished task 0.0 in stage 104.0 (TID 207). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 207) in 41 ms on localhost (1/2)
15/10/21 17:00:10 INFO PythonRDD: Times: total = 42, boot = -13, init = 55, finish = 0
15/10/21 17:00:10 INFO Executor: Finished task 1.0 in stage 104.0 (TID 208). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO TaskSetManager: Finished task 1.0 in stage 104.0 (TID 208) in 46 ms on localhost (2/2)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
15/10/21 17:00:10 INFO DAGScheduler: ResultStage 104 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:00:10 INFO DAGScheduler: Job 103 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.055923 s
15/10/21 17:00:10 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:10 INFO DAGScheduler: Got job 104 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:10 INFO DAGScheduler: Final stage: ResultStage 105(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:10 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:10 INFO DAGScheduler: Submitting ResultStage 105 (PythonRDD[111] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=355051, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=361443, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:10 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 105 (PythonRDD[111] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Adding task set 105.0 with 2 tasks
15/10/21 17:00:10 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 209, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO TaskSetManager: Starting task 1.0 in stage 105.0 (TID 210, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO Executor: Running task 0.0 in stage 105.0 (TID 209)
15/10/21 17:00:10 INFO Executor: Running task 1.0 in stage 105.0 (TID 210)
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:10 INFO PythonRDD: Times: total = 39, boot = -15, init = 54, finish = 0
15/10/21 17:00:10 INFO PythonRDD: Times: total = 39, boot = -12, init = 51, finish = 0
15/10/21 17:00:10 INFO Executor: Finished task 1.0 in stage 105.0 (TID 210). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO Executor: Finished task 0.0 in stage 105.0 (TID 209). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO TaskSetManager: Finished task 1.0 in stage 105.0 (TID 210) in 43 ms on localhost (1/2)
15/10/21 17:00:10 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 209) in 44 ms on localhost (2/2)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
15/10/21 17:00:10 INFO DAGScheduler: ResultStage 105 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:10 INFO DAGScheduler: Job 104 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053247 s
15/10/21 17:00:10 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:10 INFO DAGScheduler: Got job 105 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:10 INFO DAGScheduler: Final stage: ResultStage 106(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:10 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:10 INFO DAGScheduler: Submitting ResultStage 106 (PythonRDD[112] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=365248, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(3804) called with curMem=371640, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:10 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 106 (PythonRDD[112] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Adding task set 106.0 with 2 tasks
15/10/21 17:00:10 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 211, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO TaskSetManager: Starting task 1.0 in stage 106.0 (TID 212, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO Executor: Running task 0.0 in stage 106.0 (TID 211)
15/10/21 17:00:10 INFO Executor: Running task 1.0 in stage 106.0 (TID 212)
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:10 INFO BlockManagerInfo: Removed broadcast_92_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Removed broadcast_91_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Removed broadcast_90_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Removed broadcast_89_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Removed broadcast_88_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Removed broadcast_96_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Removed broadcast_95_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Removed broadcast_94_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Removed broadcast_93_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Removed broadcast_106_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Removed broadcast_105_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Removed broadcast_104_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Removed broadcast_103_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Removed broadcast_102_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Removed broadcast_101_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Removed broadcast_100_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Removed broadcast_99_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Removed broadcast_98_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:10 INFO PythonRDD: Times: total = 43, boot = -13, init = 56, finish = 0
15/10/21 17:00:10 INFO BlockManagerInfo: Removed broadcast_97_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:10 INFO Executor: Finished task 1.0 in stage 106.0 (TID 212). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO TaskSetManager: Finished task 1.0 in stage 106.0 (TID 212) in 47 ms on localhost (1/2)
15/10/21 17:00:10 INFO PythonRDD: Times: total = 46, boot = -13, init = 59, finish = 0
15/10/21 17:00:10 INFO Executor: Finished task 0.0 in stage 106.0 (TID 211). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 211) in 50 ms on localhost (2/2)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
15/10/21 17:00:10 INFO DAGScheduler: ResultStage 106 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.051 s
15/10/21 17:00:10 INFO DAGScheduler: Job 105 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.059929 s
15/10/21 17:00:10 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:10 INFO DAGScheduler: Got job 106 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:10 INFO DAGScheduler: Final stage: ResultStage 107(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:10 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:10 INFO DAGScheduler: Submitting ResultStage 107 (PythonRDD[113] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=181701, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=188093, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:10 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 107 (PythonRDD[113] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Adding task set 107.0 with 2 tasks
15/10/21 17:00:10 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 213, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO TaskSetManager: Starting task 1.0 in stage 107.0 (TID 214, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO Executor: Running task 0.0 in stage 107.0 (TID 213)
15/10/21 17:00:10 INFO Executor: Running task 1.0 in stage 107.0 (TID 214)
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:10 INFO PythonRDD: Times: total = 40, boot = -9, init = 49, finish = 0
15/10/21 17:00:10 INFO PythonRDD: Times: total = 40, boot = -12, init = 52, finish = 0
15/10/21 17:00:10 INFO Executor: Finished task 1.0 in stage 107.0 (TID 214). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO Executor: Finished task 0.0 in stage 107.0 (TID 213). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO TaskSetManager: Finished task 1.0 in stage 107.0 (TID 214) in 44 ms on localhost (1/2)
15/10/21 17:00:10 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 213) in 44 ms on localhost (2/2)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool 
15/10/21 17:00:10 INFO DAGScheduler: ResultStage 107 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:10 INFO DAGScheduler: Job 106 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053814 s
15/10/21 17:00:10 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:10 INFO DAGScheduler: Got job 107 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:10 INFO DAGScheduler: Final stage: ResultStage 108(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:10 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:10 INFO DAGScheduler: Submitting ResultStage 108 (PythonRDD[114] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=191898, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=198290, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:10 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 108 (PythonRDD[114] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Adding task set 108.0 with 2 tasks
15/10/21 17:00:10 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 215, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO TaskSetManager: Starting task 1.0 in stage 108.0 (TID 216, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO Executor: Running task 0.0 in stage 108.0 (TID 215)
15/10/21 17:00:10 INFO Executor: Running task 1.0 in stage 108.0 (TID 216)
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:10 INFO PythonRDD: Times: total = 39, boot = -13, init = 52, finish = 0
15/10/21 17:00:10 INFO PythonRDD: Times: total = 40, boot = -12, init = 52, finish = 0
15/10/21 17:00:10 INFO Executor: Finished task 1.0 in stage 108.0 (TID 216). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO Executor: Finished task 0.0 in stage 108.0 (TID 215). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO TaskSetManager: Finished task 1.0 in stage 108.0 (TID 216) in 43 ms on localhost (1/2)
15/10/21 17:00:10 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 215) in 44 ms on localhost (2/2)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool 
15/10/21 17:00:10 INFO DAGScheduler: ResultStage 108 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:10 INFO DAGScheduler: Job 107 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053036 s
15/10/21 17:00:10 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:10 INFO DAGScheduler: Got job 108 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:10 INFO DAGScheduler: Final stage: ResultStage 109(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:10 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:10 INFO DAGScheduler: Submitting ResultStage 109 (PythonRDD[115] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=202095, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=208487, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:10 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 109 (PythonRDD[115] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Adding task set 109.0 with 2 tasks
15/10/21 17:00:10 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 217, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO TaskSetManager: Starting task 1.0 in stage 109.0 (TID 218, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO Executor: Running task 0.0 in stage 109.0 (TID 217)
15/10/21 17:00:10 INFO Executor: Running task 1.0 in stage 109.0 (TID 218)
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:10 INFO PythonRDD: Times: total = 40, boot = -11, init = 51, finish = 0
15/10/21 17:00:10 INFO PythonRDD: Times: total = 40, boot = -12, init = 52, finish = 0
15/10/21 17:00:10 INFO Executor: Finished task 1.0 in stage 109.0 (TID 218). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO Executor: Finished task 0.0 in stage 109.0 (TID 217). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO TaskSetManager: Finished task 1.0 in stage 109.0 (TID 218) in 44 ms on localhost (1/2)
15/10/21 17:00:10 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 217) in 45 ms on localhost (2/2)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool 
15/10/21 17:00:10 INFO DAGScheduler: ResultStage 109 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:10 INFO DAGScheduler: Job 108 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.054034 s
15/10/21 17:00:10 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:10 INFO DAGScheduler: Got job 109 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:10 INFO DAGScheduler: Final stage: ResultStage 110(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:10 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:10 INFO DAGScheduler: Submitting ResultStage 110 (PythonRDD[116] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=212292, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=218684, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:10 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 110 (PythonRDD[116] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Adding task set 110.0 with 2 tasks
15/10/21 17:00:10 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 219, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO TaskSetManager: Starting task 1.0 in stage 110.0 (TID 220, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO Executor: Running task 0.0 in stage 110.0 (TID 219)
15/10/21 17:00:10 INFO Executor: Running task 1.0 in stage 110.0 (TID 220)
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:10 INFO PythonRDD: Times: total = 40, boot = -10, init = 50, finish = 0
15/10/21 17:00:10 INFO PythonRDD: Times: total = 41, boot = -10, init = 51, finish = 0
15/10/21 17:00:10 INFO Executor: Finished task 1.0 in stage 110.0 (TID 220). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO Executor: Finished task 0.0 in stage 110.0 (TID 219). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO TaskSetManager: Finished task 1.0 in stage 110.0 (TID 220) in 45 ms on localhost (1/2)
15/10/21 17:00:10 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 219) in 45 ms on localhost (2/2)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool 
15/10/21 17:00:10 INFO DAGScheduler: ResultStage 110 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:10 INFO DAGScheduler: Job 109 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053653 s
15/10/21 17:00:10 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:10 INFO DAGScheduler: Got job 110 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:10 INFO DAGScheduler: Final stage: ResultStage 111(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:10 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:10 INFO DAGScheduler: Submitting ResultStage 111 (PythonRDD[117] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=222489, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=228881, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:10 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 111 (PythonRDD[117] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Adding task set 111.0 with 2 tasks
15/10/21 17:00:10 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 221, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO TaskSetManager: Starting task 1.0 in stage 111.0 (TID 222, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO Executor: Running task 0.0 in stage 111.0 (TID 221)
15/10/21 17:00:10 INFO Executor: Running task 1.0 in stage 111.0 (TID 222)
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:10 INFO PythonRDD: Times: total = 39, boot = -9, init = 48, finish = 0
15/10/21 17:00:10 INFO PythonRDD: Times: total = 39, boot = -10, init = 49, finish = 0
15/10/21 17:00:10 INFO Executor: Finished task 1.0 in stage 111.0 (TID 222). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO Executor: Finished task 0.0 in stage 111.0 (TID 221). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO TaskSetManager: Finished task 1.0 in stage 111.0 (TID 222) in 43 ms on localhost (1/2)
15/10/21 17:00:10 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 221) in 44 ms on localhost (2/2)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool 
15/10/21 17:00:10 INFO DAGScheduler: ResultStage 111 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:10 INFO DAGScheduler: Job 110 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053356 s
15/10/21 17:00:10 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:10 INFO DAGScheduler: Got job 111 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:10 INFO DAGScheduler: Final stage: ResultStage 112(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:10 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:10 INFO DAGScheduler: Submitting ResultStage 112 (PythonRDD[118] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=232686, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=239078, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:10 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 112 (PythonRDD[118] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Adding task set 112.0 with 2 tasks
15/10/21 17:00:10 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 223, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO TaskSetManager: Starting task 1.0 in stage 112.0 (TID 224, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO Executor: Running task 0.0 in stage 112.0 (TID 223)
15/10/21 17:00:10 INFO Executor: Running task 1.0 in stage 112.0 (TID 224)
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:10 INFO PythonRDD: Times: total = 39, boot = -13, init = 52, finish = 0
15/10/21 17:00:10 INFO PythonRDD: Times: total = 39, boot = -12, init = 51, finish = 0
15/10/21 17:00:10 INFO Executor: Finished task 0.0 in stage 112.0 (TID 223). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO Executor: Finished task 1.0 in stage 112.0 (TID 224). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 223) in 44 ms on localhost (1/2)
15/10/21 17:00:10 INFO TaskSetManager: Finished task 1.0 in stage 112.0 (TID 224) in 43 ms on localhost (2/2)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool 
15/10/21 17:00:10 INFO DAGScheduler: ResultStage 112 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:10 INFO DAGScheduler: Job 111 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.052536 s
15/10/21 17:00:10 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:10 INFO DAGScheduler: Got job 112 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:10 INFO DAGScheduler: Final stage: ResultStage 113(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:10 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:10 INFO DAGScheduler: Submitting ResultStage 113 (PythonRDD[119] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=242883, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=249275, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:10 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 113 (PythonRDD[119] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Adding task set 113.0 with 2 tasks
15/10/21 17:00:10 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 225, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO TaskSetManager: Starting task 1.0 in stage 113.0 (TID 226, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO Executor: Running task 1.0 in stage 113.0 (TID 226)
15/10/21 17:00:10 INFO Executor: Running task 0.0 in stage 113.0 (TID 225)
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:10 INFO PythonRDD: Times: total = 38, boot = -10, init = 48, finish = 0
15/10/21 17:00:10 INFO PythonRDD: Times: total = 38, boot = -12, init = 50, finish = 0
15/10/21 17:00:10 INFO Executor: Finished task 1.0 in stage 113.0 (TID 226). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO Executor: Finished task 0.0 in stage 113.0 (TID 225). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO TaskSetManager: Finished task 1.0 in stage 113.0 (TID 226) in 42 ms on localhost (1/2)
15/10/21 17:00:10 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 225) in 42 ms on localhost (2/2)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool 
15/10/21 17:00:10 INFO DAGScheduler: ResultStage 113 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:10 INFO DAGScheduler: Job 112 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.052820 s
15/10/21 17:00:10 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:10 INFO DAGScheduler: Got job 113 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:10 INFO DAGScheduler: Final stage: ResultStage 114(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:10 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:10 INFO DAGScheduler: Submitting ResultStage 114 (PythonRDD[120] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=253080, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(3803) called with curMem=259472, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:10 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 114 (PythonRDD[120] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Adding task set 114.0 with 2 tasks
15/10/21 17:00:10 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 227, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO TaskSetManager: Starting task 1.0 in stage 114.0 (TID 228, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO Executor: Running task 0.0 in stage 114.0 (TID 227)
15/10/21 17:00:10 INFO Executor: Running task 1.0 in stage 114.0 (TID 228)
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:10 INFO PythonRDD: Times: total = 38, boot = -10, init = 48, finish = 0
15/10/21 17:00:10 INFO PythonRDD: Times: total = 39, boot = -9, init = 48, finish = 0
15/10/21 17:00:10 INFO Executor: Finished task 1.0 in stage 114.0 (TID 228). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO Executor: Finished task 0.0 in stage 114.0 (TID 227). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO TaskSetManager: Finished task 1.0 in stage 114.0 (TID 228) in 43 ms on localhost (1/2)
15/10/21 17:00:10 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 227) in 43 ms on localhost (2/2)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool 
15/10/21 17:00:10 INFO DAGScheduler: ResultStage 114 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:10 INFO DAGScheduler: Job 113 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.051998 s
15/10/21 17:00:10 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:10 INFO DAGScheduler: Got job 114 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:10 INFO DAGScheduler: Final stage: ResultStage 115(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:10 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:10 INFO DAGScheduler: Submitting ResultStage 115 (PythonRDD[121] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=263275, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 6.2 KB, free 265.2 MB)
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=269667, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:10 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 115 (PythonRDD[121] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Adding task set 115.0 with 2 tasks
15/10/21 17:00:10 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 229, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO TaskSetManager: Starting task 1.0 in stage 115.0 (TID 230, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO Executor: Running task 0.0 in stage 115.0 (TID 229)
15/10/21 17:00:10 INFO Executor: Running task 1.0 in stage 115.0 (TID 230)
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:10 INFO PythonRDD: Times: total = 38, boot = -9, init = 47, finish = 0
15/10/21 17:00:10 INFO PythonRDD: Times: total = 39, boot = -10, init = 49, finish = 0
15/10/21 17:00:10 INFO Executor: Finished task 0.0 in stage 115.0 (TID 229). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO Executor: Finished task 1.0 in stage 115.0 (TID 230). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 229) in 43 ms on localhost (1/2)
15/10/21 17:00:10 INFO TaskSetManager: Finished task 1.0 in stage 115.0 (TID 230) in 43 ms on localhost (2/2)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool 
15/10/21 17:00:10 INFO DAGScheduler: ResultStage 115 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:10 INFO DAGScheduler: Job 114 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053601 s
15/10/21 17:00:10 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:10 INFO DAGScheduler: Got job 115 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:10 INFO DAGScheduler: Final stage: ResultStage 116(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:10 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:10 INFO DAGScheduler: Submitting ResultStage 116 (PythonRDD[122] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=273472, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=279864, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:10 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 116 (PythonRDD[122] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Adding task set 116.0 with 2 tasks
15/10/21 17:00:10 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 231, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO TaskSetManager: Starting task 1.0 in stage 116.0 (TID 232, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO Executor: Running task 0.0 in stage 116.0 (TID 231)
15/10/21 17:00:10 INFO Executor: Running task 1.0 in stage 116.0 (TID 232)
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:10 INFO PythonRDD: Times: total = 39, boot = -13, init = 52, finish = 0
15/10/21 17:00:10 INFO Executor: Finished task 1.0 in stage 116.0 (TID 232). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO TaskSetManager: Finished task 1.0 in stage 116.0 (TID 232) in 42 ms on localhost (1/2)
15/10/21 17:00:10 INFO PythonRDD: Times: total = 43, boot = -13, init = 56, finish = 0
15/10/21 17:00:10 INFO Executor: Finished task 0.0 in stage 116.0 (TID 231). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 231) in 47 ms on localhost (2/2)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool 
15/10/21 17:00:10 INFO DAGScheduler: ResultStage 116 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.048 s
15/10/21 17:00:10 INFO DAGScheduler: Job 115 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.056441 s
15/10/21 17:00:10 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:10 INFO DAGScheduler: Got job 116 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:10 INFO DAGScheduler: Final stage: ResultStage 117(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:10 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:10 INFO DAGScheduler: Submitting ResultStage 117 (PythonRDD[123] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=283669, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=290061, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:10 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 117 (PythonRDD[123] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Adding task set 117.0 with 2 tasks
15/10/21 17:00:10 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 233, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO TaskSetManager: Starting task 1.0 in stage 117.0 (TID 234, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO Executor: Running task 0.0 in stage 117.0 (TID 233)
15/10/21 17:00:10 INFO Executor: Running task 1.0 in stage 117.0 (TID 234)
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:10 INFO PythonRDD: Times: total = 41, boot = -15, init = 56, finish = 0
15/10/21 17:00:10 INFO PythonRDD: Times: total = 41, boot = -9, init = 50, finish = 0
15/10/21 17:00:10 INFO Executor: Finished task 1.0 in stage 117.0 (TID 234). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO Executor: Finished task 0.0 in stage 117.0 (TID 233). 1870 bytes result sent to driver
15/10/21 17:00:10 INFO TaskSetManager: Finished task 1.0 in stage 117.0 (TID 234) in 45 ms on localhost (1/2)
15/10/21 17:00:10 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 233) in 45 ms on localhost (2/2)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool 
15/10/21 17:00:10 INFO DAGScheduler: ResultStage 117 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:10 INFO DAGScheduler: Job 116 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053823 s
15/10/21 17:00:10 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:10 INFO DAGScheduler: Got job 117 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:10 INFO DAGScheduler: Final stage: ResultStage 118(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:10 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:10 INFO DAGScheduler: Submitting ResultStage 118 (PythonRDD[124] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=293866, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:10 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=300258, maxMem=278302556
15/10/21 17:00:10 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:10 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:10 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 118 (PythonRDD[124] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:10 INFO TaskSchedulerImpl: Adding task set 118.0 with 2 tasks
15/10/21 17:00:10 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 235, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO TaskSetManager: Starting task 1.0 in stage 118.0 (TID 236, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:10 INFO Executor: Running task 0.0 in stage 118.0 (TID 235)
15/10/21 17:00:10 INFO Executor: Running task 1.0 in stage 118.0 (TID 236)
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:10 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:11 INFO PythonRDD: Times: total = 39, boot = -13, init = 52, finish = 0
15/10/21 17:00:11 INFO PythonRDD: Times: total = 39, boot = -14, init = 53, finish = 0
15/10/21 17:00:11 INFO Executor: Finished task 1.0 in stage 118.0 (TID 236). 1870 bytes result sent to driver
15/10/21 17:00:11 INFO Executor: Finished task 0.0 in stage 118.0 (TID 235). 1870 bytes result sent to driver
15/10/21 17:00:11 INFO TaskSetManager: Finished task 1.0 in stage 118.0 (TID 236) in 44 ms on localhost (1/2)
15/10/21 17:00:11 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 235) in 44 ms on localhost (2/2)
15/10/21 17:00:11 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool 
15/10/21 17:00:11 INFO DAGScheduler: ResultStage 118 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:11 INFO DAGScheduler: Job 117 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053043 s
15/10/21 17:00:11 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:11 INFO DAGScheduler: Got job 118 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:11 INFO DAGScheduler: Final stage: ResultStage 119(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:11 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:11 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:11 INFO DAGScheduler: Submitting ResultStage 119 (PythonRDD[125] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:11 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=304063, maxMem=278302556
15/10/21 17:00:11 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:11 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=310455, maxMem=278302556
15/10/21 17:00:11 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:11 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:11 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 119 (PythonRDD[125] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:11 INFO TaskSchedulerImpl: Adding task set 119.0 with 2 tasks
15/10/21 17:00:11 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 237, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:11 INFO TaskSetManager: Starting task 1.0 in stage 119.0 (TID 238, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:11 INFO Executor: Running task 0.0 in stage 119.0 (TID 237)
15/10/21 17:00:11 INFO Executor: Running task 1.0 in stage 119.0 (TID 238)
15/10/21 17:00:11 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:11 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:11 INFO PythonRDD: Times: total = 40, boot = -11, init = 51, finish = 0
15/10/21 17:00:11 INFO PythonRDD: Times: total = 40, boot = -11, init = 51, finish = 0
15/10/21 17:00:11 INFO Executor: Finished task 1.0 in stage 119.0 (TID 238). 1870 bytes result sent to driver
15/10/21 17:00:11 INFO Executor: Finished task 0.0 in stage 119.0 (TID 237). 1870 bytes result sent to driver
15/10/21 17:00:11 INFO TaskSetManager: Finished task 1.0 in stage 119.0 (TID 238) in 44 ms on localhost (1/2)
15/10/21 17:00:11 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 237) in 45 ms on localhost (2/2)
15/10/21 17:00:11 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool 
15/10/21 17:00:11 INFO DAGScheduler: ResultStage 119 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:11 INFO DAGScheduler: Job 118 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053379 s
15/10/21 17:00:11 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:11 INFO DAGScheduler: Got job 119 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:11 INFO DAGScheduler: Final stage: ResultStage 120(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:11 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:11 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:11 INFO DAGScheduler: Submitting ResultStage 120 (PythonRDD[126] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:11 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=314260, maxMem=278302556
15/10/21 17:00:11 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:00:11 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=320652, maxMem=278302556
15/10/21 17:00:11 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:00:11 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:11 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:11 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 120 (PythonRDD[126] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:11 INFO TaskSchedulerImpl: Adding task set 120.0 with 2 tasks
15/10/21 17:00:11 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 239, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:11 INFO TaskSetManager: Starting task 1.0 in stage 120.0 (TID 240, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:11 INFO Executor: Running task 0.0 in stage 120.0 (TID 239)
15/10/21 17:00:11 INFO Executor: Running task 1.0 in stage 120.0 (TID 240)
15/10/21 17:00:11 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:11 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:11 INFO PythonRDD: Times: total = 38, boot = -13, init = 51, finish = 0
15/10/21 17:00:11 INFO PythonRDD: Times: total = 38, boot = -14, init = 52, finish = 0
15/10/21 17:00:11 INFO Executor: Finished task 1.0 in stage 120.0 (TID 240). 1870 bytes result sent to driver
15/10/21 17:00:11 INFO Executor: Finished task 0.0 in stage 120.0 (TID 239). 1870 bytes result sent to driver
15/10/21 17:00:11 INFO TaskSetManager: Finished task 1.0 in stage 120.0 (TID 240) in 42 ms on localhost (1/2)
15/10/21 17:00:11 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 239) in 43 ms on localhost (2/2)
15/10/21 17:00:11 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool 
15/10/21 17:00:11 INFO DAGScheduler: ResultStage 120 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:11 INFO DAGScheduler: Job 119 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.052857 s
15/10/21 17:00:19 INFO PythonRDD: Removing RDD 12 from persistence list
15/10/21 17:00:19 INFO BlockManager: Removing RDD 12
15/10/21 17:00:26 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:26 INFO DAGScheduler: Got job 120 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:26 INFO DAGScheduler: Final stage: ResultStage 121(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:26 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:26 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:26 INFO DAGScheduler: Submitting ResultStage 121 (PythonRDD[127] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:26 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=324457, maxMem=278302556
15/10/21 17:00:26 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:26 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=331465, maxMem=278302556
15/10/21 17:00:26 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:26 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:26 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 121 (PythonRDD[127] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:26 INFO TaskSchedulerImpl: Adding task set 121.0 with 2 tasks
15/10/21 17:00:26 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 241, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:26 INFO TaskSetManager: Starting task 1.0 in stage 121.0 (TID 242, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:26 INFO Executor: Running task 0.0 in stage 121.0 (TID 241)
15/10/21 17:00:26 INFO Executor: Running task 1.0 in stage 121.0 (TID 242)
15/10/21 17:00:26 INFO CacheManager: Partition rdd_12_0 not found, computing it
15/10/21 17:00:26 INFO CacheManager: Partition rdd_12_1 not found, computing it
15/10/21 17:00:26 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:00:26 INFO PythonRDD: Times: total = 68, boot = 64, init = 3, finish = 1
15/10/21 17:00:26 INFO MemoryStore: ensureFreeSpace(682) called with curMem=335420, maxMem=278302556
15/10/21 17:00:26 INFO MemoryStore: Block rdd_12_0 stored as bytes in memory (estimated size 682.0 B, free 265.1 MB)
15/10/21 17:00:26 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:00:26 INFO BlockManagerInfo: Added rdd_12_0 in memory on localhost:54908 (size: 682.0 B, free: 265.3 MB)
15/10/21 17:00:26 INFO PythonRDD: Times: total = 124, boot = -15383, init = 15507, finish = 0
15/10/21 17:00:26 INFO Executor: Finished task 0.0 in stage 121.0 (TID 241). 2450 bytes result sent to driver
15/10/21 17:00:26 INFO PythonRDD: Times: total = 125, boot = 121, init = 3, finish = 1
15/10/21 17:00:26 INFO MemoryStore: ensureFreeSpace(497) called with curMem=336102, maxMem=278302556
15/10/21 17:00:26 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 241) in 130 ms on localhost (1/2)
15/10/21 17:00:26 INFO MemoryStore: Block rdd_12_1 stored as bytes in memory (estimated size 497.0 B, free 265.1 MB)
15/10/21 17:00:26 INFO BlockManagerInfo: Added rdd_12_1 in memory on localhost:54908 (size: 497.0 B, free: 265.3 MB)
15/10/21 17:00:26 INFO PythonRDD: Times: total = 129, boot = -15381, init = 15509, finish = 1
15/10/21 17:00:26 INFO Executor: Finished task 1.0 in stage 121.0 (TID 242). 2450 bytes result sent to driver
15/10/21 17:00:26 INFO TaskSetManager: Finished task 1.0 in stage 121.0 (TID 242) in 133 ms on localhost (2/2)
15/10/21 17:00:26 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool 
15/10/21 17:00:26 INFO DAGScheduler: ResultStage 121 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.134 s
15/10/21 17:00:26 INFO DAGScheduler: Job 120 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.144212 s
15/10/21 17:00:26 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:26 INFO DAGScheduler: Got job 121 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:26 INFO DAGScheduler: Final stage: ResultStage 122(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:26 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:26 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:26 INFO DAGScheduler: Submitting ResultStage 122 (PythonRDD[128] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:26 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=336599, maxMem=278302556
15/10/21 17:00:26 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:26 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=343607, maxMem=278302556
15/10/21 17:00:26 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:26 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:26 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 122 (PythonRDD[128] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:26 INFO TaskSchedulerImpl: Adding task set 122.0 with 2 tasks
15/10/21 17:00:26 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 243, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:26 INFO TaskSetManager: Starting task 1.0 in stage 122.0 (TID 244, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:26 INFO Executor: Running task 1.0 in stage 122.0 (TID 244)
15/10/21 17:00:26 INFO Executor: Running task 0.0 in stage 122.0 (TID 243)
15/10/21 17:00:26 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:26 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:26 INFO PythonRDD: Times: total = 40, boot = -13, init = 53, finish = 0
15/10/21 17:00:26 INFO PythonRDD: Times: total = 40, boot = -16, init = 56, finish = 0
15/10/21 17:00:26 INFO Executor: Finished task 0.0 in stage 122.0 (TID 243). 1870 bytes result sent to driver
15/10/21 17:00:26 INFO Executor: Finished task 1.0 in stage 122.0 (TID 244). 1870 bytes result sent to driver
15/10/21 17:00:26 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 243) in 45 ms on localhost (1/2)
15/10/21 17:00:26 INFO TaskSetManager: Finished task 1.0 in stage 122.0 (TID 244) in 44 ms on localhost (2/2)
15/10/21 17:00:26 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool 
15/10/21 17:00:26 INFO DAGScheduler: ResultStage 122 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:26 INFO DAGScheduler: Job 121 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.052749 s
15/10/21 17:00:26 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:26 INFO DAGScheduler: Got job 122 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:26 INFO DAGScheduler: Final stage: ResultStage 123(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:26 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:26 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:26 INFO DAGScheduler: Submitting ResultStage 123 (PythonRDD[129] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:26 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=347562, maxMem=278302556
15/10/21 17:00:26 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:26 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=354570, maxMem=278302556
15/10/21 17:00:26 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:26 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:26 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 123 (PythonRDD[129] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:26 INFO TaskSchedulerImpl: Adding task set 123.0 with 2 tasks
15/10/21 17:00:26 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 245, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:26 INFO TaskSetManager: Starting task 1.0 in stage 123.0 (TID 246, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:26 INFO Executor: Running task 0.0 in stage 123.0 (TID 245)
15/10/21 17:00:26 INFO Executor: Running task 1.0 in stage 123.0 (TID 246)
15/10/21 17:00:26 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:26 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:26 INFO PythonRDD: Times: total = 38, boot = -74, init = 112, finish = 0
15/10/21 17:00:26 INFO PythonRDD: Times: total = 38, boot = -27, init = 65, finish = 0
15/10/21 17:00:26 INFO Executor: Finished task 1.0 in stage 123.0 (TID 246). 1870 bytes result sent to driver
15/10/21 17:00:26 INFO Executor: Finished task 0.0 in stage 123.0 (TID 245). 1870 bytes result sent to driver
15/10/21 17:00:26 INFO TaskSetManager: Finished task 1.0 in stage 123.0 (TID 246) in 41 ms on localhost (1/2)
15/10/21 17:00:26 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 245) in 42 ms on localhost (2/2)
15/10/21 17:00:26 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool 
15/10/21 17:00:26 INFO DAGScheduler: ResultStage 123 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.042 s
15/10/21 17:00:26 INFO DAGScheduler: Job 122 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.050562 s
15/10/21 17:00:26 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:26 INFO DAGScheduler: Got job 123 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:26 INFO DAGScheduler: Final stage: ResultStage 124(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:26 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:26 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:26 INFO DAGScheduler: Submitting ResultStage 124 (PythonRDD[130] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:26 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=358525, maxMem=278302556
15/10/21 17:00:26 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:26 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=365533, maxMem=278302556
15/10/21 17:00:26 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:26 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:26 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 124 (PythonRDD[130] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:26 INFO TaskSchedulerImpl: Adding task set 124.0 with 2 tasks
15/10/21 17:00:26 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 247, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:26 INFO TaskSetManager: Starting task 1.0 in stage 124.0 (TID 248, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:26 INFO Executor: Running task 0.0 in stage 124.0 (TID 247)
15/10/21 17:00:26 INFO Executor: Running task 1.0 in stage 124.0 (TID 248)
15/10/21 17:00:26 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:26 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:26 INFO PythonRDD: Times: total = 39, boot = -70, init = 109, finish = 0
15/10/21 17:00:26 INFO PythonRDD: Times: total = 39, boot = -72, init = 111, finish = 0
15/10/21 17:00:26 INFO Executor: Finished task 0.0 in stage 124.0 (TID 247). 1870 bytes result sent to driver
15/10/21 17:00:26 INFO Executor: Finished task 1.0 in stage 124.0 (TID 248). 1870 bytes result sent to driver
15/10/21 17:00:26 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 247) in 44 ms on localhost (1/2)
15/10/21 17:00:26 INFO TaskSetManager: Finished task 1.0 in stage 124.0 (TID 248) in 43 ms on localhost (2/2)
15/10/21 17:00:26 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool 
15/10/21 17:00:26 INFO DAGScheduler: ResultStage 124 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:26 INFO DAGScheduler: Job 123 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.051913 s
15/10/21 17:00:26 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:26 INFO DAGScheduler: Got job 124 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:26 INFO DAGScheduler: Final stage: ResultStage 125(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:26 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:26 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:26 INFO DAGScheduler: Submitting ResultStage 125 (PythonRDD[131] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:26 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=369488, maxMem=278302556
15/10/21 17:00:26 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:26 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=376496, maxMem=278302556
15/10/21 17:00:26 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:00:26 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:26 INFO BlockManagerInfo: Removed broadcast_125_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:26 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 125 (PythonRDD[131] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:26 INFO TaskSchedulerImpl: Adding task set 125.0 with 2 tasks
15/10/21 17:00:26 INFO TaskSetManager: Starting task 0.0 in stage 125.0 (TID 249, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:26 INFO BlockManagerInfo: Removed broadcast_124_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:26 INFO TaskSetManager: Starting task 1.0 in stage 125.0 (TID 250, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:26 INFO Executor: Running task 0.0 in stage 125.0 (TID 249)
15/10/21 17:00:26 INFO Executor: Running task 1.0 in stage 125.0 (TID 250)
15/10/21 17:00:26 INFO BlockManagerInfo: Removed broadcast_123_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:26 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:26 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:26 INFO BlockManagerInfo: Removed broadcast_122_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:26 INFO BlockManagerInfo: Removed broadcast_121_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:26 INFO BlockManagerInfo: Removed broadcast_120_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:26 INFO BlockManagerInfo: Removed broadcast_119_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:00:26 INFO BlockManagerInfo: Removed broadcast_118_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:26 INFO BlockManagerInfo: Removed broadcast_117_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:26 INFO BlockManagerInfo: Removed broadcast_116_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:26 INFO BlockManagerInfo: Removed broadcast_115_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:26 INFO BlockManagerInfo: Removed broadcast_114_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:26 INFO BlockManagerInfo: Removed broadcast_113_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:26 INFO BlockManagerInfo: Removed broadcast_112_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:26 INFO BlockManagerInfo: Removed broadcast_111_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:26 INFO BlockManagerInfo: Removed broadcast_110_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:26 INFO BlockManagerInfo: Removed broadcast_109_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:26 INFO BlockManagerInfo: Removed broadcast_108_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:26 INFO BlockManagerInfo: Removed broadcast_107_piece0 on localhost:54908 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:00:26 INFO PythonRDD: Times: total = 41, boot = -77, init = 118, finish = 0
15/10/21 17:00:26 INFO PythonRDD: Times: total = 40, boot = -78, init = 118, finish = 0
15/10/21 17:00:26 INFO Executor: Finished task 0.0 in stage 125.0 (TID 249). 1870 bytes result sent to driver
15/10/21 17:00:26 INFO Executor: Finished task 1.0 in stage 125.0 (TID 250). 1870 bytes result sent to driver
15/10/21 17:00:26 INFO TaskSetManager: Finished task 0.0 in stage 125.0 (TID 249) in 45 ms on localhost (1/2)
15/10/21 17:00:26 INFO TaskSetManager: Finished task 1.0 in stage 125.0 (TID 250) in 45 ms on localhost (2/2)
15/10/21 17:00:26 INFO TaskSchedulerImpl: Removed TaskSet 125.0, whose tasks have all completed, from pool 
15/10/21 17:00:26 INFO DAGScheduler: ResultStage 125 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:26 INFO DAGScheduler: Job 124 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.058155 s
15/10/21 17:00:26 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:26 INFO DAGScheduler: Got job 125 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:26 INFO DAGScheduler: Final stage: ResultStage 126(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:26 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:26 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:26 INFO DAGScheduler: Submitting ResultStage 126 (PythonRDD[132] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:26 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=183647, maxMem=278302556
15/10/21 17:00:26 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:26 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=190655, maxMem=278302556
15/10/21 17:00:26 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:26 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:26 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:26 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 126 (PythonRDD[132] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:26 INFO TaskSchedulerImpl: Adding task set 126.0 with 2 tasks
15/10/21 17:00:26 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 251, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:26 INFO TaskSetManager: Starting task 1.0 in stage 126.0 (TID 252, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:26 INFO Executor: Running task 0.0 in stage 126.0 (TID 251)
15/10/21 17:00:26 INFO Executor: Running task 1.0 in stage 126.0 (TID 252)
15/10/21 17:00:26 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:26 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:27 INFO PythonRDD: Times: total = 39, boot = -83, init = 122, finish = 0
15/10/21 17:00:27 INFO PythonRDD: Times: total = 39, boot = -82, init = 121, finish = 0
15/10/21 17:00:27 INFO Executor: Finished task 0.0 in stage 126.0 (TID 251). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO Executor: Finished task 1.0 in stage 126.0 (TID 252). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 251) in 44 ms on localhost (1/2)
15/10/21 17:00:27 INFO TaskSetManager: Finished task 1.0 in stage 126.0 (TID 252) in 44 ms on localhost (2/2)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool 
15/10/21 17:00:27 INFO DAGScheduler: ResultStage 126 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:27 INFO DAGScheduler: Job 125 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053111 s
15/10/21 17:00:27 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:27 INFO DAGScheduler: Got job 126 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:27 INFO DAGScheduler: Final stage: ResultStage 127(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:27 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:27 INFO DAGScheduler: Submitting ResultStage 127 (PythonRDD[133] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=194610, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=201618, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:27 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:27 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 127 (PythonRDD[133] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Adding task set 127.0 with 2 tasks
15/10/21 17:00:27 INFO TaskSetManager: Starting task 0.0 in stage 127.0 (TID 253, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO TaskSetManager: Starting task 1.0 in stage 127.0 (TID 254, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO Executor: Running task 0.0 in stage 127.0 (TID 253)
15/10/21 17:00:27 INFO Executor: Running task 1.0 in stage 127.0 (TID 254)
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:27 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:00:27 INFO PythonRDD: Times: total = 40, boot = -75, init = 115, finish = 0
15/10/21 17:00:27 INFO Executor: Finished task 0.0 in stage 127.0 (TID 253). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO Executor: Finished task 1.0 in stage 127.0 (TID 254). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO TaskSetManager: Finished task 0.0 in stage 127.0 (TID 253) in 45 ms on localhost (1/2)
15/10/21 17:00:27 INFO TaskSetManager: Finished task 1.0 in stage 127.0 (TID 254) in 44 ms on localhost (2/2)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool 
15/10/21 17:00:27 INFO DAGScheduler: ResultStage 127 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:27 INFO DAGScheduler: Job 126 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053292 s
15/10/21 17:00:27 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:27 INFO DAGScheduler: Got job 127 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:27 INFO DAGScheduler: Final stage: ResultStage 128(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:27 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:27 INFO DAGScheduler: Submitting ResultStage 128 (PythonRDD[134] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=205573, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=212581, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:27 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:27 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 128 (PythonRDD[134] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Adding task set 128.0 with 2 tasks
15/10/21 17:00:27 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 255, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO TaskSetManager: Starting task 1.0 in stage 128.0 (TID 256, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO Executor: Running task 0.0 in stage 128.0 (TID 255)
15/10/21 17:00:27 INFO Executor: Running task 1.0 in stage 128.0 (TID 256)
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:27 INFO PythonRDD: Times: total = 39, boot = -76, init = 115, finish = 0
15/10/21 17:00:27 INFO PythonRDD: Times: total = 39, boot = -77, init = 116, finish = 0
15/10/21 17:00:27 INFO Executor: Finished task 0.0 in stage 128.0 (TID 255). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO Executor: Finished task 1.0 in stage 128.0 (TID 256). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 255) in 44 ms on localhost (1/2)
15/10/21 17:00:27 INFO TaskSetManager: Finished task 1.0 in stage 128.0 (TID 256) in 43 ms on localhost (2/2)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool 
15/10/21 17:00:27 INFO DAGScheduler: ResultStage 128 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:27 INFO DAGScheduler: Job 127 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.052994 s
15/10/21 17:00:27 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:27 INFO DAGScheduler: Got job 128 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:27 INFO DAGScheduler: Final stage: ResultStage 129(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:27 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:27 INFO DAGScheduler: Submitting ResultStage 129 (PythonRDD[135] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=216536, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=223544, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:27 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:27 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 129 (PythonRDD[135] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Adding task set 129.0 with 2 tasks
15/10/21 17:00:27 INFO TaskSetManager: Starting task 0.0 in stage 129.0 (TID 257, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO TaskSetManager: Starting task 1.0 in stage 129.0 (TID 258, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO Executor: Running task 0.0 in stage 129.0 (TID 257)
15/10/21 17:00:27 INFO Executor: Running task 1.0 in stage 129.0 (TID 258)
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:27 INFO PythonRDD: Times: total = 40, boot = -77, init = 117, finish = 0
15/10/21 17:00:27 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:00:27 INFO Executor: Finished task 0.0 in stage 129.0 (TID 257). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO Executor: Finished task 1.0 in stage 129.0 (TID 258). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO TaskSetManager: Finished task 0.0 in stage 129.0 (TID 257) in 45 ms on localhost (1/2)
15/10/21 17:00:27 INFO TaskSetManager: Finished task 1.0 in stage 129.0 (TID 258) in 44 ms on localhost (2/2)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool 
15/10/21 17:00:27 INFO DAGScheduler: ResultStage 129 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:27 INFO DAGScheduler: Job 128 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053139 s
15/10/21 17:00:27 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:27 INFO DAGScheduler: Got job 129 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:27 INFO DAGScheduler: Final stage: ResultStage 130(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:27 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:27 INFO DAGScheduler: Submitting ResultStage 130 (PythonRDD[136] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=227499, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=234507, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:27 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:27 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 130 (PythonRDD[136] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Adding task set 130.0 with 2 tasks
15/10/21 17:00:27 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 259, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO TaskSetManager: Starting task 1.0 in stage 130.0 (TID 260, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO Executor: Running task 1.0 in stage 130.0 (TID 260)
15/10/21 17:00:27 INFO Executor: Running task 0.0 in stage 130.0 (TID 259)
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:27 INFO PythonRDD: Times: total = 37, boot = -75, init = 112, finish = 0
15/10/21 17:00:27 INFO Executor: Finished task 1.0 in stage 130.0 (TID 260). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO TaskSetManager: Finished task 1.0 in stage 130.0 (TID 260) in 40 ms on localhost (1/2)
15/10/21 17:00:27 INFO PythonRDD: Times: total = 41, boot = -74, init = 115, finish = 0
15/10/21 17:00:27 INFO Executor: Finished task 0.0 in stage 130.0 (TID 259). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO TaskSetManager: Finished task 0.0 in stage 130.0 (TID 259) in 45 ms on localhost (2/2)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool 
15/10/21 17:00:27 INFO DAGScheduler: ResultStage 130 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:27 INFO DAGScheduler: Job 129 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053651 s
15/10/21 17:00:27 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:27 INFO DAGScheduler: Got job 130 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:27 INFO DAGScheduler: Final stage: ResultStage 131(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:27 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:27 INFO DAGScheduler: Submitting ResultStage 131 (PythonRDD[137] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=238462, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=245470, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:27 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:27 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 131 (PythonRDD[137] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Adding task set 131.0 with 2 tasks
15/10/21 17:00:27 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 261, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO TaskSetManager: Starting task 1.0 in stage 131.0 (TID 262, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO Executor: Running task 0.0 in stage 131.0 (TID 261)
15/10/21 17:00:27 INFO Executor: Running task 1.0 in stage 131.0 (TID 262)
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:27 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:00:27 INFO PythonRDD: Times: total = 40, boot = -75, init = 115, finish = 0
15/10/21 17:00:27 INFO Executor: Finished task 0.0 in stage 131.0 (TID 261). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO Executor: Finished task 1.0 in stage 131.0 (TID 262). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 261) in 45 ms on localhost (1/2)
15/10/21 17:00:27 INFO TaskSetManager: Finished task 1.0 in stage 131.0 (TID 262) in 44 ms on localhost (2/2)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool 
15/10/21 17:00:27 INFO DAGScheduler: ResultStage 131 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:27 INFO DAGScheduler: Job 130 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053656 s
15/10/21 17:00:27 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:27 INFO DAGScheduler: Got job 131 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:27 INFO DAGScheduler: Final stage: ResultStage 132(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:27 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:27 INFO DAGScheduler: Submitting ResultStage 132 (PythonRDD[138] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=249425, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=256433, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:27 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:27 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 132 (PythonRDD[138] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Adding task set 132.0 with 2 tasks
15/10/21 17:00:27 INFO TaskSetManager: Starting task 0.0 in stage 132.0 (TID 263, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO TaskSetManager: Starting task 1.0 in stage 132.0 (TID 264, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO Executor: Running task 0.0 in stage 132.0 (TID 263)
15/10/21 17:00:27 INFO Executor: Running task 1.0 in stage 132.0 (TID 264)
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:27 INFO PythonRDD: Times: total = 40, boot = -79, init = 119, finish = 0
15/10/21 17:00:27 INFO PythonRDD: Times: total = 40, boot = -77, init = 117, finish = 0
15/10/21 17:00:27 INFO Executor: Finished task 0.0 in stage 132.0 (TID 263). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO Executor: Finished task 1.0 in stage 132.0 (TID 264). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO TaskSetManager: Finished task 0.0 in stage 132.0 (TID 263) in 44 ms on localhost (1/2)
15/10/21 17:00:27 INFO TaskSetManager: Finished task 1.0 in stage 132.0 (TID 264) in 44 ms on localhost (2/2)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Removed TaskSet 132.0, whose tasks have all completed, from pool 
15/10/21 17:00:27 INFO DAGScheduler: ResultStage 132 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:27 INFO DAGScheduler: Job 131 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053988 s
15/10/21 17:00:27 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:27 INFO DAGScheduler: Got job 132 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:27 INFO DAGScheduler: Final stage: ResultStage 133(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:27 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:27 INFO DAGScheduler: Submitting ResultStage 133 (PythonRDD[139] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=260388, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=267396, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:27 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:27 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 133 (PythonRDD[139] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Adding task set 133.0 with 2 tasks
15/10/21 17:00:27 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 265, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO TaskSetManager: Starting task 1.0 in stage 133.0 (TID 266, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO Executor: Running task 0.0 in stage 133.0 (TID 265)
15/10/21 17:00:27 INFO Executor: Running task 1.0 in stage 133.0 (TID 266)
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:27 INFO PythonRDD: Times: total = 38, boot = -78, init = 116, finish = 0
15/10/21 17:00:27 INFO PythonRDD: Times: total = 39, boot = -76, init = 115, finish = 0
15/10/21 17:00:27 INFO Executor: Finished task 1.0 in stage 133.0 (TID 266). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO Executor: Finished task 0.0 in stage 133.0 (TID 265). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO TaskSetManager: Finished task 1.0 in stage 133.0 (TID 266) in 43 ms on localhost (1/2)
15/10/21 17:00:27 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 265) in 43 ms on localhost (2/2)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool 
15/10/21 17:00:27 INFO DAGScheduler: ResultStage 133 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:27 INFO DAGScheduler: Job 132 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.052428 s
15/10/21 17:00:27 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:27 INFO DAGScheduler: Got job 133 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:27 INFO DAGScheduler: Final stage: ResultStage 134(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:27 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:27 INFO DAGScheduler: Submitting ResultStage 134 (PythonRDD[140] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=271351, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=278359, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:27 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:27 INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 134 (PythonRDD[140] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Adding task set 134.0 with 2 tasks
15/10/21 17:00:27 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 267, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO TaskSetManager: Starting task 1.0 in stage 134.0 (TID 268, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO Executor: Running task 0.0 in stage 134.0 (TID 267)
15/10/21 17:00:27 INFO Executor: Running task 1.0 in stage 134.0 (TID 268)
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:27 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:00:27 INFO PythonRDD: Times: total = 41, boot = -77, init = 118, finish = 0
15/10/21 17:00:27 INFO Executor: Finished task 1.0 in stage 134.0 (TID 268). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO Executor: Finished task 0.0 in stage 134.0 (TID 267). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO TaskSetManager: Finished task 1.0 in stage 134.0 (TID 268) in 45 ms on localhost (1/2)
15/10/21 17:00:27 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 267) in 45 ms on localhost (2/2)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool 
15/10/21 17:00:27 INFO DAGScheduler: ResultStage 134 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:27 INFO DAGScheduler: Job 133 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053881 s
15/10/21 17:00:27 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:27 INFO DAGScheduler: Got job 134 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:27 INFO DAGScheduler: Final stage: ResultStage 135(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:27 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:27 INFO DAGScheduler: Submitting ResultStage 135 (PythonRDD[141] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=282314, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=289322, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:27 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:27 INFO SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 135 (PythonRDD[141] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Adding task set 135.0 with 2 tasks
15/10/21 17:00:27 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 269, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO TaskSetManager: Starting task 1.0 in stage 135.0 (TID 270, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO Executor: Running task 0.0 in stage 135.0 (TID 269)
15/10/21 17:00:27 INFO Executor: Running task 1.0 in stage 135.0 (TID 270)
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:27 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:00:27 INFO PythonRDD: Times: total = 40, boot = -75, init = 115, finish = 0
15/10/21 17:00:27 INFO Executor: Finished task 1.0 in stage 135.0 (TID 270). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO Executor: Finished task 0.0 in stage 135.0 (TID 269). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO TaskSetManager: Finished task 1.0 in stage 135.0 (TID 270) in 44 ms on localhost (1/2)
15/10/21 17:00:27 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 269) in 45 ms on localhost (2/2)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool 
15/10/21 17:00:27 INFO DAGScheduler: ResultStage 135 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:27 INFO DAGScheduler: Job 134 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053876 s
15/10/21 17:00:27 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:27 INFO DAGScheduler: Got job 135 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:27 INFO DAGScheduler: Final stage: ResultStage 136(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:27 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:27 INFO DAGScheduler: Submitting ResultStage 136 (PythonRDD[142] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=293277, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=300285, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:27 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:27 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 136 (PythonRDD[142] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Adding task set 136.0 with 2 tasks
15/10/21 17:00:27 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 271, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO TaskSetManager: Starting task 1.0 in stage 136.0 (TID 272, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO Executor: Running task 0.0 in stage 136.0 (TID 271)
15/10/21 17:00:27 INFO Executor: Running task 1.0 in stage 136.0 (TID 272)
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:27 INFO PythonRDD: Times: total = 38, boot = -73, init = 111, finish = 0
15/10/21 17:00:27 INFO PythonRDD: Times: total = 39, boot = -74, init = 113, finish = 0
15/10/21 17:00:27 INFO Executor: Finished task 1.0 in stage 136.0 (TID 272). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO Executor: Finished task 0.0 in stage 136.0 (TID 271). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO TaskSetManager: Finished task 1.0 in stage 136.0 (TID 272) in 42 ms on localhost (1/2)
15/10/21 17:00:27 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 271) in 43 ms on localhost (2/2)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool 
15/10/21 17:00:27 INFO DAGScheduler: ResultStage 136 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:27 INFO DAGScheduler: Job 135 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.051347 s
15/10/21 17:00:27 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:27 INFO DAGScheduler: Got job 136 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:27 INFO DAGScheduler: Final stage: ResultStage 137(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:27 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:27 INFO DAGScheduler: Submitting ResultStage 137 (PythonRDD[143] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=304240, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=311248, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:27 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:27 INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 137 (PythonRDD[143] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Adding task set 137.0 with 2 tasks
15/10/21 17:00:27 INFO TaskSetManager: Starting task 0.0 in stage 137.0 (TID 273, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO TaskSetManager: Starting task 1.0 in stage 137.0 (TID 274, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO Executor: Running task 0.0 in stage 137.0 (TID 273)
15/10/21 17:00:27 INFO Executor: Running task 1.0 in stage 137.0 (TID 274)
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:27 INFO PythonRDD: Times: total = 41, boot = -70, init = 111, finish = 0
15/10/21 17:00:27 INFO PythonRDD: Times: total = 41, boot = -71, init = 112, finish = 0
15/10/21 17:00:27 INFO Executor: Finished task 1.0 in stage 137.0 (TID 274). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO Executor: Finished task 0.0 in stage 137.0 (TID 273). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO TaskSetManager: Finished task 1.0 in stage 137.0 (TID 274) in 45 ms on localhost (1/2)
15/10/21 17:00:27 INFO TaskSetManager: Finished task 0.0 in stage 137.0 (TID 273) in 46 ms on localhost (2/2)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool 
15/10/21 17:00:27 INFO DAGScheduler: ResultStage 137 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:27 INFO DAGScheduler: Job 136 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.054591 s
15/10/21 17:00:27 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:27 INFO DAGScheduler: Got job 137 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:27 INFO DAGScheduler: Final stage: ResultStage 138(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:27 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:27 INFO DAGScheduler: Submitting ResultStage 138 (PythonRDD[144] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=315203, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=322211, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:27 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:27 INFO SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 138 (PythonRDD[144] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Adding task set 138.0 with 2 tasks
15/10/21 17:00:27 INFO TaskSetManager: Starting task 0.0 in stage 138.0 (TID 275, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO TaskSetManager: Starting task 1.0 in stage 138.0 (TID 276, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO Executor: Running task 0.0 in stage 138.0 (TID 275)
15/10/21 17:00:27 INFO Executor: Running task 1.0 in stage 138.0 (TID 276)
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:27 INFO PythonRDD: Times: total = 39, boot = -75, init = 114, finish = 0
15/10/21 17:00:27 INFO PythonRDD: Times: total = 39, boot = -78, init = 117, finish = 0
15/10/21 17:00:27 INFO Executor: Finished task 1.0 in stage 138.0 (TID 276). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO Executor: Finished task 0.0 in stage 138.0 (TID 275). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO TaskSetManager: Finished task 1.0 in stage 138.0 (TID 276) in 43 ms on localhost (1/2)
15/10/21 17:00:27 INFO TaskSetManager: Finished task 0.0 in stage 138.0 (TID 275) in 44 ms on localhost (2/2)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Removed TaskSet 138.0, whose tasks have all completed, from pool 
15/10/21 17:00:27 INFO DAGScheduler: ResultStage 138 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:27 INFO DAGScheduler: Job 137 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.052978 s
15/10/21 17:00:27 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:27 INFO DAGScheduler: Got job 138 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:27 INFO DAGScheduler: Final stage: ResultStage 139(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:27 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:27 INFO DAGScheduler: Submitting ResultStage 139 (PythonRDD[145] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=326166, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=333174, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:27 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:27 INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 139 (PythonRDD[145] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Adding task set 139.0 with 2 tasks
15/10/21 17:00:27 INFO TaskSetManager: Starting task 0.0 in stage 139.0 (TID 277, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO TaskSetManager: Starting task 1.0 in stage 139.0 (TID 278, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO Executor: Running task 0.0 in stage 139.0 (TID 277)
15/10/21 17:00:27 INFO Executor: Running task 1.0 in stage 139.0 (TID 278)
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:27 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:00:27 INFO PythonRDD: Times: total = 40, boot = -75, init = 115, finish = 0
15/10/21 17:00:27 INFO Executor: Finished task 1.0 in stage 139.0 (TID 278). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO Executor: Finished task 0.0 in stage 139.0 (TID 277). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO TaskSetManager: Finished task 1.0 in stage 139.0 (TID 278) in 43 ms on localhost (1/2)
15/10/21 17:00:27 INFO TaskSetManager: Finished task 0.0 in stage 139.0 (TID 277) in 45 ms on localhost (2/2)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Removed TaskSet 139.0, whose tasks have all completed, from pool 
15/10/21 17:00:27 INFO DAGScheduler: ResultStage 139 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:27 INFO DAGScheduler: Job 138 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053261 s
15/10/21 17:00:27 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:27 INFO DAGScheduler: Got job 139 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:27 INFO DAGScheduler: Final stage: ResultStage 140(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:27 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:27 INFO DAGScheduler: Submitting ResultStage 140 (PythonRDD[146] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=337129, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=344137, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:27 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:27 INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 140 (PythonRDD[146] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Adding task set 140.0 with 2 tasks
15/10/21 17:00:27 INFO TaskSetManager: Starting task 0.0 in stage 140.0 (TID 279, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO TaskSetManager: Starting task 1.0 in stage 140.0 (TID 280, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:27 INFO Executor: Running task 0.0 in stage 140.0 (TID 279)
15/10/21 17:00:27 INFO Executor: Running task 1.0 in stage 140.0 (TID 280)
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:27 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:27 INFO PythonRDD: Times: total = 41, boot = -75, init = 116, finish = 0
15/10/21 17:00:27 INFO PythonRDD: Times: total = 41, boot = -76, init = 117, finish = 0
15/10/21 17:00:27 INFO Executor: Finished task 1.0 in stage 140.0 (TID 280). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO Executor: Finished task 0.0 in stage 140.0 (TID 279). 1870 bytes result sent to driver
15/10/21 17:00:27 INFO TaskSetManager: Finished task 1.0 in stage 140.0 (TID 280) in 44 ms on localhost (1/2)
15/10/21 17:00:27 INFO TaskSetManager: Finished task 0.0 in stage 140.0 (TID 279) in 45 ms on localhost (2/2)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Removed TaskSet 140.0, whose tasks have all completed, from pool 
15/10/21 17:00:27 INFO DAGScheduler: ResultStage 140 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:27 INFO DAGScheduler: Job 139 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053651 s
15/10/21 17:00:27 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:27 INFO DAGScheduler: Got job 140 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:27 INFO DAGScheduler: Final stage: ResultStage 141(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:27 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:27 INFO DAGScheduler: Submitting ResultStage 141 (PythonRDD[147] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=348092, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:27 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=355100, maxMem=278302556
15/10/21 17:00:27 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:27 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:27 INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 141 (PythonRDD[147] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:27 INFO TaskSchedulerImpl: Adding task set 141.0 with 2 tasks
15/10/21 17:00:28 INFO TaskSetManager: Starting task 0.0 in stage 141.0 (TID 281, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO TaskSetManager: Starting task 1.0 in stage 141.0 (TID 282, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO Executor: Running task 0.0 in stage 141.0 (TID 281)
15/10/21 17:00:28 INFO Executor: Running task 1.0 in stage 141.0 (TID 282)
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:28 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:00:28 INFO PythonRDD: Times: total = 40, boot = -75, init = 115, finish = 0
15/10/21 17:00:28 INFO Executor: Finished task 0.0 in stage 141.0 (TID 281). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO Executor: Finished task 1.0 in stage 141.0 (TID 282). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO TaskSetManager: Finished task 0.0 in stage 141.0 (TID 281) in 45 ms on localhost (1/2)
15/10/21 17:00:28 INFO TaskSetManager: Finished task 1.0 in stage 141.0 (TID 282) in 44 ms on localhost (2/2)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Removed TaskSet 141.0, whose tasks have all completed, from pool 
15/10/21 17:00:28 INFO DAGScheduler: ResultStage 141 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:28 INFO DAGScheduler: Job 140 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053741 s
15/10/21 17:00:28 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:28 INFO DAGScheduler: Got job 141 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:28 INFO DAGScheduler: Final stage: ResultStage 142(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:28 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:28 INFO DAGScheduler: Submitting ResultStage 142 (PythonRDD[148] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=359055, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=366063, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:28 INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 142 (PythonRDD[148] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Adding task set 142.0 with 2 tasks
15/10/21 17:00:28 INFO TaskSetManager: Starting task 0.0 in stage 142.0 (TID 283, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO TaskSetManager: Starting task 1.0 in stage 142.0 (TID 284, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO Executor: Running task 0.0 in stage 142.0 (TID 283)
15/10/21 17:00:28 INFO Executor: Running task 1.0 in stage 142.0 (TID 284)
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:28 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:00:28 INFO PythonRDD: Times: total = 40, boot = -78, init = 118, finish = 0
15/10/21 17:00:28 INFO Executor: Finished task 1.0 in stage 142.0 (TID 284). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO Executor: Finished task 0.0 in stage 142.0 (TID 283). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO TaskSetManager: Finished task 1.0 in stage 142.0 (TID 284) in 43 ms on localhost (1/2)
15/10/21 17:00:28 INFO TaskSetManager: Finished task 0.0 in stage 142.0 (TID 283) in 45 ms on localhost (2/2)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Removed TaskSet 142.0, whose tasks have all completed, from pool 
15/10/21 17:00:28 INFO DAGScheduler: ResultStage 142 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:28 INFO DAGScheduler: Job 141 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053097 s
15/10/21 17:00:28 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:28 INFO DAGScheduler: Got job 142 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:28 INFO DAGScheduler: Final stage: ResultStage 143(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:28 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:28 INFO DAGScheduler: Submitting ResultStage 143 (PythonRDD[149] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=370018, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=377026, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:28 INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 143 (PythonRDD[149] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Adding task set 143.0 with 2 tasks
15/10/21 17:00:28 INFO TaskSetManager: Starting task 0.0 in stage 143.0 (TID 285, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO TaskSetManager: Starting task 1.0 in stage 143.0 (TID 286, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO Executor: Running task 1.0 in stage 143.0 (TID 286)
15/10/21 17:00:28 INFO Executor: Running task 0.0 in stage 143.0 (TID 285)
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:28 INFO PythonRDD: Times: total = 38, boot = -73, init = 111, finish = 0
15/10/21 17:00:28 INFO Executor: Finished task 1.0 in stage 143.0 (TID 286). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO TaskSetManager: Finished task 1.0 in stage 143.0 (TID 286) in 41 ms on localhost (1/2)
15/10/21 17:00:28 INFO PythonRDD: Times: total = 41, boot = -76, init = 117, finish = 0
15/10/21 17:00:28 INFO Executor: Finished task 0.0 in stage 143.0 (TID 285). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO TaskSetManager: Finished task 0.0 in stage 143.0 (TID 285) in 45 ms on localhost (2/2)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Removed TaskSet 143.0, whose tasks have all completed, from pool 
15/10/21 17:00:28 INFO DAGScheduler: ResultStage 143 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:28 INFO DAGScheduler: Job 142 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053204 s
15/10/21 17:00:28 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:28 INFO DAGScheduler: Got job 143 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:28 INFO DAGScheduler: Final stage: ResultStage 144(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:28 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:28 INFO DAGScheduler: Submitting ResultStage 144 (PythonRDD[150] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=380981, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=387989, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:28 INFO SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 144 (PythonRDD[150] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Adding task set 144.0 with 2 tasks
15/10/21 17:00:28 INFO TaskSetManager: Starting task 0.0 in stage 144.0 (TID 287, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO TaskSetManager: Starting task 1.0 in stage 144.0 (TID 288, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO Executor: Running task 0.0 in stage 144.0 (TID 287)
15/10/21 17:00:28 INFO Executor: Running task 1.0 in stage 144.0 (TID 288)
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:28 INFO BlockManagerInfo: Removed broadcast_132_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Removed broadcast_131_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Removed broadcast_130_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Removed broadcast_129_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Removed broadcast_128_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Removed broadcast_127_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Removed broadcast_126_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Removed broadcast_144_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Removed broadcast_143_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Removed broadcast_142_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Removed broadcast_141_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Removed broadcast_140_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Removed broadcast_139_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Removed broadcast_138_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Removed broadcast_137_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Removed broadcast_136_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Removed broadcast_135_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Removed broadcast_134_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Removed broadcast_133_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:28 INFO PythonRDD: Times: total = 37, boot = -79, init = 116, finish = 0
15/10/21 17:00:28 INFO PythonRDD: Times: total = 41, boot = -76, init = 117, finish = 0
15/10/21 17:00:28 INFO Executor: Finished task 1.0 in stage 144.0 (TID 288). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO Executor: Finished task 0.0 in stage 144.0 (TID 287). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO TaskSetManager: Finished task 1.0 in stage 144.0 (TID 288) in 44 ms on localhost (1/2)
15/10/21 17:00:28 INFO TaskSetManager: Finished task 0.0 in stage 144.0 (TID 287) in 46 ms on localhost (2/2)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Removed TaskSet 144.0, whose tasks have all completed, from pool 
15/10/21 17:00:28 INFO DAGScheduler: ResultStage 144 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:28 INFO DAGScheduler: Job 143 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.054451 s
15/10/21 17:00:28 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:28 INFO DAGScheduler: Got job 144 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:28 INFO DAGScheduler: Final stage: ResultStage 145(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:28 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:28 INFO DAGScheduler: Submitting ResultStage 145 (PythonRDD[151] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=183647, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=190655, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:28 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 145 (PythonRDD[151] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Adding task set 145.0 with 2 tasks
15/10/21 17:00:28 INFO TaskSetManager: Starting task 0.0 in stage 145.0 (TID 289, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO TaskSetManager: Starting task 1.0 in stage 145.0 (TID 290, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO Executor: Running task 1.0 in stage 145.0 (TID 290)
15/10/21 17:00:28 INFO Executor: Running task 0.0 in stage 145.0 (TID 289)
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:28 INFO PythonRDD: Times: total = 41, boot = -81, init = 122, finish = 0
15/10/21 17:00:28 INFO PythonRDD: Times: total = 41, boot = -74, init = 115, finish = 0
15/10/21 17:00:28 INFO Executor: Finished task 1.0 in stage 145.0 (TID 290). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO Executor: Finished task 0.0 in stage 145.0 (TID 289). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO TaskSetManager: Finished task 1.0 in stage 145.0 (TID 290) in 45 ms on localhost (1/2)
15/10/21 17:00:28 INFO TaskSetManager: Finished task 0.0 in stage 145.0 (TID 289) in 45 ms on localhost (2/2)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Removed TaskSet 145.0, whose tasks have all completed, from pool 
15/10/21 17:00:28 INFO DAGScheduler: ResultStage 145 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:28 INFO DAGScheduler: Job 144 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053906 s
15/10/21 17:00:28 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:28 INFO DAGScheduler: Got job 145 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:28 INFO DAGScheduler: Final stage: ResultStage 146(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:28 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:28 INFO DAGScheduler: Submitting ResultStage 146 (PythonRDD[152] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=194610, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=201618, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:28 INFO SparkContext: Created broadcast 147 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 146 (PythonRDD[152] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Adding task set 146.0 with 2 tasks
15/10/21 17:00:28 INFO TaskSetManager: Starting task 0.0 in stage 146.0 (TID 291, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO TaskSetManager: Starting task 1.0 in stage 146.0 (TID 292, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO Executor: Running task 0.0 in stage 146.0 (TID 291)
15/10/21 17:00:28 INFO Executor: Running task 1.0 in stage 146.0 (TID 292)
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:28 INFO PythonRDD: Times: total = 40, boot = -75, init = 115, finish = 0
15/10/21 17:00:28 INFO PythonRDD: Times: total = 40, boot = -77, init = 117, finish = 0
15/10/21 17:00:28 INFO Executor: Finished task 1.0 in stage 146.0 (TID 292). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO Executor: Finished task 0.0 in stage 146.0 (TID 291). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO TaskSetManager: Finished task 1.0 in stage 146.0 (TID 292) in 43 ms on localhost (1/2)
15/10/21 17:00:28 INFO TaskSetManager: Finished task 0.0 in stage 146.0 (TID 291) in 44 ms on localhost (2/2)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Removed TaskSet 146.0, whose tasks have all completed, from pool 
15/10/21 17:00:28 INFO DAGScheduler: ResultStage 146 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:28 INFO DAGScheduler: Job 145 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.052974 s
15/10/21 17:00:28 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:28 INFO DAGScheduler: Got job 146 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:28 INFO DAGScheduler: Final stage: ResultStage 147(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:28 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:28 INFO DAGScheduler: Submitting ResultStage 147 (PythonRDD[153] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=205573, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=212581, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:28 INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 147 (PythonRDD[153] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Adding task set 147.0 with 2 tasks
15/10/21 17:00:28 INFO TaskSetManager: Starting task 0.0 in stage 147.0 (TID 293, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO TaskSetManager: Starting task 1.0 in stage 147.0 (TID 294, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO Executor: Running task 0.0 in stage 147.0 (TID 293)
15/10/21 17:00:28 INFO Executor: Running task 1.0 in stage 147.0 (TID 294)
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:28 INFO PythonRDD: Times: total = 41, boot = -76, init = 117, finish = 0
15/10/21 17:00:28 INFO PythonRDD: Times: total = 41, boot = -75, init = 116, finish = 0
15/10/21 17:00:28 INFO Executor: Finished task 0.0 in stage 147.0 (TID 293). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO Executor: Finished task 1.0 in stage 147.0 (TID 294). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO TaskSetManager: Finished task 0.0 in stage 147.0 (TID 293) in 46 ms on localhost (1/2)
15/10/21 17:00:28 INFO TaskSetManager: Finished task 1.0 in stage 147.0 (TID 294) in 45 ms on localhost (2/2)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Removed TaskSet 147.0, whose tasks have all completed, from pool 
15/10/21 17:00:28 INFO DAGScheduler: ResultStage 147 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:28 INFO DAGScheduler: Job 146 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.054047 s
15/10/21 17:00:28 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:28 INFO DAGScheduler: Got job 147 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:28 INFO DAGScheduler: Final stage: ResultStage 148(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:28 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:28 INFO DAGScheduler: Submitting ResultStage 148 (PythonRDD[154] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=216536, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=223544, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:28 INFO SparkContext: Created broadcast 149 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 148 (PythonRDD[154] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Adding task set 148.0 with 2 tasks
15/10/21 17:00:28 INFO TaskSetManager: Starting task 0.0 in stage 148.0 (TID 295, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO TaskSetManager: Starting task 1.0 in stage 148.0 (TID 296, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO Executor: Running task 1.0 in stage 148.0 (TID 296)
15/10/21 17:00:28 INFO Executor: Running task 0.0 in stage 148.0 (TID 295)
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:28 INFO PythonRDD: Times: total = 41, boot = -76, init = 117, finish = 0
15/10/21 17:00:28 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:00:28 INFO Executor: Finished task 1.0 in stage 148.0 (TID 296). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO Executor: Finished task 0.0 in stage 148.0 (TID 295). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO TaskSetManager: Finished task 1.0 in stage 148.0 (TID 296) in 44 ms on localhost (1/2)
15/10/21 17:00:28 INFO TaskSetManager: Finished task 0.0 in stage 148.0 (TID 295) in 45 ms on localhost (2/2)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Removed TaskSet 148.0, whose tasks have all completed, from pool 
15/10/21 17:00:28 INFO DAGScheduler: ResultStage 148 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:28 INFO DAGScheduler: Job 147 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053998 s
15/10/21 17:00:28 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:28 INFO DAGScheduler: Got job 148 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:28 INFO DAGScheduler: Final stage: ResultStage 149(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:28 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:28 INFO DAGScheduler: Submitting ResultStage 149 (PythonRDD[155] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=227499, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=234507, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:28 INFO SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 149 (PythonRDD[155] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Adding task set 149.0 with 2 tasks
15/10/21 17:00:28 INFO TaskSetManager: Starting task 0.0 in stage 149.0 (TID 297, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO TaskSetManager: Starting task 1.0 in stage 149.0 (TID 298, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO Executor: Running task 0.0 in stage 149.0 (TID 297)
15/10/21 17:00:28 INFO Executor: Running task 1.0 in stage 149.0 (TID 298)
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:28 INFO PythonRDD: Times: total = 39, boot = -73, init = 112, finish = 0
15/10/21 17:00:28 INFO PythonRDD: Times: total = 39, boot = -74, init = 113, finish = 0
15/10/21 17:00:28 INFO Executor: Finished task 1.0 in stage 149.0 (TID 298). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO Executor: Finished task 0.0 in stage 149.0 (TID 297). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO TaskSetManager: Finished task 1.0 in stage 149.0 (TID 298) in 42 ms on localhost (1/2)
15/10/21 17:00:28 INFO TaskSetManager: Finished task 0.0 in stage 149.0 (TID 297) in 43 ms on localhost (2/2)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Removed TaskSet 149.0, whose tasks have all completed, from pool 
15/10/21 17:00:28 INFO DAGScheduler: ResultStage 149 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:28 INFO DAGScheduler: Job 148 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.050486 s
15/10/21 17:00:28 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:28 INFO DAGScheduler: Got job 149 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:28 INFO DAGScheduler: Final stage: ResultStage 150(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:28 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:28 INFO DAGScheduler: Submitting ResultStage 150 (PythonRDD[156] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=238462, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=245470, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:28 INFO SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 150 (PythonRDD[156] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Adding task set 150.0 with 2 tasks
15/10/21 17:00:28 INFO TaskSetManager: Starting task 0.0 in stage 150.0 (TID 299, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO TaskSetManager: Starting task 1.0 in stage 150.0 (TID 300, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO Executor: Running task 0.0 in stage 150.0 (TID 299)
15/10/21 17:00:28 INFO Executor: Running task 1.0 in stage 150.0 (TID 300)
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:28 INFO PythonRDD: Times: total = 38, boot = -71, init = 109, finish = 0
15/10/21 17:00:28 INFO PythonRDD: Times: total = 38, boot = -70, init = 108, finish = 0
15/10/21 17:00:28 INFO Executor: Finished task 1.0 in stage 150.0 (TID 300). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO Executor: Finished task 0.0 in stage 150.0 (TID 299). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO TaskSetManager: Finished task 1.0 in stage 150.0 (TID 300) in 41 ms on localhost (1/2)
15/10/21 17:00:28 INFO TaskSetManager: Finished task 0.0 in stage 150.0 (TID 299) in 42 ms on localhost (2/2)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Removed TaskSet 150.0, whose tasks have all completed, from pool 
15/10/21 17:00:28 INFO DAGScheduler: ResultStage 150 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.042 s
15/10/21 17:00:28 INFO DAGScheduler: Job 149 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.050827 s
15/10/21 17:00:28 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:28 INFO DAGScheduler: Got job 150 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:28 INFO DAGScheduler: Final stage: ResultStage 151(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:28 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:28 INFO DAGScheduler: Submitting ResultStage 151 (PythonRDD[157] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=249425, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=256433, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:28 INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 151 (PythonRDD[157] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Adding task set 151.0 with 2 tasks
15/10/21 17:00:28 INFO TaskSetManager: Starting task 0.0 in stage 151.0 (TID 301, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO TaskSetManager: Starting task 1.0 in stage 151.0 (TID 302, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO Executor: Running task 0.0 in stage 151.0 (TID 301)
15/10/21 17:00:28 INFO Executor: Running task 1.0 in stage 151.0 (TID 302)
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:28 INFO PythonRDD: Times: total = 41, boot = -71, init = 112, finish = 0
15/10/21 17:00:28 INFO PythonRDD: Times: total = 40, boot = -72, init = 112, finish = 0
15/10/21 17:00:28 INFO Executor: Finished task 1.0 in stage 151.0 (TID 302). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO Executor: Finished task 0.0 in stage 151.0 (TID 301). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO TaskSetManager: Finished task 1.0 in stage 151.0 (TID 302) in 45 ms on localhost (1/2)
15/10/21 17:00:28 INFO TaskSetManager: Finished task 0.0 in stage 151.0 (TID 301) in 45 ms on localhost (2/2)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Removed TaskSet 151.0, whose tasks have all completed, from pool 
15/10/21 17:00:28 INFO DAGScheduler: ResultStage 151 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:28 INFO DAGScheduler: Job 150 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053889 s
15/10/21 17:00:28 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:28 INFO DAGScheduler: Got job 151 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:28 INFO DAGScheduler: Final stage: ResultStage 152(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:28 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:28 INFO DAGScheduler: Submitting ResultStage 152 (PythonRDD[158] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=260388, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=267396, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:28 INFO SparkContext: Created broadcast 153 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 152 (PythonRDD[158] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Adding task set 152.0 with 2 tasks
15/10/21 17:00:28 INFO TaskSetManager: Starting task 0.0 in stage 152.0 (TID 303, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO TaskSetManager: Starting task 1.0 in stage 152.0 (TID 304, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO Executor: Running task 0.0 in stage 152.0 (TID 303)
15/10/21 17:00:28 INFO Executor: Running task 1.0 in stage 152.0 (TID 304)
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:28 INFO PythonRDD: Times: total = 37, boot = -75, init = 112, finish = 0
15/10/21 17:00:28 INFO Executor: Finished task 0.0 in stage 152.0 (TID 303). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO TaskSetManager: Finished task 0.0 in stage 152.0 (TID 303) in 41 ms on localhost (1/2)
15/10/21 17:00:28 INFO PythonRDD: Times: total = 41, boot = -76, init = 117, finish = 0
15/10/21 17:00:28 INFO Executor: Finished task 1.0 in stage 152.0 (TID 304). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO TaskSetManager: Finished task 1.0 in stage 152.0 (TID 304) in 44 ms on localhost (2/2)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Removed TaskSet 152.0, whose tasks have all completed, from pool 
15/10/21 17:00:28 INFO DAGScheduler: ResultStage 152 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:28 INFO DAGScheduler: Job 151 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053752 s
15/10/21 17:00:28 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:28 INFO DAGScheduler: Got job 152 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:28 INFO DAGScheduler: Final stage: ResultStage 153(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:28 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:28 INFO DAGScheduler: Submitting ResultStage 153 (PythonRDD[159] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=271351, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=278359, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:28 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 153 (PythonRDD[159] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Adding task set 153.0 with 2 tasks
15/10/21 17:00:28 INFO TaskSetManager: Starting task 0.0 in stage 153.0 (TID 305, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO TaskSetManager: Starting task 1.0 in stage 153.0 (TID 306, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO Executor: Running task 0.0 in stage 153.0 (TID 305)
15/10/21 17:00:28 INFO Executor: Running task 1.0 in stage 153.0 (TID 306)
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:28 INFO PythonRDD: Times: total = 41, boot = -76, init = 117, finish = 0
15/10/21 17:00:28 INFO PythonRDD: Times: total = 41, boot = -76, init = 117, finish = 0
15/10/21 17:00:28 INFO Executor: Finished task 1.0 in stage 153.0 (TID 306). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO Executor: Finished task 0.0 in stage 153.0 (TID 305). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO TaskSetManager: Finished task 1.0 in stage 153.0 (TID 306) in 45 ms on localhost (1/2)
15/10/21 17:00:28 INFO TaskSetManager: Finished task 0.0 in stage 153.0 (TID 305) in 45 ms on localhost (2/2)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Removed TaskSet 153.0, whose tasks have all completed, from pool 
15/10/21 17:00:28 INFO DAGScheduler: ResultStage 153 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:28 INFO DAGScheduler: Job 152 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.054263 s
15/10/21 17:00:28 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:28 INFO DAGScheduler: Got job 153 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:28 INFO DAGScheduler: Final stage: ResultStage 154(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:28 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:28 INFO DAGScheduler: Submitting ResultStage 154 (PythonRDD[160] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=282314, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=289322, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:28 INFO SparkContext: Created broadcast 155 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 154 (PythonRDD[160] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Adding task set 154.0 with 2 tasks
15/10/21 17:00:28 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 307, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO TaskSetManager: Starting task 1.0 in stage 154.0 (TID 308, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO Executor: Running task 0.0 in stage 154.0 (TID 307)
15/10/21 17:00:28 INFO Executor: Running task 1.0 in stage 154.0 (TID 308)
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:28 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:00:28 INFO PythonRDD: Times: total = 40, boot = -80, init = 120, finish = 0
15/10/21 17:00:28 INFO Executor: Finished task 1.0 in stage 154.0 (TID 308). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO Executor: Finished task 0.0 in stage 154.0 (TID 307). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO TaskSetManager: Finished task 1.0 in stage 154.0 (TID 308) in 44 ms on localhost (1/2)
15/10/21 17:00:28 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 307) in 45 ms on localhost (2/2)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool 
15/10/21 17:00:28 INFO DAGScheduler: ResultStage 154 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:28 INFO DAGScheduler: Job 153 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053142 s
15/10/21 17:00:28 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:28 INFO DAGScheduler: Got job 154 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:28 INFO DAGScheduler: Final stage: ResultStage 155(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:28 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:28 INFO DAGScheduler: Submitting ResultStage 155 (PythonRDD[161] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=293277, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:28 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=300285, maxMem=278302556
15/10/21 17:00:28 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:28 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:28 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 155 (PythonRDD[161] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Adding task set 155.0 with 2 tasks
15/10/21 17:00:28 INFO TaskSetManager: Starting task 0.0 in stage 155.0 (TID 309, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO TaskSetManager: Starting task 1.0 in stage 155.0 (TID 310, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:28 INFO Executor: Running task 0.0 in stage 155.0 (TID 309)
15/10/21 17:00:28 INFO Executor: Running task 1.0 in stage 155.0 (TID 310)
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:28 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:28 INFO PythonRDD: Times: total = 37, boot = -75, init = 112, finish = 0
15/10/21 17:00:28 INFO Executor: Finished task 0.0 in stage 155.0 (TID 309). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO TaskSetManager: Finished task 0.0 in stage 155.0 (TID 309) in 41 ms on localhost (1/2)
15/10/21 17:00:28 INFO PythonRDD: Times: total = 41, boot = -76, init = 117, finish = 0
15/10/21 17:00:28 INFO Executor: Finished task 1.0 in stage 155.0 (TID 310). 1870 bytes result sent to driver
15/10/21 17:00:28 INFO TaskSetManager: Finished task 1.0 in stage 155.0 (TID 310) in 44 ms on localhost (2/2)
15/10/21 17:00:28 INFO TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool 
15/10/21 17:00:28 INFO DAGScheduler: ResultStage 155 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:28 INFO DAGScheduler: Job 154 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.052997 s
15/10/21 17:00:29 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:29 INFO DAGScheduler: Got job 155 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:29 INFO DAGScheduler: Final stage: ResultStage 156(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:29 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:29 INFO DAGScheduler: Submitting ResultStage 156 (PythonRDD[162] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=304240, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=311248, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:29 INFO SparkContext: Created broadcast 157 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 156 (PythonRDD[162] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Adding task set 156.0 with 2 tasks
15/10/21 17:00:29 INFO TaskSetManager: Starting task 0.0 in stage 156.0 (TID 311, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO TaskSetManager: Starting task 1.0 in stage 156.0 (TID 312, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO Executor: Running task 0.0 in stage 156.0 (TID 311)
15/10/21 17:00:29 INFO Executor: Running task 1.0 in stage 156.0 (TID 312)
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:29 INFO PythonRDD: Times: total = 39, boot = -74, init = 113, finish = 0
15/10/21 17:00:29 INFO PythonRDD: Times: total = 39, boot = -72, init = 111, finish = 0
15/10/21 17:00:29 INFO Executor: Finished task 0.0 in stage 156.0 (TID 311). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO Executor: Finished task 1.0 in stage 156.0 (TID 312). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO TaskSetManager: Finished task 0.0 in stage 156.0 (TID 311) in 43 ms on localhost (1/2)
15/10/21 17:00:29 INFO TaskSetManager: Finished task 1.0 in stage 156.0 (TID 312) in 43 ms on localhost (2/2)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool 
15/10/21 17:00:29 INFO DAGScheduler: ResultStage 156 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:29 INFO DAGScheduler: Job 155 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.051294 s
15/10/21 17:00:29 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:29 INFO DAGScheduler: Got job 156 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:29 INFO DAGScheduler: Final stage: ResultStage 157(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:29 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:29 INFO DAGScheduler: Submitting ResultStage 157 (PythonRDD[163] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=315203, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=322211, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:29 INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 157 (PythonRDD[163] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Adding task set 157.0 with 2 tasks
15/10/21 17:00:29 INFO TaskSetManager: Starting task 0.0 in stage 157.0 (TID 313, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO TaskSetManager: Starting task 1.0 in stage 157.0 (TID 314, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO Executor: Running task 0.0 in stage 157.0 (TID 313)
15/10/21 17:00:29 INFO Executor: Running task 1.0 in stage 157.0 (TID 314)
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:29 INFO PythonRDD: Times: total = 39, boot = -74, init = 113, finish = 0
15/10/21 17:00:29 INFO PythonRDD: Times: total = 39, boot = -68, init = 107, finish = 0
15/10/21 17:00:29 INFO Executor: Finished task 0.0 in stage 157.0 (TID 313). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO Executor: Finished task 1.0 in stage 157.0 (TID 314). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO TaskSetManager: Finished task 0.0 in stage 157.0 (TID 313) in 43 ms on localhost (1/2)
15/10/21 17:00:29 INFO TaskSetManager: Finished task 1.0 in stage 157.0 (TID 314) in 43 ms on localhost (2/2)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Removed TaskSet 157.0, whose tasks have all completed, from pool 
15/10/21 17:00:29 INFO DAGScheduler: ResultStage 157 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:29 INFO DAGScheduler: Job 156 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.051565 s
15/10/21 17:00:29 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:29 INFO DAGScheduler: Got job 157 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:29 INFO DAGScheduler: Final stage: ResultStage 158(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:29 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:29 INFO DAGScheduler: Submitting ResultStage 158 (PythonRDD[164] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=326166, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=333174, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:29 INFO SparkContext: Created broadcast 159 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 158 (PythonRDD[164] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Adding task set 158.0 with 2 tasks
15/10/21 17:00:29 INFO TaskSetManager: Starting task 0.0 in stage 158.0 (TID 315, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO TaskSetManager: Starting task 1.0 in stage 158.0 (TID 316, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO Executor: Running task 0.0 in stage 158.0 (TID 315)
15/10/21 17:00:29 INFO Executor: Running task 1.0 in stage 158.0 (TID 316)
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:29 INFO PythonRDD: Times: total = 41, boot = -72, init = 113, finish = 0
15/10/21 17:00:29 INFO PythonRDD: Times: total = 41, boot = -70, init = 111, finish = 0
15/10/21 17:00:29 INFO Executor: Finished task 1.0 in stage 158.0 (TID 316). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO Executor: Finished task 0.0 in stage 158.0 (TID 315). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO TaskSetManager: Finished task 1.0 in stage 158.0 (TID 316) in 45 ms on localhost (1/2)
15/10/21 17:00:29 INFO TaskSetManager: Finished task 0.0 in stage 158.0 (TID 315) in 45 ms on localhost (2/2)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Removed TaskSet 158.0, whose tasks have all completed, from pool 
15/10/21 17:00:29 INFO DAGScheduler: ResultStage 158 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:29 INFO DAGScheduler: Job 157 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053621 s
15/10/21 17:00:29 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:29 INFO DAGScheduler: Got job 158 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:29 INFO DAGScheduler: Final stage: ResultStage 159(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:29 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:29 INFO DAGScheduler: Submitting ResultStage 159 (PythonRDD[165] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=337129, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=344137, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:29 INFO SparkContext: Created broadcast 160 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 159 (PythonRDD[165] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Adding task set 159.0 with 2 tasks
15/10/21 17:00:29 INFO TaskSetManager: Starting task 0.0 in stage 159.0 (TID 317, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO TaskSetManager: Starting task 1.0 in stage 159.0 (TID 318, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO Executor: Running task 0.0 in stage 159.0 (TID 317)
15/10/21 17:00:29 INFO Executor: Running task 1.0 in stage 159.0 (TID 318)
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:29 INFO PythonRDD: Times: total = 41, boot = -74, init = 115, finish = 0
15/10/21 17:00:29 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:00:29 INFO Executor: Finished task 0.0 in stage 159.0 (TID 317). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO Executor: Finished task 1.0 in stage 159.0 (TID 318). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO TaskSetManager: Finished task 0.0 in stage 159.0 (TID 317) in 45 ms on localhost (1/2)
15/10/21 17:00:29 INFO TaskSetManager: Finished task 1.0 in stage 159.0 (TID 318) in 45 ms on localhost (2/2)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Removed TaskSet 159.0, whose tasks have all completed, from pool 
15/10/21 17:00:29 INFO DAGScheduler: ResultStage 159 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:29 INFO DAGScheduler: Job 158 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053606 s
15/10/21 17:00:29 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:29 INFO DAGScheduler: Got job 159 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:29 INFO DAGScheduler: Final stage: ResultStage 160(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:29 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:29 INFO DAGScheduler: Submitting ResultStage 160 (PythonRDD[166] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=348092, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=355100, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:29 INFO SparkContext: Created broadcast 161 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 160 (PythonRDD[166] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Adding task set 160.0 with 2 tasks
15/10/21 17:00:29 INFO TaskSetManager: Starting task 0.0 in stage 160.0 (TID 319, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO TaskSetManager: Starting task 1.0 in stage 160.0 (TID 320, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO Executor: Running task 0.0 in stage 160.0 (TID 319)
15/10/21 17:00:29 INFO Executor: Running task 1.0 in stage 160.0 (TID 320)
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:29 INFO PythonRDD: Times: total = 37, boot = -76, init = 113, finish = 0
15/10/21 17:00:29 INFO Executor: Finished task 0.0 in stage 160.0 (TID 319). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO TaskSetManager: Finished task 0.0 in stage 160.0 (TID 319) in 40 ms on localhost (1/2)
15/10/21 17:00:29 INFO PythonRDD: Times: total = 41, boot = -76, init = 117, finish = 0
15/10/21 17:00:29 INFO Executor: Finished task 1.0 in stage 160.0 (TID 320). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO TaskSetManager: Finished task 1.0 in stage 160.0 (TID 320) in 44 ms on localhost (2/2)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Removed TaskSet 160.0, whose tasks have all completed, from pool 
15/10/21 17:00:29 INFO DAGScheduler: ResultStage 160 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:29 INFO DAGScheduler: Job 159 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053168 s
15/10/21 17:00:29 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:29 INFO DAGScheduler: Got job 160 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:29 INFO DAGScheduler: Final stage: ResultStage 161(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:29 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:29 INFO DAGScheduler: Submitting ResultStage 161 (PythonRDD[167] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=359055, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=366063, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:29 INFO SparkContext: Created broadcast 162 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 161 (PythonRDD[167] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Adding task set 161.0 with 2 tasks
15/10/21 17:00:29 INFO TaskSetManager: Starting task 0.0 in stage 161.0 (TID 321, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO TaskSetManager: Starting task 1.0 in stage 161.0 (TID 322, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO Executor: Running task 0.0 in stage 161.0 (TID 321)
15/10/21 17:00:29 INFO Executor: Running task 1.0 in stage 161.0 (TID 322)
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:29 INFO PythonRDD: Times: total = 38, boot = -73, init = 111, finish = 0
15/10/21 17:00:29 INFO PythonRDD: Times: total = 38, boot = -75, init = 113, finish = 0
15/10/21 17:00:29 INFO Executor: Finished task 1.0 in stage 161.0 (TID 322). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO Executor: Finished task 0.0 in stage 161.0 (TID 321). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO TaskSetManager: Finished task 1.0 in stage 161.0 (TID 322) in 42 ms on localhost (1/2)
15/10/21 17:00:29 INFO TaskSetManager: Finished task 0.0 in stage 161.0 (TID 321) in 42 ms on localhost (2/2)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Removed TaskSet 161.0, whose tasks have all completed, from pool 
15/10/21 17:00:29 INFO DAGScheduler: ResultStage 161 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.042 s
15/10/21 17:00:29 INFO DAGScheduler: Job 160 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.049689 s
15/10/21 17:00:29 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:29 INFO DAGScheduler: Got job 161 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:29 INFO DAGScheduler: Final stage: ResultStage 162(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:29 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:29 INFO DAGScheduler: Submitting ResultStage 162 (PythonRDD[168] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=370018, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=377026, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:29 INFO SparkContext: Created broadcast 163 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 162 (PythonRDD[168] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Adding task set 162.0 with 2 tasks
15/10/21 17:00:29 INFO TaskSetManager: Starting task 0.0 in stage 162.0 (TID 323, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO TaskSetManager: Starting task 1.0 in stage 162.0 (TID 324, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO Executor: Running task 0.0 in stage 162.0 (TID 323)
15/10/21 17:00:29 INFO Executor: Running task 1.0 in stage 162.0 (TID 324)
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:29 INFO PythonRDD: Times: total = 41, boot = -79, init = 120, finish = 0
15/10/21 17:00:29 INFO PythonRDD: Times: total = 41, boot = -71, init = 112, finish = 0
15/10/21 17:00:29 INFO Executor: Finished task 0.0 in stage 162.0 (TID 323). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO Executor: Finished task 1.0 in stage 162.0 (TID 324). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO TaskSetManager: Finished task 0.0 in stage 162.0 (TID 323) in 44 ms on localhost (1/2)
15/10/21 17:00:29 INFO TaskSetManager: Finished task 1.0 in stage 162.0 (TID 324) in 45 ms on localhost (2/2)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Removed TaskSet 162.0, whose tasks have all completed, from pool 
15/10/21 17:00:29 INFO DAGScheduler: ResultStage 162 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:29 INFO DAGScheduler: Job 161 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053724 s
15/10/21 17:00:29 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:29 INFO DAGScheduler: Got job 162 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:29 INFO DAGScheduler: Final stage: ResultStage 163(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:29 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:29 INFO DAGScheduler: Submitting ResultStage 163 (PythonRDD[169] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=380981, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=387989, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:29 INFO SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 163 (PythonRDD[169] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Adding task set 163.0 with 2 tasks
15/10/21 17:00:29 INFO TaskSetManager: Starting task 0.0 in stage 163.0 (TID 325, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO TaskSetManager: Starting task 1.0 in stage 163.0 (TID 326, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO Executor: Running task 0.0 in stage 163.0 (TID 325)
15/10/21 17:00:29 INFO Executor: Running task 1.0 in stage 163.0 (TID 326)
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:29 INFO PythonRDD: Times: total = 41, boot = -75, init = 116, finish = 0
15/10/21 17:00:29 INFO PythonRDD: Times: total = 41, boot = -75, init = 116, finish = 0
15/10/21 17:00:29 INFO Executor: Finished task 1.0 in stage 163.0 (TID 326). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO Executor: Finished task 0.0 in stage 163.0 (TID 325). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO TaskSetManager: Finished task 1.0 in stage 163.0 (TID 326) in 44 ms on localhost (1/2)
15/10/21 17:00:29 INFO TaskSetManager: Finished task 0.0 in stage 163.0 (TID 325) in 46 ms on localhost (2/2)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Removed TaskSet 163.0, whose tasks have all completed, from pool 
15/10/21 17:00:29 INFO DAGScheduler: ResultStage 163 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:29 INFO DAGScheduler: Job 162 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053474 s
15/10/21 17:00:29 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:29 INFO DAGScheduler: Got job 163 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:29 INFO DAGScheduler: Final stage: ResultStage 164(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:29 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:29 INFO DAGScheduler: Submitting ResultStage 164 (PythonRDD[170] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=391944, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=398952, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Removed broadcast_164_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:29 INFO SparkContext: Created broadcast 165 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 164 (PythonRDD[170] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Adding task set 164.0 with 2 tasks
15/10/21 17:00:29 INFO TaskSetManager: Starting task 0.0 in stage 164.0 (TID 327, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO BlockManagerInfo: Removed broadcast_163_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:29 INFO TaskSetManager: Starting task 1.0 in stage 164.0 (TID 328, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO Executor: Running task 1.0 in stage 164.0 (TID 328)
15/10/21 17:00:29 INFO Executor: Running task 0.0 in stage 164.0 (TID 327)
15/10/21 17:00:29 INFO BlockManagerInfo: Removed broadcast_162_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:29 INFO BlockManagerInfo: Removed broadcast_161_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Removed broadcast_160_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Removed broadcast_159_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Removed broadcast_158_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Removed broadcast_157_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Removed broadcast_153_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Removed broadcast_152_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Removed broadcast_151_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Removed broadcast_150_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Removed broadcast_149_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Removed broadcast_148_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Removed broadcast_147_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Removed broadcast_146_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Removed broadcast_156_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Removed broadcast_155_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Removed broadcast_154_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:29 INFO PythonRDD: Times: total = 40, boot = -80, init = 120, finish = 0
15/10/21 17:00:29 INFO PythonRDD: Times: total = 40, boot = -79, init = 119, finish = 0
15/10/21 17:00:29 INFO Executor: Finished task 0.0 in stage 164.0 (TID 327). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO Executor: Finished task 1.0 in stage 164.0 (TID 328). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO TaskSetManager: Finished task 0.0 in stage 164.0 (TID 327) in 45 ms on localhost (1/2)
15/10/21 17:00:29 INFO TaskSetManager: Finished task 1.0 in stage 164.0 (TID 328) in 44 ms on localhost (2/2)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Removed TaskSet 164.0, whose tasks have all completed, from pool 
15/10/21 17:00:29 INFO DAGScheduler: ResultStage 164 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:29 INFO DAGScheduler: Job 163 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.057373 s
15/10/21 17:00:29 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:29 INFO DAGScheduler: Got job 164 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:29 INFO DAGScheduler: Final stage: ResultStage 165(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:29 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:29 INFO DAGScheduler: Submitting ResultStage 165 (PythonRDD[171] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=194610, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_166 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=201618, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:29 INFO SparkContext: Created broadcast 166 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 165 (PythonRDD[171] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Adding task set 165.0 with 2 tasks
15/10/21 17:00:29 INFO TaskSetManager: Starting task 0.0 in stage 165.0 (TID 329, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO TaskSetManager: Starting task 1.0 in stage 165.0 (TID 330, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO Executor: Running task 0.0 in stage 165.0 (TID 329)
15/10/21 17:00:29 INFO Executor: Running task 1.0 in stage 165.0 (TID 330)
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:29 INFO PythonRDD: Times: total = 37, boot = -82, init = 119, finish = 0
15/10/21 17:00:29 INFO Executor: Finished task 1.0 in stage 165.0 (TID 330). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO TaskSetManager: Finished task 1.0 in stage 165.0 (TID 330) in 40 ms on localhost (1/2)
15/10/21 17:00:29 INFO PythonRDD: Times: total = 45, boot = -78, init = 123, finish = 0
15/10/21 17:00:29 INFO Executor: Finished task 0.0 in stage 165.0 (TID 329). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO TaskSetManager: Finished task 0.0 in stage 165.0 (TID 329) in 49 ms on localhost (2/2)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Removed TaskSet 165.0, whose tasks have all completed, from pool 
15/10/21 17:00:29 INFO DAGScheduler: ResultStage 165 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.050 s
15/10/21 17:00:29 INFO DAGScheduler: Job 164 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.057688 s
15/10/21 17:00:29 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:29 INFO DAGScheduler: Got job 165 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:29 INFO DAGScheduler: Final stage: ResultStage 166(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:29 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:29 INFO DAGScheduler: Submitting ResultStage 166 (PythonRDD[172] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=205573, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_167 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=212581, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:29 INFO SparkContext: Created broadcast 167 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 166 (PythonRDD[172] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Adding task set 166.0 with 2 tasks
15/10/21 17:00:29 INFO TaskSetManager: Starting task 0.0 in stage 166.0 (TID 331, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO TaskSetManager: Starting task 1.0 in stage 166.0 (TID 332, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO Executor: Running task 1.0 in stage 166.0 (TID 332)
15/10/21 17:00:29 INFO Executor: Running task 0.0 in stage 166.0 (TID 331)
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:29 INFO PythonRDD: Times: total = 41, boot = -79, init = 120, finish = 0
15/10/21 17:00:29 INFO PythonRDD: Times: total = 41, boot = -79, init = 120, finish = 0
15/10/21 17:00:29 INFO Executor: Finished task 0.0 in stage 166.0 (TID 331). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO Executor: Finished task 1.0 in stage 166.0 (TID 332). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO TaskSetManager: Finished task 0.0 in stage 166.0 (TID 331) in 45 ms on localhost (1/2)
15/10/21 17:00:29 INFO TaskSetManager: Finished task 1.0 in stage 166.0 (TID 332) in 45 ms on localhost (2/2)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Removed TaskSet 166.0, whose tasks have all completed, from pool 
15/10/21 17:00:29 INFO DAGScheduler: ResultStage 166 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:29 INFO DAGScheduler: Job 165 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.054119 s
15/10/21 17:00:29 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:29 INFO DAGScheduler: Got job 166 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:29 INFO DAGScheduler: Final stage: ResultStage 167(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:29 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:29 INFO DAGScheduler: Submitting ResultStage 167 (PythonRDD[173] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=216536, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_168 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=223544, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:29 INFO SparkContext: Created broadcast 168 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 167 (PythonRDD[173] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Adding task set 167.0 with 2 tasks
15/10/21 17:00:29 INFO TaskSetManager: Starting task 0.0 in stage 167.0 (TID 333, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO TaskSetManager: Starting task 1.0 in stage 167.0 (TID 334, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO Executor: Running task 1.0 in stage 167.0 (TID 334)
15/10/21 17:00:29 INFO Executor: Running task 0.0 in stage 167.0 (TID 333)
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:29 INFO PythonRDD: Times: total = 41, boot = -76, init = 117, finish = 0
15/10/21 17:00:29 INFO Executor: Finished task 0.0 in stage 167.0 (TID 333). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO TaskSetManager: Finished task 0.0 in stage 167.0 (TID 333) in 44 ms on localhost (1/2)
15/10/21 17:00:29 INFO PythonRDD: Times: total = 45, boot = -85, init = 130, finish = 0
15/10/21 17:00:29 INFO Executor: Finished task 1.0 in stage 167.0 (TID 334). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO TaskSetManager: Finished task 1.0 in stage 167.0 (TID 334) in 48 ms on localhost (2/2)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Removed TaskSet 167.0, whose tasks have all completed, from pool 
15/10/21 17:00:29 INFO DAGScheduler: ResultStage 167 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.049 s
15/10/21 17:00:29 INFO DAGScheduler: Job 166 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.056782 s
15/10/21 17:00:29 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:29 INFO DAGScheduler: Got job 167 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:29 INFO DAGScheduler: Final stage: ResultStage 168(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:29 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:29 INFO DAGScheduler: Submitting ResultStage 168 (PythonRDD[174] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=227499, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_169 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=234507, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:29 INFO SparkContext: Created broadcast 169 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 168 (PythonRDD[174] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Adding task set 168.0 with 2 tasks
15/10/21 17:00:29 INFO TaskSetManager: Starting task 0.0 in stage 168.0 (TID 335, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO TaskSetManager: Starting task 1.0 in stage 168.0 (TID 336, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO Executor: Running task 0.0 in stage 168.0 (TID 335)
15/10/21 17:00:29 INFO Executor: Running task 1.0 in stage 168.0 (TID 336)
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:29 INFO PythonRDD: Times: total = 37, boot = -79, init = 116, finish = 0
15/10/21 17:00:29 INFO PythonRDD: Times: total = 38, boot = -79, init = 117, finish = 0
15/10/21 17:00:29 INFO Executor: Finished task 1.0 in stage 168.0 (TID 336). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO Executor: Finished task 0.0 in stage 168.0 (TID 335). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO TaskSetManager: Finished task 1.0 in stage 168.0 (TID 336) in 41 ms on localhost (1/2)
15/10/21 17:00:29 INFO TaskSetManager: Finished task 0.0 in stage 168.0 (TID 335) in 42 ms on localhost (2/2)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Removed TaskSet 168.0, whose tasks have all completed, from pool 
15/10/21 17:00:29 INFO DAGScheduler: ResultStage 168 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.042 s
15/10/21 17:00:29 INFO DAGScheduler: Job 167 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.050613 s
15/10/21 17:00:29 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:29 INFO DAGScheduler: Got job 168 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:29 INFO DAGScheduler: Final stage: ResultStage 169(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:29 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:29 INFO DAGScheduler: Submitting ResultStage 169 (PythonRDD[175] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=238462, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_170 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=245470, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:29 INFO SparkContext: Created broadcast 170 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 169 (PythonRDD[175] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Adding task set 169.0 with 2 tasks
15/10/21 17:00:29 INFO TaskSetManager: Starting task 0.0 in stage 169.0 (TID 337, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO TaskSetManager: Starting task 1.0 in stage 169.0 (TID 338, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO Executor: Running task 0.0 in stage 169.0 (TID 337)
15/10/21 17:00:29 INFO Executor: Running task 1.0 in stage 169.0 (TID 338)
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:29 INFO PythonRDD: Times: total = 41, boot = -75, init = 116, finish = 0
15/10/21 17:00:29 INFO PythonRDD: Times: total = 40, boot = -74, init = 114, finish = 0
15/10/21 17:00:29 INFO Executor: Finished task 0.0 in stage 169.0 (TID 337). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO Executor: Finished task 1.0 in stage 169.0 (TID 338). 1870 bytes result sent to driver
15/10/21 17:00:29 INFO TaskSetManager: Finished task 0.0 in stage 169.0 (TID 337) in 44 ms on localhost (1/2)
15/10/21 17:00:29 INFO TaskSetManager: Finished task 1.0 in stage 169.0 (TID 338) in 45 ms on localhost (2/2)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Removed TaskSet 169.0, whose tasks have all completed, from pool 
15/10/21 17:00:29 INFO DAGScheduler: ResultStage 169 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:29 INFO DAGScheduler: Job 168 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053380 s
15/10/21 17:00:29 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:29 INFO DAGScheduler: Got job 169 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:29 INFO DAGScheduler: Final stage: ResultStage 170(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:29 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:29 INFO DAGScheduler: Submitting ResultStage 170 (PythonRDD[176] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=249425, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_171 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:29 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=256433, maxMem=278302556
15/10/21 17:00:29 INFO MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:29 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:29 INFO SparkContext: Created broadcast 171 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 170 (PythonRDD[176] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:29 INFO TaskSchedulerImpl: Adding task set 170.0 with 2 tasks
15/10/21 17:00:29 INFO TaskSetManager: Starting task 0.0 in stage 170.0 (TID 339, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO TaskSetManager: Starting task 1.0 in stage 170.0 (TID 340, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:29 INFO Executor: Running task 0.0 in stage 170.0 (TID 339)
15/10/21 17:00:29 INFO Executor: Running task 1.0 in stage 170.0 (TID 340)
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:29 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:30 INFO PythonRDD: Times: total = 40, boot = -78, init = 118, finish = 0
15/10/21 17:00:30 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:00:30 INFO Executor: Finished task 1.0 in stage 170.0 (TID 340). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO Executor: Finished task 0.0 in stage 170.0 (TID 339). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO TaskSetManager: Finished task 1.0 in stage 170.0 (TID 340) in 44 ms on localhost (1/2)
15/10/21 17:00:30 INFO TaskSetManager: Finished task 0.0 in stage 170.0 (TID 339) in 45 ms on localhost (2/2)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Removed TaskSet 170.0, whose tasks have all completed, from pool 
15/10/21 17:00:30 INFO DAGScheduler: ResultStage 170 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:30 INFO DAGScheduler: Job 169 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053268 s
15/10/21 17:00:30 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:30 INFO DAGScheduler: Got job 170 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:30 INFO DAGScheduler: Final stage: ResultStage 171(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:30 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:30 INFO DAGScheduler: Submitting ResultStage 171 (PythonRDD[177] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=260388, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_172 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=267396, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:30 INFO SparkContext: Created broadcast 172 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 171 (PythonRDD[177] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Adding task set 171.0 with 2 tasks
15/10/21 17:00:30 INFO TaskSetManager: Starting task 0.0 in stage 171.0 (TID 341, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO TaskSetManager: Starting task 1.0 in stage 171.0 (TID 342, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO Executor: Running task 0.0 in stage 171.0 (TID 341)
15/10/21 17:00:30 INFO Executor: Running task 1.0 in stage 171.0 (TID 342)
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:30 INFO PythonRDD: Times: total = 41, boot = -75, init = 116, finish = 0
15/10/21 17:00:30 INFO PythonRDD: Times: total = 40, boot = -75, init = 115, finish = 0
15/10/21 17:00:30 INFO Executor: Finished task 0.0 in stage 171.0 (TID 341). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO Executor: Finished task 1.0 in stage 171.0 (TID 342). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO TaskSetManager: Finished task 0.0 in stage 171.0 (TID 341) in 45 ms on localhost (1/2)
15/10/21 17:00:30 INFO TaskSetManager: Finished task 1.0 in stage 171.0 (TID 342) in 45 ms on localhost (2/2)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Removed TaskSet 171.0, whose tasks have all completed, from pool 
15/10/21 17:00:30 INFO DAGScheduler: ResultStage 171 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:30 INFO DAGScheduler: Job 170 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053421 s
15/10/21 17:00:30 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:30 INFO DAGScheduler: Got job 171 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:30 INFO DAGScheduler: Final stage: ResultStage 172(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:30 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:30 INFO DAGScheduler: Submitting ResultStage 172 (PythonRDD[178] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=271351, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_173 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=278359, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:30 INFO SparkContext: Created broadcast 173 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 172 (PythonRDD[178] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Adding task set 172.0 with 2 tasks
15/10/21 17:00:30 INFO TaskSetManager: Starting task 0.0 in stage 172.0 (TID 343, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO TaskSetManager: Starting task 1.0 in stage 172.0 (TID 344, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO Executor: Running task 0.0 in stage 172.0 (TID 343)
15/10/21 17:00:30 INFO Executor: Running task 1.0 in stage 172.0 (TID 344)
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:30 INFO PythonRDD: Times: total = 37, boot = -77, init = 114, finish = 0
15/10/21 17:00:30 INFO Executor: Finished task 0.0 in stage 172.0 (TID 343). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO TaskSetManager: Finished task 0.0 in stage 172.0 (TID 343) in 41 ms on localhost (1/2)
15/10/21 17:00:30 INFO PythonRDD: Times: total = 41, boot = -76, init = 117, finish = 0
15/10/21 17:00:30 INFO Executor: Finished task 1.0 in stage 172.0 (TID 344). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO TaskSetManager: Finished task 1.0 in stage 172.0 (TID 344) in 44 ms on localhost (2/2)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Removed TaskSet 172.0, whose tasks have all completed, from pool 
15/10/21 17:00:30 INFO DAGScheduler: ResultStage 172 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:30 INFO DAGScheduler: Job 171 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053062 s
15/10/21 17:00:30 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:30 INFO DAGScheduler: Got job 172 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:30 INFO DAGScheduler: Final stage: ResultStage 173(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:30 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:30 INFO DAGScheduler: Submitting ResultStage 173 (PythonRDD[179] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=282314, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_174 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=289322, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:30 INFO SparkContext: Created broadcast 174 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 173 (PythonRDD[179] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Adding task set 173.0 with 2 tasks
15/10/21 17:00:30 INFO TaskSetManager: Starting task 0.0 in stage 173.0 (TID 345, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO TaskSetManager: Starting task 1.0 in stage 173.0 (TID 346, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO Executor: Running task 0.0 in stage 173.0 (TID 345)
15/10/21 17:00:30 INFO Executor: Running task 1.0 in stage 173.0 (TID 346)
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:30 INFO PythonRDD: Times: total = 37, boot = -76, init = 113, finish = 0
15/10/21 17:00:30 INFO PythonRDD: Times: total = 37, boot = -75, init = 112, finish = 0
15/10/21 17:00:30 INFO Executor: Finished task 1.0 in stage 173.0 (TID 346). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO Executor: Finished task 0.0 in stage 173.0 (TID 345). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO TaskSetManager: Finished task 1.0 in stage 173.0 (TID 346) in 41 ms on localhost (1/2)
15/10/21 17:00:30 INFO TaskSetManager: Finished task 0.0 in stage 173.0 (TID 345) in 42 ms on localhost (2/2)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Removed TaskSet 173.0, whose tasks have all completed, from pool 
15/10/21 17:00:30 INFO DAGScheduler: ResultStage 173 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:30 INFO DAGScheduler: Job 172 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.050545 s
15/10/21 17:00:30 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:30 INFO DAGScheduler: Got job 173 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:30 INFO DAGScheduler: Final stage: ResultStage 174(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:30 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:30 INFO DAGScheduler: Submitting ResultStage 174 (PythonRDD[180] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=293277, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_175 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=300285, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:30 INFO SparkContext: Created broadcast 175 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 174 (PythonRDD[180] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Adding task set 174.0 with 2 tasks
15/10/21 17:00:30 INFO TaskSetManager: Starting task 0.0 in stage 174.0 (TID 347, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO TaskSetManager: Starting task 1.0 in stage 174.0 (TID 348, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO Executor: Running task 0.0 in stage 174.0 (TID 347)
15/10/21 17:00:30 INFO Executor: Running task 1.0 in stage 174.0 (TID 348)
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:30 INFO PythonRDD: Times: total = 41, boot = -77, init = 118, finish = 0
15/10/21 17:00:30 INFO PythonRDD: Times: total = 41, boot = -69, init = 110, finish = 0
15/10/21 17:00:30 INFO Executor: Finished task 0.0 in stage 174.0 (TID 347). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO Executor: Finished task 1.0 in stage 174.0 (TID 348). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO TaskSetManager: Finished task 0.0 in stage 174.0 (TID 347) in 45 ms on localhost (1/2)
15/10/21 17:00:30 INFO TaskSetManager: Finished task 1.0 in stage 174.0 (TID 348) in 45 ms on localhost (2/2)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Removed TaskSet 174.0, whose tasks have all completed, from pool 
15/10/21 17:00:30 INFO DAGScheduler: ResultStage 174 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:00:30 INFO DAGScheduler: Job 173 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.054229 s
15/10/21 17:00:30 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:30 INFO DAGScheduler: Got job 174 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:30 INFO DAGScheduler: Final stage: ResultStage 175(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:30 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:30 INFO DAGScheduler: Submitting ResultStage 175 (PythonRDD[181] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=304240, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_176 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=311248, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:30 INFO SparkContext: Created broadcast 176 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 175 (PythonRDD[181] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Adding task set 175.0 with 2 tasks
15/10/21 17:00:30 INFO TaskSetManager: Starting task 0.0 in stage 175.0 (TID 349, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO TaskSetManager: Starting task 1.0 in stage 175.0 (TID 350, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO Executor: Running task 0.0 in stage 175.0 (TID 349)
15/10/21 17:00:30 INFO Executor: Running task 1.0 in stage 175.0 (TID 350)
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:30 INFO PythonRDD: Times: total = 37, boot = -78, init = 115, finish = 0
15/10/21 17:00:30 INFO Executor: Finished task 0.0 in stage 175.0 (TID 349). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO TaskSetManager: Finished task 0.0 in stage 175.0 (TID 349) in 41 ms on localhost (1/2)
15/10/21 17:00:30 INFO PythonRDD: Times: total = 41, boot = -79, init = 120, finish = 0
15/10/21 17:00:30 INFO Executor: Finished task 1.0 in stage 175.0 (TID 350). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO TaskSetManager: Finished task 1.0 in stage 175.0 (TID 350) in 44 ms on localhost (2/2)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Removed TaskSet 175.0, whose tasks have all completed, from pool 
15/10/21 17:00:30 INFO DAGScheduler: ResultStage 175 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:30 INFO DAGScheduler: Job 174 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053722 s
15/10/21 17:00:30 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:30 INFO DAGScheduler: Got job 175 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:30 INFO DAGScheduler: Final stage: ResultStage 176(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:30 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:30 INFO DAGScheduler: Submitting ResultStage 176 (PythonRDD[182] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=315203, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_177 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=322211, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:30 INFO SparkContext: Created broadcast 177 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 176 (PythonRDD[182] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Adding task set 176.0 with 2 tasks
15/10/21 17:00:30 INFO TaskSetManager: Starting task 0.0 in stage 176.0 (TID 351, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO TaskSetManager: Starting task 1.0 in stage 176.0 (TID 352, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO Executor: Running task 1.0 in stage 176.0 (TID 352)
15/10/21 17:00:30 INFO Executor: Running task 0.0 in stage 176.0 (TID 351)
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:30 INFO PythonRDD: Times: total = 38, boot = -77, init = 115, finish = 0
15/10/21 17:00:30 INFO Executor: Finished task 1.0 in stage 176.0 (TID 352). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO TaskSetManager: Finished task 1.0 in stage 176.0 (TID 352) in 41 ms on localhost (1/2)
15/10/21 17:00:30 INFO PythonRDD: Times: total = 41, boot = -77, init = 118, finish = 0
15/10/21 17:00:30 INFO Executor: Finished task 0.0 in stage 176.0 (TID 351). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO TaskSetManager: Finished task 0.0 in stage 176.0 (TID 351) in 45 ms on localhost (2/2)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Removed TaskSet 176.0, whose tasks have all completed, from pool 
15/10/21 17:00:30 INFO DAGScheduler: ResultStage 176 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:30 INFO DAGScheduler: Job 175 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053431 s
15/10/21 17:00:30 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:30 INFO DAGScheduler: Got job 176 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:30 INFO DAGScheduler: Final stage: ResultStage 177(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:30 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:30 INFO DAGScheduler: Submitting ResultStage 177 (PythonRDD[183] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=326166, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_178 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=333174, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:30 INFO SparkContext: Created broadcast 178 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 177 (PythonRDD[183] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Adding task set 177.0 with 2 tasks
15/10/21 17:00:30 INFO TaskSetManager: Starting task 0.0 in stage 177.0 (TID 353, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO TaskSetManager: Starting task 1.0 in stage 177.0 (TID 354, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO Executor: Running task 0.0 in stage 177.0 (TID 353)
15/10/21 17:00:30 INFO Executor: Running task 1.0 in stage 177.0 (TID 354)
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:30 INFO PythonRDD: Times: total = 38, boot = -74, init = 112, finish = 0
15/10/21 17:00:30 INFO PythonRDD: Times: total = 38, boot = -80, init = 118, finish = 0
15/10/21 17:00:30 INFO Executor: Finished task 0.0 in stage 177.0 (TID 353). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO Executor: Finished task 1.0 in stage 177.0 (TID 354). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO TaskSetManager: Finished task 0.0 in stage 177.0 (TID 353) in 42 ms on localhost (1/2)
15/10/21 17:00:30 INFO TaskSetManager: Finished task 1.0 in stage 177.0 (TID 354) in 42 ms on localhost (2/2)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Removed TaskSet 177.0, whose tasks have all completed, from pool 
15/10/21 17:00:30 INFO DAGScheduler: ResultStage 177 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:30 INFO DAGScheduler: Job 176 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.050342 s
15/10/21 17:00:30 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:30 INFO DAGScheduler: Got job 177 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:30 INFO DAGScheduler: Final stage: ResultStage 178(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:30 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:30 INFO DAGScheduler: Submitting ResultStage 178 (PythonRDD[184] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=337129, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_179 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=344137, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_179_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Added broadcast_179_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:30 INFO SparkContext: Created broadcast 179 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 178 (PythonRDD[184] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Adding task set 178.0 with 2 tasks
15/10/21 17:00:30 INFO TaskSetManager: Starting task 0.0 in stage 178.0 (TID 355, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO TaskSetManager: Starting task 1.0 in stage 178.0 (TID 356, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO Executor: Running task 1.0 in stage 178.0 (TID 356)
15/10/21 17:00:30 INFO Executor: Running task 0.0 in stage 178.0 (TID 355)
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:30 INFO PythonRDD: Times: total = 37, boot = -71, init = 108, finish = 0
15/10/21 17:00:30 INFO PythonRDD: Times: total = 38, boot = -75, init = 113, finish = 0
15/10/21 17:00:30 INFO Executor: Finished task 0.0 in stage 178.0 (TID 355). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO Executor: Finished task 1.0 in stage 178.0 (TID 356). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO TaskSetManager: Finished task 0.0 in stage 178.0 (TID 355) in 42 ms on localhost (1/2)
15/10/21 17:00:30 INFO TaskSetManager: Finished task 1.0 in stage 178.0 (TID 356) in 42 ms on localhost (2/2)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Removed TaskSet 178.0, whose tasks have all completed, from pool 
15/10/21 17:00:30 INFO DAGScheduler: ResultStage 178 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.042 s
15/10/21 17:00:30 INFO DAGScheduler: Job 177 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.049994 s
15/10/21 17:00:30 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:30 INFO DAGScheduler: Got job 178 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:30 INFO DAGScheduler: Final stage: ResultStage 179(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:30 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:30 INFO DAGScheduler: Submitting ResultStage 179 (PythonRDD[185] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=348092, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_180 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=355100, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_180_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Added broadcast_180_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:30 INFO SparkContext: Created broadcast 180 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 179 (PythonRDD[185] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Adding task set 179.0 with 2 tasks
15/10/21 17:00:30 INFO TaskSetManager: Starting task 0.0 in stage 179.0 (TID 357, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO TaskSetManager: Starting task 1.0 in stage 179.0 (TID 358, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO Executor: Running task 0.0 in stage 179.0 (TID 357)
15/10/21 17:00:30 INFO Executor: Running task 1.0 in stage 179.0 (TID 358)
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:30 INFO PythonRDD: Times: total = 37, boot = -73, init = 110, finish = 0
15/10/21 17:00:30 INFO Executor: Finished task 0.0 in stage 179.0 (TID 357). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO TaskSetManager: Finished task 0.0 in stage 179.0 (TID 357) in 41 ms on localhost (1/2)
15/10/21 17:00:30 INFO PythonRDD: Times: total = 41, boot = -70, init = 111, finish = 0
15/10/21 17:00:30 INFO Executor: Finished task 1.0 in stage 179.0 (TID 358). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO TaskSetManager: Finished task 1.0 in stage 179.0 (TID 358) in 44 ms on localhost (2/2)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Removed TaskSet 179.0, whose tasks have all completed, from pool 
15/10/21 17:00:30 INFO DAGScheduler: ResultStage 179 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:30 INFO DAGScheduler: Job 178 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053451 s
15/10/21 17:00:30 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:30 INFO DAGScheduler: Got job 179 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:30 INFO DAGScheduler: Final stage: ResultStage 180(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:30 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:30 INFO DAGScheduler: Submitting ResultStage 180 (PythonRDD[186] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=359055, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_181 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=366063, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_181_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Added broadcast_181_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:30 INFO SparkContext: Created broadcast 181 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 180 (PythonRDD[186] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Adding task set 180.0 with 2 tasks
15/10/21 17:00:30 INFO TaskSetManager: Starting task 0.0 in stage 180.0 (TID 359, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO TaskSetManager: Starting task 1.0 in stage 180.0 (TID 360, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO Executor: Running task 0.0 in stage 180.0 (TID 359)
15/10/21 17:00:30 INFO Executor: Running task 1.0 in stage 180.0 (TID 360)
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:30 INFO PythonRDD: Times: total = 41, boot = -77, init = 118, finish = 0
15/10/21 17:00:30 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:00:30 INFO Executor: Finished task 1.0 in stage 180.0 (TID 360). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO Executor: Finished task 0.0 in stage 180.0 (TID 359). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO TaskSetManager: Finished task 1.0 in stage 180.0 (TID 360) in 44 ms on localhost (1/2)
15/10/21 17:00:30 INFO TaskSetManager: Finished task 0.0 in stage 180.0 (TID 359) in 45 ms on localhost (2/2)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Removed TaskSet 180.0, whose tasks have all completed, from pool 
15/10/21 17:00:30 INFO DAGScheduler: ResultStage 180 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:30 INFO DAGScheduler: Job 179 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053708 s
15/10/21 17:00:30 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:30 INFO DAGScheduler: Got job 180 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:30 INFO DAGScheduler: Final stage: ResultStage 181(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:30 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:30 INFO DAGScheduler: Submitting ResultStage 181 (PythonRDD[187] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=370018, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_182 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=377026, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_182_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Added broadcast_182_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:30 INFO SparkContext: Created broadcast 182 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 181 (PythonRDD[187] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Adding task set 181.0 with 2 tasks
15/10/21 17:00:30 INFO TaskSetManager: Starting task 0.0 in stage 181.0 (TID 361, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO TaskSetManager: Starting task 1.0 in stage 181.0 (TID 362, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO Executor: Running task 1.0 in stage 181.0 (TID 362)
15/10/21 17:00:30 INFO Executor: Running task 0.0 in stage 181.0 (TID 361)
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:30 INFO PythonRDD: Times: total = 41, boot = -77, init = 118, finish = 0
15/10/21 17:00:30 INFO PythonRDD: Times: total = 41, boot = -79, init = 120, finish = 0
15/10/21 17:00:30 INFO Executor: Finished task 1.0 in stage 181.0 (TID 362). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO Executor: Finished task 0.0 in stage 181.0 (TID 361). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO TaskSetManager: Finished task 1.0 in stage 181.0 (TID 362) in 45 ms on localhost (1/2)
15/10/21 17:00:30 INFO TaskSetManager: Finished task 0.0 in stage 181.0 (TID 361) in 45 ms on localhost (2/2)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Removed TaskSet 181.0, whose tasks have all completed, from pool 
15/10/21 17:00:30 INFO DAGScheduler: ResultStage 181 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:30 INFO DAGScheduler: Job 180 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053628 s
15/10/21 17:00:30 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:30 INFO DAGScheduler: Got job 181 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:30 INFO DAGScheduler: Final stage: ResultStage 182(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:30 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:30 INFO DAGScheduler: Submitting ResultStage 182 (PythonRDD[188] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=380981, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_183 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=387989, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_183_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Added broadcast_183_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:30 INFO SparkContext: Created broadcast 183 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 182 (PythonRDD[188] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Adding task set 182.0 with 2 tasks
15/10/21 17:00:30 INFO TaskSetManager: Starting task 0.0 in stage 182.0 (TID 363, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO TaskSetManager: Starting task 1.0 in stage 182.0 (TID 364, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO Executor: Running task 0.0 in stage 182.0 (TID 363)
15/10/21 17:00:30 INFO Executor: Running task 1.0 in stage 182.0 (TID 364)
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:30 INFO PythonRDD: Times: total = 40, boot = -77, init = 117, finish = 0
15/10/21 17:00:30 INFO PythonRDD: Times: total = 41, boot = -77, init = 118, finish = 0
15/10/21 17:00:30 INFO Executor: Finished task 1.0 in stage 182.0 (TID 364). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO Executor: Finished task 0.0 in stage 182.0 (TID 363). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO TaskSetManager: Finished task 1.0 in stage 182.0 (TID 364) in 44 ms on localhost (1/2)
15/10/21 17:00:30 INFO TaskSetManager: Finished task 0.0 in stage 182.0 (TID 363) in 45 ms on localhost (2/2)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Removed TaskSet 182.0, whose tasks have all completed, from pool 
15/10/21 17:00:30 INFO DAGScheduler: ResultStage 182 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:30 INFO DAGScheduler: Job 181 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053653 s
15/10/21 17:00:30 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:30 INFO DAGScheduler: Got job 182 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:30 INFO DAGScheduler: Final stage: ResultStage 183(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:30 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:30 INFO DAGScheduler: Submitting ResultStage 183 (PythonRDD[189] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=391944, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_184 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=398952, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_184_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Added broadcast_184_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:30 INFO SparkContext: Created broadcast 184 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:30 INFO BlockManagerInfo: Removed broadcast_172_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 183 (PythonRDD[189] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Adding task set 183.0 with 2 tasks
15/10/21 17:00:30 INFO TaskSetManager: Starting task 0.0 in stage 183.0 (TID 365, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO TaskSetManager: Starting task 1.0 in stage 183.0 (TID 366, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO BlockManagerInfo: Removed broadcast_171_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:30 INFO Executor: Running task 0.0 in stage 183.0 (TID 365)
15/10/21 17:00:30 INFO Executor: Running task 1.0 in stage 183.0 (TID 366)
15/10/21 17:00:30 INFO BlockManagerInfo: Removed broadcast_170_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:30 INFO BlockManagerInfo: Removed broadcast_169_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Removed broadcast_168_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Removed broadcast_167_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Removed broadcast_166_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Removed broadcast_165_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Removed broadcast_175_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Removed broadcast_174_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Removed broadcast_173_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Removed broadcast_183_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Removed broadcast_182_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Removed broadcast_181_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Removed broadcast_180_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Removed broadcast_179_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Removed broadcast_178_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Removed broadcast_177_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Removed broadcast_176_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:30 INFO PythonRDD: Times: total = 41, boot = -78, init = 119, finish = 0
15/10/21 17:00:30 INFO Executor: Finished task 0.0 in stage 183.0 (TID 365). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO TaskSetManager: Finished task 0.0 in stage 183.0 (TID 365) in 44 ms on localhost (1/2)
15/10/21 17:00:30 INFO PythonRDD: Times: total = 45, boot = -80, init = 125, finish = 0
15/10/21 17:00:30 INFO Executor: Finished task 1.0 in stage 183.0 (TID 366). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO TaskSetManager: Finished task 1.0 in stage 183.0 (TID 366) in 48 ms on localhost (2/2)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Removed TaskSet 183.0, whose tasks have all completed, from pool 
15/10/21 17:00:30 INFO DAGScheduler: ResultStage 183 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.050 s
15/10/21 17:00:30 INFO DAGScheduler: Job 182 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.061315 s
15/10/21 17:00:30 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:30 INFO DAGScheduler: Got job 183 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:30 INFO DAGScheduler: Final stage: ResultStage 184(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:30 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:30 INFO DAGScheduler: Submitting ResultStage 184 (PythonRDD[190] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=194610, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_185 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=201618, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_185_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Added broadcast_185_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:30 INFO SparkContext: Created broadcast 185 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 184 (PythonRDD[190] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Adding task set 184.0 with 2 tasks
15/10/21 17:00:30 INFO TaskSetManager: Starting task 0.0 in stage 184.0 (TID 367, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO TaskSetManager: Starting task 1.0 in stage 184.0 (TID 368, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO Executor: Running task 0.0 in stage 184.0 (TID 367)
15/10/21 17:00:30 INFO Executor: Running task 1.0 in stage 184.0 (TID 368)
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:30 INFO PythonRDD: Times: total = 41, boot = -83, init = 124, finish = 0
15/10/21 17:00:30 INFO Executor: Finished task 0.0 in stage 184.0 (TID 367). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO TaskSetManager: Finished task 0.0 in stage 184.0 (TID 367) in 45 ms on localhost (1/2)
15/10/21 17:00:30 INFO PythonRDD: Times: total = 45, boot = -84, init = 129, finish = 0
15/10/21 17:00:30 INFO Executor: Finished task 1.0 in stage 184.0 (TID 368). 1870 bytes result sent to driver
15/10/21 17:00:30 INFO TaskSetManager: Finished task 1.0 in stage 184.0 (TID 368) in 48 ms on localhost (2/2)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Removed TaskSet 184.0, whose tasks have all completed, from pool 
15/10/21 17:00:30 INFO DAGScheduler: ResultStage 184 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.050 s
15/10/21 17:00:30 INFO DAGScheduler: Job 183 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.057020 s
15/10/21 17:00:30 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:30 INFO DAGScheduler: Got job 184 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:30 INFO DAGScheduler: Final stage: ResultStage 185(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:30 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:30 INFO DAGScheduler: Submitting ResultStage 185 (PythonRDD[191] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=205573, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_186 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:30 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=212581, maxMem=278302556
15/10/21 17:00:30 INFO MemoryStore: Block broadcast_186_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:30 INFO BlockManagerInfo: Added broadcast_186_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:30 INFO SparkContext: Created broadcast 186 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:30 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 185 (PythonRDD[191] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:30 INFO TaskSchedulerImpl: Adding task set 185.0 with 2 tasks
15/10/21 17:00:30 INFO TaskSetManager: Starting task 0.0 in stage 185.0 (TID 369, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO TaskSetManager: Starting task 1.0 in stage 185.0 (TID 370, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:30 INFO Executor: Running task 0.0 in stage 185.0 (TID 369)
15/10/21 17:00:30 INFO Executor: Running task 1.0 in stage 185.0 (TID 370)
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:30 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:31 INFO PythonRDD: Times: total = 38, boot = -78, init = 116, finish = 0
15/10/21 17:00:31 INFO Executor: Finished task 0.0 in stage 185.0 (TID 369). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO TaskSetManager: Finished task 0.0 in stage 185.0 (TID 369) in 42 ms on localhost (1/2)
15/10/21 17:00:31 INFO PythonRDD: Times: total = 43, boot = -82, init = 125, finish = 0
15/10/21 17:00:31 INFO Executor: Finished task 1.0 in stage 185.0 (TID 370). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO TaskSetManager: Finished task 1.0 in stage 185.0 (TID 370) in 46 ms on localhost (2/2)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Removed TaskSet 185.0, whose tasks have all completed, from pool 
15/10/21 17:00:31 INFO DAGScheduler: ResultStage 185 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:00:31 INFO DAGScheduler: Job 184 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.054068 s
15/10/21 17:00:31 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:31 INFO DAGScheduler: Got job 185 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:31 INFO DAGScheduler: Final stage: ResultStage 186(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:31 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:31 INFO DAGScheduler: Submitting ResultStage 186 (PythonRDD[192] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=216536, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_187 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=223544, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_187_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:31 INFO BlockManagerInfo: Added broadcast_187_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:31 INFO SparkContext: Created broadcast 187 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 186 (PythonRDD[192] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Adding task set 186.0 with 2 tasks
15/10/21 17:00:31 INFO TaskSetManager: Starting task 0.0 in stage 186.0 (TID 371, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO TaskSetManager: Starting task 1.0 in stage 186.0 (TID 372, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO Executor: Running task 0.0 in stage 186.0 (TID 371)
15/10/21 17:00:31 INFO Executor: Running task 1.0 in stage 186.0 (TID 372)
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:31 INFO PythonRDD: Times: total = 38, boot = -74, init = 112, finish = 0
15/10/21 17:00:31 INFO Executor: Finished task 0.0 in stage 186.0 (TID 371). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO TaskSetManager: Finished task 0.0 in stage 186.0 (TID 371) in 42 ms on localhost (1/2)
15/10/21 17:00:31 INFO PythonRDD: Times: total = 42, boot = -79, init = 121, finish = 0
15/10/21 17:00:31 INFO Executor: Finished task 1.0 in stage 186.0 (TID 372). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO TaskSetManager: Finished task 1.0 in stage 186.0 (TID 372) in 45 ms on localhost (2/2)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Removed TaskSet 186.0, whose tasks have all completed, from pool 
15/10/21 17:00:31 INFO DAGScheduler: ResultStage 186 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:00:31 INFO DAGScheduler: Job 185 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.054121 s
15/10/21 17:00:31 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:31 INFO DAGScheduler: Got job 186 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:31 INFO DAGScheduler: Final stage: ResultStage 187(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:31 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:31 INFO DAGScheduler: Submitting ResultStage 187 (PythonRDD[193] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=227499, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_188 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=234507, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_188_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:31 INFO BlockManagerInfo: Added broadcast_188_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:31 INFO SparkContext: Created broadcast 188 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 187 (PythonRDD[193] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Adding task set 187.0 with 2 tasks
15/10/21 17:00:31 INFO TaskSetManager: Starting task 0.0 in stage 187.0 (TID 373, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO TaskSetManager: Starting task 1.0 in stage 187.0 (TID 374, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO Executor: Running task 0.0 in stage 187.0 (TID 373)
15/10/21 17:00:31 INFO Executor: Running task 1.0 in stage 187.0 (TID 374)
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:31 INFO PythonRDD: Times: total = 38, boot = -78, init = 116, finish = 0
15/10/21 17:00:31 INFO PythonRDD: Times: total = 38, boot = -74, init = 112, finish = 0
15/10/21 17:00:31 INFO Executor: Finished task 0.0 in stage 187.0 (TID 373). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO Executor: Finished task 1.0 in stage 187.0 (TID 374). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO TaskSetManager: Finished task 0.0 in stage 187.0 (TID 373) in 41 ms on localhost (1/2)
15/10/21 17:00:31 INFO TaskSetManager: Finished task 1.0 in stage 187.0 (TID 374) in 42 ms on localhost (2/2)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Removed TaskSet 187.0, whose tasks have all completed, from pool 
15/10/21 17:00:31 INFO DAGScheduler: ResultStage 187 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:31 INFO DAGScheduler: Job 186 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.049834 s
15/10/21 17:00:31 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:31 INFO DAGScheduler: Got job 187 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:31 INFO DAGScheduler: Final stage: ResultStage 188(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:31 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:31 INFO DAGScheduler: Submitting ResultStage 188 (PythonRDD[194] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=238462, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_189 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=245470, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_189_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:31 INFO BlockManagerInfo: Added broadcast_189_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:31 INFO SparkContext: Created broadcast 189 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 188 (PythonRDD[194] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Adding task set 188.0 with 2 tasks
15/10/21 17:00:31 INFO TaskSetManager: Starting task 0.0 in stage 188.0 (TID 375, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO TaskSetManager: Starting task 1.0 in stage 188.0 (TID 376, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO Executor: Running task 1.0 in stage 188.0 (TID 376)
15/10/21 17:00:31 INFO Executor: Running task 0.0 in stage 188.0 (TID 375)
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:31 INFO PythonRDD: Times: total = 38, boot = -75, init = 113, finish = 0
15/10/21 17:00:31 INFO PythonRDD: Times: total = 37, boot = -71, init = 108, finish = 0
15/10/21 17:00:31 INFO Executor: Finished task 1.0 in stage 188.0 (TID 376). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO Executor: Finished task 0.0 in stage 188.0 (TID 375). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO TaskSetManager: Finished task 1.0 in stage 188.0 (TID 376) in 42 ms on localhost (1/2)
15/10/21 17:00:31 INFO TaskSetManager: Finished task 0.0 in stage 188.0 (TID 375) in 42 ms on localhost (2/2)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Removed TaskSet 188.0, whose tasks have all completed, from pool 
15/10/21 17:00:31 INFO DAGScheduler: ResultStage 188 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.042 s
15/10/21 17:00:31 INFO DAGScheduler: Job 187 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.049856 s
15/10/21 17:00:31 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:31 INFO DAGScheduler: Got job 188 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:31 INFO DAGScheduler: Final stage: ResultStage 189(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:31 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:31 INFO DAGScheduler: Submitting ResultStage 189 (PythonRDD[195] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=249425, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_190 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=256433, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_190_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:31 INFO BlockManagerInfo: Added broadcast_190_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:31 INFO SparkContext: Created broadcast 190 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 189 (PythonRDD[195] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Adding task set 189.0 with 2 tasks
15/10/21 17:00:31 INFO TaskSetManager: Starting task 0.0 in stage 189.0 (TID 377, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO TaskSetManager: Starting task 1.0 in stage 189.0 (TID 378, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO Executor: Running task 0.0 in stage 189.0 (TID 377)
15/10/21 17:00:31 INFO Executor: Running task 1.0 in stage 189.0 (TID 378)
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:31 INFO PythonRDD: Times: total = 41, boot = -71, init = 112, finish = 0
15/10/21 17:00:31 INFO PythonRDD: Times: total = 41, boot = -72, init = 113, finish = 0
15/10/21 17:00:31 INFO Executor: Finished task 0.0 in stage 189.0 (TID 377). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO Executor: Finished task 1.0 in stage 189.0 (TID 378). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO TaskSetManager: Finished task 0.0 in stage 189.0 (TID 377) in 46 ms on localhost (1/2)
15/10/21 17:00:31 INFO TaskSetManager: Finished task 1.0 in stage 189.0 (TID 378) in 45 ms on localhost (2/2)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Removed TaskSet 189.0, whose tasks have all completed, from pool 
15/10/21 17:00:31 INFO DAGScheduler: ResultStage 189 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:31 INFO DAGScheduler: Job 188 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053775 s
15/10/21 17:00:31 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:31 INFO DAGScheduler: Got job 189 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:31 INFO DAGScheduler: Final stage: ResultStage 190(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:31 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:31 INFO DAGScheduler: Submitting ResultStage 190 (PythonRDD[196] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=260388, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_191 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=267396, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_191_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:31 INFO BlockManagerInfo: Added broadcast_191_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:31 INFO SparkContext: Created broadcast 191 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 190 (PythonRDD[196] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Adding task set 190.0 with 2 tasks
15/10/21 17:00:31 INFO TaskSetManager: Starting task 0.0 in stage 190.0 (TID 379, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO TaskSetManager: Starting task 1.0 in stage 190.0 (TID 380, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO Executor: Running task 0.0 in stage 190.0 (TID 379)
15/10/21 17:00:31 INFO Executor: Running task 1.0 in stage 190.0 (TID 380)
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:31 INFO PythonRDD: Times: total = 37, boot = -75, init = 112, finish = 0
15/10/21 17:00:31 INFO Executor: Finished task 0.0 in stage 190.0 (TID 379). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO TaskSetManager: Finished task 0.0 in stage 190.0 (TID 379) in 41 ms on localhost (1/2)
15/10/21 17:00:31 INFO PythonRDD: Times: total = 41, boot = -75, init = 116, finish = 0
15/10/21 17:00:31 INFO Executor: Finished task 1.0 in stage 190.0 (TID 380). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO TaskSetManager: Finished task 1.0 in stage 190.0 (TID 380) in 44 ms on localhost (2/2)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Removed TaskSet 190.0, whose tasks have all completed, from pool 
15/10/21 17:00:31 INFO DAGScheduler: ResultStage 190 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:31 INFO DAGScheduler: Job 189 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053097 s
15/10/21 17:00:31 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:31 INFO DAGScheduler: Got job 190 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:31 INFO DAGScheduler: Final stage: ResultStage 191(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:31 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:31 INFO DAGScheduler: Submitting ResultStage 191 (PythonRDD[197] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=271351, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_192 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=278359, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_192_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:31 INFO BlockManagerInfo: Added broadcast_192_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:31 INFO SparkContext: Created broadcast 192 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 191 (PythonRDD[197] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Adding task set 191.0 with 2 tasks
15/10/21 17:00:31 INFO TaskSetManager: Starting task 0.0 in stage 191.0 (TID 381, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO TaskSetManager: Starting task 1.0 in stage 191.0 (TID 382, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO Executor: Running task 0.0 in stage 191.0 (TID 381)
15/10/21 17:00:31 INFO Executor: Running task 1.0 in stage 191.0 (TID 382)
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:31 INFO PythonRDD: Times: total = 38, boot = -74, init = 112, finish = 0
15/10/21 17:00:31 INFO PythonRDD: Times: total = 38, boot = -74, init = 112, finish = 0
15/10/21 17:00:31 INFO Executor: Finished task 0.0 in stage 191.0 (TID 381). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO Executor: Finished task 1.0 in stage 191.0 (TID 382). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO TaskSetManager: Finished task 0.0 in stage 191.0 (TID 381) in 41 ms on localhost (1/2)
15/10/21 17:00:31 INFO TaskSetManager: Finished task 1.0 in stage 191.0 (TID 382) in 42 ms on localhost (2/2)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Removed TaskSet 191.0, whose tasks have all completed, from pool 
15/10/21 17:00:31 INFO DAGScheduler: ResultStage 191 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:31 INFO DAGScheduler: Job 190 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.050465 s
15/10/21 17:00:31 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:31 INFO DAGScheduler: Got job 191 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:31 INFO DAGScheduler: Final stage: ResultStage 192(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:31 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:31 INFO DAGScheduler: Submitting ResultStage 192 (PythonRDD[198] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=282314, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_193 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=289322, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_193_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:31 INFO BlockManagerInfo: Added broadcast_193_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:31 INFO SparkContext: Created broadcast 193 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 192 (PythonRDD[198] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Adding task set 192.0 with 2 tasks
15/10/21 17:00:31 INFO TaskSetManager: Starting task 0.0 in stage 192.0 (TID 383, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO TaskSetManager: Starting task 1.0 in stage 192.0 (TID 384, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO Executor: Running task 0.0 in stage 192.0 (TID 383)
15/10/21 17:00:31 INFO Executor: Running task 1.0 in stage 192.0 (TID 384)
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:31 INFO PythonRDD: Times: total = 41, boot = -71, init = 112, finish = 0
15/10/21 17:00:31 INFO PythonRDD: Times: total = 41, boot = -76, init = 117, finish = 0
15/10/21 17:00:31 INFO Executor: Finished task 1.0 in stage 192.0 (TID 384). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO Executor: Finished task 0.0 in stage 192.0 (TID 383). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO TaskSetManager: Finished task 1.0 in stage 192.0 (TID 384) in 45 ms on localhost (1/2)
15/10/21 17:00:31 INFO TaskSetManager: Finished task 0.0 in stage 192.0 (TID 383) in 45 ms on localhost (2/2)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Removed TaskSet 192.0, whose tasks have all completed, from pool 
15/10/21 17:00:31 INFO DAGScheduler: ResultStage 192 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:31 INFO DAGScheduler: Job 191 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053668 s
15/10/21 17:00:31 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:31 INFO DAGScheduler: Got job 192 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:31 INFO DAGScheduler: Final stage: ResultStage 193(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:31 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:31 INFO DAGScheduler: Submitting ResultStage 193 (PythonRDD[199] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=293277, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_194 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=300285, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_194_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:31 INFO BlockManagerInfo: Added broadcast_194_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:31 INFO SparkContext: Created broadcast 194 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 193 (PythonRDD[199] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Adding task set 193.0 with 2 tasks
15/10/21 17:00:31 INFO TaskSetManager: Starting task 0.0 in stage 193.0 (TID 385, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO TaskSetManager: Starting task 1.0 in stage 193.0 (TID 386, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO Executor: Running task 0.0 in stage 193.0 (TID 385)
15/10/21 17:00:31 INFO Executor: Running task 1.0 in stage 193.0 (TID 386)
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:31 INFO PythonRDD: Times: total = 41, boot = -75, init = 116, finish = 0
15/10/21 17:00:31 INFO PythonRDD: Times: total = 40, boot = -78, init = 118, finish = 0
15/10/21 17:00:31 INFO Executor: Finished task 1.0 in stage 193.0 (TID 386). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO Executor: Finished task 0.0 in stage 193.0 (TID 385). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO TaskSetManager: Finished task 1.0 in stage 193.0 (TID 386) in 44 ms on localhost (1/2)
15/10/21 17:00:31 INFO TaskSetManager: Finished task 0.0 in stage 193.0 (TID 385) in 45 ms on localhost (2/2)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Removed TaskSet 193.0, whose tasks have all completed, from pool 
15/10/21 17:00:31 INFO DAGScheduler: ResultStage 193 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:31 INFO DAGScheduler: Job 192 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053179 s
15/10/21 17:00:31 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:31 INFO DAGScheduler: Got job 193 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:31 INFO DAGScheduler: Final stage: ResultStage 194(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:31 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:31 INFO DAGScheduler: Submitting ResultStage 194 (PythonRDD[200] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=304240, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_195 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=311248, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_195_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:31 INFO BlockManagerInfo: Added broadcast_195_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:31 INFO SparkContext: Created broadcast 195 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 194 (PythonRDD[200] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Adding task set 194.0 with 2 tasks
15/10/21 17:00:31 INFO TaskSetManager: Starting task 0.0 in stage 194.0 (TID 387, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO TaskSetManager: Starting task 1.0 in stage 194.0 (TID 388, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO Executor: Running task 1.0 in stage 194.0 (TID 388)
15/10/21 17:00:31 INFO Executor: Running task 0.0 in stage 194.0 (TID 387)
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:31 INFO PythonRDD: Times: total = 37, boot = -76, init = 113, finish = 0
15/10/21 17:00:31 INFO Executor: Finished task 1.0 in stage 194.0 (TID 388). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO TaskSetManager: Finished task 1.0 in stage 194.0 (TID 388) in 40 ms on localhost (1/2)
15/10/21 17:00:31 INFO PythonRDD: Times: total = 41, boot = -76, init = 117, finish = 0
15/10/21 17:00:31 INFO Executor: Finished task 0.0 in stage 194.0 (TID 387). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO TaskSetManager: Finished task 0.0 in stage 194.0 (TID 387) in 45 ms on localhost (2/2)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Removed TaskSet 194.0, whose tasks have all completed, from pool 
15/10/21 17:00:31 INFO DAGScheduler: ResultStage 194 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:31 INFO DAGScheduler: Job 193 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053080 s
15/10/21 17:00:31 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:31 INFO DAGScheduler: Got job 194 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:31 INFO DAGScheduler: Final stage: ResultStage 195(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:31 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:31 INFO DAGScheduler: Submitting ResultStage 195 (PythonRDD[201] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=315203, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_196 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=322211, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_196_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:31 INFO BlockManagerInfo: Added broadcast_196_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:31 INFO SparkContext: Created broadcast 196 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 195 (PythonRDD[201] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Adding task set 195.0 with 2 tasks
15/10/21 17:00:31 INFO TaskSetManager: Starting task 0.0 in stage 195.0 (TID 389, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO TaskSetManager: Starting task 1.0 in stage 195.0 (TID 390, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO Executor: Running task 0.0 in stage 195.0 (TID 389)
15/10/21 17:00:31 INFO Executor: Running task 1.0 in stage 195.0 (TID 390)
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:31 INFO PythonRDD: Times: total = 37, boot = -76, init = 113, finish = 0
15/10/21 17:00:31 INFO PythonRDD: Times: total = 37, boot = -76, init = 113, finish = 0
15/10/21 17:00:31 INFO Executor: Finished task 1.0 in stage 195.0 (TID 390). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO Executor: Finished task 0.0 in stage 195.0 (TID 389). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO TaskSetManager: Finished task 1.0 in stage 195.0 (TID 390) in 41 ms on localhost (1/2)
15/10/21 17:00:31 INFO TaskSetManager: Finished task 0.0 in stage 195.0 (TID 389) in 42 ms on localhost (2/2)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Removed TaskSet 195.0, whose tasks have all completed, from pool 
15/10/21 17:00:31 INFO DAGScheduler: ResultStage 195 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.042 s
15/10/21 17:00:31 INFO DAGScheduler: Job 194 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.050028 s
15/10/21 17:00:31 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:31 INFO DAGScheduler: Got job 195 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:31 INFO DAGScheduler: Final stage: ResultStage 196(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:31 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:31 INFO DAGScheduler: Submitting ResultStage 196 (PythonRDD[202] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=326166, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_197 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=333174, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_197_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:31 INFO BlockManagerInfo: Added broadcast_197_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:31 INFO SparkContext: Created broadcast 197 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 196 (PythonRDD[202] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Adding task set 196.0 with 2 tasks
15/10/21 17:00:31 INFO TaskSetManager: Starting task 0.0 in stage 196.0 (TID 391, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO TaskSetManager: Starting task 1.0 in stage 196.0 (TID 392, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO Executor: Running task 1.0 in stage 196.0 (TID 392)
15/10/21 17:00:31 INFO Executor: Running task 0.0 in stage 196.0 (TID 391)
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:31 INFO PythonRDD: Times: total = 41, boot = -72, init = 113, finish = 0
15/10/21 17:00:31 INFO PythonRDD: Times: total = 41, boot = -73, init = 114, finish = 0
15/10/21 17:00:31 INFO Executor: Finished task 0.0 in stage 196.0 (TID 391). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO Executor: Finished task 1.0 in stage 196.0 (TID 392). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO TaskSetManager: Finished task 1.0 in stage 196.0 (TID 392) in 45 ms on localhost (1/2)
15/10/21 17:00:31 INFO TaskSetManager: Finished task 0.0 in stage 196.0 (TID 391) in 46 ms on localhost (2/2)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Removed TaskSet 196.0, whose tasks have all completed, from pool 
15/10/21 17:00:31 INFO DAGScheduler: ResultStage 196 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:31 INFO DAGScheduler: Job 195 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053487 s
15/10/21 17:00:31 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:31 INFO DAGScheduler: Got job 196 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:31 INFO DAGScheduler: Final stage: ResultStage 197(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:31 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:31 INFO DAGScheduler: Submitting ResultStage 197 (PythonRDD[203] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=337129, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_198 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=344137, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_198_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:31 INFO BlockManagerInfo: Added broadcast_198_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:31 INFO SparkContext: Created broadcast 198 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 197 (PythonRDD[203] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Adding task set 197.0 with 2 tasks
15/10/21 17:00:31 INFO TaskSetManager: Starting task 0.0 in stage 197.0 (TID 393, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO TaskSetManager: Starting task 1.0 in stage 197.0 (TID 394, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO Executor: Running task 0.0 in stage 197.0 (TID 393)
15/10/21 17:00:31 INFO Executor: Running task 1.0 in stage 197.0 (TID 394)
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:31 INFO PythonRDD: Times: total = 39, boot = -76, init = 115, finish = 0
15/10/21 17:00:31 INFO PythonRDD: Times: total = 39, boot = -72, init = 111, finish = 0
15/10/21 17:00:31 INFO Executor: Finished task 0.0 in stage 197.0 (TID 393). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO Executor: Finished task 1.0 in stage 197.0 (TID 394). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO TaskSetManager: Finished task 0.0 in stage 197.0 (TID 393) in 42 ms on localhost (1/2)
15/10/21 17:00:31 INFO TaskSetManager: Finished task 1.0 in stage 197.0 (TID 394) in 42 ms on localhost (2/2)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Removed TaskSet 197.0, whose tasks have all completed, from pool 
15/10/21 17:00:31 INFO DAGScheduler: ResultStage 197 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:31 INFO DAGScheduler: Job 196 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.050551 s
15/10/21 17:00:31 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:31 INFO DAGScheduler: Got job 197 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:31 INFO DAGScheduler: Final stage: ResultStage 198(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:31 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:31 INFO DAGScheduler: Submitting ResultStage 198 (PythonRDD[204] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=348092, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_199 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=355100, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_199_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:31 INFO BlockManagerInfo: Added broadcast_199_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:31 INFO SparkContext: Created broadcast 199 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 198 (PythonRDD[204] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Adding task set 198.0 with 2 tasks
15/10/21 17:00:31 INFO TaskSetManager: Starting task 0.0 in stage 198.0 (TID 395, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO TaskSetManager: Starting task 1.0 in stage 198.0 (TID 396, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO Executor: Running task 0.0 in stage 198.0 (TID 395)
15/10/21 17:00:31 INFO Executor: Running task 1.0 in stage 198.0 (TID 396)
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:31 INFO PythonRDD: Times: total = 39, boot = -71, init = 110, finish = 0
15/10/21 17:00:31 INFO PythonRDD: Times: total = 39, boot = -72, init = 111, finish = 0
15/10/21 17:00:31 INFO Executor: Finished task 1.0 in stage 198.0 (TID 396). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO Executor: Finished task 0.0 in stage 198.0 (TID 395). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO TaskSetManager: Finished task 1.0 in stage 198.0 (TID 396) in 42 ms on localhost (1/2)
15/10/21 17:00:31 INFO TaskSetManager: Finished task 0.0 in stage 198.0 (TID 395) in 43 ms on localhost (2/2)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Removed TaskSet 198.0, whose tasks have all completed, from pool 
15/10/21 17:00:31 INFO DAGScheduler: ResultStage 198 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:31 INFO DAGScheduler: Job 197 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.050520 s
15/10/21 17:00:31 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:31 INFO DAGScheduler: Got job 198 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:31 INFO DAGScheduler: Final stage: ResultStage 199(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:31 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:31 INFO DAGScheduler: Submitting ResultStage 199 (PythonRDD[205] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=359055, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_200 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=366063, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_200_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:31 INFO BlockManagerInfo: Added broadcast_200_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:31 INFO SparkContext: Created broadcast 200 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 199 (PythonRDD[205] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Adding task set 199.0 with 2 tasks
15/10/21 17:00:31 INFO TaskSetManager: Starting task 0.0 in stage 199.0 (TID 397, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO TaskSetManager: Starting task 1.0 in stage 199.0 (TID 398, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO Executor: Running task 0.0 in stage 199.0 (TID 397)
15/10/21 17:00:31 INFO Executor: Running task 1.0 in stage 199.0 (TID 398)
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:31 INFO PythonRDD: Times: total = 38, boot = -71, init = 109, finish = 0
15/10/21 17:00:31 INFO PythonRDD: Times: total = 37, boot = -73, init = 110, finish = 0
15/10/21 17:00:31 INFO Executor: Finished task 0.0 in stage 199.0 (TID 397). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO Executor: Finished task 1.0 in stage 199.0 (TID 398). 1870 bytes result sent to driver
15/10/21 17:00:31 INFO TaskSetManager: Finished task 0.0 in stage 199.0 (TID 397) in 41 ms on localhost (1/2)
15/10/21 17:00:31 INFO TaskSetManager: Finished task 1.0 in stage 199.0 (TID 398) in 41 ms on localhost (2/2)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Removed TaskSet 199.0, whose tasks have all completed, from pool 
15/10/21 17:00:31 INFO DAGScheduler: ResultStage 199 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.042 s
15/10/21 17:00:31 INFO DAGScheduler: Job 198 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.049807 s
15/10/21 17:00:31 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:31 INFO DAGScheduler: Got job 199 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:31 INFO DAGScheduler: Final stage: ResultStage 200(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:31 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:31 INFO DAGScheduler: Submitting ResultStage 200 (PythonRDD[206] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=370018, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_201 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:31 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=377026, maxMem=278302556
15/10/21 17:00:31 INFO MemoryStore: Block broadcast_201_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:00:31 INFO BlockManagerInfo: Added broadcast_201_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:31 INFO SparkContext: Created broadcast 201 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 200 (PythonRDD[206] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:31 INFO TaskSchedulerImpl: Adding task set 200.0 with 2 tasks
15/10/21 17:00:31 INFO TaskSetManager: Starting task 0.0 in stage 200.0 (TID 399, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO TaskSetManager: Starting task 1.0 in stage 200.0 (TID 400, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:31 INFO Executor: Running task 0.0 in stage 200.0 (TID 399)
15/10/21 17:00:31 INFO Executor: Running task 1.0 in stage 200.0 (TID 400)
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:31 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:32 INFO PythonRDD: Times: total = 38, boot = -71, init = 109, finish = 0
15/10/21 17:00:32 INFO PythonRDD: Times: total = 37, boot = -71, init = 108, finish = 0
15/10/21 17:00:32 INFO Executor: Finished task 1.0 in stage 200.0 (TID 400). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO Executor: Finished task 0.0 in stage 200.0 (TID 399). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO TaskSetManager: Finished task 1.0 in stage 200.0 (TID 400) in 41 ms on localhost (1/2)
15/10/21 17:00:32 INFO TaskSetManager: Finished task 0.0 in stage 200.0 (TID 399) in 42 ms on localhost (2/2)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Removed TaskSet 200.0, whose tasks have all completed, from pool 
15/10/21 17:00:32 INFO DAGScheduler: ResultStage 200 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.042 s
15/10/21 17:00:32 INFO DAGScheduler: Job 199 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.049592 s
15/10/21 17:00:32 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:32 INFO DAGScheduler: Got job 200 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:32 INFO DAGScheduler: Final stage: ResultStage 201(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:32 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:32 INFO DAGScheduler: Submitting ResultStage 201 (PythonRDD[207] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=380981, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_202 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=387989, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_202_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Added broadcast_202_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:32 INFO SparkContext: Created broadcast 202 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 201 (PythonRDD[207] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Adding task set 201.0 with 2 tasks
15/10/21 17:00:32 INFO TaskSetManager: Starting task 0.0 in stage 201.0 (TID 401, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO TaskSetManager: Starting task 1.0 in stage 201.0 (TID 402, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO Executor: Running task 0.0 in stage 201.0 (TID 401)
15/10/21 17:00:32 INFO Executor: Running task 1.0 in stage 201.0 (TID 402)
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:32 INFO PythonRDD: Times: total = 38, boot = -69, init = 107, finish = 0
15/10/21 17:00:32 INFO PythonRDD: Times: total = 38, boot = -71, init = 109, finish = 0
15/10/21 17:00:32 INFO Executor: Finished task 1.0 in stage 201.0 (TID 402). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO Executor: Finished task 0.0 in stage 201.0 (TID 401). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO TaskSetManager: Finished task 1.0 in stage 201.0 (TID 402) in 42 ms on localhost (1/2)
15/10/21 17:00:32 INFO TaskSetManager: Finished task 0.0 in stage 201.0 (TID 401) in 43 ms on localhost (2/2)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Removed TaskSet 201.0, whose tasks have all completed, from pool 
15/10/21 17:00:32 INFO DAGScheduler: ResultStage 201 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:32 INFO DAGScheduler: Job 200 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.050033 s
15/10/21 17:00:32 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:32 INFO DAGScheduler: Got job 201 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:32 INFO DAGScheduler: Final stage: ResultStage 202(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:32 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:32 INFO DAGScheduler: Submitting ResultStage 202 (PythonRDD[208] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=391944, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_203 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=398952, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_203_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Added broadcast_203_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Removed broadcast_184_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:32 INFO SparkContext: Created broadcast 203 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 202 (PythonRDD[208] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Adding task set 202.0 with 2 tasks
15/10/21 17:00:32 INFO TaskSetManager: Starting task 0.0 in stage 202.0 (TID 403, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO TaskSetManager: Starting task 1.0 in stage 202.0 (TID 404, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO BlockManagerInfo: Removed broadcast_192_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:32 INFO Executor: Running task 0.0 in stage 202.0 (TID 403)
15/10/21 17:00:32 INFO Executor: Running task 1.0 in stage 202.0 (TID 404)
15/10/21 17:00:32 INFO BlockManagerInfo: Removed broadcast_191_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:32 INFO BlockManagerInfo: Removed broadcast_190_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Removed broadcast_189_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Removed broadcast_188_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Removed broadcast_187_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Removed broadcast_186_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Removed broadcast_185_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Removed broadcast_194_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Removed broadcast_193_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Removed broadcast_202_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Removed broadcast_201_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Removed broadcast_200_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Removed broadcast_199_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Removed broadcast_198_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Removed broadcast_197_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Removed broadcast_196_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Removed broadcast_195_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:32 INFO PythonRDD: Times: total = 38, boot = -74, init = 112, finish = 0
15/10/21 17:00:32 INFO Executor: Finished task 0.0 in stage 202.0 (TID 403). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO TaskSetManager: Finished task 0.0 in stage 202.0 (TID 403) in 41 ms on localhost (1/2)
15/10/21 17:00:32 INFO PythonRDD: Times: total = 41, boot = -75, init = 116, finish = 0
15/10/21 17:00:32 INFO Executor: Finished task 1.0 in stage 202.0 (TID 404). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO TaskSetManager: Finished task 1.0 in stage 202.0 (TID 404) in 45 ms on localhost (2/2)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Removed TaskSet 202.0, whose tasks have all completed, from pool 
15/10/21 17:00:32 INFO DAGScheduler: ResultStage 202 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:32 INFO DAGScheduler: Job 201 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.057790 s
15/10/21 17:00:32 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:32 INFO DAGScheduler: Got job 202 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:32 INFO DAGScheduler: Final stage: ResultStage 203(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:32 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:32 INFO DAGScheduler: Submitting ResultStage 203 (PythonRDD[209] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=194610, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_204 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=201618, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_204_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Added broadcast_204_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:32 INFO SparkContext: Created broadcast 204 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 203 (PythonRDD[209] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Adding task set 203.0 with 2 tasks
15/10/21 17:00:32 INFO TaskSetManager: Starting task 0.0 in stage 203.0 (TID 405, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO TaskSetManager: Starting task 1.0 in stage 203.0 (TID 406, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO Executor: Running task 0.0 in stage 203.0 (TID 405)
15/10/21 17:00:32 INFO Executor: Running task 1.0 in stage 203.0 (TID 406)
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:32 INFO PythonRDD: Times: total = 38, boot = -80, init = 118, finish = 0
15/10/21 17:00:32 INFO PythonRDD: Times: total = 38, boot = -78, init = 116, finish = 0
15/10/21 17:00:32 INFO Executor: Finished task 1.0 in stage 203.0 (TID 406). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO Executor: Finished task 0.0 in stage 203.0 (TID 405). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO TaskSetManager: Finished task 1.0 in stage 203.0 (TID 406) in 41 ms on localhost (1/2)
15/10/21 17:00:32 INFO TaskSetManager: Finished task 0.0 in stage 203.0 (TID 405) in 43 ms on localhost (2/2)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Removed TaskSet 203.0, whose tasks have all completed, from pool 
15/10/21 17:00:32 INFO DAGScheduler: ResultStage 203 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:32 INFO DAGScheduler: Job 202 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.050470 s
15/10/21 17:00:32 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:32 INFO DAGScheduler: Got job 203 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:32 INFO DAGScheduler: Final stage: ResultStage 204(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:32 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:32 INFO DAGScheduler: Submitting ResultStage 204 (PythonRDD[210] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=205573, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_205 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=212581, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_205_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Added broadcast_205_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:32 INFO SparkContext: Created broadcast 205 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 204 (PythonRDD[210] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Adding task set 204.0 with 2 tasks
15/10/21 17:00:32 INFO TaskSetManager: Starting task 0.0 in stage 204.0 (TID 407, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO TaskSetManager: Starting task 1.0 in stage 204.0 (TID 408, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO Executor: Running task 0.0 in stage 204.0 (TID 407)
15/10/21 17:00:32 INFO Executor: Running task 1.0 in stage 204.0 (TID 408)
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:32 INFO PythonRDD: Times: total = 38, boot = -75, init = 113, finish = 0
15/10/21 17:00:32 INFO PythonRDD: Times: total = 37, boot = -70, init = 107, finish = 0
15/10/21 17:00:32 INFO Executor: Finished task 1.0 in stage 204.0 (TID 408). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO Executor: Finished task 0.0 in stage 204.0 (TID 407). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO TaskSetManager: Finished task 1.0 in stage 204.0 (TID 408) in 40 ms on localhost (1/2)
15/10/21 17:00:32 INFO TaskSetManager: Finished task 0.0 in stage 204.0 (TID 407) in 42 ms on localhost (2/2)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Removed TaskSet 204.0, whose tasks have all completed, from pool 
15/10/21 17:00:32 INFO DAGScheduler: ResultStage 204 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.042 s
15/10/21 17:00:32 INFO DAGScheduler: Job 203 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.049694 s
15/10/21 17:00:32 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:32 INFO DAGScheduler: Got job 204 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:32 INFO DAGScheduler: Final stage: ResultStage 205(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:32 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:32 INFO DAGScheduler: Submitting ResultStage 205 (PythonRDD[211] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=216536, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_206 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=223544, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_206_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Added broadcast_206_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:32 INFO SparkContext: Created broadcast 206 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 205 (PythonRDD[211] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Adding task set 205.0 with 2 tasks
15/10/21 17:00:32 INFO TaskSetManager: Starting task 0.0 in stage 205.0 (TID 409, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO TaskSetManager: Starting task 1.0 in stage 205.0 (TID 410, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO Executor: Running task 0.0 in stage 205.0 (TID 409)
15/10/21 17:00:32 INFO Executor: Running task 1.0 in stage 205.0 (TID 410)
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:32 INFO PythonRDD: Times: total = 41, boot = -72, init = 113, finish = 0
15/10/21 17:00:32 INFO PythonRDD: Times: total = 41, boot = -71, init = 112, finish = 0
15/10/21 17:00:32 INFO Executor: Finished task 1.0 in stage 205.0 (TID 410). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO Executor: Finished task 0.0 in stage 205.0 (TID 409). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO TaskSetManager: Finished task 1.0 in stage 205.0 (TID 410) in 44 ms on localhost (1/2)
15/10/21 17:00:32 INFO TaskSetManager: Finished task 0.0 in stage 205.0 (TID 409) in 45 ms on localhost (2/2)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Removed TaskSet 205.0, whose tasks have all completed, from pool 
15/10/21 17:00:32 INFO DAGScheduler: ResultStage 205 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:32 INFO DAGScheduler: Job 204 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053673 s
15/10/21 17:00:32 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:32 INFO DAGScheduler: Got job 205 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:32 INFO DAGScheduler: Final stage: ResultStage 206(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:32 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:32 INFO DAGScheduler: Submitting ResultStage 206 (PythonRDD[212] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=227499, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_207 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=234507, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_207_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Added broadcast_207_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:32 INFO SparkContext: Created broadcast 207 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 206 (PythonRDD[212] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Adding task set 206.0 with 2 tasks
15/10/21 17:00:32 INFO TaskSetManager: Starting task 0.0 in stage 206.0 (TID 411, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO TaskSetManager: Starting task 1.0 in stage 206.0 (TID 412, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO Executor: Running task 0.0 in stage 206.0 (TID 411)
15/10/21 17:00:32 INFO Executor: Running task 1.0 in stage 206.0 (TID 412)
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:32 INFO PythonRDD: Times: total = 38, boot = -74, init = 112, finish = 0
15/10/21 17:00:32 INFO Executor: Finished task 1.0 in stage 206.0 (TID 412). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO TaskSetManager: Finished task 1.0 in stage 206.0 (TID 412) in 41 ms on localhost (1/2)
15/10/21 17:00:32 INFO PythonRDD: Times: total = 42, boot = -74, init = 116, finish = 0
15/10/21 17:00:32 INFO Executor: Finished task 0.0 in stage 206.0 (TID 411). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO TaskSetManager: Finished task 0.0 in stage 206.0 (TID 411) in 46 ms on localhost (2/2)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Removed TaskSet 206.0, whose tasks have all completed, from pool 
15/10/21 17:00:32 INFO DAGScheduler: ResultStage 206 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:00:32 INFO DAGScheduler: Job 205 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053875 s
15/10/21 17:00:32 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:32 INFO DAGScheduler: Got job 206 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:32 INFO DAGScheduler: Final stage: ResultStage 207(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:32 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:32 INFO DAGScheduler: Submitting ResultStage 207 (PythonRDD[213] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=238462, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_208 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=245470, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_208_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Added broadcast_208_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:32 INFO SparkContext: Created broadcast 208 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 207 (PythonRDD[213] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Adding task set 207.0 with 2 tasks
15/10/21 17:00:32 INFO TaskSetManager: Starting task 0.0 in stage 207.0 (TID 413, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO TaskSetManager: Starting task 1.0 in stage 207.0 (TID 414, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO Executor: Running task 0.0 in stage 207.0 (TID 413)
15/10/21 17:00:32 INFO Executor: Running task 1.0 in stage 207.0 (TID 414)
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:32 INFO PythonRDD: Times: total = 38, boot = -74, init = 112, finish = 0
15/10/21 17:00:32 INFO PythonRDD: Times: total = 38, boot = -74, init = 112, finish = 0
15/10/21 17:00:32 INFO Executor: Finished task 0.0 in stage 207.0 (TID 413). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO Executor: Finished task 1.0 in stage 207.0 (TID 414). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO TaskSetManager: Finished task 0.0 in stage 207.0 (TID 413) in 42 ms on localhost (1/2)
15/10/21 17:00:32 INFO TaskSetManager: Finished task 1.0 in stage 207.0 (TID 414) in 42 ms on localhost (2/2)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Removed TaskSet 207.0, whose tasks have all completed, from pool 
15/10/21 17:00:32 INFO DAGScheduler: ResultStage 207 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.042 s
15/10/21 17:00:32 INFO DAGScheduler: Job 206 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.050198 s
15/10/21 17:00:32 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:32 INFO DAGScheduler: Got job 207 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:32 INFO DAGScheduler: Final stage: ResultStage 208(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:32 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:32 INFO DAGScheduler: Submitting ResultStage 208 (PythonRDD[214] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=249425, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_209 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=256433, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_209_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Added broadcast_209_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:32 INFO SparkContext: Created broadcast 209 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 208 (PythonRDD[214] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Adding task set 208.0 with 2 tasks
15/10/21 17:00:32 INFO TaskSetManager: Starting task 0.0 in stage 208.0 (TID 415, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO TaskSetManager: Starting task 1.0 in stage 208.0 (TID 416, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO Executor: Running task 1.0 in stage 208.0 (TID 416)
15/10/21 17:00:32 INFO Executor: Running task 0.0 in stage 208.0 (TID 415)
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:32 INFO PythonRDD: Times: total = 38, boot = -72, init = 110, finish = 0
15/10/21 17:00:32 INFO PythonRDD: Times: total = 39, boot = -73, init = 112, finish = 0
15/10/21 17:00:32 INFO Executor: Finished task 1.0 in stage 208.0 (TID 416). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO Executor: Finished task 0.0 in stage 208.0 (TID 415). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO TaskSetManager: Finished task 1.0 in stage 208.0 (TID 416) in 42 ms on localhost (1/2)
15/10/21 17:00:32 INFO TaskSetManager: Finished task 0.0 in stage 208.0 (TID 415) in 43 ms on localhost (2/2)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Removed TaskSet 208.0, whose tasks have all completed, from pool 
15/10/21 17:00:32 INFO DAGScheduler: ResultStage 208 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:32 INFO DAGScheduler: Job 207 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.050112 s
15/10/21 17:00:32 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:32 INFO DAGScheduler: Got job 208 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:32 INFO DAGScheduler: Final stage: ResultStage 209(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:32 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:32 INFO DAGScheduler: Submitting ResultStage 209 (PythonRDD[215] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=260388, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_210 stored as values in memory (estimated size 6.8 KB, free 265.2 MB)
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=267396, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_210_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Added broadcast_210_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:32 INFO SparkContext: Created broadcast 210 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 209 (PythonRDD[215] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Adding task set 209.0 with 2 tasks
15/10/21 17:00:32 INFO TaskSetManager: Starting task 0.0 in stage 209.0 (TID 417, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO TaskSetManager: Starting task 1.0 in stage 209.0 (TID 418, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO Executor: Running task 0.0 in stage 209.0 (TID 417)
15/10/21 17:00:32 INFO Executor: Running task 1.0 in stage 209.0 (TID 418)
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:32 INFO PythonRDD: Times: total = 41, boot = -72, init = 113, finish = 0
15/10/21 17:00:32 INFO PythonRDD: Times: total = 41, boot = -70, init = 111, finish = 0
15/10/21 17:00:32 INFO Executor: Finished task 1.0 in stage 209.0 (TID 418). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO Executor: Finished task 0.0 in stage 209.0 (TID 417). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO TaskSetManager: Finished task 1.0 in stage 209.0 (TID 418) in 44 ms on localhost (1/2)
15/10/21 17:00:32 INFO TaskSetManager: Finished task 0.0 in stage 209.0 (TID 417) in 45 ms on localhost (2/2)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Removed TaskSet 209.0, whose tasks have all completed, from pool 
15/10/21 17:00:32 INFO DAGScheduler: ResultStage 209 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:32 INFO DAGScheduler: Job 208 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053468 s
15/10/21 17:00:32 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:32 INFO DAGScheduler: Got job 209 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:32 INFO DAGScheduler: Final stage: ResultStage 210(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:32 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:32 INFO DAGScheduler: Submitting ResultStage 210 (PythonRDD[216] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=271351, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_211 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=278359, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_211_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Added broadcast_211_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:32 INFO SparkContext: Created broadcast 211 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 210 (PythonRDD[216] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Adding task set 210.0 with 2 tasks
15/10/21 17:00:32 INFO TaskSetManager: Starting task 0.0 in stage 210.0 (TID 419, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO TaskSetManager: Starting task 1.0 in stage 210.0 (TID 420, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO Executor: Running task 0.0 in stage 210.0 (TID 419)
15/10/21 17:00:32 INFO Executor: Running task 1.0 in stage 210.0 (TID 420)
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:32 INFO PythonRDD: Times: total = 38, boot = -79, init = 117, finish = 0
15/10/21 17:00:32 INFO PythonRDD: Times: total = 38, boot = -78, init = 116, finish = 0
15/10/21 17:00:32 INFO Executor: Finished task 0.0 in stage 210.0 (TID 419). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO Executor: Finished task 1.0 in stage 210.0 (TID 420). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO TaskSetManager: Finished task 0.0 in stage 210.0 (TID 419) in 42 ms on localhost (1/2)
15/10/21 17:00:32 INFO TaskSetManager: Finished task 1.0 in stage 210.0 (TID 420) in 42 ms on localhost (2/2)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Removed TaskSet 210.0, whose tasks have all completed, from pool 
15/10/21 17:00:32 INFO DAGScheduler: ResultStage 210 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:32 INFO DAGScheduler: Job 209 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.052707 s
15/10/21 17:00:32 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:32 INFO DAGScheduler: Got job 210 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:32 INFO DAGScheduler: Final stage: ResultStage 211(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:32 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:32 INFO DAGScheduler: Submitting ResultStage 211 (PythonRDD[217] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=282314, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_212 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=289322, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_212_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Added broadcast_212_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:32 INFO SparkContext: Created broadcast 212 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 211 (PythonRDD[217] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Adding task set 211.0 with 2 tasks
15/10/21 17:00:32 INFO TaskSetManager: Starting task 0.0 in stage 211.0 (TID 421, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO TaskSetManager: Starting task 1.0 in stage 211.0 (TID 422, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO Executor: Running task 1.0 in stage 211.0 (TID 422)
15/10/21 17:00:32 INFO Executor: Running task 0.0 in stage 211.0 (TID 421)
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:32 INFO PythonRDD: Times: total = 39, boot = -73, init = 112, finish = 0
15/10/21 17:00:32 INFO PythonRDD: Times: total = 38, boot = -75, init = 113, finish = 0
15/10/21 17:00:32 INFO Executor: Finished task 1.0 in stage 211.0 (TID 422). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO Executor: Finished task 0.0 in stage 211.0 (TID 421). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO TaskSetManager: Finished task 1.0 in stage 211.0 (TID 422) in 42 ms on localhost (1/2)
15/10/21 17:00:32 INFO TaskSetManager: Finished task 0.0 in stage 211.0 (TID 421) in 43 ms on localhost (2/2)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Removed TaskSet 211.0, whose tasks have all completed, from pool 
15/10/21 17:00:32 INFO DAGScheduler: ResultStage 211 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:32 INFO DAGScheduler: Job 210 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.050035 s
15/10/21 17:00:32 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:32 INFO DAGScheduler: Got job 211 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:32 INFO DAGScheduler: Final stage: ResultStage 212(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:32 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:32 INFO DAGScheduler: Submitting ResultStage 212 (PythonRDD[218] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=293277, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_213 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=300285, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_213_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Added broadcast_213_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:00:32 INFO SparkContext: Created broadcast 213 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 212 (PythonRDD[218] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Adding task set 212.0 with 2 tasks
15/10/21 17:00:32 INFO TaskSetManager: Starting task 0.0 in stage 212.0 (TID 423, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO TaskSetManager: Starting task 1.0 in stage 212.0 (TID 424, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO Executor: Running task 0.0 in stage 212.0 (TID 423)
15/10/21 17:00:32 INFO Executor: Running task 1.0 in stage 212.0 (TID 424)
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:32 INFO PythonRDD: Times: total = 41, boot = -71, init = 112, finish = 0
15/10/21 17:00:32 INFO PythonRDD: Times: total = 41, boot = -70, init = 111, finish = 0
15/10/21 17:00:32 INFO Executor: Finished task 1.0 in stage 212.0 (TID 424). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO Executor: Finished task 0.0 in stage 212.0 (TID 423). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO TaskSetManager: Finished task 1.0 in stage 212.0 (TID 424) in 44 ms on localhost (1/2)
15/10/21 17:00:32 INFO TaskSetManager: Finished task 0.0 in stage 212.0 (TID 423) in 45 ms on localhost (2/2)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Removed TaskSet 212.0, whose tasks have all completed, from pool 
15/10/21 17:00:32 INFO DAGScheduler: ResultStage 212 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:32 INFO DAGScheduler: Job 211 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.052837 s
15/10/21 17:00:32 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:32 INFO DAGScheduler: Got job 212 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:32 INFO DAGScheduler: Final stage: ResultStage 213(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:32 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:32 INFO DAGScheduler: Submitting ResultStage 213 (PythonRDD[219] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=304240, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_214 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=311248, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_214_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Added broadcast_214_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:32 INFO SparkContext: Created broadcast 214 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 213 (PythonRDD[219] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Adding task set 213.0 with 2 tasks
15/10/21 17:00:32 INFO TaskSetManager: Starting task 0.0 in stage 213.0 (TID 425, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO TaskSetManager: Starting task 1.0 in stage 213.0 (TID 426, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO Executor: Running task 0.0 in stage 213.0 (TID 425)
15/10/21 17:00:32 INFO Executor: Running task 1.0 in stage 213.0 (TID 426)
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:32 INFO PythonRDD: Times: total = 38, boot = -74, init = 112, finish = 0
15/10/21 17:00:32 INFO PythonRDD: Times: total = 38, boot = -74, init = 112, finish = 0
15/10/21 17:00:32 INFO Executor: Finished task 1.0 in stage 213.0 (TID 426). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO Executor: Finished task 0.0 in stage 213.0 (TID 425). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO TaskSetManager: Finished task 1.0 in stage 213.0 (TID 426) in 41 ms on localhost (1/2)
15/10/21 17:00:32 INFO TaskSetManager: Finished task 0.0 in stage 213.0 (TID 425) in 42 ms on localhost (2/2)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Removed TaskSet 213.0, whose tasks have all completed, from pool 
15/10/21 17:00:32 INFO DAGScheduler: ResultStage 213 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:32 INFO DAGScheduler: Job 212 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.049938 s
15/10/21 17:00:32 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:32 INFO DAGScheduler: Got job 213 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:32 INFO DAGScheduler: Final stage: ResultStage 214(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:32 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:32 INFO DAGScheduler: Submitting ResultStage 214 (PythonRDD[220] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=315203, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_215 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=322211, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_215_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Added broadcast_215_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:32 INFO SparkContext: Created broadcast 215 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 214 (PythonRDD[220] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Adding task set 214.0 with 2 tasks
15/10/21 17:00:32 INFO TaskSetManager: Starting task 0.0 in stage 214.0 (TID 427, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO TaskSetManager: Starting task 1.0 in stage 214.0 (TID 428, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO Executor: Running task 0.0 in stage 214.0 (TID 427)
15/10/21 17:00:32 INFO Executor: Running task 1.0 in stage 214.0 (TID 428)
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:32 INFO PythonRDD: Times: total = 38, boot = -70, init = 108, finish = 0
15/10/21 17:00:32 INFO Executor: Finished task 0.0 in stage 214.0 (TID 427). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO TaskSetManager: Finished task 0.0 in stage 214.0 (TID 427) in 41 ms on localhost (1/2)
15/10/21 17:00:32 INFO PythonRDD: Times: total = 42, boot = -71, init = 113, finish = 0
15/10/21 17:00:32 INFO Executor: Finished task 1.0 in stage 214.0 (TID 428). 1870 bytes result sent to driver
15/10/21 17:00:32 INFO TaskSetManager: Finished task 1.0 in stage 214.0 (TID 428) in 45 ms on localhost (2/2)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Removed TaskSet 214.0, whose tasks have all completed, from pool 
15/10/21 17:00:32 INFO DAGScheduler: ResultStage 214 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:00:32 INFO DAGScheduler: Job 213 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.053343 s
15/10/21 17:00:32 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:32 INFO DAGScheduler: Got job 214 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:32 INFO DAGScheduler: Final stage: ResultStage 215(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:32 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:32 INFO DAGScheduler: Submitting ResultStage 215 (PythonRDD[221] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=326166, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_216 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:32 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=333174, maxMem=278302556
15/10/21 17:00:32 INFO MemoryStore: Block broadcast_216_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:32 INFO BlockManagerInfo: Added broadcast_216_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:32 INFO SparkContext: Created broadcast 216 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 215 (PythonRDD[221] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:32 INFO TaskSchedulerImpl: Adding task set 215.0 with 2 tasks
15/10/21 17:00:32 INFO TaskSetManager: Starting task 0.0 in stage 215.0 (TID 429, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO TaskSetManager: Starting task 1.0 in stage 215.0 (TID 430, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:32 INFO Executor: Running task 0.0 in stage 215.0 (TID 429)
15/10/21 17:00:32 INFO Executor: Running task 1.0 in stage 215.0 (TID 430)
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:32 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:33 INFO PythonRDD: Times: total = 38, boot = -73, init = 111, finish = 0
15/10/21 17:00:33 INFO PythonRDD: Times: total = 38, boot = -75, init = 113, finish = 0
15/10/21 17:00:33 INFO Executor: Finished task 1.0 in stage 215.0 (TID 430). 1870 bytes result sent to driver
15/10/21 17:00:33 INFO Executor: Finished task 0.0 in stage 215.0 (TID 429). 1870 bytes result sent to driver
15/10/21 17:00:33 INFO TaskSetManager: Finished task 1.0 in stage 215.0 (TID 430) in 42 ms on localhost (1/2)
15/10/21 17:00:33 INFO TaskSetManager: Finished task 0.0 in stage 215.0 (TID 429) in 42 ms on localhost (2/2)
15/10/21 17:00:33 INFO TaskSchedulerImpl: Removed TaskSet 215.0, whose tasks have all completed, from pool 
15/10/21 17:00:33 INFO DAGScheduler: ResultStage 215 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:33 INFO DAGScheduler: Job 214 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.050261 s
15/10/21 17:00:33 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:33 INFO DAGScheduler: Got job 215 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:33 INFO DAGScheduler: Final stage: ResultStage 216(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:33 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:33 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:33 INFO DAGScheduler: Submitting ResultStage 216 (PythonRDD[222] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:33 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=337129, maxMem=278302556
15/10/21 17:00:33 INFO MemoryStore: Block broadcast_217 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:33 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=344137, maxMem=278302556
15/10/21 17:00:33 INFO MemoryStore: Block broadcast_217_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:33 INFO BlockManagerInfo: Added broadcast_217_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:33 INFO SparkContext: Created broadcast 217 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 216 (PythonRDD[222] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:33 INFO TaskSchedulerImpl: Adding task set 216.0 with 2 tasks
15/10/21 17:00:33 INFO TaskSetManager: Starting task 0.0 in stage 216.0 (TID 431, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:33 INFO TaskSetManager: Starting task 1.0 in stage 216.0 (TID 432, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:33 INFO Executor: Running task 0.0 in stage 216.0 (TID 431)
15/10/21 17:00:33 INFO Executor: Running task 1.0 in stage 216.0 (TID 432)
15/10/21 17:00:33 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:33 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:33 INFO PythonRDD: Times: total = 38, boot = -74, init = 112, finish = 0
15/10/21 17:00:33 INFO PythonRDD: Times: total = 38, boot = -69, init = 107, finish = 0
15/10/21 17:00:33 INFO Executor: Finished task 0.0 in stage 216.0 (TID 431). 1870 bytes result sent to driver
15/10/21 17:00:33 INFO Executor: Finished task 1.0 in stage 216.0 (TID 432). 1870 bytes result sent to driver
15/10/21 17:00:33 INFO TaskSetManager: Finished task 0.0 in stage 216.0 (TID 431) in 42 ms on localhost (1/2)
15/10/21 17:00:33 INFO TaskSetManager: Finished task 1.0 in stage 216.0 (TID 432) in 42 ms on localhost (2/2)
15/10/21 17:00:33 INFO TaskSchedulerImpl: Removed TaskSet 216.0, whose tasks have all completed, from pool 
15/10/21 17:00:33 INFO DAGScheduler: ResultStage 216 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:33 INFO DAGScheduler: Job 215 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.050436 s
15/10/21 17:00:33 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:33 INFO DAGScheduler: Got job 216 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:33 INFO DAGScheduler: Final stage: ResultStage 217(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:33 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:33 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:33 INFO DAGScheduler: Submitting ResultStage 217 (PythonRDD[223] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:33 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=348092, maxMem=278302556
15/10/21 17:00:33 INFO MemoryStore: Block broadcast_218 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:33 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=355100, maxMem=278302556
15/10/21 17:00:33 INFO MemoryStore: Block broadcast_218_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:33 INFO BlockManagerInfo: Added broadcast_218_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:33 INFO SparkContext: Created broadcast 218 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 217 (PythonRDD[223] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:33 INFO TaskSchedulerImpl: Adding task set 217.0 with 2 tasks
15/10/21 17:00:33 INFO TaskSetManager: Starting task 0.0 in stage 217.0 (TID 433, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:33 INFO TaskSetManager: Starting task 1.0 in stage 217.0 (TID 434, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:33 INFO Executor: Running task 0.0 in stage 217.0 (TID 433)
15/10/21 17:00:33 INFO Executor: Running task 1.0 in stage 217.0 (TID 434)
15/10/21 17:00:33 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:33 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:33 INFO PythonRDD: Times: total = 39, boot = -72, init = 111, finish = 0
15/10/21 17:00:33 INFO PythonRDD: Times: total = 39, boot = -71, init = 110, finish = 0
15/10/21 17:00:33 INFO Executor: Finished task 0.0 in stage 217.0 (TID 433). 1870 bytes result sent to driver
15/10/21 17:00:33 INFO Executor: Finished task 1.0 in stage 217.0 (TID 434). 1870 bytes result sent to driver
15/10/21 17:00:33 INFO TaskSetManager: Finished task 0.0 in stage 217.0 (TID 433) in 43 ms on localhost (1/2)
15/10/21 17:00:33 INFO TaskSetManager: Finished task 1.0 in stage 217.0 (TID 434) in 43 ms on localhost (2/2)
15/10/21 17:00:33 INFO TaskSchedulerImpl: Removed TaskSet 217.0, whose tasks have all completed, from pool 
15/10/21 17:00:33 INFO DAGScheduler: ResultStage 217 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:00:33 INFO DAGScheduler: Job 216 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.051576 s
15/10/21 17:00:33 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:33 INFO DAGScheduler: Got job 217 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:33 INFO DAGScheduler: Final stage: ResultStage 218(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:33 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:33 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:33 INFO DAGScheduler: Submitting ResultStage 218 (PythonRDD[224] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:33 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=359055, maxMem=278302556
15/10/21 17:00:33 INFO MemoryStore: Block broadcast_219 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:33 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=366063, maxMem=278302556
15/10/21 17:00:33 INFO MemoryStore: Block broadcast_219_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:00:33 INFO BlockManagerInfo: Added broadcast_219_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:33 INFO SparkContext: Created broadcast 219 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 218 (PythonRDD[224] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:33 INFO TaskSchedulerImpl: Adding task set 218.0 with 2 tasks
15/10/21 17:00:33 INFO TaskSetManager: Starting task 0.0 in stage 218.0 (TID 435, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:33 INFO TaskSetManager: Starting task 1.0 in stage 218.0 (TID 436, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:33 INFO Executor: Running task 1.0 in stage 218.0 (TID 436)
15/10/21 17:00:33 INFO Executor: Running task 0.0 in stage 218.0 (TID 435)
15/10/21 17:00:33 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:33 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:33 INFO PythonRDD: Times: total = 39, boot = -72, init = 111, finish = 0
15/10/21 17:00:33 INFO PythonRDD: Times: total = 38, boot = -74, init = 112, finish = 0
15/10/21 17:00:33 INFO Executor: Finished task 1.0 in stage 218.0 (TID 436). 1870 bytes result sent to driver
15/10/21 17:00:33 INFO Executor: Finished task 0.0 in stage 218.0 (TID 435). 1870 bytes result sent to driver
15/10/21 17:00:33 INFO TaskSetManager: Finished task 1.0 in stage 218.0 (TID 436) in 41 ms on localhost (1/2)
15/10/21 17:00:33 INFO TaskSetManager: Finished task 0.0 in stage 218.0 (TID 435) in 43 ms on localhost (2/2)
15/10/21 17:00:33 INFO TaskSchedulerImpl: Removed TaskSet 218.0, whose tasks have all completed, from pool 
15/10/21 17:00:33 INFO DAGScheduler: ResultStage 218 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:00:33 INFO DAGScheduler: Job 217 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.050100 s
15/10/21 17:00:33 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:33 INFO DAGScheduler: Got job 218 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:33 INFO DAGScheduler: Final stage: ResultStage 219(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:33 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:33 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:33 INFO DAGScheduler: Submitting ResultStage 219 (PythonRDD[225] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:33 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=370018, maxMem=278302556
15/10/21 17:00:33 INFO MemoryStore: Block broadcast_220 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:00:33 INFO MemoryStore: ensureFreeSpace(3958) called with curMem=377026, maxMem=278302556
15/10/21 17:00:33 INFO MemoryStore: Block broadcast_220_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:00:33 INFO BlockManagerInfo: Added broadcast_220_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:33 INFO SparkContext: Created broadcast 220 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 219 (PythonRDD[225] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:33 INFO TaskSchedulerImpl: Adding task set 219.0 with 2 tasks
15/10/21 17:00:33 INFO TaskSetManager: Starting task 0.0 in stage 219.0 (TID 437, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:33 INFO TaskSetManager: Starting task 1.0 in stage 219.0 (TID 438, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:33 INFO Executor: Running task 0.0 in stage 219.0 (TID 437)
15/10/21 17:00:33 INFO Executor: Running task 1.0 in stage 219.0 (TID 438)
15/10/21 17:00:33 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:33 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:33 INFO PythonRDD: Times: total = 38, boot = -71, init = 109, finish = 0
15/10/21 17:00:33 INFO PythonRDD: Times: total = 38, boot = -72, init = 110, finish = 0
15/10/21 17:00:33 INFO Executor: Finished task 0.0 in stage 219.0 (TID 437). 1870 bytes result sent to driver
15/10/21 17:00:33 INFO Executor: Finished task 1.0 in stage 219.0 (TID 438). 1870 bytes result sent to driver
15/10/21 17:00:33 INFO TaskSetManager: Finished task 0.0 in stage 219.0 (TID 437) in 41 ms on localhost (1/2)
15/10/21 17:00:33 INFO TaskSetManager: Finished task 1.0 in stage 219.0 (TID 438) in 42 ms on localhost (2/2)
15/10/21 17:00:33 INFO TaskSchedulerImpl: Removed TaskSet 219.0, whose tasks have all completed, from pool 
15/10/21 17:00:33 INFO DAGScheduler: ResultStage 219 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.042 s
15/10/21 17:00:33 INFO DAGScheduler: Job 218 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.050022 s
15/10/21 17:00:33 INFO SparkContext: Starting job: count at <ipython-input-46-d3fd33c73668>:3
15/10/21 17:00:33 INFO DAGScheduler: Got job 219 (count at <ipython-input-46-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:00:33 INFO DAGScheduler: Final stage: ResultStage 220(count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:33 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:00:33 INFO DAGScheduler: Missing parents: List()
15/10/21 17:00:33 INFO DAGScheduler: Submitting ResultStage 220 (PythonRDD[226] at count at <ipython-input-46-d3fd33c73668>:3), which has no missing parents
15/10/21 17:00:33 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=380984, maxMem=278302556
15/10/21 17:00:33 INFO MemoryStore: Block broadcast_221 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:00:33 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=387992, maxMem=278302556
15/10/21 17:00:33 INFO MemoryStore: Block broadcast_221_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:00:33 INFO BlockManagerInfo: Added broadcast_221_piece0 in memory on localhost:54908 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:00:33 INFO SparkContext: Created broadcast 221 from broadcast at DAGScheduler.scala:874
15/10/21 17:00:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 220 (PythonRDD[226] at count at <ipython-input-46-d3fd33c73668>:3)
15/10/21 17:00:33 INFO TaskSchedulerImpl: Adding task set 220.0 with 2 tasks
15/10/21 17:00:33 INFO TaskSetManager: Starting task 0.0 in stage 220.0 (TID 439, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:33 INFO TaskSetManager: Starting task 1.0 in stage 220.0 (TID 440, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:00:33 INFO Executor: Running task 0.0 in stage 220.0 (TID 439)
15/10/21 17:00:33 INFO Executor: Running task 1.0 in stage 220.0 (TID 440)
15/10/21 17:00:33 INFO BlockManager: Found block rdd_12_0 locally
15/10/21 17:00:33 INFO BlockManager: Found block rdd_12_1 locally
15/10/21 17:00:33 INFO PythonRDD: Times: total = 40, boot = -69, init = 109, finish = 0
15/10/21 17:00:33 INFO PythonRDD: Times: total = 40, boot = -68, init = 108, finish = 0
15/10/21 17:00:33 INFO Executor: Finished task 0.0 in stage 220.0 (TID 439). 1870 bytes result sent to driver
15/10/21 17:00:33 INFO Executor: Finished task 1.0 in stage 220.0 (TID 440). 1870 bytes result sent to driver
15/10/21 17:00:33 INFO TaskSetManager: Finished task 1.0 in stage 220.0 (TID 440) in 44 ms on localhost (1/2)
15/10/21 17:00:33 INFO TaskSetManager: Finished task 0.0 in stage 220.0 (TID 439) in 44 ms on localhost (2/2)
15/10/21 17:00:33 INFO TaskSchedulerImpl: Removed TaskSet 220.0, whose tasks have all completed, from pool 
15/10/21 17:00:33 INFO DAGScheduler: ResultStage 220 (count at <ipython-input-46-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:00:33 INFO DAGScheduler: Job 219 finished: count at <ipython-input-46-d3fd33c73668>:3, took 0.052039 s
15/10/21 17:01:16 INFO PythonRDD: Removing RDD 12 from persistence list
15/10/21 17:01:16 INFO BlockManager: Removing RDD 12
15/10/21 17:01:27 INFO SparkContext: Starting job: count at <ipython-input-52-e4ff7c746e95>:1
15/10/21 17:01:27 INFO DAGScheduler: Got job 220 (count at <ipython-input-52-e4ff7c746e95>:1) with 2 output partitions (allowLocal=false)
15/10/21 17:01:27 INFO DAGScheduler: Final stage: ResultStage 221(count at <ipython-input-52-e4ff7c746e95>:1)
15/10/21 17:01:27 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:01:27 INFO DAGScheduler: Missing parents: List()
15/10/21 17:01:27 INFO DAGScheduler: Submitting ResultStage 221 (PythonRDD[227] at count at <ipython-input-52-e4ff7c746e95>:1), which has no missing parents
15/10/21 17:01:27 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=390768, maxMem=278302556
15/10/21 17:01:27 INFO MemoryStore: Block broadcast_222 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:01:27 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=397160, maxMem=278302556
15/10/21 17:01:27 INFO MemoryStore: Block broadcast_222_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:01:27 INFO BlockManagerInfo: Added broadcast_222_piece0 in memory on localhost:54908 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:01:27 INFO BlockManagerInfo: Removed broadcast_221_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:01:27 INFO SparkContext: Created broadcast 222 from broadcast at DAGScheduler.scala:874
15/10/21 17:01:27 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 221 (PythonRDD[227] at count at <ipython-input-52-e4ff7c746e95>:1)
15/10/21 17:01:27 INFO TaskSchedulerImpl: Adding task set 221.0 with 2 tasks
15/10/21 17:01:27 INFO TaskSetManager: Starting task 0.0 in stage 221.0 (TID 441, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:01:27 INFO TaskSetManager: Starting task 1.0 in stage 221.0 (TID 442, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:01:27 INFO BlockManagerInfo: Removed broadcast_220_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:01:27 INFO Executor: Running task 0.0 in stage 221.0 (TID 441)
15/10/21 17:01:27 INFO Executor: Running task 1.0 in stage 221.0 (TID 442)
15/10/21 17:01:27 INFO BlockManagerInfo: Removed broadcast_219_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:01:27 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:01:27 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:01:27 INFO BlockManagerInfo: Removed broadcast_218_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:01:27 INFO BlockManagerInfo: Removed broadcast_217_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:01:27 INFO BlockManagerInfo: Removed broadcast_216_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:01:27 INFO BlockManagerInfo: Removed broadcast_215_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:01:27 INFO BlockManagerInfo: Removed broadcast_214_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:01:27 INFO BlockManagerInfo: Removed broadcast_203_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:01:27 INFO BlockManagerInfo: Removed broadcast_211_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:01:27 INFO BlockManagerInfo: Removed broadcast_210_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:01:27 INFO BlockManagerInfo: Removed broadcast_209_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:01:27 INFO BlockManagerInfo: Removed broadcast_208_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:01:27 INFO BlockManagerInfo: Removed broadcast_207_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:01:27 INFO BlockManagerInfo: Removed broadcast_206_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:01:27 INFO BlockManagerInfo: Removed broadcast_205_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:01:27 INFO BlockManagerInfo: Removed broadcast_204_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:01:27 INFO BlockManagerInfo: Removed broadcast_213_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:01:27 INFO BlockManagerInfo: Removed broadcast_212_piece0 on localhost:54908 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:01:27 INFO PythonRDD: Times: total = 39, boot = -54248, init = 54287, finish = 0
15/10/21 17:01:27 INFO PythonRDD: Times: total = 39, boot = -54249, init = 54288, finish = 0
15/10/21 17:01:27 INFO Executor: Finished task 1.0 in stage 221.0 (TID 442). 1870 bytes result sent to driver
15/10/21 17:01:27 INFO Executor: Finished task 0.0 in stage 221.0 (TID 441). 1870 bytes result sent to driver
15/10/21 17:01:27 INFO TaskSetManager: Finished task 1.0 in stage 221.0 (TID 442) in 42 ms on localhost (1/2)
15/10/21 17:01:27 INFO TaskSetManager: Finished task 0.0 in stage 221.0 (TID 441) in 43 ms on localhost (2/2)
15/10/21 17:01:27 INFO TaskSchedulerImpl: Removed TaskSet 221.0, whose tasks have all completed, from pool 
15/10/21 17:01:27 INFO DAGScheduler: ResultStage 221 (count at <ipython-input-52-e4ff7c746e95>:1) finished in 0.044 s
15/10/21 17:01:27 INFO DAGScheduler: Job 220 finished: count at <ipython-input-52-e4ff7c746e95>:1, took 0.056349 s
[I 17:01:41.568 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[I 17:02:06.519 NotebookApp] Request restart_kernel: 66656a3b-1fea-4dac-b8a8-45cef547f01d, <IPython.kernel.ioloop.manager.IOLoopKernelManager object at 0x7fd6317fbdd0>
15/10/21 17:02:06 INFO SparkUI: Stopped Spark web UI at http://172.17.0.22:4049
15/10/21 17:02:06 INFO DAGScheduler: Stopping DAGScheduler
15/10/21 17:02:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/10/21 17:02:06 INFO Utils: path = /tmp/spark-6e54b9ef-eeee-4cb9-bdd3-c91f0bfba6e8/blockmgr-586c41e5-996a-4a68-87a5-5b736a9618b6, already present as root for deletion.
15/10/21 17:02:06 INFO MemoryStore: MemoryStore cleared
15/10/21 17:02:06 INFO BlockManager: BlockManager stopped
15/10/21 17:02:06 INFO BlockManagerMaster: BlockManagerMaster stopped
15/10/21 17:02:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/10/21 17:02:06 INFO SparkContext: Successfully stopped SparkContext
15/10/21 17:02:06 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/10/21 17:02:06 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/10/21 17:02:06 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
15/10/21 17:02:07 INFO Utils: Shutdown hook called
15/10/21 17:02:07 INFO Utils: Deleting directory /tmp/spark-6e54b9ef-eeee-4cb9-bdd3-c91f0bfba6e8
[I 17:02:07.578 NotebookApp] Kernel restarted: 66656a3b-1fea-4dac-b8a8-45cef547f01d
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/21 17:02:10 INFO SparkContext: Running Spark version 1.4.1
15/10/21 17:02:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/21 17:02:11 INFO SecurityManager: Changing view acls to: notebook
15/10/21 17:02:11 INFO SecurityManager: Changing modify acls to: notebook
15/10/21 17:02:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
15/10/21 17:02:12 INFO Slf4jLogger: Slf4jLogger started
15/10/21 17:02:12 INFO Remoting: Starting remoting
15/10/21 17:02:12 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.22:42749]
15/10/21 17:02:12 INFO Utils: Successfully started service 'sparkDriver' on port 42749.
15/10/21 17:02:12 INFO SparkEnv: Registering MapOutputTracker
15/10/21 17:02:12 INFO SparkEnv: Registering BlockManagerMaster
15/10/21 17:02:12 INFO DiskBlockManager: Created local directory at /tmp/spark-dc939ed3-9bec-4751-8e83-df927a97a500/blockmgr-264e8036-5ed0-4b03-b896-6ff04e27f572
15/10/21 17:02:12 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/10/21 17:02:12 INFO HttpFileServer: HTTP File server directory is /tmp/spark-dc939ed3-9bec-4751-8e83-df927a97a500/httpd-fc7a9c70-76bc-4605-958f-e115bd3e8d47
15/10/21 17:02:12 INFO HttpServer: Starting HTTP Server
15/10/21 17:02:12 INFO Utils: Successfully started service 'HTTP file server' on port 56787.
15/10/21 17:02:12 INFO SparkEnv: Registering OutputCommitCoordinator
15/10/21 17:02:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/10/21 17:02:13 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
15/10/21 17:02:13 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
15/10/21 17:02:13 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
15/10/21 17:02:13 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
15/10/21 17:02:13 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
15/10/21 17:02:13 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.
15/10/21 17:02:13 WARN Utils: Service 'SparkUI' could not bind on port 4047. Attempting port 4048.
15/10/21 17:02:13 WARN Utils: Service 'SparkUI' could not bind on port 4048. Attempting port 4049.
15/10/21 17:02:13 INFO Utils: Successfully started service 'SparkUI' on port 4049.
15/10/21 17:02:13 INFO SparkUI: Started SparkUI at http://172.17.0.22:4049
15/10/21 17:02:13 INFO Executor: Starting executor ID driver on host localhost
15/10/21 17:02:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45162.
15/10/21 17:02:13 INFO NettyBlockTransferService: Server created on 45162
15/10/21 17:02:13 INFO BlockManagerMaster: Trying to register BlockManager
15/10/21 17:02:13 INFO BlockManagerMasterEndpoint: Registering block manager localhost:45162 with 265.4 MB RAM, BlockManagerId(driver, localhost, 45162)
15/10/21 17:02:13 INFO BlockManagerMaster: Registered BlockManager
15/10/21 17:02:29 INFO MemoryStore: ensureFreeSpace(157248) called with curMem=0, maxMem=278302556
15/10/21 17:02:29 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 153.6 KB, free 265.3 MB)
15/10/21 17:02:29 INFO MemoryStore: ensureFreeSpace(14257) called with curMem=157248, maxMem=278302556
15/10/21 17:02:29 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 13.9 KB, free 265.2 MB)
15/10/21 17:02:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:45162 (size: 13.9 KB, free: 265.4 MB)
15/10/21 17:02:29 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2
15/10/21 17:02:43 INFO MemoryStore: ensureFreeSpace(88472) called with curMem=171505, maxMem=278302556
15/10/21 17:02:43 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 86.4 KB, free 265.2 MB)
15/10/21 17:02:43 INFO MemoryStore: ensureFreeSpace(19750) called with curMem=259977, maxMem=278302556
15/10/21 17:02:43 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 19.3 KB, free 265.1 MB)
15/10/21 17:02:43 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:45162 (size: 19.3 KB, free: 265.4 MB)
15/10/21 17:02:43 INFO SparkContext: Created broadcast 1 from textFile at NativeMethodAccessorImpl.java:-2
15/10/21 17:02:44 INFO FileInputFormat: Total input paths to process : 1
15/10/21 17:02:44 INFO SparkContext: Starting job: count at <ipython-input-8-98a3501d210e>:1
15/10/21 17:02:44 INFO DAGScheduler: Got job 0 (count at <ipython-input-8-98a3501d210e>:1) with 2 output partitions (allowLocal=false)
15/10/21 17:02:44 INFO DAGScheduler: Final stage: ResultStage 0(count at <ipython-input-8-98a3501d210e>:1)
15/10/21 17:02:44 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:02:44 INFO DAGScheduler: Missing parents: List()
15/10/21 17:02:44 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[6] at count at <ipython-input-8-98a3501d210e>:1), which has no missing parents
15/10/21 17:02:44 INFO MemoryStore: ensureFreeSpace(6024) called with curMem=279727, maxMem=278302556
15/10/21 17:02:44 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.9 KB, free 265.1 MB)
15/10/21 17:02:44 INFO MemoryStore: ensureFreeSpace(3555) called with curMem=285751, maxMem=278302556
15/10/21 17:02:44 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.5 KB, free 265.1 MB)
15/10/21 17:02:44 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:45162 (size: 3.5 KB, free: 265.4 MB)
15/10/21 17:02:44 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:874
15/10/21 17:02:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[6] at count at <ipython-input-8-98a3501d210e>:1)
15/10/21 17:02:44 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/10/21 17:02:44 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:02:44 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:02:44 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/10/21 17:02:44 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/10/21 17:02:48 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:02:48 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
15/10/21 17:02:48 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
15/10/21 17:02:48 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
15/10/21 17:02:48 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
15/10/21 17:02:48 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
15/10/21 17:02:48 INFO PythonRDD: Times: total = 3718, boot = 3677, init = 41, finish = 0
15/10/21 17:02:48 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:02:48 INFO PythonRDD: Times: total = 3743, boot = 3736, init = 7, finish = 0
15/10/21 17:02:48 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1870 bytes result sent to driver
15/10/21 17:02:48 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1870 bytes result sent to driver
15/10/21 17:02:48 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3823 ms on localhost (1/2)
15/10/21 17:02:48 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 3812 ms on localhost (2/2)
15/10/21 17:02:48 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/10/21 17:02:48 INFO DAGScheduler: ResultStage 0 (count at <ipython-input-8-98a3501d210e>:1) finished in 3.845 s
15/10/21 17:02:48 INFO DAGScheduler: Job 0 finished: count at <ipython-input-8-98a3501d210e>:1, took 3.968554 s
15/10/21 17:02:50 INFO SparkContext: Starting job: runJob at PythonRDD.scala:366
15/10/21 17:02:50 INFO DAGScheduler: Got job 1 (runJob at PythonRDD.scala:366) with 1 output partitions (allowLocal=true)
15/10/21 17:02:50 INFO DAGScheduler: Final stage: ResultStage 1(runJob at PythonRDD.scala:366)
15/10/21 17:02:50 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:02:50 INFO DAGScheduler: Missing parents: List()
15/10/21 17:02:50 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[7] at RDD at PythonRDD.scala:43), which has no missing parents
15/10/21 17:02:50 INFO MemoryStore: ensureFreeSpace(5136) called with curMem=289306, maxMem=278302556
15/10/21 17:02:50 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 5.0 KB, free 265.1 MB)
15/10/21 17:02:50 INFO MemoryStore: ensureFreeSpace(3077) called with curMem=294442, maxMem=278302556
15/10/21 17:02:50 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.0 KB, free 265.1 MB)
15/10/21 17:02:50 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:45162 (size: 3.0 KB, free: 265.4 MB)
15/10/21 17:02:50 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:874
15/10/21 17:02:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (PythonRDD[7] at RDD at PythonRDD.scala:43)
15/10/21 17:02:50 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
15/10/21 17:02:50 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:02:50 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/10/21 17:02:50 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:02:50 INFO PythonRDD: Times: total = 40, boot = -2163, init = 2203, finish = 0
15/10/21 17:02:50 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1889 bytes result sent to driver
15/10/21 17:02:50 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 54 ms on localhost (1/1)
15/10/21 17:02:50 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/10/21 17:02:50 INFO DAGScheduler: ResultStage 1 (runJob at PythonRDD.scala:366) finished in 0.054 s
15/10/21 17:02:50 INFO DAGScheduler: Job 1 finished: runJob at PythonRDD.scala:366, took 0.071983 s
15/10/21 17:02:51 INFO SparkContext: Starting job: count at <ipython-input-10-af61aa398f2b>:3
15/10/21 17:02:51 INFO DAGScheduler: Got job 2 (count at <ipython-input-10-af61aa398f2b>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:02:51 INFO DAGScheduler: Final stage: ResultStage 2(count at <ipython-input-10-af61aa398f2b>:3)
15/10/21 17:02:51 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:02:51 INFO DAGScheduler: Missing parents: List()
15/10/21 17:02:51 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[8] at count at <ipython-input-10-af61aa398f2b>:3), which has no missing parents
15/10/21 17:02:51 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=297519, maxMem=278302556
15/10/21 17:02:51 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:02:51 INFO MemoryStore: ensureFreeSpace(3806) called with curMem=303911, maxMem=278302556
15/10/21 17:02:51 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:02:51 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:02:51 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:874
15/10/21 17:02:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[8] at count at <ipython-input-10-af61aa398f2b>:3)
15/10/21 17:02:51 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/10/21 17:02:51 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 3, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:02:51 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:02:51 INFO Executor: Running task 0.0 in stage 2.0 (TID 3)
15/10/21 17:02:51 INFO Executor: Running task 1.0 in stage 2.0 (TID 4)
15/10/21 17:02:51 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:02:51 INFO PythonRDD: Times: total = 40, boot = -2992, init = 3032, finish = 0
15/10/21 17:02:51 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:02:51 INFO Executor: Finished task 0.0 in stage 2.0 (TID 3). 1870 bytes result sent to driver
15/10/21 17:02:51 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 3) in 78 ms on localhost (1/2)
15/10/21 17:02:51 INFO PythonRDD: Times: total = 71, boot = 65, init = 5, finish = 1
15/10/21 17:02:51 INFO Executor: Finished task 1.0 in stage 2.0 (TID 4). 1870 bytes result sent to driver
15/10/21 17:02:51 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 4) in 84 ms on localhost (2/2)
15/10/21 17:02:51 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/10/21 17:02:51 INFO DAGScheduler: ResultStage 2 (count at <ipython-input-10-af61aa398f2b>:3) finished in 0.086 s
15/10/21 17:02:51 INFO DAGScheduler: Job 2 finished: count at <ipython-input-10-af61aa398f2b>:3, took 0.102340 s
15/10/21 17:02:52 INFO SparkContext: Starting job: reduce at <ipython-input-11-1df081d8b441>:1
15/10/21 17:02:52 INFO DAGScheduler: Got job 3 (reduce at <ipython-input-11-1df081d8b441>:1) with 2 output partitions (allowLocal=false)
15/10/21 17:02:52 INFO DAGScheduler: Final stage: ResultStage 3(reduce at <ipython-input-11-1df081d8b441>:1)
15/10/21 17:02:52 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:02:52 INFO DAGScheduler: Missing parents: List()
15/10/21 17:02:52 INFO DAGScheduler: Submitting ResultStage 3 (PythonRDD[9] at reduce at <ipython-input-11-1df081d8b441>:1), which has no missing parents
15/10/21 17:02:52 INFO MemoryStore: ensureFreeSpace(5976) called with curMem=307717, maxMem=278302556
15/10/21 17:02:52 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 5.8 KB, free 265.1 MB)
15/10/21 17:02:52 INFO MemoryStore: ensureFreeSpace(3579) called with curMem=313693, maxMem=278302556
15/10/21 17:02:52 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.5 KB, free 265.1 MB)
15/10/21 17:02:52 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:45162 (size: 3.5 KB, free: 265.4 MB)
15/10/21 17:02:52 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:874
15/10/21 17:02:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (PythonRDD[9] at reduce at <ipython-input-11-1df081d8b441>:1)
15/10/21 17:02:52 INFO TaskSchedulerImpl: Adding task set 3.0 with 2 tasks
15/10/21 17:02:52 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 5, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:02:52 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 6, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:02:52 INFO Executor: Running task 0.0 in stage 3.0 (TID 5)
15/10/21 17:02:52 INFO Executor: Running task 1.0 in stage 3.0 (TID 6)
15/10/21 17:02:52 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:02:52 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:02:52 INFO PythonRDD: Times: total = 38, boot = -1272, init = 1310, finish = 0
15/10/21 17:02:52 INFO PythonRDD: Times: total = 39, boot = -1351, init = 1390, finish = 0
15/10/21 17:02:52 INFO Executor: Finished task 1.0 in stage 3.0 (TID 6). 1870 bytes result sent to driver
15/10/21 17:02:52 INFO Executor: Finished task 0.0 in stage 3.0 (TID 5). 1870 bytes result sent to driver
15/10/21 17:02:52 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 6) in 54 ms on localhost (1/2)
15/10/21 17:02:52 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 5) in 56 ms on localhost (2/2)
15/10/21 17:02:52 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
15/10/21 17:02:52 INFO DAGScheduler: ResultStage 3 (reduce at <ipython-input-11-1df081d8b441>:1) finished in 0.057 s
15/10/21 17:02:52 INFO DAGScheduler: Job 3 finished: reduce at <ipython-input-11-1df081d8b441>:1, took 0.076705 s
15/10/21 17:02:53 INFO SparkContext: Starting job: reduce at <ipython-input-13-7ec28932a355>:1
15/10/21 17:02:53 INFO DAGScheduler: Got job 4 (reduce at <ipython-input-13-7ec28932a355>:1) with 2 output partitions (allowLocal=false)
15/10/21 17:02:53 INFO DAGScheduler: Final stage: ResultStage 4(reduce at <ipython-input-13-7ec28932a355>:1)
15/10/21 17:02:53 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:02:53 INFO DAGScheduler: Missing parents: List()
15/10/21 17:02:53 INFO DAGScheduler: Submitting ResultStage 4 (PythonRDD[10] at reduce at <ipython-input-13-7ec28932a355>:1), which has no missing parents
15/10/21 17:02:53 INFO MemoryStore: ensureFreeSpace(5992) called with curMem=317272, maxMem=278302556
15/10/21 17:02:53 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 5.9 KB, free 265.1 MB)
15/10/21 17:02:53 INFO MemoryStore: ensureFreeSpace(3608) called with curMem=323264, maxMem=278302556
15/10/21 17:02:53 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.5 KB, free 265.1 MB)
15/10/21 17:02:53 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:45162 (size: 3.5 KB, free: 265.4 MB)
15/10/21 17:02:53 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:874
15/10/21 17:02:53 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (PythonRDD[10] at reduce at <ipython-input-13-7ec28932a355>:1)
15/10/21 17:02:53 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks
15/10/21 17:02:53 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 7, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:02:53 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 8, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:02:53 INFO Executor: Running task 0.0 in stage 4.0 (TID 7)
15/10/21 17:02:53 INFO Executor: Running task 1.0 in stage 4.0 (TID 8)
15/10/21 17:02:53 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:02:53 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:02:53 INFO PythonRDD: Times: total = 38, boot = -710, init = 748, finish = 0
15/10/21 17:02:53 INFO Executor: Finished task 1.0 in stage 4.0 (TID 8). 1870 bytes result sent to driver
15/10/21 17:02:53 INFO PythonRDD: Times: total = 41, boot = -709, init = 750, finish = 0
15/10/21 17:02:53 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 8) in 52 ms on localhost (1/2)
15/10/21 17:02:53 INFO Executor: Finished task 0.0 in stage 4.0 (TID 7). 1870 bytes result sent to driver
15/10/21 17:02:53 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 7) in 57 ms on localhost (2/2)
15/10/21 17:02:53 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
15/10/21 17:02:53 INFO DAGScheduler: ResultStage 4 (reduce at <ipython-input-13-7ec28932a355>:1) finished in 0.057 s
15/10/21 17:02:53 INFO DAGScheduler: Job 4 finished: reduce at <ipython-input-13-7ec28932a355>:1, took 0.075173 s
15/10/21 17:02:53 INFO SparkContext: Starting job: collect at <ipython-input-15-be52ca2d5e05>:1
15/10/21 17:02:53 INFO DAGScheduler: Registering RDD 12 (reduceByKey at <ipython-input-14-fa54d2c9e6e8>:1)
15/10/21 17:02:53 INFO DAGScheduler: Got job 5 (collect at <ipython-input-15-be52ca2d5e05>:1) with 2 output partitions (allowLocal=false)
15/10/21 17:02:53 INFO DAGScheduler: Final stage: ResultStage 6(collect at <ipython-input-15-be52ca2d5e05>:1)
15/10/21 17:02:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
15/10/21 17:02:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
15/10/21 17:02:53 INFO DAGScheduler: Submitting ShuffleMapStage 5 (PairwiseRDD[12] at reduceByKey at <ipython-input-14-fa54d2c9e6e8>:1), which has no missing parents
15/10/21 17:02:53 INFO MemoryStore: ensureFreeSpace(8560) called with curMem=326872, maxMem=278302556
15/10/21 17:02:53 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 8.4 KB, free 265.1 MB)
15/10/21 17:02:53 INFO MemoryStore: ensureFreeSpace(5267) called with curMem=335432, maxMem=278302556
15/10/21 17:02:53 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.1 KB, free 265.1 MB)
15/10/21 17:02:53 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:45162 (size: 5.1 KB, free: 265.4 MB)
15/10/21 17:02:53 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:874
15/10/21 17:02:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 5 (PairwiseRDD[12] at reduceByKey at <ipython-input-14-fa54d2c9e6e8>:1)
15/10/21 17:02:53 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks
15/10/21 17:02:53 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 9, localhost, PROCESS_LOCAL, 1387 bytes)
15/10/21 17:02:53 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 10, localhost, PROCESS_LOCAL, 1387 bytes)
15/10/21 17:02:53 INFO Executor: Running task 0.0 in stage 5.0 (TID 9)
15/10/21 17:02:53 INFO Executor: Running task 1.0 in stage 5.0 (TID 10)
15/10/21 17:02:53 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:02:53 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:02:54 INFO PythonRDD: Times: total = 40, boot = -421, init = 459, finish = 2
15/10/21 17:02:54 INFO PythonRDD: Times: total = 40, boot = -418, init = 456, finish = 2
15/10/21 17:02:54 INFO Executor: Finished task 0.0 in stage 5.0 (TID 9). 2064 bytes result sent to driver
15/10/21 17:02:54 INFO Executor: Finished task 1.0 in stage 5.0 (TID 10). 2064 bytes result sent to driver
15/10/21 17:02:54 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 10) in 106 ms on localhost (1/2)
15/10/21 17:02:54 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 9) in 108 ms on localhost (2/2)
15/10/21 17:02:54 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
15/10/21 17:02:54 INFO DAGScheduler: ShuffleMapStage 5 (reduceByKey at <ipython-input-14-fa54d2c9e6e8>:1) finished in 0.111 s
15/10/21 17:02:54 INFO DAGScheduler: looking for newly runnable stages
15/10/21 17:02:54 INFO DAGScheduler: running: Set()
15/10/21 17:02:54 INFO DAGScheduler: waiting: Set(ResultStage 6)
15/10/21 17:02:54 INFO DAGScheduler: failed: Set()
15/10/21 17:02:54 INFO DAGScheduler: Missing parents for ResultStage 6: List()
15/10/21 17:02:54 INFO DAGScheduler: Submitting ResultStage 6 (PythonRDD[15] at collect at <ipython-input-15-be52ca2d5e05>:1), which is now runnable
15/10/21 17:02:54 INFO MemoryStore: ensureFreeSpace(5136) called with curMem=340699, maxMem=278302556
15/10/21 17:02:54 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 5.0 KB, free 265.1 MB)
15/10/21 17:02:54 INFO MemoryStore: ensureFreeSpace(3084) called with curMem=345835, maxMem=278302556
15/10/21 17:02:54 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.0 KB, free 265.1 MB)
15/10/21 17:02:54 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:45162 (size: 3.0 KB, free: 265.4 MB)
15/10/21 17:02:54 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:874
15/10/21 17:02:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 6 (PythonRDD[15] at collect at <ipython-input-15-be52ca2d5e05>:1)
15/10/21 17:02:54 INFO TaskSchedulerImpl: Adding task set 6.0 with 2 tasks
15/10/21 17:02:54 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 11, localhost, PROCESS_LOCAL, 1165 bytes)
15/10/21 17:02:54 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 12, localhost, PROCESS_LOCAL, 1165 bytes)
15/10/21 17:02:54 INFO Executor: Running task 0.0 in stage 6.0 (TID 11)
15/10/21 17:02:54 INFO Executor: Running task 1.0 in stage 6.0 (TID 12)
15/10/21 17:02:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/10/21 17:02:54 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/10/21 17:02:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
15/10/21 17:02:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
15/10/21 17:02:54 INFO PythonRDD: Times: total = 41, boot = -67, init = 107, finish = 1
15/10/21 17:02:54 INFO Executor: Finished task 1.0 in stage 6.0 (TID 12). 3461 bytes result sent to driver
15/10/21 17:02:54 INFO PythonRDD: Times: total = 45, boot = -65, init = 109, finish = 1
15/10/21 17:02:54 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 12) in 52 ms on localhost (1/2)
15/10/21 17:02:54 INFO Executor: Finished task 0.0 in stage 6.0 (TID 11). 3685 bytes result sent to driver
15/10/21 17:02:54 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 11) in 56 ms on localhost (2/2)
15/10/21 17:02:54 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
15/10/21 17:02:54 INFO DAGScheduler: ResultStage 6 (collect at <ipython-input-15-be52ca2d5e05>:1) finished in 0.057 s
15/10/21 17:02:54 INFO DAGScheduler: Job 5 finished: collect at <ipython-input-15-be52ca2d5e05>:1, took 0.222901 s
15/10/21 17:03:35 INFO SparkContext: Starting job: count at <ipython-input-18-e4ff7c746e95>:1
15/10/21 17:03:35 INFO DAGScheduler: Got job 6 (count at <ipython-input-18-e4ff7c746e95>:1) with 2 output partitions (allowLocal=false)
15/10/21 17:03:35 INFO DAGScheduler: Final stage: ResultStage 7(count at <ipython-input-18-e4ff7c746e95>:1)
15/10/21 17:03:35 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:35 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:35 INFO DAGScheduler: Submitting ResultStage 7 (PythonRDD[17] at count at <ipython-input-18-e4ff7c746e95>:1), which has no missing parents
15/10/21 17:03:35 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=348919, maxMem=278302556
15/10/21 17:03:35 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:03:35 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=355311, maxMem=278302556
15/10/21 17:03:35 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:03:35 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:35 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 7 (PythonRDD[17] at count at <ipython-input-18-e4ff7c746e95>:1)
15/10/21 17:03:35 INFO TaskSchedulerImpl: Adding task set 7.0 with 2 tasks
15/10/21 17:03:35 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 13, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:35 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 14, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:35 INFO Executor: Running task 0.0 in stage 7.0 (TID 13)
15/10/21 17:03:35 INFO Executor: Running task 1.0 in stage 7.0 (TID 14)
15/10/21 17:03:35 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:35 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:35 INFO PythonRDD: Times: total = 38, boot = -41326, init = 41364, finish = 0
15/10/21 17:03:35 INFO PythonRDD: Times: total = 38, boot = -41327, init = 41365, finish = 0
15/10/21 17:03:35 INFO Executor: Finished task 1.0 in stage 7.0 (TID 14). 1870 bytes result sent to driver
15/10/21 17:03:35 INFO Executor: Finished task 0.0 in stage 7.0 (TID 13). 1870 bytes result sent to driver
15/10/21 17:03:35 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 14) in 52 ms on localhost (1/2)
15/10/21 17:03:35 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 13) in 54 ms on localhost (2/2)
15/10/21 17:03:35 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
15/10/21 17:03:35 INFO DAGScheduler: ResultStage 7 (count at <ipython-input-18-e4ff7c746e95>:1) finished in 0.054 s
15/10/21 17:03:35 INFO DAGScheduler: Job 6 finished: count at <ipython-input-18-e4ff7c746e95>:1, took 0.069942 s
[I 17:03:41.560 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
15/10/21 17:03:41 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:41 INFO DAGScheduler: Got job 7 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:41 INFO DAGScheduler: Final stage: ResultStage 8(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:41 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:41 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:41 INFO DAGScheduler: Submitting ResultStage 8 (PythonRDD[18] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:41 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=359116, maxMem=278302556
15/10/21 17:03:41 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:03:41 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=365508, maxMem=278302556
15/10/21 17:03:41 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:03:41 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:41 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:41 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 8 (PythonRDD[18] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:41 INFO TaskSchedulerImpl: Adding task set 8.0 with 2 tasks
15/10/21 17:03:41 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 15, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:41 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 16, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:41 INFO Executor: Running task 0.0 in stage 8.0 (TID 15)
15/10/21 17:03:41 INFO Executor: Running task 1.0 in stage 8.0 (TID 16)
15/10/21 17:03:41 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:42 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:42 INFO PythonRDD: Times: total = 40, boot = -6488, init = 6528, finish = 0
15/10/21 17:03:42 INFO PythonRDD: Times: total = 41, boot = -6486, init = 6527, finish = 0
15/10/21 17:03:42 INFO Executor: Finished task 0.0 in stage 8.0 (TID 15). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO Executor: Finished task 1.0 in stage 8.0 (TID 16). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 15) in 56 ms on localhost (1/2)
15/10/21 17:03:42 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 16) in 55 ms on localhost (2/2)
15/10/21 17:03:42 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
15/10/21 17:03:42 INFO DAGScheduler: ResultStage 8 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.058 s
15/10/21 17:03:42 INFO DAGScheduler: Job 7 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.073842 s
15/10/21 17:03:42 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:42 INFO DAGScheduler: Got job 8 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:42 INFO DAGScheduler: Final stage: ResultStage 9(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:42 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:42 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:42 INFO DAGScheduler: Submitting ResultStage 9 (PythonRDD[19] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:42 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=369313, maxMem=278302556
15/10/21 17:03:42 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:03:42 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=375705, maxMem=278302556
15/10/21 17:03:42 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:42 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 9 (PythonRDD[19] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:42 INFO TaskSchedulerImpl: Adding task set 9.0 with 2 tasks
15/10/21 17:03:42 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 17, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:42 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 18, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:42 INFO Executor: Running task 1.0 in stage 9.0 (TID 18)
15/10/21 17:03:42 INFO Executor: Running task 0.0 in stage 9.0 (TID 17)
15/10/21 17:03:42 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:42 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:42 INFO PythonRDD: Times: total = 40, boot = -29, init = 69, finish = 0
15/10/21 17:03:42 INFO PythonRDD: Times: total = 40, boot = -28, init = 68, finish = 0
15/10/21 17:03:42 INFO Executor: Finished task 1.0 in stage 9.0 (TID 18). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO Executor: Finished task 0.0 in stage 9.0 (TID 17). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 18) in 51 ms on localhost (1/2)
15/10/21 17:03:42 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 17) in 53 ms on localhost (2/2)
15/10/21 17:03:42 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
15/10/21 17:03:42 INFO DAGScheduler: ResultStage 9 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.053 s
15/10/21 17:03:42 INFO DAGScheduler: Job 8 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.069144 s
15/10/21 17:03:42 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:42 INFO DAGScheduler: Got job 9 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:42 INFO DAGScheduler: Final stage: ResultStage 10(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:42 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:42 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:42 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[20] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:42 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=379512, maxMem=278302556
15/10/21 17:03:42 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:42 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=385904, maxMem=278302556
15/10/21 17:03:42 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:42 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 10 (PythonRDD[20] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:42 INFO TaskSchedulerImpl: Adding task set 10.0 with 2 tasks
15/10/21 17:03:42 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 19, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:42 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 20, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:42 INFO Executor: Running task 0.0 in stage 10.0 (TID 19)
15/10/21 17:03:42 INFO Executor: Running task 1.0 in stage 10.0 (TID 20)
15/10/21 17:03:42 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:42 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:42 INFO PythonRDD: Times: total = 39, boot = -28, init = 67, finish = 0
15/10/21 17:03:42 INFO PythonRDD: Times: total = 40, boot = -28, init = 68, finish = 0
15/10/21 17:03:42 INFO Executor: Finished task 1.0 in stage 10.0 (TID 20). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO Executor: Finished task 0.0 in stage 10.0 (TID 19). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 20) in 51 ms on localhost (1/2)
15/10/21 17:03:42 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 19) in 51 ms on localhost (2/2)
15/10/21 17:03:42 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
15/10/21 17:03:42 INFO DAGScheduler: ResultStage 10 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.053 s
15/10/21 17:03:42 INFO DAGScheduler: Job 9 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.066848 s
15/10/21 17:03:42 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:42 INFO DAGScheduler: Got job 10 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:42 INFO DAGScheduler: Final stage: ResultStage 11(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:42 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:42 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:42 INFO DAGScheduler: Submitting ResultStage 11 (PythonRDD[21] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:42 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=389711, maxMem=278302556
15/10/21 17:03:42 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:42 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=396103, maxMem=278302556
15/10/21 17:03:42 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:42 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 11 (PythonRDD[21] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:42 INFO TaskSchedulerImpl: Adding task set 11.0 with 2 tasks
15/10/21 17:03:42 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 21, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:42 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 22, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:42 INFO Executor: Running task 0.0 in stage 11.0 (TID 21)
15/10/21 17:03:42 INFO Executor: Running task 1.0 in stage 11.0 (TID 22)
15/10/21 17:03:42 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:42 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:42 INFO PythonRDD: Times: total = 39, boot = -25, init = 64, finish = 0
15/10/21 17:03:42 INFO PythonRDD: Times: total = 39, boot = -26, init = 65, finish = 0
15/10/21 17:03:42 INFO Executor: Finished task 1.0 in stage 11.0 (TID 22). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO Executor: Finished task 0.0 in stage 11.0 (TID 21). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 22) in 49 ms on localhost (1/2)
15/10/21 17:03:42 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 21) in 51 ms on localhost (2/2)
15/10/21 17:03:42 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
15/10/21 17:03:42 INFO DAGScheduler: ResultStage 11 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.051 s
15/10/21 17:03:42 INFO DAGScheduler: Job 10 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.065538 s
15/10/21 17:03:42 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:42 INFO DAGScheduler: Got job 11 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:42 INFO DAGScheduler: Final stage: ResultStage 12(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:42 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:42 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:42 INFO DAGScheduler: Submitting ResultStage 12 (PythonRDD[22] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:42 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=399910, maxMem=278302556
15/10/21 17:03:42 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:42 INFO MemoryStore: ensureFreeSpace(3805) called with curMem=406302, maxMem=278302556
15/10/21 17:03:42 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:42 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 12 (PythonRDD[22] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:42 INFO TaskSchedulerImpl: Adding task set 12.0 with 2 tasks
15/10/21 17:03:42 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 23, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:42 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 24, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:42 INFO Executor: Running task 0.0 in stage 12.0 (TID 23)
15/10/21 17:03:42 INFO Executor: Running task 1.0 in stage 12.0 (TID 24)
15/10/21 17:03:42 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:42 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:42 INFO PythonRDD: Times: total = 39, boot = -26, init = 65, finish = 0
15/10/21 17:03:42 INFO PythonRDD: Times: total = 39, boot = -27, init = 66, finish = 0
15/10/21 17:03:42 INFO Executor: Finished task 1.0 in stage 12.0 (TID 24). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO Executor: Finished task 0.0 in stage 12.0 (TID 23). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 24) in 50 ms on localhost (1/2)
15/10/21 17:03:42 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 23) in 51 ms on localhost (2/2)
15/10/21 17:03:42 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
15/10/21 17:03:42 INFO DAGScheduler: ResultStage 12 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.052 s
15/10/21 17:03:42 INFO DAGScheduler: Job 11 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.065269 s
15/10/21 17:03:42 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:42 INFO DAGScheduler: Got job 12 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:42 INFO DAGScheduler: Final stage: ResultStage 13(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:42 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:42 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:42 INFO DAGScheduler: Submitting ResultStage 13 (PythonRDD[23] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:42 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=410107, maxMem=278302556
15/10/21 17:03:42 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:42 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=416499, maxMem=278302556
15/10/21 17:03:42 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:42 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 13 (PythonRDD[23] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:42 INFO TaskSchedulerImpl: Adding task set 13.0 with 2 tasks
15/10/21 17:03:42 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 25, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:42 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 26, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:42 INFO Executor: Running task 0.0 in stage 13.0 (TID 25)
15/10/21 17:03:42 INFO Executor: Running task 1.0 in stage 13.0 (TID 26)
15/10/21 17:03:42 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:42 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:42 INFO PythonRDD: Times: total = 39, boot = -25, init = 64, finish = 0
15/10/21 17:03:42 INFO PythonRDD: Times: total = 39, boot = -29, init = 68, finish = 0
15/10/21 17:03:42 INFO Executor: Finished task 1.0 in stage 13.0 (TID 26). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO Executor: Finished task 0.0 in stage 13.0 (TID 25). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 26) in 49 ms on localhost (1/2)
15/10/21 17:03:42 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 25) in 51 ms on localhost (2/2)
15/10/21 17:03:42 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
15/10/21 17:03:42 INFO DAGScheduler: ResultStage 13 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.051 s
15/10/21 17:03:42 INFO DAGScheduler: Job 12 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.065615 s
15/10/21 17:03:42 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:42 INFO DAGScheduler: Got job 13 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:42 INFO DAGScheduler: Final stage: ResultStage 14(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:42 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:42 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:42 INFO DAGScheduler: Submitting ResultStage 14 (PythonRDD[24] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:42 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=420306, maxMem=278302556
15/10/21 17:03:42 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:42 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=426698, maxMem=278302556
15/10/21 17:03:42 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:42 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 14 (PythonRDD[24] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:42 INFO TaskSchedulerImpl: Adding task set 14.0 with 2 tasks
15/10/21 17:03:42 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 27, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:42 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 28, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:42 INFO Executor: Running task 1.0 in stage 14.0 (TID 28)
15/10/21 17:03:42 INFO Executor: Running task 0.0 in stage 14.0 (TID 27)
15/10/21 17:03:42 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:42 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:42 INFO PythonRDD: Times: total = 41, boot = -25, init = 66, finish = 0
15/10/21 17:03:42 INFO PythonRDD: Times: total = 41, boot = -25, init = 66, finish = 0
15/10/21 17:03:42 INFO Executor: Finished task 0.0 in stage 14.0 (TID 27). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO Executor: Finished task 1.0 in stage 14.0 (TID 28). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 27) in 52 ms on localhost (1/2)
15/10/21 17:03:42 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 28) in 52 ms on localhost (2/2)
15/10/21 17:03:42 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
15/10/21 17:03:42 INFO DAGScheduler: ResultStage 14 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.053 s
15/10/21 17:03:42 INFO DAGScheduler: Job 13 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.066758 s
15/10/21 17:03:42 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:42 INFO DAGScheduler: Got job 14 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:42 INFO DAGScheduler: Final stage: ResultStage 15(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:42 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:42 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:42 INFO DAGScheduler: Submitting ResultStage 15 (PythonRDD[25] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:42 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=430505, maxMem=278302556
15/10/21 17:03:42 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:42 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=436897, maxMem=278302556
15/10/21 17:03:42 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:42 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 15 (PythonRDD[25] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:42 INFO TaskSchedulerImpl: Adding task set 15.0 with 2 tasks
15/10/21 17:03:42 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 29, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:42 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 30, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:42 INFO Executor: Running task 0.0 in stage 15.0 (TID 29)
15/10/21 17:03:42 INFO Executor: Running task 1.0 in stage 15.0 (TID 30)
15/10/21 17:03:42 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:42 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:42 INFO PythonRDD: Times: total = 39, boot = -25, init = 64, finish = 0
15/10/21 17:03:42 INFO PythonRDD: Times: total = 39, boot = -24, init = 63, finish = 0
15/10/21 17:03:42 INFO Executor: Finished task 1.0 in stage 15.0 (TID 30). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO Executor: Finished task 0.0 in stage 15.0 (TID 29). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 30) in 49 ms on localhost (1/2)
15/10/21 17:03:42 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 29) in 50 ms on localhost (2/2)
15/10/21 17:03:42 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
15/10/21 17:03:42 INFO DAGScheduler: ResultStage 15 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.051 s
15/10/21 17:03:42 INFO DAGScheduler: Job 14 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.063491 s
15/10/21 17:03:42 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:42 INFO DAGScheduler: Got job 15 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:42 INFO DAGScheduler: Final stage: ResultStage 16(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:42 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:42 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:42 INFO DAGScheduler: Submitting ResultStage 16 (PythonRDD[26] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:42 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=440704, maxMem=278302556
15/10/21 17:03:42 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:42 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=447096, maxMem=278302556
15/10/21 17:03:42 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:42 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 16 (PythonRDD[26] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:42 INFO TaskSchedulerImpl: Adding task set 16.0 with 2 tasks
15/10/21 17:03:42 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 31, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:42 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 32, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:42 INFO Executor: Running task 0.0 in stage 16.0 (TID 31)
15/10/21 17:03:42 INFO Executor: Running task 1.0 in stage 16.0 (TID 32)
15/10/21 17:03:42 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:42 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:42 INFO PythonRDD: Times: total = 40, boot = -20, init = 60, finish = 0
15/10/21 17:03:42 INFO PythonRDD: Times: total = 39, boot = -23, init = 62, finish = 0
15/10/21 17:03:42 INFO Executor: Finished task 0.0 in stage 16.0 (TID 31). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO Executor: Finished task 1.0 in stage 16.0 (TID 32). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 31) in 50 ms on localhost (1/2)
15/10/21 17:03:42 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 32) in 50 ms on localhost (2/2)
15/10/21 17:03:42 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
15/10/21 17:03:42 INFO DAGScheduler: ResultStage 16 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.051 s
15/10/21 17:03:42 INFO DAGScheduler: Job 15 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.064424 s
15/10/21 17:03:42 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:42 INFO DAGScheduler: Got job 16 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:42 INFO DAGScheduler: Final stage: ResultStage 17(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:42 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:42 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:42 INFO DAGScheduler: Submitting ResultStage 17 (PythonRDD[27] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:42 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=450903, maxMem=278302556
15/10/21 17:03:42 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:42 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=457295, maxMem=278302556
15/10/21 17:03:42 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:42 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 17 (PythonRDD[27] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:42 INFO TaskSchedulerImpl: Adding task set 17.0 with 2 tasks
15/10/21 17:03:42 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 33, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:42 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 34, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:42 INFO Executor: Running task 0.0 in stage 17.0 (TID 33)
15/10/21 17:03:42 INFO Executor: Running task 1.0 in stage 17.0 (TID 34)
15/10/21 17:03:42 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:42 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:42 INFO PythonRDD: Times: total = 38, boot = -23, init = 61, finish = 0
15/10/21 17:03:42 INFO PythonRDD: Times: total = 39, boot = -23, init = 62, finish = 0
15/10/21 17:03:42 INFO Executor: Finished task 1.0 in stage 17.0 (TID 34). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO Executor: Finished task 0.0 in stage 17.0 (TID 33). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 34) in 48 ms on localhost (1/2)
15/10/21 17:03:42 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 33) in 49 ms on localhost (2/2)
15/10/21 17:03:42 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
15/10/21 17:03:42 INFO DAGScheduler: ResultStage 17 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.050 s
15/10/21 17:03:42 INFO DAGScheduler: Job 16 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.062708 s
15/10/21 17:03:42 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:42 INFO DAGScheduler: Got job 17 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:42 INFO DAGScheduler: Final stage: ResultStage 18(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:42 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:42 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:42 INFO DAGScheduler: Submitting ResultStage 18 (PythonRDD[28] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:42 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=461102, maxMem=278302556
15/10/21 17:03:42 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:42 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=467494, maxMem=278302556
15/10/21 17:03:42 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:42 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 18 (PythonRDD[28] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:42 INFO TaskSchedulerImpl: Adding task set 18.0 with 2 tasks
15/10/21 17:03:42 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 35, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:42 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 36, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:42 INFO Executor: Running task 0.0 in stage 18.0 (TID 35)
15/10/21 17:03:42 INFO Executor: Running task 1.0 in stage 18.0 (TID 36)
15/10/21 17:03:42 INFO BlockManagerInfo: Removed broadcast_19_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:42 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:42 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:42 INFO BlockManagerInfo: Removed broadcast_18_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Removed broadcast_17_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Removed broadcast_13_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Removed broadcast_9_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:45162 in memory (size: 3.0 KB, free: 265.4 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:45162 in memory (size: 5.1 KB, free: 265.4 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:45162 in memory (size: 3.5 KB, free: 265.4 MB)
15/10/21 17:03:42 INFO PythonRDD: Times: total = 41, boot = -45, init = 86, finish = 0
15/10/21 17:03:42 INFO PythonRDD: Times: total = 40, boot = -45, init = 85, finish = 0
15/10/21 17:03:42 INFO Executor: Finished task 1.0 in stage 18.0 (TID 36). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO Executor: Finished task 0.0 in stage 18.0 (TID 35). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:45162 in memory (size: 3.5 KB, free: 265.4 MB)
15/10/21 17:03:42 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 36) in 52 ms on localhost (1/2)
15/10/21 17:03:42 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 35) in 54 ms on localhost (2/2)
15/10/21 17:03:42 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
15/10/21 17:03:42 INFO DAGScheduler: ResultStage 18 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.054 s
15/10/21 17:03:42 INFO DAGScheduler: Job 17 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.087085 s
15/10/21 17:03:42 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:45162 in memory (size: 3.0 KB, free: 265.4 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:45162 in memory (size: 3.5 KB, free: 265.4 MB)
15/10/21 17:03:42 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:42 INFO DAGScheduler: Got job 18 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:42 INFO DAGScheduler: Final stage: ResultStage 19(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:42 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:42 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:42 INFO DAGScheduler: Submitting ResultStage 19 (PythonRDD[29] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:42 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=289926, maxMem=278302556
15/10/21 17:03:42 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:03:42 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=296318, maxMem=278302556
15/10/21 17:03:42 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:03:42 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:42 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 19 (PythonRDD[29] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:42 INFO TaskSchedulerImpl: Adding task set 19.0 with 2 tasks
15/10/21 17:03:42 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 37, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:42 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 38, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:42 INFO Executor: Running task 0.0 in stage 19.0 (TID 37)
15/10/21 17:03:42 INFO Executor: Running task 1.0 in stage 19.0 (TID 38)
15/10/21 17:03:42 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:42 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:42 INFO PythonRDD: Times: total = 38, boot = -24, init = 62, finish = 0
15/10/21 17:03:42 INFO PythonRDD: Times: total = 38, boot = -24, init = 62, finish = 0
15/10/21 17:03:42 INFO Executor: Finished task 1.0 in stage 19.0 (TID 38). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO Executor: Finished task 0.0 in stage 19.0 (TID 37). 1870 bytes result sent to driver
15/10/21 17:03:42 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 38) in 46 ms on localhost (1/2)
15/10/21 17:03:42 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 37) in 48 ms on localhost (2/2)
15/10/21 17:03:42 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
15/10/21 17:03:42 INFO DAGScheduler: ResultStage 19 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.049 s
15/10/21 17:03:42 INFO DAGScheduler: Job 18 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.061371 s
15/10/21 17:03:42 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:42 INFO DAGScheduler: Got job 19 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:42 INFO DAGScheduler: Final stage: ResultStage 20(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:42 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:42 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:42 INFO DAGScheduler: Submitting ResultStage 20 (PythonRDD[30] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:42 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=300125, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=306517, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:03:43 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:43 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 20 (PythonRDD[30] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Adding task set 20.0 with 2 tasks
15/10/21 17:03:43 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 39, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 40, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO Executor: Running task 0.0 in stage 20.0 (TID 39)
15/10/21 17:03:43 INFO Executor: Running task 1.0 in stage 20.0 (TID 40)
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:43 INFO PythonRDD: Times: total = 40, boot = -25, init = 65, finish = 0
15/10/21 17:03:43 INFO PythonRDD: Times: total = 40, boot = -23, init = 63, finish = 0
15/10/21 17:03:43 INFO Executor: Finished task 1.0 in stage 20.0 (TID 40). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO Executor: Finished task 0.0 in stage 20.0 (TID 39). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 40) in 48 ms on localhost (1/2)
15/10/21 17:03:43 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 39) in 50 ms on localhost (2/2)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
15/10/21 17:03:43 INFO DAGScheduler: ResultStage 20 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.050 s
15/10/21 17:03:43 INFO DAGScheduler: Job 19 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.063713 s
15/10/21 17:03:43 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:43 INFO DAGScheduler: Got job 20 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:43 INFO DAGScheduler: Final stage: ResultStage 21(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:43 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:43 INFO DAGScheduler: Submitting ResultStage 21 (PythonRDD[31] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=310324, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=316716, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:03:43 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:43 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 21 (PythonRDD[31] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Adding task set 21.0 with 2 tasks
15/10/21 17:03:43 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 41, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 42, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO Executor: Running task 0.0 in stage 21.0 (TID 41)
15/10/21 17:03:43 INFO Executor: Running task 1.0 in stage 21.0 (TID 42)
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:43 INFO PythonRDD: Times: total = 40, boot = -26, init = 66, finish = 0
15/10/21 17:03:43 INFO PythonRDD: Times: total = 41, boot = -23, init = 64, finish = 0
15/10/21 17:03:43 INFO Executor: Finished task 0.0 in stage 21.0 (TID 41). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO Executor: Finished task 1.0 in stage 21.0 (TID 42). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 41) in 50 ms on localhost (1/2)
15/10/21 17:03:43 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 42) in 50 ms on localhost (2/2)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
15/10/21 17:03:43 INFO DAGScheduler: ResultStage 21 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.051 s
15/10/21 17:03:43 INFO DAGScheduler: Job 20 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.064434 s
15/10/21 17:03:43 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:43 INFO DAGScheduler: Got job 21 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:43 INFO DAGScheduler: Final stage: ResultStage 22(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:43 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:43 INFO DAGScheduler: Submitting ResultStage 22 (PythonRDD[32] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=320523, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=326915, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:03:43 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:43 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 22 (PythonRDD[32] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Adding task set 22.0 with 2 tasks
15/10/21 17:03:43 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 43, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 44, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO Executor: Running task 0.0 in stage 22.0 (TID 43)
15/10/21 17:03:43 INFO Executor: Running task 1.0 in stage 22.0 (TID 44)
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:43 INFO PythonRDD: Times: total = 39, boot = -23, init = 62, finish = 0
15/10/21 17:03:43 INFO PythonRDD: Times: total = 39, boot = -26, init = 65, finish = 0
15/10/21 17:03:43 INFO Executor: Finished task 1.0 in stage 22.0 (TID 44). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO Executor: Finished task 0.0 in stage 22.0 (TID 43). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 44) in 47 ms on localhost (1/2)
15/10/21 17:03:43 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 43) in 49 ms on localhost (2/2)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
15/10/21 17:03:43 INFO DAGScheduler: ResultStage 22 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.049 s
15/10/21 17:03:43 INFO DAGScheduler: Job 21 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.062299 s
15/10/21 17:03:43 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:43 INFO DAGScheduler: Got job 22 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:43 INFO DAGScheduler: Final stage: ResultStage 23(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:43 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:43 INFO DAGScheduler: Submitting ResultStage 23 (PythonRDD[33] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=330722, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=337114, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:03:43 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:43 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 23 (PythonRDD[33] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Adding task set 23.0 with 2 tasks
15/10/21 17:03:43 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 45, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 46, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO Executor: Running task 0.0 in stage 23.0 (TID 45)
15/10/21 17:03:43 INFO Executor: Running task 1.0 in stage 23.0 (TID 46)
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:43 INFO PythonRDD: Times: total = 39, boot = -27, init = 66, finish = 0
15/10/21 17:03:43 INFO PythonRDD: Times: total = 39, boot = -22, init = 61, finish = 0
15/10/21 17:03:43 INFO Executor: Finished task 1.0 in stage 23.0 (TID 46). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO Executor: Finished task 0.0 in stage 23.0 (TID 45). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 46) in 47 ms on localhost (1/2)
15/10/21 17:03:43 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 45) in 48 ms on localhost (2/2)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
15/10/21 17:03:43 INFO DAGScheduler: ResultStage 23 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.049 s
15/10/21 17:03:43 INFO DAGScheduler: Job 22 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.063704 s
15/10/21 17:03:43 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:43 INFO DAGScheduler: Got job 23 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:43 INFO DAGScheduler: Final stage: ResultStage 24(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:43 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:43 INFO DAGScheduler: Submitting ResultStage 24 (PythonRDD[34] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=340921, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=347313, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:03:43 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:43 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 24 (PythonRDD[34] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Adding task set 24.0 with 2 tasks
15/10/21 17:03:43 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 47, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 48, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO Executor: Running task 1.0 in stage 24.0 (TID 48)
15/10/21 17:03:43 INFO Executor: Running task 0.0 in stage 24.0 (TID 47)
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:43 INFO PythonRDD: Times: total = 39, boot = -21, init = 60, finish = 0
15/10/21 17:03:43 INFO PythonRDD: Times: total = 39, boot = -21, init = 60, finish = 0
15/10/21 17:03:43 INFO Executor: Finished task 1.0 in stage 24.0 (TID 48). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO Executor: Finished task 0.0 in stage 24.0 (TID 47). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 48) in 47 ms on localhost (1/2)
15/10/21 17:03:43 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 47) in 49 ms on localhost (2/2)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
15/10/21 17:03:43 INFO DAGScheduler: ResultStage 24 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.049 s
15/10/21 17:03:43 INFO DAGScheduler: Job 23 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.061342 s
15/10/21 17:03:43 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:43 INFO DAGScheduler: Got job 24 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:43 INFO DAGScheduler: Final stage: ResultStage 25(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:43 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:43 INFO DAGScheduler: Submitting ResultStage 25 (PythonRDD[35] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=351120, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=357512, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:03:43 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:43 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 25 (PythonRDD[35] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Adding task set 25.0 with 2 tasks
15/10/21 17:03:43 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 49, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 50, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO Executor: Running task 0.0 in stage 25.0 (TID 49)
15/10/21 17:03:43 INFO Executor: Running task 1.0 in stage 25.0 (TID 50)
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:43 INFO PythonRDD: Times: total = 38, boot = -21, init = 59, finish = 0
15/10/21 17:03:43 INFO PythonRDD: Times: total = 39, boot = -20, init = 59, finish = 0
15/10/21 17:03:43 INFO Executor: Finished task 1.0 in stage 25.0 (TID 50). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO Executor: Finished task 0.0 in stage 25.0 (TID 49). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 50) in 47 ms on localhost (1/2)
15/10/21 17:03:43 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 49) in 49 ms on localhost (2/2)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
15/10/21 17:03:43 INFO DAGScheduler: ResultStage 25 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.049 s
15/10/21 17:03:43 INFO DAGScheduler: Job 24 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.061012 s
15/10/21 17:03:43 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:43 INFO DAGScheduler: Got job 25 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:43 INFO DAGScheduler: Final stage: ResultStage 26(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:43 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:43 INFO DAGScheduler: Submitting ResultStage 26 (PythonRDD[36] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=361319, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=367711, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:03:43 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:43 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 26 (PythonRDD[36] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Adding task set 26.0 with 2 tasks
15/10/21 17:03:43 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 51, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 52, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO Executor: Running task 0.0 in stage 26.0 (TID 51)
15/10/21 17:03:43 INFO Executor: Running task 1.0 in stage 26.0 (TID 52)
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:43 INFO PythonRDD: Times: total = 38, boot = -17, init = 55, finish = 0
15/10/21 17:03:43 INFO PythonRDD: Times: total = 39, boot = -17, init = 56, finish = 0
15/10/21 17:03:43 INFO Executor: Finished task 1.0 in stage 26.0 (TID 52). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO Executor: Finished task 0.0 in stage 26.0 (TID 51). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 52) in 47 ms on localhost (1/2)
15/10/21 17:03:43 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 51) in 48 ms on localhost (2/2)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
15/10/21 17:03:43 INFO DAGScheduler: ResultStage 26 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.049 s
15/10/21 17:03:43 INFO DAGScheduler: Job 25 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.060117 s
15/10/21 17:03:43 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:43 INFO DAGScheduler: Got job 26 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:43 INFO DAGScheduler: Final stage: ResultStage 27(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:43 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:43 INFO DAGScheduler: Submitting ResultStage 27 (PythonRDD[37] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=371518, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=377910, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:43 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:43 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 27 (PythonRDD[37] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Adding task set 27.0 with 2 tasks
15/10/21 17:03:43 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 53, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 54, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO Executor: Running task 0.0 in stage 27.0 (TID 53)
15/10/21 17:03:43 INFO Executor: Running task 1.0 in stage 27.0 (TID 54)
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:43 INFO PythonRDD: Times: total = 39, boot = -17, init = 56, finish = 0
15/10/21 17:03:43 INFO Executor: Finished task 1.0 in stage 27.0 (TID 54). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 54) in 47 ms on localhost (1/2)
15/10/21 17:03:43 INFO PythonRDD: Times: total = 44, boot = -18, init = 62, finish = 0
15/10/21 17:03:43 INFO Executor: Finished task 0.0 in stage 27.0 (TID 53). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 53) in 51 ms on localhost (2/2)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
15/10/21 17:03:43 INFO DAGScheduler: ResultStage 27 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.053 s
15/10/21 17:03:43 INFO DAGScheduler: Job 26 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.063111 s
15/10/21 17:03:43 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:43 INFO DAGScheduler: Got job 27 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:43 INFO DAGScheduler: Final stage: ResultStage 28(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:43 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:43 INFO DAGScheduler: Submitting ResultStage 28 (PythonRDD[38] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=381717, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=388109, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:43 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:43 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 28 (PythonRDD[38] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Adding task set 28.0 with 2 tasks
15/10/21 17:03:43 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 55, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO TaskSetManager: Starting task 1.0 in stage 28.0 (TID 56, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO Executor: Running task 0.0 in stage 28.0 (TID 55)
15/10/21 17:03:43 INFO Executor: Running task 1.0 in stage 28.0 (TID 56)
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:43 INFO PythonRDD: Times: total = 39, boot = -15, init = 54, finish = 0
15/10/21 17:03:43 INFO PythonRDD: Times: total = 39, boot = -20, init = 59, finish = 0
15/10/21 17:03:43 INFO Executor: Finished task 1.0 in stage 28.0 (TID 56). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO Executor: Finished task 0.0 in stage 28.0 (TID 55). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO TaskSetManager: Finished task 1.0 in stage 28.0 (TID 56) in 46 ms on localhost (1/2)
15/10/21 17:03:43 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 55) in 48 ms on localhost (2/2)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
15/10/21 17:03:43 INFO DAGScheduler: ResultStage 28 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.048 s
15/10/21 17:03:43 INFO DAGScheduler: Job 27 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.059017 s
15/10/21 17:03:43 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:43 INFO DAGScheduler: Got job 28 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:43 INFO DAGScheduler: Final stage: ResultStage 29(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:43 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:43 INFO DAGScheduler: Submitting ResultStage 29 (PythonRDD[39] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=391916, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=398308, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:43 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:43 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 29 (PythonRDD[39] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Adding task set 29.0 with 2 tasks
15/10/21 17:03:43 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 57, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 58, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO Executor: Running task 0.0 in stage 29.0 (TID 57)
15/10/21 17:03:43 INFO Executor: Running task 1.0 in stage 29.0 (TID 58)
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:43 INFO PythonRDD: Times: total = 40, boot = -18, init = 58, finish = 0
15/10/21 17:03:43 INFO Executor: Finished task 0.0 in stage 29.0 (TID 57). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 57) in 47 ms on localhost (1/2)
15/10/21 17:03:43 INFO PythonRDD: Times: total = 44, boot = -19, init = 63, finish = 0
15/10/21 17:03:43 INFO Executor: Finished task 1.0 in stage 29.0 (TID 58). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 58) in 50 ms on localhost (2/2)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
15/10/21 17:03:43 INFO DAGScheduler: ResultStage 29 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.051 s
15/10/21 17:03:43 INFO DAGScheduler: Job 28 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.063636 s
15/10/21 17:03:43 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:43 INFO DAGScheduler: Got job 29 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:43 INFO DAGScheduler: Final stage: ResultStage 30(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:43 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:43 INFO DAGScheduler: Submitting ResultStage 30 (PythonRDD[40] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=402115, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(3806) called with curMem=408507, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:43 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:43 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 30 (PythonRDD[40] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Adding task set 30.0 with 2 tasks
15/10/21 17:03:43 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 59, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 60, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO Executor: Running task 1.0 in stage 30.0 (TID 60)
15/10/21 17:03:43 INFO Executor: Running task 0.0 in stage 30.0 (TID 59)
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:43 INFO PythonRDD: Times: total = 40, boot = -15, init = 55, finish = 0
15/10/21 17:03:43 INFO PythonRDD: Times: total = 40, boot = -20, init = 60, finish = 0
15/10/21 17:03:43 INFO Executor: Finished task 0.0 in stage 30.0 (TID 59). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO Executor: Finished task 1.0 in stage 30.0 (TID 60). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 59) in 46 ms on localhost (1/2)
15/10/21 17:03:43 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 60) in 47 ms on localhost (2/2)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
15/10/21 17:03:43 INFO DAGScheduler: ResultStage 30 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.049 s
15/10/21 17:03:43 INFO DAGScheduler: Job 29 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.059619 s
15/10/21 17:03:43 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:43 INFO DAGScheduler: Got job 30 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:43 INFO DAGScheduler: Final stage: ResultStage 31(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:43 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:43 INFO DAGScheduler: Submitting ResultStage 31 (PythonRDD[41] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=412313, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=418705, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:43 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:43 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 31 (PythonRDD[41] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Adding task set 31.0 with 2 tasks
15/10/21 17:03:43 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 61, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 62, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO Executor: Running task 0.0 in stage 31.0 (TID 61)
15/10/21 17:03:43 INFO Executor: Running task 1.0 in stage 31.0 (TID 62)
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:43 INFO PythonRDD: Times: total = 38, boot = -19, init = 57, finish = 0
15/10/21 17:03:43 INFO PythonRDD: Times: total = 38, boot = -16, init = 54, finish = 0
15/10/21 17:03:43 INFO Executor: Finished task 1.0 in stage 31.0 (TID 62). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO Executor: Finished task 0.0 in stage 31.0 (TID 61). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 62) in 44 ms on localhost (1/2)
15/10/21 17:03:43 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 61) in 46 ms on localhost (2/2)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
15/10/21 17:03:43 INFO DAGScheduler: ResultStage 31 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:03:43 INFO DAGScheduler: Job 30 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.056959 s
15/10/21 17:03:43 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:43 INFO DAGScheduler: Got job 31 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:43 INFO DAGScheduler: Final stage: ResultStage 32(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:43 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:43 INFO DAGScheduler: Submitting ResultStage 32 (PythonRDD[42] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=422512, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=428904, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:43 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:43 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 32 (PythonRDD[42] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Adding task set 32.0 with 2 tasks
15/10/21 17:03:43 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 63, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 64, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO Executor: Running task 0.0 in stage 32.0 (TID 63)
15/10/21 17:03:43 INFO Executor: Running task 1.0 in stage 32.0 (TID 64)
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:43 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:43 INFO PythonRDD: Times: total = 39, boot = -16, init = 55, finish = 0
15/10/21 17:03:43 INFO PythonRDD: Times: total = 39, boot = -18, init = 57, finish = 0
15/10/21 17:03:43 INFO Executor: Finished task 1.0 in stage 32.0 (TID 64). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO Executor: Finished task 0.0 in stage 32.0 (TID 63). 1870 bytes result sent to driver
15/10/21 17:03:43 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 64) in 45 ms on localhost (1/2)
15/10/21 17:03:43 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 63) in 46 ms on localhost (2/2)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
15/10/21 17:03:43 INFO DAGScheduler: ResultStage 32 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:03:43 INFO DAGScheduler: Job 31 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.058149 s
15/10/21 17:03:43 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:43 INFO DAGScheduler: Got job 32 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:43 INFO DAGScheduler: Final stage: ResultStage 33(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:43 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:43 INFO DAGScheduler: Submitting ResultStage 33 (PythonRDD[43] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=432711, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:43 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=439103, maxMem=278302556
15/10/21 17:03:43 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:43 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:43 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 33 (PythonRDD[43] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:43 INFO TaskSchedulerImpl: Adding task set 33.0 with 2 tasks
15/10/21 17:03:43 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 65, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 66, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:43 INFO Executor: Running task 0.0 in stage 33.0 (TID 65)
15/10/21 17:03:43 INFO Executor: Running task 1.0 in stage 33.0 (TID 66)
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:44 INFO PythonRDD: Times: total = 38, boot = -17, init = 55, finish = 0
15/10/21 17:03:44 INFO PythonRDD: Times: total = 38, boot = -17, init = 55, finish = 0
15/10/21 17:03:44 INFO Executor: Finished task 0.0 in stage 33.0 (TID 65). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO Executor: Finished task 1.0 in stage 33.0 (TID 66). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 65) in 45 ms on localhost (1/2)
15/10/21 17:03:44 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 66) in 46 ms on localhost (2/2)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
15/10/21 17:03:44 INFO DAGScheduler: ResultStage 33 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:03:44 INFO DAGScheduler: Job 32 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.058312 s
15/10/21 17:03:44 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:44 INFO DAGScheduler: Got job 33 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:44 INFO DAGScheduler: Final stage: ResultStage 34(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:44 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:44 INFO DAGScheduler: Submitting ResultStage 34 (PythonRDD[44] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=442910, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=449302, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:44 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 34 (PythonRDD[44] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Adding task set 34.0 with 2 tasks
15/10/21 17:03:44 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 67, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO TaskSetManager: Starting task 1.0 in stage 34.0 (TID 68, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO Executor: Running task 0.0 in stage 34.0 (TID 67)
15/10/21 17:03:44 INFO Executor: Running task 1.0 in stage 34.0 (TID 68)
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:44 INFO PythonRDD: Times: total = 39, boot = -14, init = 53, finish = 0
15/10/21 17:03:44 INFO PythonRDD: Times: total = 40, boot = -12, init = 52, finish = 0
15/10/21 17:03:44 INFO Executor: Finished task 1.0 in stage 34.0 (TID 68). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO Executor: Finished task 0.0 in stage 34.0 (TID 67). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO TaskSetManager: Finished task 1.0 in stage 34.0 (TID 68) in 45 ms on localhost (1/2)
15/10/21 17:03:44 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 67) in 46 ms on localhost (2/2)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
15/10/21 17:03:44 INFO DAGScheduler: ResultStage 34 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:03:44 INFO DAGScheduler: Job 33 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.056952 s
15/10/21 17:03:44 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:44 INFO DAGScheduler: Got job 34 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:44 INFO DAGScheduler: Final stage: ResultStage 35(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:44 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:44 INFO DAGScheduler: Submitting ResultStage 35 (PythonRDD[45] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=453109, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=459501, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:44 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 35 (PythonRDD[45] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Adding task set 35.0 with 2 tasks
15/10/21 17:03:44 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 69, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO TaskSetManager: Starting task 1.0 in stage 35.0 (TID 70, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO Executor: Running task 0.0 in stage 35.0 (TID 69)
15/10/21 17:03:44 INFO Executor: Running task 1.0 in stage 35.0 (TID 70)
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:44 INFO PythonRDD: Times: total = 40, boot = -16, init = 56, finish = 0
15/10/21 17:03:44 INFO Executor: Finished task 1.0 in stage 35.0 (TID 70). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO TaskSetManager: Finished task 1.0 in stage 35.0 (TID 70) in 45 ms on localhost (1/2)
15/10/21 17:03:44 INFO PythonRDD: Times: total = 44, boot = -14, init = 58, finish = 0
15/10/21 17:03:44 INFO Executor: Finished task 0.0 in stage 35.0 (TID 69). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 69) in 50 ms on localhost (2/2)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
15/10/21 17:03:44 INFO DAGScheduler: ResultStage 35 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.050 s
15/10/21 17:03:44 INFO DAGScheduler: Job 34 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.061707 s
15/10/21 17:03:44 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:44 INFO DAGScheduler: Got job 35 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:44 INFO DAGScheduler: Final stage: ResultStage 36(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:44 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:44 INFO DAGScheduler: Submitting ResultStage 36 (PythonRDD[46] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=463308, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=469700, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:44 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:44 INFO BlockManagerInfo: Removed broadcast_36_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 36 (PythonRDD[46] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Adding task set 36.0 with 2 tasks
15/10/21 17:03:44 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 71, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO TaskSetManager: Starting task 1.0 in stage 36.0 (TID 72, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO Executor: Running task 0.0 in stage 36.0 (TID 71)
15/10/21 17:03:44 INFO BlockManagerInfo: Removed broadcast_37_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:44 INFO Executor: Running task 1.0 in stage 36.0 (TID 72)
15/10/21 17:03:44 INFO BlockManagerInfo: Removed broadcast_35_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:44 INFO BlockManagerInfo: Removed broadcast_34_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Removed broadcast_33_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Removed broadcast_32_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Removed broadcast_31_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Removed broadcast_30_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Removed broadcast_29_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Removed broadcast_28_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Removed broadcast_27_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Removed broadcast_26_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Removed broadcast_25_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Removed broadcast_24_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Removed broadcast_23_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Removed broadcast_22_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Removed broadcast_21_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Removed broadcast_20_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:44 INFO PythonRDD: Times: total = 40, boot = -37, init = 77, finish = 0
15/10/21 17:03:44 INFO PythonRDD: Times: total = 40, boot = -40, init = 80, finish = 0
15/10/21 17:03:44 INFO Executor: Finished task 1.0 in stage 36.0 (TID 72). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO Executor: Finished task 0.0 in stage 36.0 (TID 71). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO TaskSetManager: Finished task 1.0 in stage 36.0 (TID 72) in 46 ms on localhost (1/2)
15/10/21 17:03:44 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 71) in 46 ms on localhost (2/2)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
15/10/21 17:03:44 INFO DAGScheduler: ResultStage 36 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.048 s
15/10/21 17:03:44 INFO DAGScheduler: Job 35 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.078309 s
15/10/21 17:03:44 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:44 INFO DAGScheduler: Got job 36 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:44 INFO DAGScheduler: Final stage: ResultStage 37(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:44 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:44 INFO DAGScheduler: Submitting ResultStage 37 (PythonRDD[47] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=289926, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=296318, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:44 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 37 (PythonRDD[47] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Adding task set 37.0 with 2 tasks
15/10/21 17:03:44 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 73, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 74, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO Executor: Running task 0.0 in stage 37.0 (TID 73)
15/10/21 17:03:44 INFO Executor: Running task 1.0 in stage 37.0 (TID 74)
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:44 INFO PythonRDD: Times: total = 39, boot = -15, init = 54, finish = 0
15/10/21 17:03:44 INFO PythonRDD: Times: total = 39, boot = -15, init = 54, finish = 0
15/10/21 17:03:44 INFO Executor: Finished task 1.0 in stage 37.0 (TID 74). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO Executor: Finished task 0.0 in stage 37.0 (TID 73). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 74) in 45 ms on localhost (1/2)
15/10/21 17:03:44 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 73) in 46 ms on localhost (2/2)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
15/10/21 17:03:44 INFO DAGScheduler: ResultStage 37 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:03:44 INFO DAGScheduler: Job 36 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.057506 s
15/10/21 17:03:44 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:44 INFO DAGScheduler: Got job 37 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:44 INFO DAGScheduler: Final stage: ResultStage 38(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:44 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:44 INFO DAGScheduler: Submitting ResultStage 38 (PythonRDD[48] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=300125, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=306517, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:44 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 38 (PythonRDD[48] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Adding task set 38.0 with 2 tasks
15/10/21 17:03:44 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 75, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 76, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO Executor: Running task 0.0 in stage 38.0 (TID 75)
15/10/21 17:03:44 INFO Executor: Running task 1.0 in stage 38.0 (TID 76)
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:44 INFO PythonRDD: Times: total = 41, boot = -16, init = 57, finish = 0
15/10/21 17:03:44 INFO Executor: Finished task 0.0 in stage 38.0 (TID 75). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 75) in 46 ms on localhost (1/2)
15/10/21 17:03:44 INFO PythonRDD: Times: total = 44, boot = -18, init = 62, finish = 0
15/10/21 17:03:44 INFO Executor: Finished task 1.0 in stage 38.0 (TID 76). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 76) in 50 ms on localhost (2/2)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
15/10/21 17:03:44 INFO DAGScheduler: ResultStage 38 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.051 s
15/10/21 17:03:44 INFO DAGScheduler: Job 37 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.061285 s
15/10/21 17:03:44 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:44 INFO DAGScheduler: Got job 38 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:44 INFO DAGScheduler: Final stage: ResultStage 39(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:44 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:44 INFO DAGScheduler: Submitting ResultStage 39 (PythonRDD[49] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=310324, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=316716, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:44 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 39 (PythonRDD[49] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Adding task set 39.0 with 2 tasks
15/10/21 17:03:44 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 77, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 78, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO Executor: Running task 1.0 in stage 39.0 (TID 78)
15/10/21 17:03:44 INFO Executor: Running task 0.0 in stage 39.0 (TID 77)
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:44 INFO PythonRDD: Times: total = 38, boot = -16, init = 54, finish = 0
15/10/21 17:03:44 INFO PythonRDD: Times: total = 37, boot = -15, init = 52, finish = 0
15/10/21 17:03:44 INFO Executor: Finished task 1.0 in stage 39.0 (TID 78). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO Executor: Finished task 0.0 in stage 39.0 (TID 77). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 78) in 42 ms on localhost (1/2)
15/10/21 17:03:44 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 77) in 43 ms on localhost (2/2)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
15/10/21 17:03:44 INFO DAGScheduler: ResultStage 39 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:03:44 INFO DAGScheduler: Job 38 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053986 s
15/10/21 17:03:44 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:44 INFO DAGScheduler: Got job 39 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:44 INFO DAGScheduler: Final stage: ResultStage 40(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:44 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:44 INFO DAGScheduler: Submitting ResultStage 40 (PythonRDD[50] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=320523, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=326915, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:44 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 40 (PythonRDD[50] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Adding task set 40.0 with 2 tasks
15/10/21 17:03:44 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 79, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 80, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO Executor: Running task 0.0 in stage 40.0 (TID 79)
15/10/21 17:03:44 INFO Executor: Running task 1.0 in stage 40.0 (TID 80)
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:44 INFO PythonRDD: Times: total = 37, boot = -13, init = 50, finish = 0
15/10/21 17:03:44 INFO PythonRDD: Times: total = 38, boot = -12, init = 50, finish = 0
15/10/21 17:03:44 INFO Executor: Finished task 1.0 in stage 40.0 (TID 80). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO Executor: Finished task 0.0 in stage 40.0 (TID 79). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 80) in 42 ms on localhost (1/2)
15/10/21 17:03:44 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 79) in 44 ms on localhost (2/2)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
15/10/21 17:03:44 INFO DAGScheduler: ResultStage 40 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:03:44 INFO DAGScheduler: Job 39 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.054655 s
15/10/21 17:03:44 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:44 INFO DAGScheduler: Got job 40 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:44 INFO DAGScheduler: Final stage: ResultStage 41(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:44 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:44 INFO DAGScheduler: Submitting ResultStage 41 (PythonRDD[51] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=330722, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=337114, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:44 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 41 (PythonRDD[51] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Adding task set 41.0 with 2 tasks
15/10/21 17:03:44 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 81, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO TaskSetManager: Starting task 1.0 in stage 41.0 (TID 82, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO Executor: Running task 0.0 in stage 41.0 (TID 81)
15/10/21 17:03:44 INFO Executor: Running task 1.0 in stage 41.0 (TID 82)
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:44 INFO PythonRDD: Times: total = 38, boot = -16, init = 54, finish = 0
15/10/21 17:03:44 INFO PythonRDD: Times: total = 38, boot = -15, init = 53, finish = 0
15/10/21 17:03:44 INFO Executor: Finished task 1.0 in stage 41.0 (TID 82). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO Executor: Finished task 0.0 in stage 41.0 (TID 81). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO TaskSetManager: Finished task 1.0 in stage 41.0 (TID 82) in 43 ms on localhost (1/2)
15/10/21 17:03:44 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 81) in 44 ms on localhost (2/2)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
15/10/21 17:03:44 INFO DAGScheduler: ResultStage 41 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:44 INFO DAGScheduler: Job 40 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.056405 s
15/10/21 17:03:44 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:44 INFO DAGScheduler: Got job 41 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:44 INFO DAGScheduler: Final stage: ResultStage 42(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:44 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:44 INFO DAGScheduler: Submitting ResultStage 42 (PythonRDD[52] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=340921, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=347313, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:44 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 42 (PythonRDD[52] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Adding task set 42.0 with 2 tasks
15/10/21 17:03:44 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 83, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO TaskSetManager: Starting task 1.0 in stage 42.0 (TID 84, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO Executor: Running task 0.0 in stage 42.0 (TID 83)
15/10/21 17:03:44 INFO Executor: Running task 1.0 in stage 42.0 (TID 84)
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:44 INFO PythonRDD: Times: total = 40, boot = -14, init = 54, finish = 0
15/10/21 17:03:44 INFO PythonRDD: Times: total = 41, boot = -12, init = 53, finish = 0
15/10/21 17:03:44 INFO Executor: Finished task 1.0 in stage 42.0 (TID 84). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO Executor: Finished task 0.0 in stage 42.0 (TID 83). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO TaskSetManager: Finished task 1.0 in stage 42.0 (TID 84) in 46 ms on localhost (1/2)
15/10/21 17:03:44 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 83) in 46 ms on localhost (2/2)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
15/10/21 17:03:44 INFO DAGScheduler: ResultStage 42 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.048 s
15/10/21 17:03:44 INFO DAGScheduler: Job 41 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.059049 s
15/10/21 17:03:44 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:44 INFO DAGScheduler: Got job 42 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:44 INFO DAGScheduler: Final stage: ResultStage 43(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:44 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:44 INFO DAGScheduler: Submitting ResultStage 43 (PythonRDD[53] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=351120, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=357512, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:44 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 43 (PythonRDD[53] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Adding task set 43.0 with 2 tasks
15/10/21 17:03:44 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 85, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO TaskSetManager: Starting task 1.0 in stage 43.0 (TID 86, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO Executor: Running task 0.0 in stage 43.0 (TID 85)
15/10/21 17:03:44 INFO Executor: Running task 1.0 in stage 43.0 (TID 86)
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:44 INFO PythonRDD: Times: total = 40, boot = -13, init = 53, finish = 0
15/10/21 17:03:44 INFO PythonRDD: Times: total = 39, boot = -15, init = 54, finish = 0
15/10/21 17:03:44 INFO Executor: Finished task 1.0 in stage 43.0 (TID 86). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO Executor: Finished task 0.0 in stage 43.0 (TID 85). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO TaskSetManager: Finished task 1.0 in stage 43.0 (TID 86) in 44 ms on localhost (1/2)
15/10/21 17:03:44 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 85) in 45 ms on localhost (2/2)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
15/10/21 17:03:44 INFO DAGScheduler: ResultStage 43 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:03:44 INFO DAGScheduler: Job 42 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.057411 s
15/10/21 17:03:44 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:44 INFO DAGScheduler: Got job 43 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:44 INFO DAGScheduler: Final stage: ResultStage 44(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:44 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:44 INFO DAGScheduler: Submitting ResultStage 44 (PythonRDD[54] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=361319, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=367711, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:44 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 44 (PythonRDD[54] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Adding task set 44.0 with 2 tasks
15/10/21 17:03:44 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 87, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO TaskSetManager: Starting task 1.0 in stage 44.0 (TID 88, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO Executor: Running task 0.0 in stage 44.0 (TID 87)
15/10/21 17:03:44 INFO Executor: Running task 1.0 in stage 44.0 (TID 88)
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:44 INFO PythonRDD: Times: total = 40, boot = -12, init = 52, finish = 0
15/10/21 17:03:44 INFO PythonRDD: Times: total = 40, boot = -16, init = 56, finish = 0
15/10/21 17:03:44 INFO Executor: Finished task 1.0 in stage 44.0 (TID 88). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO Executor: Finished task 0.0 in stage 44.0 (TID 87). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO TaskSetManager: Finished task 1.0 in stage 44.0 (TID 88) in 45 ms on localhost (1/2)
15/10/21 17:03:44 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 87) in 46 ms on localhost (2/2)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
15/10/21 17:03:44 INFO DAGScheduler: ResultStage 44 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:03:44 INFO DAGScheduler: Job 43 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.057906 s
15/10/21 17:03:44 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:44 INFO DAGScheduler: Got job 44 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:44 INFO DAGScheduler: Final stage: ResultStage 45(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:44 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:44 INFO DAGScheduler: Submitting ResultStage 45 (PythonRDD[55] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=371518, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=377910, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:44 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 45 (PythonRDD[55] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Adding task set 45.0 with 2 tasks
15/10/21 17:03:44 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 89, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 90, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO Executor: Running task 0.0 in stage 45.0 (TID 89)
15/10/21 17:03:44 INFO Executor: Running task 1.0 in stage 45.0 (TID 90)
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:44 INFO PythonRDD: Times: total = 39, boot = -18, init = 57, finish = 0
15/10/21 17:03:44 INFO PythonRDD: Times: total = 38, boot = -18, init = 56, finish = 0
15/10/21 17:03:44 INFO Executor: Finished task 0.0 in stage 45.0 (TID 89). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO Executor: Finished task 1.0 in stage 45.0 (TID 90). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 89) in 44 ms on localhost (1/2)
15/10/21 17:03:44 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 90) in 45 ms on localhost (2/2)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
15/10/21 17:03:44 INFO DAGScheduler: ResultStage 45 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:44 INFO DAGScheduler: Job 44 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.056976 s
15/10/21 17:03:44 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:44 INFO DAGScheduler: Got job 45 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:44 INFO DAGScheduler: Final stage: ResultStage 46(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:44 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:44 INFO DAGScheduler: Submitting ResultStage 46 (PythonRDD[56] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=381717, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:44 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=388109, maxMem=278302556
15/10/21 17:03:44 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:44 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:44 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:44 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 46 (PythonRDD[56] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Adding task set 46.0 with 2 tasks
15/10/21 17:03:44 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 91, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO TaskSetManager: Starting task 1.0 in stage 46.0 (TID 92, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:44 INFO Executor: Running task 0.0 in stage 46.0 (TID 91)
15/10/21 17:03:44 INFO Executor: Running task 1.0 in stage 46.0 (TID 92)
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:44 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:44 INFO PythonRDD: Times: total = 38, boot = -16, init = 54, finish = 0
15/10/21 17:03:44 INFO PythonRDD: Times: total = 38, boot = -16, init = 54, finish = 0
15/10/21 17:03:44 INFO Executor: Finished task 1.0 in stage 46.0 (TID 92). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO Executor: Finished task 0.0 in stage 46.0 (TID 91). 1870 bytes result sent to driver
15/10/21 17:03:44 INFO TaskSetManager: Finished task 1.0 in stage 46.0 (TID 92) in 43 ms on localhost (1/2)
15/10/21 17:03:44 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 91) in 45 ms on localhost (2/2)
15/10/21 17:03:44 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
15/10/21 17:03:44 INFO DAGScheduler: ResultStage 46 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:44 INFO DAGScheduler: Job 45 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.056813 s
15/10/21 17:03:45 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:45 INFO DAGScheduler: Got job 46 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:45 INFO DAGScheduler: Final stage: ResultStage 47(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:45 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:45 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:45 INFO DAGScheduler: Submitting ResultStage 47 (PythonRDD[57] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:45 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=391916, maxMem=278302556
15/10/21 17:03:45 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:45 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=398308, maxMem=278302556
15/10/21 17:03:45 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:45 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 47 (PythonRDD[57] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:45 INFO TaskSchedulerImpl: Adding task set 47.0 with 2 tasks
15/10/21 17:03:45 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 93, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:45 INFO TaskSetManager: Starting task 1.0 in stage 47.0 (TID 94, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:45 INFO Executor: Running task 0.0 in stage 47.0 (TID 93)
15/10/21 17:03:45 INFO Executor: Running task 1.0 in stage 47.0 (TID 94)
15/10/21 17:03:45 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:45 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:45 INFO PythonRDD: Times: total = 39, boot = -9, init = 48, finish = 0
15/10/21 17:03:45 INFO PythonRDD: Times: total = 38, boot = -16, init = 54, finish = 0
15/10/21 17:03:45 INFO Executor: Finished task 0.0 in stage 47.0 (TID 93). 1870 bytes result sent to driver
15/10/21 17:03:45 INFO Executor: Finished task 1.0 in stage 47.0 (TID 94). 1870 bytes result sent to driver
15/10/21 17:03:45 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 93) in 44 ms on localhost (1/2)
15/10/21 17:03:45 INFO TaskSetManager: Finished task 1.0 in stage 47.0 (TID 94) in 45 ms on localhost (2/2)
15/10/21 17:03:45 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
15/10/21 17:03:45 INFO DAGScheduler: ResultStage 47 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:03:45 INFO DAGScheduler: Job 46 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.057538 s
15/10/21 17:03:45 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:45 INFO DAGScheduler: Got job 47 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:45 INFO DAGScheduler: Final stage: ResultStage 48(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:45 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:45 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:45 INFO DAGScheduler: Submitting ResultStage 48 (PythonRDD[58] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:45 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=402115, maxMem=278302556
15/10/21 17:03:45 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:45 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=408507, maxMem=278302556
15/10/21 17:03:45 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:45 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 48 (PythonRDD[58] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:45 INFO TaskSchedulerImpl: Adding task set 48.0 with 2 tasks
15/10/21 17:03:45 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 95, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:45 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 96, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:45 INFO Executor: Running task 0.0 in stage 48.0 (TID 95)
15/10/21 17:03:45 INFO Executor: Running task 1.0 in stage 48.0 (TID 96)
15/10/21 17:03:45 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:45 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:45 INFO PythonRDD: Times: total = 41, boot = -14, init = 55, finish = 0
15/10/21 17:03:45 INFO PythonRDD: Times: total = 41, boot = -17, init = 58, finish = 0
15/10/21 17:03:45 INFO Executor: Finished task 1.0 in stage 48.0 (TID 96). 1870 bytes result sent to driver
15/10/21 17:03:45 INFO Executor: Finished task 0.0 in stage 48.0 (TID 95). 1870 bytes result sent to driver
15/10/21 17:03:45 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 96) in 46 ms on localhost (1/2)
15/10/21 17:03:45 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 95) in 48 ms on localhost (2/2)
15/10/21 17:03:45 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
15/10/21 17:03:45 INFO DAGScheduler: ResultStage 48 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.048 s
15/10/21 17:03:45 INFO DAGScheduler: Job 47 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.060599 s
15/10/21 17:03:45 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:45 INFO DAGScheduler: Got job 48 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:45 INFO DAGScheduler: Final stage: ResultStage 49(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:45 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:45 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:45 INFO DAGScheduler: Submitting ResultStage 49 (PythonRDD[59] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:45 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=412314, maxMem=278302556
15/10/21 17:03:45 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:45 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=418706, maxMem=278302556
15/10/21 17:03:45 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:45 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 49 (PythonRDD[59] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:45 INFO TaskSchedulerImpl: Adding task set 49.0 with 2 tasks
15/10/21 17:03:45 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 97, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:45 INFO TaskSetManager: Starting task 1.0 in stage 49.0 (TID 98, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:45 INFO Executor: Running task 0.0 in stage 49.0 (TID 97)
15/10/21 17:03:45 INFO Executor: Running task 1.0 in stage 49.0 (TID 98)
15/10/21 17:03:45 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:45 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:45 INFO PythonRDD: Times: total = 37, boot = -11, init = 48, finish = 0
15/10/21 17:03:45 INFO Executor: Finished task 0.0 in stage 49.0 (TID 97). 1870 bytes result sent to driver
15/10/21 17:03:45 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 97) in 43 ms on localhost (1/2)
15/10/21 17:03:45 INFO PythonRDD: Times: total = 41, boot = -13, init = 54, finish = 0
15/10/21 17:03:45 INFO Executor: Finished task 1.0 in stage 49.0 (TID 98). 1870 bytes result sent to driver
15/10/21 17:03:45 INFO TaskSetManager: Finished task 1.0 in stage 49.0 (TID 98) in 46 ms on localhost (2/2)
15/10/21 17:03:45 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
15/10/21 17:03:45 INFO DAGScheduler: ResultStage 49 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:03:45 INFO DAGScheduler: Job 48 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.058569 s
15/10/21 17:03:45 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:45 INFO DAGScheduler: Got job 49 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:45 INFO DAGScheduler: Final stage: ResultStage 50(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:45 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:45 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:45 INFO DAGScheduler: Submitting ResultStage 50 (PythonRDD[60] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:45 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=422513, maxMem=278302556
15/10/21 17:03:45 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:45 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=428905, maxMem=278302556
15/10/21 17:03:45 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:45 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 50 (PythonRDD[60] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:45 INFO TaskSchedulerImpl: Adding task set 50.0 with 2 tasks
15/10/21 17:03:45 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 99, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:45 INFO TaskSetManager: Starting task 1.0 in stage 50.0 (TID 100, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:45 INFO Executor: Running task 0.0 in stage 50.0 (TID 99)
15/10/21 17:03:45 INFO Executor: Running task 1.0 in stage 50.0 (TID 100)
15/10/21 17:03:45 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:45 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:45 INFO PythonRDD: Times: total = 38, boot = -17, init = 55, finish = 0
15/10/21 17:03:45 INFO Executor: Finished task 1.0 in stage 50.0 (TID 100). 1870 bytes result sent to driver
15/10/21 17:03:45 INFO TaskSetManager: Finished task 1.0 in stage 50.0 (TID 100) in 42 ms on localhost (1/2)
15/10/21 17:03:45 INFO PythonRDD: Times: total = 41, boot = -14, init = 55, finish = 0
15/10/21 17:03:45 INFO Executor: Finished task 0.0 in stage 50.0 (TID 99). 1870 bytes result sent to driver
15/10/21 17:03:45 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 99) in 47 ms on localhost (2/2)
15/10/21 17:03:45 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
15/10/21 17:03:45 INFO DAGScheduler: ResultStage 50 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:03:45 INFO DAGScheduler: Job 49 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.057732 s
15/10/21 17:03:45 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:45 INFO DAGScheduler: Got job 50 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:45 INFO DAGScheduler: Final stage: ResultStage 51(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:45 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:45 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:45 INFO DAGScheduler: Submitting ResultStage 51 (PythonRDD[61] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:45 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=432712, maxMem=278302556
15/10/21 17:03:45 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:45 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=439104, maxMem=278302556
15/10/21 17:03:45 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:45 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 51 (PythonRDD[61] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:45 INFO TaskSchedulerImpl: Adding task set 51.0 with 2 tasks
15/10/21 17:03:45 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 101, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:45 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 102, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:45 INFO Executor: Running task 0.0 in stage 51.0 (TID 101)
15/10/21 17:03:45 INFO Executor: Running task 1.0 in stage 51.0 (TID 102)
15/10/21 17:03:45 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:45 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:45 INFO PythonRDD: Times: total = 38, boot = -14, init = 52, finish = 0
15/10/21 17:03:45 INFO PythonRDD: Times: total = 38, boot = -17, init = 55, finish = 0
15/10/21 17:03:45 INFO Executor: Finished task 1.0 in stage 51.0 (TID 102). 1870 bytes result sent to driver
15/10/21 17:03:45 INFO Executor: Finished task 0.0 in stage 51.0 (TID 101). 1870 bytes result sent to driver
15/10/21 17:03:45 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 102) in 42 ms on localhost (1/2)
15/10/21 17:03:45 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 101) in 43 ms on localhost (2/2)
15/10/21 17:03:45 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
15/10/21 17:03:45 INFO DAGScheduler: ResultStage 51 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:03:45 INFO DAGScheduler: Job 50 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.054801 s
15/10/21 17:03:45 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:45 INFO DAGScheduler: Got job 51 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:45 INFO DAGScheduler: Final stage: ResultStage 52(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:45 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:45 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:45 INFO DAGScheduler: Submitting ResultStage 52 (PythonRDD[62] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:45 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=442911, maxMem=278302556
15/10/21 17:03:45 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:45 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=449303, maxMem=278302556
15/10/21 17:03:45 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:45 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 52 (PythonRDD[62] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:45 INFO TaskSchedulerImpl: Adding task set 52.0 with 2 tasks
15/10/21 17:03:45 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 103, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:45 INFO TaskSetManager: Starting task 1.0 in stage 52.0 (TID 104, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:45 INFO Executor: Running task 0.0 in stage 52.0 (TID 103)
15/10/21 17:03:45 INFO Executor: Running task 1.0 in stage 52.0 (TID 104)
15/10/21 17:03:45 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:45 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:45 INFO PythonRDD: Times: total = 44, boot = -11, init = 55, finish = 0
15/10/21 17:03:45 INFO PythonRDD: Times: total = 45, boot = -15, init = 60, finish = 0
15/10/21 17:03:45 INFO Executor: Finished task 0.0 in stage 52.0 (TID 103). 1870 bytes result sent to driver
15/10/21 17:03:45 INFO Executor: Finished task 1.0 in stage 52.0 (TID 104). 1870 bytes result sent to driver
15/10/21 17:03:45 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 103) in 50 ms on localhost (1/2)
15/10/21 17:03:45 INFO TaskSetManager: Finished task 1.0 in stage 52.0 (TID 104) in 51 ms on localhost (2/2)
15/10/21 17:03:45 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
15/10/21 17:03:45 INFO DAGScheduler: ResultStage 52 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.051 s
15/10/21 17:03:45 INFO DAGScheduler: Job 51 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.061902 s
15/10/21 17:03:45 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:45 INFO DAGScheduler: Got job 52 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:45 INFO DAGScheduler: Final stage: ResultStage 53(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:45 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:45 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:45 INFO DAGScheduler: Submitting ResultStage 53 (PythonRDD[63] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:45 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=453110, maxMem=278302556
15/10/21 17:03:45 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:45 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=459502, maxMem=278302556
15/10/21 17:03:45 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:45 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 53 (PythonRDD[63] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:45 INFO TaskSchedulerImpl: Adding task set 53.0 with 2 tasks
15/10/21 17:03:45 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 105, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:45 INFO TaskSetManager: Starting task 1.0 in stage 53.0 (TID 106, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:45 INFO Executor: Running task 1.0 in stage 53.0 (TID 106)
15/10/21 17:03:45 INFO Executor: Running task 0.0 in stage 53.0 (TID 105)
15/10/21 17:03:45 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:45 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:45 INFO PythonRDD: Times: total = 39, boot = -16, init = 55, finish = 0
15/10/21 17:03:45 INFO PythonRDD: Times: total = 39, boot = -13, init = 52, finish = 0
15/10/21 17:03:45 INFO Executor: Finished task 1.0 in stage 53.0 (TID 106). 1870 bytes result sent to driver
15/10/21 17:03:45 INFO Executor: Finished task 0.0 in stage 53.0 (TID 105). 1870 bytes result sent to driver
15/10/21 17:03:45 INFO TaskSetManager: Finished task 1.0 in stage 53.0 (TID 106) in 44 ms on localhost (1/2)
15/10/21 17:03:45 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 105) in 46 ms on localhost (2/2)
15/10/21 17:03:45 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
15/10/21 17:03:45 INFO DAGScheduler: ResultStage 53 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:03:45 INFO DAGScheduler: Job 52 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.056553 s
15/10/21 17:03:45 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:45 INFO DAGScheduler: Got job 53 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:45 INFO DAGScheduler: Final stage: ResultStage 54(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:45 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:45 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:45 INFO DAGScheduler: Submitting ResultStage 54 (PythonRDD[64] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:45 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=463309, maxMem=278302556
15/10/21 17:03:45 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:45 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=469701, maxMem=278302556
15/10/21 17:03:45 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.0 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:45 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 54 (PythonRDD[64] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:45 INFO TaskSchedulerImpl: Adding task set 54.0 with 2 tasks
15/10/21 17:03:45 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 107, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:45 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 108, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:45 INFO Executor: Running task 1.0 in stage 54.0 (TID 108)
15/10/21 17:03:45 INFO Executor: Running task 0.0 in stage 54.0 (TID 107)
15/10/21 17:03:45 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:45 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:45 INFO PythonRDD: Times: total = 39, boot = -12, init = 51, finish = 0
15/10/21 17:03:45 INFO PythonRDD: Times: total = 39, boot = -14, init = 53, finish = 0
15/10/21 17:03:45 INFO Executor: Finished task 1.0 in stage 54.0 (TID 108). 1870 bytes result sent to driver
15/10/21 17:03:45 INFO Executor: Finished task 0.0 in stage 54.0 (TID 107). 1870 bytes result sent to driver
15/10/21 17:03:45 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 108) in 44 ms on localhost (1/2)
15/10/21 17:03:45 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 107) in 44 ms on localhost (2/2)
15/10/21 17:03:45 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
15/10/21 17:03:45 INFO DAGScheduler: ResultStage 54 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:03:45 INFO DAGScheduler: Job 53 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.056418 s
15/10/21 17:03:45 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:45 INFO DAGScheduler: Got job 54 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:45 INFO DAGScheduler: Final stage: ResultStage 55(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:45 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:45 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:45 INFO DAGScheduler: Submitting ResultStage 55 (PythonRDD[65] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:45 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=473508, maxMem=278302556
15/10/21 17:03:45 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 6.2 KB, free 265.0 MB)
15/10/21 17:03:45 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=479900, maxMem=278302556
15/10/21 17:03:45 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.9 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:45 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:45 INFO BlockManagerInfo: Removed broadcast_53_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 55 (PythonRDD[65] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:45 INFO TaskSchedulerImpl: Adding task set 55.0 with 2 tasks
15/10/21 17:03:45 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 109, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:45 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 110, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:45 INFO Executor: Running task 0.0 in stage 55.0 (TID 109)
15/10/21 17:03:45 INFO Executor: Running task 1.0 in stage 55.0 (TID 110)
15/10/21 17:03:45 INFO BlockManagerInfo: Removed broadcast_56_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Removed broadcast_55_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:45 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:45 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:45 INFO BlockManagerInfo: Removed broadcast_54_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Removed broadcast_52_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Removed broadcast_51_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Removed broadcast_50_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Removed broadcast_49_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Removed broadcast_48_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Removed broadcast_47_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Removed broadcast_46_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Removed broadcast_45_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Removed broadcast_44_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Removed broadcast_43_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Removed broadcast_42_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Removed broadcast_41_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Removed broadcast_40_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Removed broadcast_39_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Removed broadcast_38_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:45 INFO PythonRDD: Times: total = 40, boot = -33, init = 73, finish = 0
15/10/21 17:03:45 INFO PythonRDD: Times: total = 40, boot = -33, init = 73, finish = 0
15/10/21 17:03:45 INFO Executor: Finished task 1.0 in stage 55.0 (TID 110). 1870 bytes result sent to driver
15/10/21 17:03:45 INFO Executor: Finished task 0.0 in stage 55.0 (TID 109). 1870 bytes result sent to driver
15/10/21 17:03:45 INFO TaskSetManager: Finished task 1.0 in stage 55.0 (TID 110) in 45 ms on localhost (1/2)
15/10/21 17:03:45 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 109) in 45 ms on localhost (2/2)
15/10/21 17:03:45 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
15/10/21 17:03:45 INFO DAGScheduler: ResultStage 55 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:03:45 INFO DAGScheduler: Job 54 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.077506 s
15/10/21 17:03:45 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:45 INFO DAGScheduler: Got job 55 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:45 INFO DAGScheduler: Final stage: ResultStage 56(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:45 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:45 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:45 INFO DAGScheduler: Submitting ResultStage 56 (PythonRDD[66] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:45 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=289926, maxMem=278302556
15/10/21 17:03:45 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:03:45 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=296318, maxMem=278302556
15/10/21 17:03:45 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:45 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 56 (PythonRDD[66] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:45 INFO TaskSchedulerImpl: Adding task set 56.0 with 2 tasks
15/10/21 17:03:45 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 111, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:45 INFO TaskSetManager: Starting task 1.0 in stage 56.0 (TID 112, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:45 INFO Executor: Running task 1.0 in stage 56.0 (TID 112)
15/10/21 17:03:45 INFO Executor: Running task 0.0 in stage 56.0 (TID 111)
15/10/21 17:03:45 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:45 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:45 INFO PythonRDD: Times: total = 41, boot = -11, init = 52, finish = 0
15/10/21 17:03:45 INFO PythonRDD: Times: total = 41, boot = -12, init = 53, finish = 0
15/10/21 17:03:45 INFO Executor: Finished task 0.0 in stage 56.0 (TID 111). 1870 bytes result sent to driver
15/10/21 17:03:45 INFO Executor: Finished task 1.0 in stage 56.0 (TID 112). 1870 bytes result sent to driver
15/10/21 17:03:45 INFO TaskSetManager: Finished task 1.0 in stage 56.0 (TID 112) in 45 ms on localhost (1/2)
15/10/21 17:03:45 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 111) in 48 ms on localhost (2/2)
15/10/21 17:03:45 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
15/10/21 17:03:45 INFO DAGScheduler: ResultStage 56 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.048 s
15/10/21 17:03:45 INFO DAGScheduler: Job 55 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.058362 s
15/10/21 17:03:45 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:45 INFO DAGScheduler: Got job 56 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:45 INFO DAGScheduler: Final stage: ResultStage 57(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:45 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:45 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:45 INFO DAGScheduler: Submitting ResultStage 57 (PythonRDD[67] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:45 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=300125, maxMem=278302556
15/10/21 17:03:45 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 6.2 KB, free 265.1 MB)
15/10/21 17:03:45 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=306517, maxMem=278302556
15/10/21 17:03:45 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.1 MB)
15/10/21 17:03:45 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on localhost:45162 (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:45 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:45 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 57 (PythonRDD[67] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:45 INFO TaskSchedulerImpl: Adding task set 57.0 with 2 tasks
15/10/21 17:03:45 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 113, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:45 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 114, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:45 INFO Executor: Running task 0.0 in stage 57.0 (TID 113)
15/10/21 17:03:45 INFO Executor: Running task 1.0 in stage 57.0 (TID 114)
15/10/21 17:03:45 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:45 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:45 INFO PythonRDD: Times: total = 38, boot = -16, init = 54, finish = 0
15/10/21 17:03:45 INFO PythonRDD: Times: total = 38, boot = -14, init = 52, finish = 0
15/10/21 17:03:45 INFO Executor: Finished task 0.0 in stage 57.0 (TID 113). 1870 bytes result sent to driver
15/10/21 17:03:45 INFO Executor: Finished task 1.0 in stage 57.0 (TID 114). 1870 bytes result sent to driver
15/10/21 17:03:45 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 113) in 43 ms on localhost (1/2)
15/10/21 17:03:45 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 114) in 43 ms on localhost (2/2)
15/10/21 17:03:45 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
15/10/21 17:03:45 INFO DAGScheduler: ResultStage 57 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:45 INFO DAGScheduler: Job 56 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.055117 s
15/10/21 17:03:48 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:48 INFO DAGScheduler: Got job 57 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:48 INFO DAGScheduler: Final stage: ResultStage 58(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:48 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:48 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:48 INFO DAGScheduler: Submitting ResultStage 58 (PythonRDD[68] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:48 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=310324, maxMem=278302556
15/10/21 17:03:48 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:48 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=317332, maxMem=278302556
15/10/21 17:03:48 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:48 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:48 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:48 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 58 (PythonRDD[68] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:48 INFO TaskSchedulerImpl: Adding task set 58.0 with 2 tasks
15/10/21 17:03:48 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 115, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:48 INFO TaskSetManager: Starting task 1.0 in stage 58.0 (TID 116, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:48 INFO Executor: Running task 0.0 in stage 58.0 (TID 115)
15/10/21 17:03:48 INFO Executor: Running task 1.0 in stage 58.0 (TID 116)
15/10/21 17:03:48 INFO CacheManager: Partition rdd_16_1 not found, computing it
15/10/21 17:03:48 INFO CacheManager: Partition rdd_16_0 not found, computing it
15/10/21 17:03:48 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/21 17:03:48 INFO PythonRDD: Times: total = 70, boot = 65, init = 4, finish = 1
15/10/21 17:03:49 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(497) called with curMem=321288, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block rdd_16_1 stored as bytes in memory (estimated size 497.0 B, free 265.1 MB)
15/10/21 17:03:49 INFO BlockManagerInfo: Added rdd_16_1 in memory on localhost:45162 (size: 497.0 B, free: 265.4 MB)
15/10/21 17:03:49 INFO PythonRDD: Times: total = 131, boot = -3072, init = 3203, finish = 0
15/10/21 17:03:49 INFO Executor: Finished task 1.0 in stage 58.0 (TID 116). 2450 bytes result sent to driver
15/10/21 17:03:49 INFO PythonRDD: Times: total = 127, boot = 121, init = 5, finish = 1
15/10/21 17:03:49 INFO TaskSetManager: Finished task 1.0 in stage 58.0 (TID 116) in 138 ms on localhost (1/2)
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(682) called with curMem=321785, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block rdd_16_0 stored as bytes in memory (estimated size 682.0 B, free 265.1 MB)
15/10/21 17:03:49 INFO BlockManagerInfo: Added rdd_16_0 in memory on localhost:45162 (size: 682.0 B, free: 265.4 MB)
15/10/21 17:03:49 INFO PythonRDD: Times: total = 138, boot = -3070, init = 3208, finish = 0
15/10/21 17:03:49 INFO Executor: Finished task 0.0 in stage 58.0 (TID 115). 2450 bytes result sent to driver
15/10/21 17:03:49 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 115) in 144 ms on localhost (2/2)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
15/10/21 17:03:49 INFO DAGScheduler: ResultStage 58 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.145 s
15/10/21 17:03:49 INFO DAGScheduler: Job 57 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.157149 s
15/10/21 17:03:49 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:49 INFO DAGScheduler: Got job 58 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:49 INFO DAGScheduler: Final stage: ResultStage 59(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:49 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:49 INFO DAGScheduler: Submitting ResultStage 59 (PythonRDD[69] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=322467, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=329475, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:49 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:49 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 59 (PythonRDD[69] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Adding task set 59.0 with 2 tasks
15/10/21 17:03:49 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 117, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO TaskSetManager: Starting task 1.0 in stage 59.0 (TID 118, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO Executor: Running task 0.0 in stage 59.0 (TID 117)
15/10/21 17:03:49 INFO Executor: Running task 1.0 in stage 59.0 (TID 118)
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:49 INFO PythonRDD: Times: total = 40, boot = -24, init = 64, finish = 0
15/10/21 17:03:49 INFO PythonRDD: Times: total = 40, boot = -27, init = 67, finish = 0
15/10/21 17:03:49 INFO Executor: Finished task 1.0 in stage 59.0 (TID 118). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO Executor: Finished task 0.0 in stage 59.0 (TID 117). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO TaskSetManager: Finished task 1.0 in stage 59.0 (TID 118) in 45 ms on localhost (1/2)
15/10/21 17:03:49 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 117) in 46 ms on localhost (2/2)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
15/10/21 17:03:49 INFO DAGScheduler: ResultStage 59 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:03:49 INFO DAGScheduler: Job 58 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.060912 s
15/10/21 17:03:49 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:49 INFO DAGScheduler: Got job 59 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:49 INFO DAGScheduler: Final stage: ResultStage 60(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:49 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:49 INFO DAGScheduler: Submitting ResultStage 60 (PythonRDD[70] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=333431, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=340439, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:49 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:49 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 60 (PythonRDD[70] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Adding task set 60.0 with 2 tasks
15/10/21 17:03:49 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 119, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO TaskSetManager: Starting task 1.0 in stage 60.0 (TID 120, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO Executor: Running task 1.0 in stage 60.0 (TID 120)
15/10/21 17:03:49 INFO Executor: Running task 0.0 in stage 60.0 (TID 119)
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:49 INFO PythonRDD: Times: total = 38, boot = -87, init = 125, finish = 0
15/10/21 17:03:49 INFO PythonRDD: Times: total = 38, boot = -44, init = 82, finish = 0
15/10/21 17:03:49 INFO Executor: Finished task 0.0 in stage 60.0 (TID 119). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO Executor: Finished task 1.0 in stage 60.0 (TID 120). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 119) in 44 ms on localhost (1/2)
15/10/21 17:03:49 INFO TaskSetManager: Finished task 1.0 in stage 60.0 (TID 120) in 43 ms on localhost (2/2)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
15/10/21 17:03:49 INFO DAGScheduler: ResultStage 60 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:49 INFO DAGScheduler: Job 59 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.054602 s
15/10/21 17:03:49 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:49 INFO DAGScheduler: Got job 60 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:49 INFO DAGScheduler: Final stage: ResultStage 61(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:49 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:49 INFO DAGScheduler: Submitting ResultStage 61 (PythonRDD[71] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=344395, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=351403, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:49 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:49 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 61 (PythonRDD[71] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Adding task set 61.0 with 2 tasks
15/10/21 17:03:49 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 121, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO TaskSetManager: Starting task 1.0 in stage 61.0 (TID 122, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO Executor: Running task 0.0 in stage 61.0 (TID 121)
15/10/21 17:03:49 INFO Executor: Running task 1.0 in stage 61.0 (TID 122)
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:49 INFO PythonRDD: Times: total = 38, boot = -80, init = 118, finish = 0
15/10/21 17:03:49 INFO PythonRDD: Times: total = 38, boot = -80, init = 118, finish = 0
15/10/21 17:03:49 INFO Executor: Finished task 0.0 in stage 61.0 (TID 121). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO Executor: Finished task 1.0 in stage 61.0 (TID 122). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 121) in 44 ms on localhost (1/2)
15/10/21 17:03:49 INFO TaskSetManager: Finished task 1.0 in stage 61.0 (TID 122) in 43 ms on localhost (2/2)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
15/10/21 17:03:49 INFO DAGScheduler: ResultStage 61 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:49 INFO DAGScheduler: Job 60 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.054734 s
15/10/21 17:03:49 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:49 INFO DAGScheduler: Got job 61 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:49 INFO DAGScheduler: Final stage: ResultStage 62(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:49 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:49 INFO DAGScheduler: Submitting ResultStage 62 (PythonRDD[72] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=355359, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=362367, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:49 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:49 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 62 (PythonRDD[72] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Adding task set 62.0 with 2 tasks
15/10/21 17:03:49 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 123, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO TaskSetManager: Starting task 1.0 in stage 62.0 (TID 124, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO Executor: Running task 1.0 in stage 62.0 (TID 124)
15/10/21 17:03:49 INFO Executor: Running task 0.0 in stage 62.0 (TID 123)
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:49 INFO PythonRDD: Times: total = 38, boot = -81, init = 119, finish = 0
15/10/21 17:03:49 INFO PythonRDD: Times: total = 38, boot = -81, init = 119, finish = 0
15/10/21 17:03:49 INFO Executor: Finished task 0.0 in stage 62.0 (TID 123). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO Executor: Finished task 1.0 in stage 62.0 (TID 124). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 123) in 43 ms on localhost (1/2)
15/10/21 17:03:49 INFO TaskSetManager: Finished task 1.0 in stage 62.0 (TID 124) in 44 ms on localhost (2/2)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
15/10/21 17:03:49 INFO DAGScheduler: ResultStage 62 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:49 INFO DAGScheduler: Job 61 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.054631 s
15/10/21 17:03:49 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:49 INFO DAGScheduler: Got job 62 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:49 INFO DAGScheduler: Final stage: ResultStage 63(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:49 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:49 INFO DAGScheduler: Submitting ResultStage 63 (PythonRDD[73] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=366323, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=373331, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:49 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:49 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 63 (PythonRDD[73] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Adding task set 63.0 with 2 tasks
15/10/21 17:03:49 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 125, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO TaskSetManager: Starting task 1.0 in stage 63.0 (TID 126, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO Executor: Running task 0.0 in stage 63.0 (TID 125)
15/10/21 17:03:49 INFO Executor: Running task 1.0 in stage 63.0 (TID 126)
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:49 INFO PythonRDD: Times: total = 39, boot = -82, init = 121, finish = 0
15/10/21 17:03:49 INFO PythonRDD: Times: total = 39, boot = -81, init = 120, finish = 0
15/10/21 17:03:49 INFO Executor: Finished task 0.0 in stage 63.0 (TID 125). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO Executor: Finished task 1.0 in stage 63.0 (TID 126). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 125) in 45 ms on localhost (1/2)
15/10/21 17:03:49 INFO TaskSetManager: Finished task 1.0 in stage 63.0 (TID 126) in 44 ms on localhost (2/2)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
15/10/21 17:03:49 INFO DAGScheduler: ResultStage 63 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:03:49 INFO DAGScheduler: Job 62 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.056364 s
15/10/21 17:03:49 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:49 INFO DAGScheduler: Got job 63 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:49 INFO DAGScheduler: Final stage: ResultStage 64(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:49 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:49 INFO DAGScheduler: Submitting ResultStage 64 (PythonRDD[74] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=377287, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=384295, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:49 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:49 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 64 (PythonRDD[74] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Adding task set 64.0 with 2 tasks
15/10/21 17:03:49 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 127, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO TaskSetManager: Starting task 1.0 in stage 64.0 (TID 128, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO Executor: Running task 0.0 in stage 64.0 (TID 127)
15/10/21 17:03:49 INFO Executor: Running task 1.0 in stage 64.0 (TID 128)
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:49 INFO PythonRDD: Times: total = 40, boot = -83, init = 123, finish = 0
15/10/21 17:03:49 INFO PythonRDD: Times: total = 40, boot = -84, init = 124, finish = 0
15/10/21 17:03:49 INFO Executor: Finished task 0.0 in stage 64.0 (TID 127). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO Executor: Finished task 1.0 in stage 64.0 (TID 128). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 127) in 46 ms on localhost (1/2)
15/10/21 17:03:49 INFO TaskSetManager: Finished task 1.0 in stage 64.0 (TID 128) in 45 ms on localhost (2/2)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
15/10/21 17:03:49 INFO DAGScheduler: ResultStage 64 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:03:49 INFO DAGScheduler: Job 63 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.056945 s
15/10/21 17:03:49 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:49 INFO DAGScheduler: Got job 64 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:49 INFO DAGScheduler: Final stage: ResultStage 65(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:49 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:49 INFO DAGScheduler: Submitting ResultStage 65 (PythonRDD[75] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=388251, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=395259, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:49 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:49 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 65 (PythonRDD[75] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Adding task set 65.0 with 2 tasks
15/10/21 17:03:49 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 129, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO TaskSetManager: Starting task 1.0 in stage 65.0 (TID 130, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO Executor: Running task 0.0 in stage 65.0 (TID 129)
15/10/21 17:03:49 INFO Executor: Running task 1.0 in stage 65.0 (TID 130)
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:49 INFO PythonRDD: Times: total = 41, boot = -83, init = 124, finish = 0
15/10/21 17:03:49 INFO PythonRDD: Times: total = 40, boot = -85, init = 125, finish = 0
15/10/21 17:03:49 INFO Executor: Finished task 0.0 in stage 65.0 (TID 129). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO Executor: Finished task 1.0 in stage 65.0 (TID 130). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 129) in 46 ms on localhost (1/2)
15/10/21 17:03:49 INFO TaskSetManager: Finished task 1.0 in stage 65.0 (TID 130) in 45 ms on localhost (2/2)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
15/10/21 17:03:49 INFO DAGScheduler: ResultStage 65 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:03:49 INFO DAGScheduler: Job 64 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.056883 s
15/10/21 17:03:49 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:49 INFO DAGScheduler: Got job 65 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:49 INFO DAGScheduler: Final stage: ResultStage 66(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:49 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:49 INFO DAGScheduler: Submitting ResultStage 66 (PythonRDD[76] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=399215, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=406223, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:49 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:49 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 66 (PythonRDD[76] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Adding task set 66.0 with 2 tasks
15/10/21 17:03:49 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 131, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO TaskSetManager: Starting task 1.0 in stage 66.0 (TID 132, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO Executor: Running task 0.0 in stage 66.0 (TID 131)
15/10/21 17:03:49 INFO Executor: Running task 1.0 in stage 66.0 (TID 132)
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:49 INFO PythonRDD: Times: total = 41, boot = -84, init = 125, finish = 0
15/10/21 17:03:49 INFO Executor: Finished task 1.0 in stage 66.0 (TID 132). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO TaskSetManager: Finished task 1.0 in stage 66.0 (TID 132) in 46 ms on localhost (1/2)
15/10/21 17:03:49 INFO PythonRDD: Times: total = 45, boot = -83, init = 128, finish = 0
15/10/21 17:03:49 INFO Executor: Finished task 0.0 in stage 66.0 (TID 131). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 131) in 50 ms on localhost (2/2)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
15/10/21 17:03:49 INFO DAGScheduler: ResultStage 66 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.051 s
15/10/21 17:03:49 INFO DAGScheduler: Job 65 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.060573 s
15/10/21 17:03:49 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:49 INFO DAGScheduler: Got job 66 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:49 INFO DAGScheduler: Final stage: ResultStage 67(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:49 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:49 INFO DAGScheduler: Submitting ResultStage 67 (PythonRDD[77] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=410179, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=417187, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:49 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:49 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 67 (PythonRDD[77] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Adding task set 67.0 with 2 tasks
15/10/21 17:03:49 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 133, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO TaskSetManager: Starting task 1.0 in stage 67.0 (TID 134, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO Executor: Running task 0.0 in stage 67.0 (TID 133)
15/10/21 17:03:49 INFO Executor: Running task 1.0 in stage 67.0 (TID 134)
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:49 INFO PythonRDD: Times: total = 40, boot = -84, init = 124, finish = 0
15/10/21 17:03:49 INFO PythonRDD: Times: total = 39, boot = -83, init = 122, finish = 0
15/10/21 17:03:49 INFO Executor: Finished task 0.0 in stage 67.0 (TID 133). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO Executor: Finished task 1.0 in stage 67.0 (TID 134). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 133) in 45 ms on localhost (1/2)
15/10/21 17:03:49 INFO TaskSetManager: Finished task 1.0 in stage 67.0 (TID 134) in 44 ms on localhost (2/2)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
15/10/21 17:03:49 INFO DAGScheduler: ResultStage 67 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:49 INFO DAGScheduler: Job 66 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.054908 s
15/10/21 17:03:49 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:49 INFO DAGScheduler: Got job 67 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:49 INFO DAGScheduler: Final stage: ResultStage 68(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:49 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:49 INFO DAGScheduler: Submitting ResultStage 68 (PythonRDD[78] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=421143, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=428151, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:49 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:49 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 68 (PythonRDD[78] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Adding task set 68.0 with 2 tasks
15/10/21 17:03:49 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 135, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO TaskSetManager: Starting task 1.0 in stage 68.0 (TID 136, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO Executor: Running task 0.0 in stage 68.0 (TID 135)
15/10/21 17:03:49 INFO Executor: Running task 1.0 in stage 68.0 (TID 136)
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:49 INFO PythonRDD: Times: total = 38, boot = -81, init = 119, finish = 0
15/10/21 17:03:49 INFO PythonRDD: Times: total = 38, boot = -84, init = 122, finish = 0
15/10/21 17:03:49 INFO Executor: Finished task 0.0 in stage 68.0 (TID 135). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO Executor: Finished task 1.0 in stage 68.0 (TID 136). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 135) in 43 ms on localhost (1/2)
15/10/21 17:03:49 INFO TaskSetManager: Finished task 1.0 in stage 68.0 (TID 136) in 43 ms on localhost (2/2)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
15/10/21 17:03:49 INFO DAGScheduler: ResultStage 68 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:03:49 INFO DAGScheduler: Job 67 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.054258 s
15/10/21 17:03:49 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:49 INFO DAGScheduler: Got job 68 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:49 INFO DAGScheduler: Final stage: ResultStage 69(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:49 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:49 INFO DAGScheduler: Submitting ResultStage 69 (PythonRDD[79] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=432107, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=439115, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:49 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:49 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 69 (PythonRDD[79] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Adding task set 69.0 with 2 tasks
15/10/21 17:03:49 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 137, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 138, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO Executor: Running task 1.0 in stage 69.0 (TID 138)
15/10/21 17:03:49 INFO Executor: Running task 0.0 in stage 69.0 (TID 137)
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:49 INFO PythonRDD: Times: total = 41, boot = -80, init = 121, finish = 0
15/10/21 17:03:49 INFO PythonRDD: Times: total = 41, boot = -81, init = 122, finish = 0
15/10/21 17:03:49 INFO Executor: Finished task 1.0 in stage 69.0 (TID 138). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO Executor: Finished task 0.0 in stage 69.0 (TID 137). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 138) in 46 ms on localhost (1/2)
15/10/21 17:03:49 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 137) in 46 ms on localhost (2/2)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
15/10/21 17:03:49 INFO DAGScheduler: ResultStage 69 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.048 s
15/10/21 17:03:49 INFO DAGScheduler: Job 68 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.057010 s
15/10/21 17:03:49 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:49 INFO DAGScheduler: Got job 69 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:49 INFO DAGScheduler: Final stage: ResultStage 70(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:49 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:49 INFO DAGScheduler: Submitting ResultStage 70 (PythonRDD[80] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=443071, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=450079, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:49 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:49 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 70 (PythonRDD[80] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Adding task set 70.0 with 2 tasks
15/10/21 17:03:49 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 139, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO TaskSetManager: Starting task 1.0 in stage 70.0 (TID 140, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO Executor: Running task 0.0 in stage 70.0 (TID 139)
15/10/21 17:03:49 INFO Executor: Running task 1.0 in stage 70.0 (TID 140)
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:49 INFO PythonRDD: Times: total = 38, boot = -85, init = 123, finish = 0
15/10/21 17:03:49 INFO Executor: Finished task 0.0 in stage 70.0 (TID 139). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 139) in 43 ms on localhost (1/2)
15/10/21 17:03:49 INFO PythonRDD: Times: total = 41, boot = -85, init = 126, finish = 0
15/10/21 17:03:49 INFO Executor: Finished task 1.0 in stage 70.0 (TID 140). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO TaskSetManager: Finished task 1.0 in stage 70.0 (TID 140) in 46 ms on localhost (2/2)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
15/10/21 17:03:49 INFO DAGScheduler: ResultStage 70 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:03:49 INFO DAGScheduler: Job 69 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.056829 s
15/10/21 17:03:49 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:49 INFO DAGScheduler: Got job 70 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:49 INFO DAGScheduler: Final stage: ResultStage 71(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:49 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:49 INFO DAGScheduler: Submitting ResultStage 71 (PythonRDD[81] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=454035, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=461043, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:49 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:49 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 71 (PythonRDD[81] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Adding task set 71.0 with 2 tasks
15/10/21 17:03:49 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 141, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 142, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO Executor: Running task 0.0 in stage 71.0 (TID 141)
15/10/21 17:03:49 INFO Executor: Running task 1.0 in stage 71.0 (TID 142)
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:49 INFO PythonRDD: Times: total = 40, boot = -85, init = 125, finish = 0
15/10/21 17:03:49 INFO PythonRDD: Times: total = 40, boot = -83, init = 123, finish = 0
15/10/21 17:03:49 INFO Executor: Finished task 1.0 in stage 71.0 (TID 142). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO Executor: Finished task 0.0 in stage 71.0 (TID 141). 1870 bytes result sent to driver
15/10/21 17:03:49 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 142) in 45 ms on localhost (1/2)
15/10/21 17:03:49 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 141) in 45 ms on localhost (2/2)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
15/10/21 17:03:49 INFO DAGScheduler: ResultStage 71 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:03:49 INFO DAGScheduler: Job 70 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.057435 s
15/10/21 17:03:49 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:49 INFO DAGScheduler: Got job 71 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:49 INFO DAGScheduler: Final stage: ResultStage 72(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:49 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:49 INFO DAGScheduler: Submitting ResultStage 72 (PythonRDD[82] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=464999, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:49 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=472007, maxMem=278302556
15/10/21 17:03:49 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:49 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:49 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 72 (PythonRDD[82] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:49 INFO TaskSchedulerImpl: Adding task set 72.0 with 2 tasks
15/10/21 17:03:49 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 143, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO TaskSetManager: Starting task 1.0 in stage 72.0 (TID 144, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:49 INFO Executor: Running task 0.0 in stage 72.0 (TID 143)
15/10/21 17:03:49 INFO Executor: Running task 1.0 in stage 72.0 (TID 144)
15/10/21 17:03:49 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:50 INFO PythonRDD: Times: total = 40, boot = -87, init = 127, finish = 0
15/10/21 17:03:50 INFO PythonRDD: Times: total = 40, boot = -84, init = 124, finish = 0
15/10/21 17:03:50 INFO Executor: Finished task 1.0 in stage 72.0 (TID 144). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO Executor: Finished task 0.0 in stage 72.0 (TID 143). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO TaskSetManager: Finished task 1.0 in stage 72.0 (TID 144) in 45 ms on localhost (1/2)
15/10/21 17:03:50 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 143) in 46 ms on localhost (2/2)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
15/10/21 17:03:50 INFO DAGScheduler: ResultStage 72 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:03:50 INFO DAGScheduler: Job 71 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.057087 s
15/10/21 17:03:50 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:50 INFO DAGScheduler: Got job 72 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:50 INFO DAGScheduler: Final stage: ResultStage 73(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:50 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:50 INFO DAGScheduler: Submitting ResultStage 73 (PythonRDD[83] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=475963, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 6.8 KB, free 264.9 MB)
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=482971, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 3.9 KB, free 264.9 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:50 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 73 (PythonRDD[83] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Adding task set 73.0 with 2 tasks
15/10/21 17:03:50 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 145, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO TaskSetManager: Starting task 1.0 in stage 73.0 (TID 146, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO Executor: Running task 0.0 in stage 73.0 (TID 145)
15/10/21 17:03:50 INFO Executor: Running task 1.0 in stage 73.0 (TID 146)
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:50 INFO PythonRDD: Times: total = 40, boot = -84, init = 124, finish = 0
15/10/21 17:03:50 INFO PythonRDD: Times: total = 40, boot = -83, init = 123, finish = 0
15/10/21 17:03:50 INFO Executor: Finished task 1.0 in stage 73.0 (TID 146). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO Executor: Finished task 0.0 in stage 73.0 (TID 145). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO TaskSetManager: Finished task 1.0 in stage 73.0 (TID 146) in 44 ms on localhost (1/2)
15/10/21 17:03:50 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 145) in 45 ms on localhost (2/2)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
15/10/21 17:03:50 INFO DAGScheduler: ResultStage 73 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:03:50 INFO DAGScheduler: Job 72 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.055977 s
15/10/21 17:03:50 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:50 INFO DAGScheduler: Got job 73 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:50 INFO DAGScheduler: Final stage: ResultStage 74(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:50 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:50 INFO DAGScheduler: Submitting ResultStage 74 (PythonRDD[84] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=486927, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 6.8 KB, free 264.9 MB)
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=493935, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 3.9 KB, free 264.9 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Removed broadcast_75_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:50 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 74 (PythonRDD[84] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Adding task set 74.0 with 2 tasks
15/10/21 17:03:50 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 147, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO TaskSetManager: Starting task 1.0 in stage 74.0 (TID 148, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO BlockManagerInfo: Removed broadcast_74_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:50 INFO Executor: Running task 0.0 in stage 74.0 (TID 147)
15/10/21 17:03:50 INFO Executor: Running task 1.0 in stage 74.0 (TID 148)
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:50 INFO BlockManagerInfo: Removed broadcast_73_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Removed broadcast_72_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Removed broadcast_71_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Removed broadcast_70_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Removed broadcast_69_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Removed broadcast_68_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Removed broadcast_67_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Removed broadcast_66_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Removed broadcast_65_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Removed broadcast_64_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Removed broadcast_63_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Removed broadcast_62_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Removed broadcast_61_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Removed broadcast_60_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Removed broadcast_59_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Removed broadcast_58_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:50 INFO PythonRDD: Times: total = 38, boot = -102, init = 140, finish = 0
15/10/21 17:03:50 INFO PythonRDD: Times: total = 37, boot = -104, init = 141, finish = 0
15/10/21 17:03:50 INFO BlockManagerInfo: Removed broadcast_57_piece0 on localhost:45162 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/21 17:03:50 INFO Executor: Finished task 0.0 in stage 74.0 (TID 147). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO Executor: Finished task 1.0 in stage 74.0 (TID 148). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 147) in 43 ms on localhost (1/2)
15/10/21 17:03:50 INFO TaskSetManager: Finished task 1.0 in stage 74.0 (TID 148) in 42 ms on localhost (2/2)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
15/10/21 17:03:50 INFO DAGScheduler: ResultStage 74 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:03:50 INFO DAGScheduler: Job 73 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.073683 s
15/10/21 17:03:50 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:50 INFO DAGScheduler: Got job 74 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:50 INFO DAGScheduler: Final stage: ResultStage 75(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:50 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:50 INFO DAGScheduler: Submitting ResultStage 75 (PythonRDD[85] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=291870, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=298878, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:50 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 75 (PythonRDD[85] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Adding task set 75.0 with 2 tasks
15/10/21 17:03:50 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 149, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO TaskSetManager: Starting task 1.0 in stage 75.0 (TID 150, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO Executor: Running task 0.0 in stage 75.0 (TID 149)
15/10/21 17:03:50 INFO Executor: Running task 1.0 in stage 75.0 (TID 150)
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:50 INFO PythonRDD: Times: total = 38, boot = -98, init = 136, finish = 0
15/10/21 17:03:50 INFO PythonRDD: Times: total = 38, boot = -99, init = 137, finish = 0
15/10/21 17:03:50 INFO Executor: Finished task 0.0 in stage 75.0 (TID 149). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO Executor: Finished task 1.0 in stage 75.0 (TID 150). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 149) in 43 ms on localhost (1/2)
15/10/21 17:03:50 INFO TaskSetManager: Finished task 1.0 in stage 75.0 (TID 150) in 42 ms on localhost (2/2)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
15/10/21 17:03:50 INFO DAGScheduler: ResultStage 75 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:03:50 INFO DAGScheduler: Job 74 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053502 s
15/10/21 17:03:50 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:50 INFO DAGScheduler: Got job 75 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:50 INFO DAGScheduler: Final stage: ResultStage 76(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:50 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:50 INFO DAGScheduler: Submitting ResultStage 76 (PythonRDD[86] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=302834, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=309842, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:50 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 76 (PythonRDD[86] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Adding task set 76.0 with 2 tasks
15/10/21 17:03:50 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 151, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO TaskSetManager: Starting task 1.0 in stage 76.0 (TID 152, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO Executor: Running task 0.0 in stage 76.0 (TID 151)
15/10/21 17:03:50 INFO Executor: Running task 1.0 in stage 76.0 (TID 152)
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:50 INFO PythonRDD: Times: total = 38, boot = -78, init = 116, finish = 0
15/10/21 17:03:50 INFO PythonRDD: Times: total = 38, boot = -78, init = 116, finish = 0
15/10/21 17:03:50 INFO Executor: Finished task 1.0 in stage 76.0 (TID 152). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO Executor: Finished task 0.0 in stage 76.0 (TID 151). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO TaskSetManager: Finished task 1.0 in stage 76.0 (TID 152) in 43 ms on localhost (1/2)
15/10/21 17:03:50 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 151) in 43 ms on localhost (2/2)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
15/10/21 17:03:50 INFO DAGScheduler: ResultStage 76 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:50 INFO DAGScheduler: Job 75 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053773 s
15/10/21 17:03:50 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:50 INFO DAGScheduler: Got job 76 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:50 INFO DAGScheduler: Final stage: ResultStage 77(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:50 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:50 INFO DAGScheduler: Submitting ResultStage 77 (PythonRDD[87] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=313798, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=320806, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:50 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 77 (PythonRDD[87] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Adding task set 77.0 with 2 tasks
15/10/21 17:03:50 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 153, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 154, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO Executor: Running task 0.0 in stage 77.0 (TID 153)
15/10/21 17:03:50 INFO Executor: Running task 1.0 in stage 77.0 (TID 154)
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:50 INFO PythonRDD: Times: total = 38, boot = -78, init = 116, finish = 0
15/10/21 17:03:50 INFO PythonRDD: Times: total = 38, boot = -79, init = 117, finish = 0
15/10/21 17:03:50 INFO Executor: Finished task 1.0 in stage 77.0 (TID 154). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO Executor: Finished task 0.0 in stage 77.0 (TID 153). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 154) in 43 ms on localhost (1/2)
15/10/21 17:03:50 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 153) in 43 ms on localhost (2/2)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
15/10/21 17:03:50 INFO DAGScheduler: ResultStage 77 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:50 INFO DAGScheduler: Job 76 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.054371 s
15/10/21 17:03:50 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:50 INFO DAGScheduler: Got job 77 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:50 INFO DAGScheduler: Final stage: ResultStage 78(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:50 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:50 INFO DAGScheduler: Submitting ResultStage 78 (PythonRDD[88] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=324762, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=331770, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:50 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 78 (PythonRDD[88] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Adding task set 78.0 with 2 tasks
15/10/21 17:03:50 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 155, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 156, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO Executor: Running task 0.0 in stage 78.0 (TID 155)
15/10/21 17:03:50 INFO Executor: Running task 1.0 in stage 78.0 (TID 156)
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:50 INFO PythonRDD: Times: total = 40, boot = -82, init = 122, finish = 0
15/10/21 17:03:50 INFO PythonRDD: Times: total = 40, boot = -81, init = 121, finish = 0
15/10/21 17:03:50 INFO Executor: Finished task 0.0 in stage 78.0 (TID 155). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO Executor: Finished task 1.0 in stage 78.0 (TID 156). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 155) in 45 ms on localhost (1/2)
15/10/21 17:03:50 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 156) in 45 ms on localhost (2/2)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
15/10/21 17:03:50 INFO DAGScheduler: ResultStage 78 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:03:50 INFO DAGScheduler: Job 77 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.056919 s
15/10/21 17:03:50 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:50 INFO DAGScheduler: Got job 78 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:50 INFO DAGScheduler: Final stage: ResultStage 79(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:50 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:50 INFO DAGScheduler: Submitting ResultStage 79 (PythonRDD[89] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=335726, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=342734, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:50 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 79 (PythonRDD[89] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Adding task set 79.0 with 2 tasks
15/10/21 17:03:50 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 157, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 158, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO Executor: Running task 0.0 in stage 79.0 (TID 157)
15/10/21 17:03:50 INFO Executor: Running task 1.0 in stage 79.0 (TID 158)
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:50 INFO PythonRDD: Times: total = 39, boot = -81, init = 120, finish = 0
15/10/21 17:03:50 INFO Executor: Finished task 1.0 in stage 79.0 (TID 158). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 158) in 42 ms on localhost (1/2)
15/10/21 17:03:50 INFO PythonRDD: Times: total = 42, boot = -81, init = 123, finish = 0
15/10/21 17:03:50 INFO Executor: Finished task 0.0 in stage 79.0 (TID 157). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 157) in 46 ms on localhost (2/2)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
15/10/21 17:03:50 INFO DAGScheduler: ResultStage 79 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.048 s
15/10/21 17:03:50 INFO DAGScheduler: Job 78 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.056215 s
15/10/21 17:03:50 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:50 INFO DAGScheduler: Got job 79 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:50 INFO DAGScheduler: Final stage: ResultStage 80(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:50 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:50 INFO DAGScheduler: Submitting ResultStage 80 (PythonRDD[90] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=346690, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=353698, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:50 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 80 (PythonRDD[90] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Adding task set 80.0 with 2 tasks
15/10/21 17:03:50 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 159, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO TaskSetManager: Starting task 1.0 in stage 80.0 (TID 160, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO Executor: Running task 1.0 in stage 80.0 (TID 160)
15/10/21 17:03:50 INFO Executor: Running task 0.0 in stage 80.0 (TID 159)
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:50 INFO PythonRDD: Times: total = 41, boot = -80, init = 121, finish = 0
15/10/21 17:03:50 INFO PythonRDD: Times: total = 41, boot = -80, init = 121, finish = 0
15/10/21 17:03:50 INFO Executor: Finished task 0.0 in stage 80.0 (TID 159). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO Executor: Finished task 1.0 in stage 80.0 (TID 160). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 159) in 46 ms on localhost (1/2)
15/10/21 17:03:50 INFO TaskSetManager: Finished task 1.0 in stage 80.0 (TID 160) in 45 ms on localhost (2/2)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
15/10/21 17:03:50 INFO DAGScheduler: ResultStage 80 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:03:50 INFO DAGScheduler: Job 79 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.055315 s
15/10/21 17:03:50 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:50 INFO DAGScheduler: Got job 80 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:50 INFO DAGScheduler: Final stage: ResultStage 81(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:50 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:50 INFO DAGScheduler: Submitting ResultStage 81 (PythonRDD[91] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=357654, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=364662, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:50 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 81 (PythonRDD[91] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Adding task set 81.0 with 2 tasks
15/10/21 17:03:50 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 161, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 162, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO Executor: Running task 1.0 in stage 81.0 (TID 162)
15/10/21 17:03:50 INFO Executor: Running task 0.0 in stage 81.0 (TID 161)
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:50 INFO PythonRDD: Times: total = 39, boot = -83, init = 122, finish = 0
15/10/21 17:03:50 INFO PythonRDD: Times: total = 39, boot = -80, init = 119, finish = 0
15/10/21 17:03:50 INFO Executor: Finished task 1.0 in stage 81.0 (TID 162). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO Executor: Finished task 0.0 in stage 81.0 (TID 161). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 162) in 44 ms on localhost (1/2)
15/10/21 17:03:50 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 161) in 44 ms on localhost (2/2)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
15/10/21 17:03:50 INFO DAGScheduler: ResultStage 81 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:50 INFO DAGScheduler: Job 80 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053980 s
15/10/21 17:03:50 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:50 INFO DAGScheduler: Got job 81 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:50 INFO DAGScheduler: Final stage: ResultStage 82(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:50 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:50 INFO DAGScheduler: Submitting ResultStage 82 (PythonRDD[92] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=368618, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=375626, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:50 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 82 (PythonRDD[92] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Adding task set 82.0 with 2 tasks
15/10/21 17:03:50 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 163, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO TaskSetManager: Starting task 1.0 in stage 82.0 (TID 164, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO Executor: Running task 0.0 in stage 82.0 (TID 163)
15/10/21 17:03:50 INFO Executor: Running task 1.0 in stage 82.0 (TID 164)
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:50 INFO PythonRDD: Times: total = 38, boot = -80, init = 118, finish = 0
15/10/21 17:03:50 INFO PythonRDD: Times: total = 38, boot = -80, init = 118, finish = 0
15/10/21 17:03:50 INFO Executor: Finished task 0.0 in stage 82.0 (TID 163). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO Executor: Finished task 1.0 in stage 82.0 (TID 164). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 163) in 43 ms on localhost (1/2)
15/10/21 17:03:50 INFO TaskSetManager: Finished task 1.0 in stage 82.0 (TID 164) in 42 ms on localhost (2/2)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
15/10/21 17:03:50 INFO DAGScheduler: ResultStage 82 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:03:50 INFO DAGScheduler: Job 81 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053435 s
15/10/21 17:03:50 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:50 INFO DAGScheduler: Got job 82 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:50 INFO DAGScheduler: Final stage: ResultStage 83(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:50 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:50 INFO DAGScheduler: Submitting ResultStage 83 (PythonRDD[93] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=379582, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=386590, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:50 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 83 (PythonRDD[93] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Adding task set 83.0 with 2 tasks
15/10/21 17:03:50 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 165, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO TaskSetManager: Starting task 1.0 in stage 83.0 (TID 166, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO Executor: Running task 1.0 in stage 83.0 (TID 166)
15/10/21 17:03:50 INFO Executor: Running task 0.0 in stage 83.0 (TID 165)
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:50 INFO PythonRDD: Times: total = 39, boot = -79, init = 118, finish = 0
15/10/21 17:03:50 INFO PythonRDD: Times: total = 39, boot = -76, init = 115, finish = 0
15/10/21 17:03:50 INFO Executor: Finished task 1.0 in stage 83.0 (TID 166). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO Executor: Finished task 0.0 in stage 83.0 (TID 165). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO TaskSetManager: Finished task 1.0 in stage 83.0 (TID 166) in 43 ms on localhost (1/2)
15/10/21 17:03:50 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 165) in 44 ms on localhost (2/2)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
15/10/21 17:03:50 INFO DAGScheduler: ResultStage 83 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:50 INFO DAGScheduler: Job 82 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053918 s
15/10/21 17:03:50 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:50 INFO DAGScheduler: Got job 83 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:50 INFO DAGScheduler: Final stage: ResultStage 84(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:50 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:50 INFO DAGScheduler: Submitting ResultStage 84 (PythonRDD[94] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=390546, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=397554, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:50 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 84 (PythonRDD[94] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Adding task set 84.0 with 2 tasks
15/10/21 17:03:50 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 167, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO TaskSetManager: Starting task 1.0 in stage 84.0 (TID 168, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO Executor: Running task 0.0 in stage 84.0 (TID 167)
15/10/21 17:03:50 INFO Executor: Running task 1.0 in stage 84.0 (TID 168)
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:50 INFO PythonRDD: Times: total = 38, boot = -78, init = 116, finish = 0
15/10/21 17:03:50 INFO Executor: Finished task 0.0 in stage 84.0 (TID 167). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 167) in 42 ms on localhost (1/2)
15/10/21 17:03:50 INFO PythonRDD: Times: total = 41, boot = -78, init = 119, finish = 0
15/10/21 17:03:50 INFO Executor: Finished task 1.0 in stage 84.0 (TID 168). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO TaskSetManager: Finished task 1.0 in stage 84.0 (TID 168) in 45 ms on localhost (2/2)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
15/10/21 17:03:50 INFO DAGScheduler: ResultStage 84 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:03:50 INFO DAGScheduler: Job 83 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.056400 s
15/10/21 17:03:50 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:50 INFO DAGScheduler: Got job 84 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:50 INFO DAGScheduler: Final stage: ResultStage 85(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:50 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:50 INFO DAGScheduler: Submitting ResultStage 85 (PythonRDD[95] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=401510, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=408518, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:50 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 85 (PythonRDD[95] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Adding task set 85.0 with 2 tasks
15/10/21 17:03:50 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 169, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO TaskSetManager: Starting task 1.0 in stage 85.0 (TID 170, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO Executor: Running task 0.0 in stage 85.0 (TID 169)
15/10/21 17:03:50 INFO Executor: Running task 1.0 in stage 85.0 (TID 170)
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:50 INFO PythonRDD: Times: total = 38, boot = -83, init = 121, finish = 0
15/10/21 17:03:50 INFO PythonRDD: Times: total = 39, boot = -81, init = 120, finish = 0
15/10/21 17:03:50 INFO Executor: Finished task 1.0 in stage 85.0 (TID 170). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO Executor: Finished task 0.0 in stage 85.0 (TID 169). 1870 bytes result sent to driver
15/10/21 17:03:50 INFO TaskSetManager: Finished task 1.0 in stage 85.0 (TID 170) in 43 ms on localhost (1/2)
15/10/21 17:03:50 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 169) in 44 ms on localhost (2/2)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
15/10/21 17:03:50 INFO DAGScheduler: ResultStage 85 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:03:50 INFO DAGScheduler: Job 84 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.054466 s
15/10/21 17:03:50 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:50 INFO DAGScheduler: Got job 85 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:50 INFO DAGScheduler: Final stage: ResultStage 86(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:50 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:50 INFO DAGScheduler: Submitting ResultStage 86 (PythonRDD[96] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=412474, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:50 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=419482, maxMem=278302556
15/10/21 17:03:50 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:50 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:50 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 86 (PythonRDD[96] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:50 INFO TaskSchedulerImpl: Adding task set 86.0 with 2 tasks
15/10/21 17:03:50 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 171, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO TaskSetManager: Starting task 1.0 in stage 86.0 (TID 172, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:50 INFO Executor: Running task 0.0 in stage 86.0 (TID 171)
15/10/21 17:03:50 INFO Executor: Running task 1.0 in stage 86.0 (TID 172)
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:50 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:51 INFO PythonRDD: Times: total = 38, boot = -82, init = 120, finish = 0
15/10/21 17:03:51 INFO PythonRDD: Times: total = 38, boot = -78, init = 116, finish = 0
15/10/21 17:03:51 INFO Executor: Finished task 1.0 in stage 86.0 (TID 172). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO Executor: Finished task 0.0 in stage 86.0 (TID 171). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO TaskSetManager: Finished task 1.0 in stage 86.0 (TID 172) in 42 ms on localhost (1/2)
15/10/21 17:03:51 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 171) in 43 ms on localhost (2/2)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
15/10/21 17:03:51 INFO DAGScheduler: ResultStage 86 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:03:51 INFO DAGScheduler: Job 85 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053337 s
15/10/21 17:03:51 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:51 INFO DAGScheduler: Got job 86 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:51 INFO DAGScheduler: Final stage: ResultStage 87(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:51 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:51 INFO DAGScheduler: Submitting ResultStage 87 (PythonRDD[97] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=423438, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=430446, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:51 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 87 (PythonRDD[97] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Adding task set 87.0 with 2 tasks
15/10/21 17:03:51 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 173, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO TaskSetManager: Starting task 1.0 in stage 87.0 (TID 174, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO Executor: Running task 0.0 in stage 87.0 (TID 173)
15/10/21 17:03:51 INFO Executor: Running task 1.0 in stage 87.0 (TID 174)
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:51 INFO PythonRDD: Times: total = 39, boot = -79, init = 118, finish = 0
15/10/21 17:03:51 INFO PythonRDD: Times: total = 38, boot = -79, init = 117, finish = 0
15/10/21 17:03:51 INFO Executor: Finished task 1.0 in stage 87.0 (TID 174). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO Executor: Finished task 0.0 in stage 87.0 (TID 173). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO TaskSetManager: Finished task 1.0 in stage 87.0 (TID 174) in 43 ms on localhost (1/2)
15/10/21 17:03:51 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 173) in 43 ms on localhost (2/2)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
15/10/21 17:03:51 INFO DAGScheduler: ResultStage 87 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:51 INFO DAGScheduler: Job 86 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053464 s
15/10/21 17:03:51 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:51 INFO DAGScheduler: Got job 87 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:51 INFO DAGScheduler: Final stage: ResultStage 88(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:51 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:51 INFO DAGScheduler: Submitting ResultStage 88 (PythonRDD[98] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=434402, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=441410, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:51 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 88 (PythonRDD[98] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Adding task set 88.0 with 2 tasks
15/10/21 17:03:51 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 175, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO TaskSetManager: Starting task 1.0 in stage 88.0 (TID 176, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO Executor: Running task 0.0 in stage 88.0 (TID 175)
15/10/21 17:03:51 INFO Executor: Running task 1.0 in stage 88.0 (TID 176)
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:51 INFO PythonRDD: Times: total = 38, boot = -77, init = 115, finish = 0
15/10/21 17:03:51 INFO PythonRDD: Times: total = 37, boot = -78, init = 115, finish = 0
15/10/21 17:03:51 INFO Executor: Finished task 1.0 in stage 88.0 (TID 176). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO Executor: Finished task 0.0 in stage 88.0 (TID 175). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO TaskSetManager: Finished task 1.0 in stage 88.0 (TID 176) in 42 ms on localhost (1/2)
15/10/21 17:03:51 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 175) in 43 ms on localhost (2/2)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
15/10/21 17:03:51 INFO DAGScheduler: ResultStage 88 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:03:51 INFO DAGScheduler: Job 87 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053593 s
15/10/21 17:03:51 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:51 INFO DAGScheduler: Got job 88 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:51 INFO DAGScheduler: Final stage: ResultStage 89(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:51 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:51 INFO DAGScheduler: Submitting ResultStage 89 (PythonRDD[99] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=445366, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=452374, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:51 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 89 (PythonRDD[99] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Adding task set 89.0 with 2 tasks
15/10/21 17:03:51 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 177, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO TaskSetManager: Starting task 1.0 in stage 89.0 (TID 178, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO Executor: Running task 0.0 in stage 89.0 (TID 177)
15/10/21 17:03:51 INFO Executor: Running task 1.0 in stage 89.0 (TID 178)
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:51 INFO PythonRDD: Times: total = 39, boot = -79, init = 118, finish = 0
15/10/21 17:03:51 INFO PythonRDD: Times: total = 38, boot = -77, init = 115, finish = 0
15/10/21 17:03:51 INFO Executor: Finished task 1.0 in stage 89.0 (TID 178). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO Executor: Finished task 0.0 in stage 89.0 (TID 177). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO TaskSetManager: Finished task 1.0 in stage 89.0 (TID 178) in 43 ms on localhost (1/2)
15/10/21 17:03:51 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 177) in 43 ms on localhost (2/2)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
15/10/21 17:03:51 INFO DAGScheduler: ResultStage 89 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:03:51 INFO DAGScheduler: Job 88 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053398 s
15/10/21 17:03:51 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:51 INFO DAGScheduler: Got job 89 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:51 INFO DAGScheduler: Final stage: ResultStage 90(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:51 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:51 INFO DAGScheduler: Submitting ResultStage 90 (PythonRDD[100] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=456330, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=463338, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:51 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 90 (PythonRDD[100] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Adding task set 90.0 with 2 tasks
15/10/21 17:03:51 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 179, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO TaskSetManager: Starting task 1.0 in stage 90.0 (TID 180, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO Executor: Running task 0.0 in stage 90.0 (TID 179)
15/10/21 17:03:51 INFO Executor: Running task 1.0 in stage 90.0 (TID 180)
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:51 INFO PythonRDD: Times: total = 38, boot = -78, init = 116, finish = 0
15/10/21 17:03:51 INFO PythonRDD: Times: total = 38, boot = -79, init = 117, finish = 0
15/10/21 17:03:51 INFO Executor: Finished task 1.0 in stage 90.0 (TID 180). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO Executor: Finished task 0.0 in stage 90.0 (TID 179). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO TaskSetManager: Finished task 1.0 in stage 90.0 (TID 180) in 42 ms on localhost (1/2)
15/10/21 17:03:51 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 179) in 43 ms on localhost (2/2)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
15/10/21 17:03:51 INFO DAGScheduler: ResultStage 90 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:03:51 INFO DAGScheduler: Job 89 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053119 s
15/10/21 17:03:51 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:51 INFO DAGScheduler: Got job 90 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:51 INFO DAGScheduler: Final stage: ResultStage 91(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:51 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:51 INFO DAGScheduler: Submitting ResultStage 91 (PythonRDD[101] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=467294, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=474302, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:51 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 91 (PythonRDD[101] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Adding task set 91.0 with 2 tasks
15/10/21 17:03:51 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 181, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO TaskSetManager: Starting task 1.0 in stage 91.0 (TID 182, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO Executor: Running task 0.0 in stage 91.0 (TID 181)
15/10/21 17:03:51 INFO Executor: Running task 1.0 in stage 91.0 (TID 182)
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:51 INFO PythonRDD: Times: total = 38, boot = -76, init = 114, finish = 0
15/10/21 17:03:51 INFO PythonRDD: Times: total = 38, boot = -79, init = 117, finish = 0
15/10/21 17:03:51 INFO Executor: Finished task 0.0 in stage 91.0 (TID 181). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO Executor: Finished task 1.0 in stage 91.0 (TID 182). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 181) in 43 ms on localhost (1/2)
15/10/21 17:03:51 INFO TaskSetManager: Finished task 1.0 in stage 91.0 (TID 182) in 42 ms on localhost (2/2)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
15/10/21 17:03:51 INFO DAGScheduler: ResultStage 91 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:03:51 INFO DAGScheduler: Job 90 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053004 s
15/10/21 17:03:51 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:51 INFO DAGScheduler: Got job 91 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:51 INFO DAGScheduler: Final stage: ResultStage 92(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:51 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:51 INFO DAGScheduler: Submitting ResultStage 92 (PythonRDD[102] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=478258, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 6.8 KB, free 264.9 MB)
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=485266, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 3.9 KB, free 264.9 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:51 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 92 (PythonRDD[102] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Adding task set 92.0 with 2 tasks
15/10/21 17:03:51 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 183, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO TaskSetManager: Starting task 1.0 in stage 92.0 (TID 184, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO Executor: Running task 0.0 in stage 92.0 (TID 183)
15/10/21 17:03:51 INFO Executor: Running task 1.0 in stage 92.0 (TID 184)
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:51 INFO PythonRDD: Times: total = 43, boot = -76, init = 119, finish = 0
15/10/21 17:03:51 INFO PythonRDD: Times: total = 43, boot = -77, init = 120, finish = 0
15/10/21 17:03:51 INFO Executor: Finished task 1.0 in stage 92.0 (TID 184). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO Executor: Finished task 0.0 in stage 92.0 (TID 183). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO TaskSetManager: Finished task 1.0 in stage 92.0 (TID 184) in 47 ms on localhost (1/2)
15/10/21 17:03:51 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 183) in 47 ms on localhost (2/2)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
15/10/21 17:03:51 INFO DAGScheduler: ResultStage 92 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.049 s
15/10/21 17:03:51 INFO DAGScheduler: Job 91 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.057440 s
15/10/21 17:03:51 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:51 INFO DAGScheduler: Got job 92 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:51 INFO DAGScheduler: Final stage: ResultStage 93(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:51 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:51 INFO DAGScheduler: Submitting ResultStage 93 (PythonRDD[103] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=489222, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 6.8 KB, free 264.9 MB)
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=496230, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 3.9 KB, free 264.9 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:51 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 93 (PythonRDD[103] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Adding task set 93.0 with 2 tasks
15/10/21 17:03:51 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 185, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO TaskSetManager: Starting task 1.0 in stage 93.0 (TID 186, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO Executor: Running task 0.0 in stage 93.0 (TID 185)
15/10/21 17:03:51 INFO Executor: Running task 1.0 in stage 93.0 (TID 186)
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:51 INFO PythonRDD: Times: total = 40, boot = -80, init = 120, finish = 0
15/10/21 17:03:51 INFO PythonRDD: Times: total = 39, boot = -81, init = 120, finish = 0
15/10/21 17:03:51 INFO Executor: Finished task 0.0 in stage 93.0 (TID 185). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO Executor: Finished task 1.0 in stage 93.0 (TID 186). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 185) in 44 ms on localhost (1/2)
15/10/21 17:03:51 INFO TaskSetManager: Finished task 1.0 in stage 93.0 (TID 186) in 44 ms on localhost (2/2)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
15/10/21 17:03:51 INFO DAGScheduler: ResultStage 93 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:51 INFO DAGScheduler: Job 92 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053680 s
15/10/21 17:03:51 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:51 INFO DAGScheduler: Got job 93 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:51 INFO DAGScheduler: Final stage: ResultStage 94(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:51 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:51 INFO DAGScheduler: Submitting ResultStage 94 (PythonRDD[104] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=500186, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 6.8 KB, free 264.9 MB)
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=507194, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 3.9 KB, free 264.9 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:51 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:51 INFO BlockManagerInfo: Removed broadcast_95_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 94 (PythonRDD[104] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Adding task set 94.0 with 2 tasks
15/10/21 17:03:51 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 187, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO TaskSetManager: Starting task 1.0 in stage 94.0 (TID 188, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO BlockManagerInfo: Removed broadcast_94_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:51 INFO Executor: Running task 0.0 in stage 94.0 (TID 187)
15/10/21 17:03:51 INFO Executor: Running task 1.0 in stage 94.0 (TID 188)
15/10/21 17:03:51 INFO BlockManagerInfo: Removed broadcast_93_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:51 INFO BlockManagerInfo: Removed broadcast_92_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Removed broadcast_91_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Removed broadcast_90_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Removed broadcast_89_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Removed broadcast_88_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Removed broadcast_87_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Removed broadcast_86_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Removed broadcast_85_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Removed broadcast_84_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Removed broadcast_83_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Removed broadcast_82_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Removed broadcast_81_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Removed broadcast_80_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Removed broadcast_79_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Removed broadcast_78_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Removed broadcast_77_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Removed broadcast_76_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:51 INFO PythonRDD: Times: total = 39, boot = -105, init = 144, finish = 0
15/10/21 17:03:51 INFO PythonRDD: Times: total = 39, boot = -105, init = 144, finish = 0
15/10/21 17:03:51 INFO Executor: Finished task 1.0 in stage 94.0 (TID 188). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO Executor: Finished task 0.0 in stage 94.0 (TID 187). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO TaskSetManager: Finished task 1.0 in stage 94.0 (TID 188) in 43 ms on localhost (1/2)
15/10/21 17:03:51 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 187) in 44 ms on localhost (2/2)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
15/10/21 17:03:51 INFO DAGScheduler: ResultStage 94 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:03:51 INFO DAGScheduler: Job 93 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.080680 s
15/10/21 17:03:51 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:51 INFO DAGScheduler: Got job 94 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:51 INFO DAGScheduler: Final stage: ResultStage 95(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:51 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:51 INFO DAGScheduler: Submitting ResultStage 95 (PythonRDD[105] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=291870, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=298878, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:51 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 95 (PythonRDD[105] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Adding task set 95.0 with 2 tasks
15/10/21 17:03:51 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 189, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO TaskSetManager: Starting task 1.0 in stage 95.0 (TID 190, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO Executor: Running task 0.0 in stage 95.0 (TID 189)
15/10/21 17:03:51 INFO Executor: Running task 1.0 in stage 95.0 (TID 190)
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:51 INFO PythonRDD: Times: total = 39, boot = -104, init = 143, finish = 0
15/10/21 17:03:51 INFO PythonRDD: Times: total = 39, boot = -105, init = 144, finish = 0
15/10/21 17:03:51 INFO Executor: Finished task 1.0 in stage 95.0 (TID 190). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO Executor: Finished task 0.0 in stage 95.0 (TID 189). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO TaskSetManager: Finished task 1.0 in stage 95.0 (TID 190) in 43 ms on localhost (1/2)
15/10/21 17:03:51 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 189) in 44 ms on localhost (2/2)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
15/10/21 17:03:51 INFO DAGScheduler: ResultStage 95 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:51 INFO DAGScheduler: Job 94 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053679 s
15/10/21 17:03:51 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:51 INFO DAGScheduler: Got job 95 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:51 INFO DAGScheduler: Final stage: ResultStage 96(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:51 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:51 INFO DAGScheduler: Submitting ResultStage 96 (PythonRDD[106] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=302834, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=309842, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:51 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 96 (PythonRDD[106] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Adding task set 96.0 with 2 tasks
15/10/21 17:03:51 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 191, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO TaskSetManager: Starting task 1.0 in stage 96.0 (TID 192, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO Executor: Running task 0.0 in stage 96.0 (TID 191)
15/10/21 17:03:51 INFO Executor: Running task 1.0 in stage 96.0 (TID 192)
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:51 INFO PythonRDD: Times: total = 39, boot = -76, init = 115, finish = 0
15/10/21 17:03:51 INFO PythonRDD: Times: total = 39, boot = -77, init = 116, finish = 0
15/10/21 17:03:51 INFO Executor: Finished task 1.0 in stage 96.0 (TID 192). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO Executor: Finished task 0.0 in stage 96.0 (TID 191). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO TaskSetManager: Finished task 1.0 in stage 96.0 (TID 192) in 43 ms on localhost (1/2)
15/10/21 17:03:51 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 191) in 44 ms on localhost (2/2)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
15/10/21 17:03:51 INFO DAGScheduler: ResultStage 96 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:51 INFO DAGScheduler: Job 95 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053413 s
15/10/21 17:03:51 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:51 INFO DAGScheduler: Got job 96 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:51 INFO DAGScheduler: Final stage: ResultStage 97(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:51 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:51 INFO DAGScheduler: Submitting ResultStage 97 (PythonRDD[107] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=313798, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=320806, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:51 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 97 (PythonRDD[107] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Adding task set 97.0 with 2 tasks
15/10/21 17:03:51 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 193, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO TaskSetManager: Starting task 1.0 in stage 97.0 (TID 194, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO Executor: Running task 0.0 in stage 97.0 (TID 193)
15/10/21 17:03:51 INFO Executor: Running task 1.0 in stage 97.0 (TID 194)
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:51 INFO PythonRDD: Times: total = 39, boot = -77, init = 116, finish = 0
15/10/21 17:03:51 INFO PythonRDD: Times: total = 39, boot = -78, init = 117, finish = 0
15/10/21 17:03:51 INFO Executor: Finished task 0.0 in stage 97.0 (TID 193). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO Executor: Finished task 1.0 in stage 97.0 (TID 194). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 193) in 43 ms on localhost (1/2)
15/10/21 17:03:51 INFO TaskSetManager: Finished task 1.0 in stage 97.0 (TID 194) in 43 ms on localhost (2/2)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
15/10/21 17:03:51 INFO DAGScheduler: ResultStage 97 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:51 INFO DAGScheduler: Job 96 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053563 s
15/10/21 17:03:51 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:51 INFO DAGScheduler: Got job 97 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:51 INFO DAGScheduler: Final stage: ResultStage 98(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:51 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:51 INFO DAGScheduler: Submitting ResultStage 98 (PythonRDD[108] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=324762, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=331770, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:51 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 98 (PythonRDD[108] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Adding task set 98.0 with 2 tasks
15/10/21 17:03:51 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 195, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO TaskSetManager: Starting task 1.0 in stage 98.0 (TID 196, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO Executor: Running task 1.0 in stage 98.0 (TID 196)
15/10/21 17:03:51 INFO Executor: Running task 0.0 in stage 98.0 (TID 195)
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:51 INFO PythonRDD: Times: total = 39, boot = -77, init = 116, finish = 0
15/10/21 17:03:51 INFO PythonRDD: Times: total = 39, boot = -79, init = 118, finish = 0
15/10/21 17:03:51 INFO Executor: Finished task 0.0 in stage 98.0 (TID 195). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO Executor: Finished task 1.0 in stage 98.0 (TID 196). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 195) in 44 ms on localhost (1/2)
15/10/21 17:03:51 INFO TaskSetManager: Finished task 1.0 in stage 98.0 (TID 196) in 43 ms on localhost (2/2)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
15/10/21 17:03:51 INFO DAGScheduler: ResultStage 98 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:51 INFO DAGScheduler: Job 97 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053845 s
15/10/21 17:03:51 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:51 INFO DAGScheduler: Got job 98 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:51 INFO DAGScheduler: Final stage: ResultStage 99(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:51 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:51 INFO DAGScheduler: Submitting ResultStage 99 (PythonRDD[109] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=335726, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=342734, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:51 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 99 (PythonRDD[109] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Adding task set 99.0 with 2 tasks
15/10/21 17:03:51 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 197, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO TaskSetManager: Starting task 1.0 in stage 99.0 (TID 198, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO Executor: Running task 0.0 in stage 99.0 (TID 197)
15/10/21 17:03:51 INFO Executor: Running task 1.0 in stage 99.0 (TID 198)
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:51 INFO PythonRDD: Times: total = 40, boot = -77, init = 117, finish = 0
15/10/21 17:03:51 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:03:51 INFO Executor: Finished task 0.0 in stage 99.0 (TID 197). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO Executor: Finished task 1.0 in stage 99.0 (TID 198). 1870 bytes result sent to driver
15/10/21 17:03:51 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 197) in 44 ms on localhost (1/2)
15/10/21 17:03:51 INFO TaskSetManager: Finished task 1.0 in stage 99.0 (TID 198) in 44 ms on localhost (2/2)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
15/10/21 17:03:51 INFO DAGScheduler: ResultStage 99 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:03:51 INFO DAGScheduler: Job 98 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.054234 s
15/10/21 17:03:51 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:51 INFO DAGScheduler: Got job 99 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:51 INFO DAGScheduler: Final stage: ResultStage 100(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:51 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:51 INFO DAGScheduler: Submitting ResultStage 100 (PythonRDD[110] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=346690, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:51 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=353698, maxMem=278302556
15/10/21 17:03:51 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:51 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:51 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 100 (PythonRDD[110] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:51 INFO TaskSchedulerImpl: Adding task set 100.0 with 2 tasks
15/10/21 17:03:51 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 199, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO TaskSetManager: Starting task 1.0 in stage 100.0 (TID 200, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:51 INFO Executor: Running task 0.0 in stage 100.0 (TID 199)
15/10/21 17:03:51 INFO Executor: Running task 1.0 in stage 100.0 (TID 200)
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:51 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:52 INFO PythonRDD: Times: total = 38, boot = -79, init = 117, finish = 0
15/10/21 17:03:52 INFO PythonRDD: Times: total = 38, boot = -78, init = 116, finish = 0
15/10/21 17:03:52 INFO Executor: Finished task 0.0 in stage 100.0 (TID 199). 1870 bytes result sent to driver
15/10/21 17:03:52 INFO Executor: Finished task 1.0 in stage 100.0 (TID 200). 1870 bytes result sent to driver
15/10/21 17:03:52 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 199) in 43 ms on localhost (1/2)
15/10/21 17:03:52 INFO TaskSetManager: Finished task 1.0 in stage 100.0 (TID 200) in 42 ms on localhost (2/2)
15/10/21 17:03:52 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
15/10/21 17:03:52 INFO DAGScheduler: ResultStage 100 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:03:52 INFO DAGScheduler: Job 99 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053144 s
15/10/21 17:03:52 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:52 INFO DAGScheduler: Got job 100 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:52 INFO DAGScheduler: Final stage: ResultStage 101(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:52 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:52 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:52 INFO DAGScheduler: Submitting ResultStage 101 (PythonRDD[111] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:52 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=357654, maxMem=278302556
15/10/21 17:03:52 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:52 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=364662, maxMem=278302556
15/10/21 17:03:52 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:52 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:52 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 101 (PythonRDD[111] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:52 INFO TaskSchedulerImpl: Adding task set 101.0 with 2 tasks
15/10/21 17:03:52 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 201, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:52 INFO TaskSetManager: Starting task 1.0 in stage 101.0 (TID 202, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:52 INFO Executor: Running task 1.0 in stage 101.0 (TID 202)
15/10/21 17:03:52 INFO Executor: Running task 0.0 in stage 101.0 (TID 201)
15/10/21 17:03:52 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:52 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:52 INFO PythonRDD: Times: total = 39, boot = -76, init = 115, finish = 0
15/10/21 17:03:52 INFO PythonRDD: Times: total = 39, boot = -78, init = 117, finish = 0
15/10/21 17:03:52 INFO Executor: Finished task 1.0 in stage 101.0 (TID 202). 1870 bytes result sent to driver
15/10/21 17:03:52 INFO Executor: Finished task 0.0 in stage 101.0 (TID 201). 1870 bytes result sent to driver
15/10/21 17:03:52 INFO TaskSetManager: Finished task 1.0 in stage 101.0 (TID 202) in 43 ms on localhost (1/2)
15/10/21 17:03:52 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 201) in 43 ms on localhost (2/2)
15/10/21 17:03:52 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
15/10/21 17:03:52 INFO DAGScheduler: ResultStage 101 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:03:52 INFO DAGScheduler: Job 100 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053049 s
15/10/21 17:03:52 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:52 INFO DAGScheduler: Got job 101 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:52 INFO DAGScheduler: Final stage: ResultStage 102(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:52 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:52 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:52 INFO DAGScheduler: Submitting ResultStage 102 (PythonRDD[112] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:52 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=368618, maxMem=278302556
15/10/21 17:03:52 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:52 INFO MemoryStore: ensureFreeSpace(3955) called with curMem=375626, maxMem=278302556
15/10/21 17:03:52 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:52 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:52 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 102 (PythonRDD[112] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:52 INFO TaskSchedulerImpl: Adding task set 102.0 with 2 tasks
15/10/21 17:03:52 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 203, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:52 INFO TaskSetManager: Starting task 1.0 in stage 102.0 (TID 204, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:52 INFO Executor: Running task 0.0 in stage 102.0 (TID 203)
15/10/21 17:03:52 INFO Executor: Running task 1.0 in stage 102.0 (TID 204)
15/10/21 17:03:52 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:52 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:52 INFO PythonRDD: Times: total = 39, boot = -79, init = 118, finish = 0
15/10/21 17:03:52 INFO PythonRDD: Times: total = 39, boot = -78, init = 117, finish = 0
15/10/21 17:03:52 INFO Executor: Finished task 0.0 in stage 102.0 (TID 203). 1870 bytes result sent to driver
15/10/21 17:03:52 INFO Executor: Finished task 1.0 in stage 102.0 (TID 204). 1870 bytes result sent to driver
15/10/21 17:03:52 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 203) in 44 ms on localhost (1/2)
15/10/21 17:03:52 INFO TaskSetManager: Finished task 1.0 in stage 102.0 (TID 204) in 43 ms on localhost (2/2)
15/10/21 17:03:52 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
15/10/21 17:03:52 INFO DAGScheduler: ResultStage 102 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:03:52 INFO DAGScheduler: Job 101 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.052858 s
15/10/21 17:03:52 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:52 INFO DAGScheduler: Got job 102 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:52 INFO DAGScheduler: Final stage: ResultStage 103(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:52 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:52 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:52 INFO DAGScheduler: Submitting ResultStage 103 (PythonRDD[113] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:52 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=379581, maxMem=278302556
15/10/21 17:03:52 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:52 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=386589, maxMem=278302556
15/10/21 17:03:52 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:52 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:52 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 103 (PythonRDD[113] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:52 INFO TaskSchedulerImpl: Adding task set 103.0 with 2 tasks
15/10/21 17:03:52 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 205, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:52 INFO TaskSetManager: Starting task 1.0 in stage 103.0 (TID 206, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:52 INFO Executor: Running task 0.0 in stage 103.0 (TID 205)
15/10/21 17:03:52 INFO Executor: Running task 1.0 in stage 103.0 (TID 206)
15/10/21 17:03:52 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:52 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:52 INFO PythonRDD: Times: total = 39, boot = -79, init = 118, finish = 0
15/10/21 17:03:52 INFO PythonRDD: Times: total = 39, boot = -76, init = 115, finish = 0
15/10/21 17:03:52 INFO Executor: Finished task 0.0 in stage 103.0 (TID 205). 1870 bytes result sent to driver
15/10/21 17:03:52 INFO Executor: Finished task 1.0 in stage 103.0 (TID 206). 1870 bytes result sent to driver
15/10/21 17:03:52 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 205) in 43 ms on localhost (1/2)
15/10/21 17:03:52 INFO TaskSetManager: Finished task 1.0 in stage 103.0 (TID 206) in 43 ms on localhost (2/2)
15/10/21 17:03:52 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
15/10/21 17:03:52 INFO DAGScheduler: ResultStage 103 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:52 INFO DAGScheduler: Job 102 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053154 s
15/10/21 17:03:52 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:52 INFO DAGScheduler: Got job 103 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:52 INFO DAGScheduler: Final stage: ResultStage 104(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:52 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:52 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:52 INFO DAGScheduler: Submitting ResultStage 104 (PythonRDD[114] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:52 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=390545, maxMem=278302556
15/10/21 17:03:52 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:52 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=397553, maxMem=278302556
15/10/21 17:03:52 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:52 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:52 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 104 (PythonRDD[114] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:52 INFO TaskSchedulerImpl: Adding task set 104.0 with 2 tasks
15/10/21 17:03:52 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 207, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:52 INFO TaskSetManager: Starting task 1.0 in stage 104.0 (TID 208, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:52 INFO Executor: Running task 0.0 in stage 104.0 (TID 207)
15/10/21 17:03:52 INFO Executor: Running task 1.0 in stage 104.0 (TID 208)
15/10/21 17:03:52 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:52 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:52 INFO PythonRDD: Times: total = 39, boot = -78, init = 117, finish = 0
15/10/21 17:03:52 INFO PythonRDD: Times: total = 39, boot = -78, init = 117, finish = 0
15/10/21 17:03:52 INFO Executor: Finished task 0.0 in stage 104.0 (TID 207). 1870 bytes result sent to driver
15/10/21 17:03:52 INFO Executor: Finished task 1.0 in stage 104.0 (TID 208). 1870 bytes result sent to driver
15/10/21 17:03:52 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 207) in 44 ms on localhost (1/2)
15/10/21 17:03:52 INFO TaskSetManager: Finished task 1.0 in stage 104.0 (TID 208) in 43 ms on localhost (2/2)
15/10/21 17:03:52 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
15/10/21 17:03:52 INFO DAGScheduler: ResultStage 104 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:52 INFO DAGScheduler: Job 103 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053555 s
15/10/21 17:03:52 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:52 INFO DAGScheduler: Got job 104 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:52 INFO DAGScheduler: Final stage: ResultStage 105(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:52 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:52 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:52 INFO DAGScheduler: Submitting ResultStage 105 (PythonRDD[115] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:52 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=401509, maxMem=278302556
15/10/21 17:03:52 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:52 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=408517, maxMem=278302556
15/10/21 17:03:52 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:52 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:52 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 105 (PythonRDD[115] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:52 INFO TaskSchedulerImpl: Adding task set 105.0 with 2 tasks
15/10/21 17:03:52 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 209, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:52 INFO TaskSetManager: Starting task 1.0 in stage 105.0 (TID 210, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:52 INFO Executor: Running task 0.0 in stage 105.0 (TID 209)
15/10/21 17:03:52 INFO Executor: Running task 1.0 in stage 105.0 (TID 210)
15/10/21 17:03:52 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:52 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:52 INFO PythonRDD: Times: total = 38, boot = -78, init = 116, finish = 0
15/10/21 17:03:52 INFO PythonRDD: Times: total = 38, boot = -79, init = 117, finish = 0
15/10/21 17:03:52 INFO Executor: Finished task 1.0 in stage 105.0 (TID 210). 1870 bytes result sent to driver
15/10/21 17:03:52 INFO Executor: Finished task 0.0 in stage 105.0 (TID 209). 1870 bytes result sent to driver
15/10/21 17:03:52 INFO TaskSetManager: Finished task 1.0 in stage 105.0 (TID 210) in 42 ms on localhost (1/2)
15/10/21 17:03:52 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 209) in 43 ms on localhost (2/2)
15/10/21 17:03:52 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
15/10/21 17:03:52 INFO DAGScheduler: ResultStage 105 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.043 s
15/10/21 17:03:52 INFO DAGScheduler: Job 104 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.052962 s
15/10/21 17:03:52 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:52 INFO DAGScheduler: Got job 105 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:52 INFO DAGScheduler: Final stage: ResultStage 106(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:52 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:52 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:52 INFO DAGScheduler: Submitting ResultStage 106 (PythonRDD[116] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:52 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=412473, maxMem=278302556
15/10/21 17:03:52 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:52 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=419481, maxMem=278302556
15/10/21 17:03:52 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:52 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:52 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 106 (PythonRDD[116] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:52 INFO TaskSchedulerImpl: Adding task set 106.0 with 2 tasks
15/10/21 17:03:52 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 211, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:52 INFO TaskSetManager: Starting task 1.0 in stage 106.0 (TID 212, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:52 INFO Executor: Running task 0.0 in stage 106.0 (TID 211)
15/10/21 17:03:52 INFO Executor: Running task 1.0 in stage 106.0 (TID 212)
15/10/21 17:03:52 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:52 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:52 INFO PythonRDD: Times: total = 40, boot = -77, init = 117, finish = 0
15/10/21 17:03:52 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:03:52 INFO Executor: Finished task 0.0 in stage 106.0 (TID 211). 1870 bytes result sent to driver
15/10/21 17:03:52 INFO Executor: Finished task 1.0 in stage 106.0 (TID 212). 1870 bytes result sent to driver
15/10/21 17:03:52 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 211) in 44 ms on localhost (1/2)
15/10/21 17:03:52 INFO TaskSetManager: Finished task 1.0 in stage 106.0 (TID 212) in 44 ms on localhost (2/2)
15/10/21 17:03:52 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
15/10/21 17:03:52 INFO DAGScheduler: ResultStage 106 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:03:52 INFO DAGScheduler: Job 105 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.054190 s
15/10/21 17:03:52 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:52 INFO DAGScheduler: Got job 106 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:52 INFO DAGScheduler: Final stage: ResultStage 107(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:52 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:52 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:52 INFO DAGScheduler: Submitting ResultStage 107 (PythonRDD[117] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:52 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=423437, maxMem=278302556
15/10/21 17:03:52 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:52 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=430445, maxMem=278302556
15/10/21 17:03:52 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:52 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:52 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:52 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 107 (PythonRDD[117] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:52 INFO TaskSchedulerImpl: Adding task set 107.0 with 2 tasks
15/10/21 17:03:52 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 213, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:52 INFO TaskSetManager: Starting task 1.0 in stage 107.0 (TID 214, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:52 INFO Executor: Running task 0.0 in stage 107.0 (TID 213)
15/10/21 17:03:52 INFO Executor: Running task 1.0 in stage 107.0 (TID 214)
15/10/21 17:03:52 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:52 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:52 INFO PythonRDD: Times: total = 39, boot = -76, init = 115, finish = 0
15/10/21 17:03:52 INFO PythonRDD: Times: total = 39, boot = -77, init = 116, finish = 0
15/10/21 17:03:52 INFO Executor: Finished task 0.0 in stage 107.0 (TID 213). 1870 bytes result sent to driver
15/10/21 17:03:52 INFO Executor: Finished task 1.0 in stage 107.0 (TID 214). 1870 bytes result sent to driver
15/10/21 17:03:52 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 213) in 44 ms on localhost (1/2)
15/10/21 17:03:52 INFO TaskSetManager: Finished task 1.0 in stage 107.0 (TID 214) in 43 ms on localhost (2/2)
15/10/21 17:03:52 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool 
15/10/21 17:03:52 INFO DAGScheduler: ResultStage 107 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:52 INFO DAGScheduler: Job 106 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.054399 s
15/10/21 17:03:57 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:57 INFO DAGScheduler: Got job 107 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:57 INFO DAGScheduler: Final stage: ResultStage 108(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:57 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:57 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:57 INFO DAGScheduler: Submitting ResultStage 108 (PythonRDD[118] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:57 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=434401, maxMem=278302556
15/10/21 17:03:57 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:57 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=441409, maxMem=278302556
15/10/21 17:03:57 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:57 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 108 (PythonRDD[118] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:57 INFO TaskSchedulerImpl: Adding task set 108.0 with 2 tasks
15/10/21 17:03:57 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 215, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:57 INFO TaskSetManager: Starting task 1.0 in stage 108.0 (TID 216, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:57 INFO Executor: Running task 0.0 in stage 108.0 (TID 215)
15/10/21 17:03:57 INFO Executor: Running task 1.0 in stage 108.0 (TID 216)
15/10/21 17:03:57 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:57 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:57 INFO PythonRDD: Times: total = 41, boot = -5128, init = 5169, finish = 0
15/10/21 17:03:57 INFO PythonRDD: Times: total = 41, boot = -5126, init = 5167, finish = 0
15/10/21 17:03:57 INFO Executor: Finished task 0.0 in stage 108.0 (TID 215). 1870 bytes result sent to driver
15/10/21 17:03:57 INFO Executor: Finished task 1.0 in stage 108.0 (TID 216). 1870 bytes result sent to driver
15/10/21 17:03:57 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 215) in 46 ms on localhost (1/2)
15/10/21 17:03:57 INFO TaskSetManager: Finished task 1.0 in stage 108.0 (TID 216) in 45 ms on localhost (2/2)
15/10/21 17:03:57 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool 
15/10/21 17:03:57 INFO DAGScheduler: ResultStage 108 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.047 s
15/10/21 17:03:57 INFO DAGScheduler: Job 107 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.057516 s
15/10/21 17:03:57 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:57 INFO DAGScheduler: Got job 108 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:57 INFO DAGScheduler: Final stage: ResultStage 109(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:57 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:57 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:57 INFO DAGScheduler: Submitting ResultStage 109 (PythonRDD[119] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:57 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=445365, maxMem=278302556
15/10/21 17:03:57 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:57 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=452373, maxMem=278302556
15/10/21 17:03:57 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:57 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 109 (PythonRDD[119] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:57 INFO TaskSchedulerImpl: Adding task set 109.0 with 2 tasks
15/10/21 17:03:57 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 217, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:57 INFO TaskSetManager: Starting task 1.0 in stage 109.0 (TID 218, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:57 INFO Executor: Running task 0.0 in stage 109.0 (TID 217)
15/10/21 17:03:57 INFO Executor: Running task 1.0 in stage 109.0 (TID 218)
15/10/21 17:03:57 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:57 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:57 INFO PythonRDD: Times: total = 39, boot = -5130, init = 5169, finish = 0
15/10/21 17:03:57 INFO PythonRDD: Times: total = 38, boot = -5129, init = 5167, finish = 0
15/10/21 17:03:57 INFO Executor: Finished task 0.0 in stage 109.0 (TID 217). 1870 bytes result sent to driver
15/10/21 17:03:57 INFO Executor: Finished task 1.0 in stage 109.0 (TID 218). 1870 bytes result sent to driver
15/10/21 17:03:57 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 217) in 43 ms on localhost (1/2)
15/10/21 17:03:57 INFO TaskSetManager: Finished task 1.0 in stage 109.0 (TID 218) in 43 ms on localhost (2/2)
15/10/21 17:03:57 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool 
15/10/21 17:03:57 INFO DAGScheduler: ResultStage 109 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:57 INFO DAGScheduler: Job 108 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053382 s
15/10/21 17:03:57 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:57 INFO DAGScheduler: Got job 109 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:57 INFO DAGScheduler: Final stage: ResultStage 110(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:57 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:57 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:57 INFO DAGScheduler: Submitting ResultStage 110 (PythonRDD[120] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:57 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=456329, maxMem=278302556
15/10/21 17:03:57 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:57 INFO MemoryStore: ensureFreeSpace(3954) called with curMem=463337, maxMem=278302556
15/10/21 17:03:57 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:57 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 110 (PythonRDD[120] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:57 INFO TaskSchedulerImpl: Adding task set 110.0 with 2 tasks
15/10/21 17:03:57 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 219, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:57 INFO TaskSetManager: Starting task 1.0 in stage 110.0 (TID 220, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:57 INFO Executor: Running task 0.0 in stage 110.0 (TID 219)
15/10/21 17:03:57 INFO Executor: Running task 1.0 in stage 110.0 (TID 220)
15/10/21 17:03:57 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:57 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:57 INFO PythonRDD: Times: total = 39, boot = -89, init = 128, finish = 0
15/10/21 17:03:57 INFO PythonRDD: Times: total = 40, boot = -88, init = 128, finish = 0
15/10/21 17:03:57 INFO Executor: Finished task 1.0 in stage 110.0 (TID 220). 1870 bytes result sent to driver
15/10/21 17:03:57 INFO Executor: Finished task 0.0 in stage 110.0 (TID 219). 1870 bytes result sent to driver
15/10/21 17:03:57 INFO TaskSetManager: Finished task 1.0 in stage 110.0 (TID 220) in 44 ms on localhost (1/2)
15/10/21 17:03:57 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 219) in 44 ms on localhost (2/2)
15/10/21 17:03:57 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool 
15/10/21 17:03:57 INFO DAGScheduler: ResultStage 110 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:57 INFO DAGScheduler: Job 109 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.065845 s
15/10/21 17:03:57 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:57 INFO DAGScheduler: Got job 110 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:57 INFO DAGScheduler: Final stage: ResultStage 111(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:57 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:57 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:57 INFO DAGScheduler: Submitting ResultStage 111 (PythonRDD[121] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:57 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=467291, maxMem=278302556
15/10/21 17:03:57 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:57 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=474299, maxMem=278302556
15/10/21 17:03:57 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:57 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 111 (PythonRDD[121] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:57 INFO TaskSchedulerImpl: Adding task set 111.0 with 2 tasks
15/10/21 17:03:57 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 221, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:57 INFO TaskSetManager: Starting task 1.0 in stage 111.0 (TID 222, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:57 INFO Executor: Running task 0.0 in stage 111.0 (TID 221)
15/10/21 17:03:57 INFO Executor: Running task 1.0 in stage 111.0 (TID 222)
15/10/21 17:03:57 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:57 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:57 INFO PythonRDD: Times: total = 38, boot = -92, init = 130, finish = 0
15/10/21 17:03:57 INFO PythonRDD: Times: total = 39, boot = -90, init = 129, finish = 0
15/10/21 17:03:57 INFO Executor: Finished task 1.0 in stage 111.0 (TID 222). 1870 bytes result sent to driver
15/10/21 17:03:57 INFO Executor: Finished task 0.0 in stage 111.0 (TID 221). 1870 bytes result sent to driver
15/10/21 17:03:57 INFO TaskSetManager: Finished task 1.0 in stage 111.0 (TID 222) in 43 ms on localhost (1/2)
15/10/21 17:03:57 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 221) in 43 ms on localhost (2/2)
15/10/21 17:03:57 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool 
15/10/21 17:03:57 INFO DAGScheduler: ResultStage 111 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:03:57 INFO DAGScheduler: Job 110 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053223 s
15/10/21 17:03:57 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:57 INFO DAGScheduler: Got job 111 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:57 INFO DAGScheduler: Final stage: ResultStage 112(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:57 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:57 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:57 INFO DAGScheduler: Submitting ResultStage 112 (PythonRDD[122] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:57 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=478255, maxMem=278302556
15/10/21 17:03:57 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 6.8 KB, free 264.9 MB)
15/10/21 17:03:57 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=485263, maxMem=278302556
15/10/21 17:03:57 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 3.9 KB, free 264.9 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:57 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 112 (PythonRDD[122] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:57 INFO TaskSchedulerImpl: Adding task set 112.0 with 2 tasks
15/10/21 17:03:57 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 223, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:57 INFO TaskSetManager: Starting task 1.0 in stage 112.0 (TID 224, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:57 INFO Executor: Running task 1.0 in stage 112.0 (TID 224)
15/10/21 17:03:57 INFO Executor: Running task 0.0 in stage 112.0 (TID 223)
15/10/21 17:03:57 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:57 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:57 INFO PythonRDD: Times: total = 38, boot = -78, init = 116, finish = 0
15/10/21 17:03:57 INFO PythonRDD: Times: total = 38, boot = -78, init = 116, finish = 0
15/10/21 17:03:57 INFO Executor: Finished task 0.0 in stage 112.0 (TID 223). 1870 bytes result sent to driver
15/10/21 17:03:57 INFO Executor: Finished task 1.0 in stage 112.0 (TID 224). 1870 bytes result sent to driver
15/10/21 17:03:57 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 223) in 43 ms on localhost (1/2)
15/10/21 17:03:57 INFO TaskSetManager: Finished task 1.0 in stage 112.0 (TID 224) in 42 ms on localhost (2/2)
15/10/21 17:03:57 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool 
15/10/21 17:03:57 INFO DAGScheduler: ResultStage 112 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:03:57 INFO DAGScheduler: Job 111 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053265 s
15/10/21 17:03:57 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:57 INFO DAGScheduler: Got job 112 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:57 INFO DAGScheduler: Final stage: ResultStage 113(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:57 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:57 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:57 INFO DAGScheduler: Submitting ResultStage 113 (PythonRDD[123] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:57 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=489219, maxMem=278302556
15/10/21 17:03:57 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 6.8 KB, free 264.9 MB)
15/10/21 17:03:57 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=496227, maxMem=278302556
15/10/21 17:03:57 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 3.9 KB, free 264.9 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:57 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 113 (PythonRDD[123] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:57 INFO TaskSchedulerImpl: Adding task set 113.0 with 2 tasks
15/10/21 17:03:57 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 225, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:57 INFO TaskSetManager: Starting task 1.0 in stage 113.0 (TID 226, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:57 INFO Executor: Running task 1.0 in stage 113.0 (TID 226)
15/10/21 17:03:57 INFO Executor: Running task 0.0 in stage 113.0 (TID 225)
15/10/21 17:03:57 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:57 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:57 INFO BlockManagerInfo: Removed broadcast_103_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Removed broadcast_102_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Removed broadcast_101_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Removed broadcast_100_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Removed broadcast_99_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Removed broadcast_98_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Removed broadcast_97_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Removed broadcast_96_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Removed broadcast_108_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Removed broadcast_107_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Removed broadcast_106_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Removed broadcast_105_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Removed broadcast_104_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Removed broadcast_114_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Removed broadcast_113_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Removed broadcast_112_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Removed broadcast_111_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Removed broadcast_110_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:57 INFO PythonRDD: Times: total = 44, boot = -76, init = 120, finish = 0
15/10/21 17:03:57 INFO PythonRDD: Times: total = 39, boot = -80, init = 119, finish = 0
15/10/21 17:03:57 INFO Executor: Finished task 1.0 in stage 113.0 (TID 226). 1870 bytes result sent to driver
15/10/21 17:03:57 INFO Executor: Finished task 0.0 in stage 113.0 (TID 225). 1870 bytes result sent to driver
15/10/21 17:03:57 INFO BlockManagerInfo: Removed broadcast_109_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:57 INFO TaskSetManager: Finished task 1.0 in stage 113.0 (TID 226) in 48 ms on localhost (1/2)
15/10/21 17:03:57 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 225) in 50 ms on localhost (2/2)
15/10/21 17:03:57 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool 
15/10/21 17:03:57 INFO DAGScheduler: ResultStage 113 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.050 s
15/10/21 17:03:57 INFO DAGScheduler: Job 112 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.058342 s
15/10/21 17:03:57 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:57 INFO DAGScheduler: Got job 113 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:57 INFO DAGScheduler: Final stage: ResultStage 114(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:57 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:57 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:57 INFO DAGScheduler: Submitting ResultStage 114 (PythonRDD[124] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:57 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=291870, maxMem=278302556
15/10/21 17:03:57 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:57 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=298878, maxMem=278302556
15/10/21 17:03:57 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:57 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:57 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:57 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 114 (PythonRDD[124] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:57 INFO TaskSchedulerImpl: Adding task set 114.0 with 2 tasks
15/10/21 17:03:57 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 227, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:57 INFO TaskSetManager: Starting task 1.0 in stage 114.0 (TID 228, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:57 INFO Executor: Running task 0.0 in stage 114.0 (TID 227)
15/10/21 17:03:57 INFO Executor: Running task 1.0 in stage 114.0 (TID 228)
15/10/21 17:03:57 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:57 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:58 INFO PythonRDD: Times: total = 39, boot = -83, init = 122, finish = 0
15/10/21 17:03:58 INFO PythonRDD: Times: total = 40, boot = -82, init = 122, finish = 0
15/10/21 17:03:58 INFO Executor: Finished task 1.0 in stage 114.0 (TID 228). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO Executor: Finished task 0.0 in stage 114.0 (TID 227). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO TaskSetManager: Finished task 1.0 in stage 114.0 (TID 228) in 44 ms on localhost (1/2)
15/10/21 17:03:58 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 227) in 44 ms on localhost (2/2)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool 
15/10/21 17:03:58 INFO DAGScheduler: ResultStage 114 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:03:58 INFO DAGScheduler: Job 113 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053683 s
15/10/21 17:03:58 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:58 INFO DAGScheduler: Got job 114 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:58 INFO DAGScheduler: Final stage: ResultStage 115(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:58 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:58 INFO DAGScheduler: Submitting ResultStage 115 (PythonRDD[125] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=302834, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=309842, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:58 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:58 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 115 (PythonRDD[125] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Adding task set 115.0 with 2 tasks
15/10/21 17:03:58 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 229, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO TaskSetManager: Starting task 1.0 in stage 115.0 (TID 230, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO Executor: Running task 0.0 in stage 115.0 (TID 229)
15/10/21 17:03:58 INFO Executor: Running task 1.0 in stage 115.0 (TID 230)
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:58 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:03:58 INFO PythonRDD: Times: total = 40, boot = -78, init = 118, finish = 0
15/10/21 17:03:58 INFO Executor: Finished task 1.0 in stage 115.0 (TID 230). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO Executor: Finished task 0.0 in stage 115.0 (TID 229). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO TaskSetManager: Finished task 1.0 in stage 115.0 (TID 230) in 44 ms on localhost (1/2)
15/10/21 17:03:58 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 229) in 45 ms on localhost (2/2)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool 
15/10/21 17:03:58 INFO DAGScheduler: ResultStage 115 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:03:58 INFO DAGScheduler: Job 114 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.054087 s
15/10/21 17:03:58 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:58 INFO DAGScheduler: Got job 115 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:58 INFO DAGScheduler: Final stage: ResultStage 116(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:58 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:58 INFO DAGScheduler: Submitting ResultStage 116 (PythonRDD[126] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=313798, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=320806, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:58 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:58 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 116 (PythonRDD[126] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Adding task set 116.0 with 2 tasks
15/10/21 17:03:58 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 231, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO TaskSetManager: Starting task 1.0 in stage 116.0 (TID 232, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO Executor: Running task 1.0 in stage 116.0 (TID 232)
15/10/21 17:03:58 INFO Executor: Running task 0.0 in stage 116.0 (TID 231)
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:58 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:03:58 INFO PythonRDD: Times: total = 39, boot = -77, init = 116, finish = 0
15/10/21 17:03:58 INFO Executor: Finished task 1.0 in stage 116.0 (TID 232). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO Executor: Finished task 0.0 in stage 116.0 (TID 231). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO TaskSetManager: Finished task 1.0 in stage 116.0 (TID 232) in 44 ms on localhost (1/2)
15/10/21 17:03:58 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 231) in 44 ms on localhost (2/2)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool 
15/10/21 17:03:58 INFO DAGScheduler: ResultStage 116 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:58 INFO DAGScheduler: Job 115 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053120 s
15/10/21 17:03:58 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:58 INFO DAGScheduler: Got job 116 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:58 INFO DAGScheduler: Final stage: ResultStage 117(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:58 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:58 INFO DAGScheduler: Submitting ResultStage 117 (PythonRDD[127] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=324762, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=331770, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:58 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:58 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 117 (PythonRDD[127] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Adding task set 117.0 with 2 tasks
15/10/21 17:03:58 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 233, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO TaskSetManager: Starting task 1.0 in stage 117.0 (TID 234, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO Executor: Running task 0.0 in stage 117.0 (TID 233)
15/10/21 17:03:58 INFO Executor: Running task 1.0 in stage 117.0 (TID 234)
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:58 INFO PythonRDD: Times: total = 39, boot = -76, init = 115, finish = 0
15/10/21 17:03:58 INFO PythonRDD: Times: total = 39, boot = -77, init = 116, finish = 0
15/10/21 17:03:58 INFO Executor: Finished task 1.0 in stage 117.0 (TID 234). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO Executor: Finished task 0.0 in stage 117.0 (TID 233). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO TaskSetManager: Finished task 1.0 in stage 117.0 (TID 234) in 43 ms on localhost (1/2)
15/10/21 17:03:58 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 233) in 44 ms on localhost (2/2)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool 
15/10/21 17:03:58 INFO DAGScheduler: ResultStage 117 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:58 INFO DAGScheduler: Job 116 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053646 s
15/10/21 17:03:58 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:58 INFO DAGScheduler: Got job 117 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:58 INFO DAGScheduler: Final stage: ResultStage 118(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:58 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:58 INFO DAGScheduler: Submitting ResultStage 118 (PythonRDD[128] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=335726, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=342734, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:58 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:58 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 118 (PythonRDD[128] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Adding task set 118.0 with 2 tasks
15/10/21 17:03:58 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 235, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO TaskSetManager: Starting task 1.0 in stage 118.0 (TID 236, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO Executor: Running task 1.0 in stage 118.0 (TID 236)
15/10/21 17:03:58 INFO Executor: Running task 0.0 in stage 118.0 (TID 235)
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:58 INFO PythonRDD: Times: total = 44, boot = -76, init = 120, finish = 0
15/10/21 17:03:58 INFO PythonRDD: Times: total = 43, boot = -78, init = 121, finish = 0
15/10/21 17:03:58 INFO Executor: Finished task 1.0 in stage 118.0 (TID 236). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO Executor: Finished task 0.0 in stage 118.0 (TID 235). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO TaskSetManager: Finished task 1.0 in stage 118.0 (TID 236) in 48 ms on localhost (1/2)
15/10/21 17:03:58 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 235) in 48 ms on localhost (2/2)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool 
15/10/21 17:03:58 INFO DAGScheduler: ResultStage 118 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.049 s
15/10/21 17:03:58 INFO DAGScheduler: Job 117 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.057298 s
15/10/21 17:03:58 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:58 INFO DAGScheduler: Got job 118 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:58 INFO DAGScheduler: Final stage: ResultStage 119(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:58 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:58 INFO DAGScheduler: Submitting ResultStage 119 (PythonRDD[129] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=346690, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=353698, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:58 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:58 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 119 (PythonRDD[129] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Adding task set 119.0 with 2 tasks
15/10/21 17:03:58 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 237, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO TaskSetManager: Starting task 1.0 in stage 119.0 (TID 238, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO Executor: Running task 0.0 in stage 119.0 (TID 237)
15/10/21 17:03:58 INFO Executor: Running task 1.0 in stage 119.0 (TID 238)
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:58 INFO PythonRDD: Times: total = 39, boot = -82, init = 121, finish = 0
15/10/21 17:03:58 INFO PythonRDD: Times: total = 39, boot = -80, init = 119, finish = 0
15/10/21 17:03:58 INFO Executor: Finished task 0.0 in stage 119.0 (TID 237). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO Executor: Finished task 1.0 in stage 119.0 (TID 238). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 237) in 44 ms on localhost (1/2)
15/10/21 17:03:58 INFO TaskSetManager: Finished task 1.0 in stage 119.0 (TID 238) in 43 ms on localhost (2/2)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool 
15/10/21 17:03:58 INFO DAGScheduler: ResultStage 119 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:03:58 INFO DAGScheduler: Job 118 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053684 s
15/10/21 17:03:58 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:58 INFO DAGScheduler: Got job 119 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:58 INFO DAGScheduler: Final stage: ResultStage 120(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:58 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:58 INFO DAGScheduler: Submitting ResultStage 120 (PythonRDD[130] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=357654, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=364662, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:58 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:58 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 120 (PythonRDD[130] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Adding task set 120.0 with 2 tasks
15/10/21 17:03:58 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 239, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO TaskSetManager: Starting task 1.0 in stage 120.0 (TID 240, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO Executor: Running task 0.0 in stage 120.0 (TID 239)
15/10/21 17:03:58 INFO Executor: Running task 1.0 in stage 120.0 (TID 240)
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:58 INFO PythonRDD: Times: total = 40, boot = -77, init = 117, finish = 0
15/10/21 17:03:58 INFO PythonRDD: Times: total = 40, boot = -75, init = 115, finish = 0
15/10/21 17:03:58 INFO Executor: Finished task 0.0 in stage 120.0 (TID 239). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO Executor: Finished task 1.0 in stage 120.0 (TID 240). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 239) in 44 ms on localhost (1/2)
15/10/21 17:03:58 INFO TaskSetManager: Finished task 1.0 in stage 120.0 (TID 240) in 44 ms on localhost (2/2)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool 
15/10/21 17:03:58 INFO DAGScheduler: ResultStage 120 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:03:58 INFO DAGScheduler: Job 119 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053472 s
15/10/21 17:03:58 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:58 INFO DAGScheduler: Got job 120 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:58 INFO DAGScheduler: Final stage: ResultStage 121(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:58 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:58 INFO DAGScheduler: Submitting ResultStage 121 (PythonRDD[131] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=368618, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=375626, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:58 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:58 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 121 (PythonRDD[131] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Adding task set 121.0 with 2 tasks
15/10/21 17:03:58 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 241, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO TaskSetManager: Starting task 1.0 in stage 121.0 (TID 242, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO Executor: Running task 0.0 in stage 121.0 (TID 241)
15/10/21 17:03:58 INFO Executor: Running task 1.0 in stage 121.0 (TID 242)
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:58 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:03:58 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:03:58 INFO Executor: Finished task 1.0 in stage 121.0 (TID 242). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO Executor: Finished task 0.0 in stage 121.0 (TID 241). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO TaskSetManager: Finished task 1.0 in stage 121.0 (TID 242) in 44 ms on localhost (1/2)
15/10/21 17:03:58 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 241) in 44 ms on localhost (2/2)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool 
15/10/21 17:03:58 INFO DAGScheduler: ResultStage 121 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:58 INFO DAGScheduler: Job 120 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.054021 s
15/10/21 17:03:58 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:58 INFO DAGScheduler: Got job 121 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:58 INFO DAGScheduler: Final stage: ResultStage 122(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:58 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:58 INFO DAGScheduler: Submitting ResultStage 122 (PythonRDD[132] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=379582, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=386590, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:58 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:58 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 122 (PythonRDD[132] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Adding task set 122.0 with 2 tasks
15/10/21 17:03:58 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 243, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO TaskSetManager: Starting task 1.0 in stage 122.0 (TID 244, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO Executor: Running task 0.0 in stage 122.0 (TID 243)
15/10/21 17:03:58 INFO Executor: Running task 1.0 in stage 122.0 (TID 244)
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:58 INFO PythonRDD: Times: total = 39, boot = -78, init = 117, finish = 0
15/10/21 17:03:58 INFO PythonRDD: Times: total = 39, boot = -79, init = 118, finish = 0
15/10/21 17:03:58 INFO Executor: Finished task 0.0 in stage 122.0 (TID 243). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO Executor: Finished task 1.0 in stage 122.0 (TID 244). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 243) in 44 ms on localhost (1/2)
15/10/21 17:03:58 INFO TaskSetManager: Finished task 1.0 in stage 122.0 (TID 244) in 44 ms on localhost (2/2)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool 
15/10/21 17:03:58 INFO DAGScheduler: ResultStage 122 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:58 INFO DAGScheduler: Job 121 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053581 s
15/10/21 17:03:58 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:58 INFO DAGScheduler: Got job 122 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:58 INFO DAGScheduler: Final stage: ResultStage 123(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:58 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:58 INFO DAGScheduler: Submitting ResultStage 123 (PythonRDD[133] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=390546, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=397554, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:58 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:58 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 123 (PythonRDD[133] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Adding task set 123.0 with 2 tasks
15/10/21 17:03:58 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 245, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO TaskSetManager: Starting task 1.0 in stage 123.0 (TID 246, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO Executor: Running task 0.0 in stage 123.0 (TID 245)
15/10/21 17:03:58 INFO Executor: Running task 1.0 in stage 123.0 (TID 246)
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:58 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:03:58 INFO PythonRDD: Times: total = 40, boot = -75, init = 115, finish = 0
15/10/21 17:03:58 INFO Executor: Finished task 0.0 in stage 123.0 (TID 245). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO Executor: Finished task 1.0 in stage 123.0 (TID 246). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 245) in 44 ms on localhost (1/2)
15/10/21 17:03:58 INFO TaskSetManager: Finished task 1.0 in stage 123.0 (TID 246) in 44 ms on localhost (2/2)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool 
15/10/21 17:03:58 INFO DAGScheduler: ResultStage 123 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:58 INFO DAGScheduler: Job 122 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053745 s
15/10/21 17:03:58 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:58 INFO DAGScheduler: Got job 123 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:58 INFO DAGScheduler: Final stage: ResultStage 124(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:58 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:58 INFO DAGScheduler: Submitting ResultStage 124 (PythonRDD[134] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=401510, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=408518, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:58 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:58 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 124 (PythonRDD[134] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Adding task set 124.0 with 2 tasks
15/10/21 17:03:58 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 247, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO TaskSetManager: Starting task 1.0 in stage 124.0 (TID 248, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO Executor: Running task 0.0 in stage 124.0 (TID 247)
15/10/21 17:03:58 INFO Executor: Running task 1.0 in stage 124.0 (TID 248)
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:58 INFO PythonRDD: Times: total = 39, boot = -76, init = 115, finish = 0
15/10/21 17:03:58 INFO PythonRDD: Times: total = 39, boot = -77, init = 116, finish = 0
15/10/21 17:03:58 INFO Executor: Finished task 1.0 in stage 124.0 (TID 248). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO Executor: Finished task 0.0 in stage 124.0 (TID 247). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO TaskSetManager: Finished task 1.0 in stage 124.0 (TID 248) in 43 ms on localhost (1/2)
15/10/21 17:03:58 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 247) in 43 ms on localhost (2/2)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool 
15/10/21 17:03:58 INFO DAGScheduler: ResultStage 124 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:03:58 INFO DAGScheduler: Job 123 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053092 s
15/10/21 17:03:58 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:58 INFO DAGScheduler: Got job 124 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:58 INFO DAGScheduler: Final stage: ResultStage 125(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:58 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:58 INFO DAGScheduler: Submitting ResultStage 125 (PythonRDD[135] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=412474, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=419482, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:58 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:58 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 125 (PythonRDD[135] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Adding task set 125.0 with 2 tasks
15/10/21 17:03:58 INFO TaskSetManager: Starting task 0.0 in stage 125.0 (TID 249, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO TaskSetManager: Starting task 1.0 in stage 125.0 (TID 250, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO Executor: Running task 0.0 in stage 125.0 (TID 249)
15/10/21 17:03:58 INFO Executor: Running task 1.0 in stage 125.0 (TID 250)
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:58 INFO PythonRDD: Times: total = 39, boot = -77, init = 116, finish = 0
15/10/21 17:03:58 INFO PythonRDD: Times: total = 39, boot = -78, init = 117, finish = 0
15/10/21 17:03:58 INFO Executor: Finished task 0.0 in stage 125.0 (TID 249). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO Executor: Finished task 1.0 in stage 125.0 (TID 250). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO TaskSetManager: Finished task 0.0 in stage 125.0 (TID 249) in 43 ms on localhost (1/2)
15/10/21 17:03:58 INFO TaskSetManager: Finished task 1.0 in stage 125.0 (TID 250) in 43 ms on localhost (2/2)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Removed TaskSet 125.0, whose tasks have all completed, from pool 
15/10/21 17:03:58 INFO DAGScheduler: ResultStage 125 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:58 INFO DAGScheduler: Job 124 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053261 s
15/10/21 17:03:58 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:58 INFO DAGScheduler: Got job 125 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:58 INFO DAGScheduler: Final stage: ResultStage 126(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:58 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:58 INFO DAGScheduler: Submitting ResultStage 126 (PythonRDD[136] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=423438, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=430446, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:58 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:58 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 126 (PythonRDD[136] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Adding task set 126.0 with 2 tasks
15/10/21 17:03:58 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 251, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO TaskSetManager: Starting task 1.0 in stage 126.0 (TID 252, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO Executor: Running task 1.0 in stage 126.0 (TID 252)
15/10/21 17:03:58 INFO Executor: Running task 0.0 in stage 126.0 (TID 251)
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:58 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:03:58 INFO PythonRDD: Times: total = 39, boot = -77, init = 116, finish = 0
15/10/21 17:03:58 INFO Executor: Finished task 1.0 in stage 126.0 (TID 252). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO Executor: Finished task 0.0 in stage 126.0 (TID 251). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO TaskSetManager: Finished task 1.0 in stage 126.0 (TID 252) in 44 ms on localhost (1/2)
15/10/21 17:03:58 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 251) in 44 ms on localhost (2/2)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool 
15/10/21 17:03:58 INFO DAGScheduler: ResultStage 126 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:03:58 INFO DAGScheduler: Job 125 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053492 s
15/10/21 17:03:58 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:58 INFO DAGScheduler: Got job 126 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:58 INFO DAGScheduler: Final stage: ResultStage 127(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:58 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:58 INFO DAGScheduler: Submitting ResultStage 127 (PythonRDD[137] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=434402, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=441410, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:58 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:58 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 127 (PythonRDD[137] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Adding task set 127.0 with 2 tasks
15/10/21 17:03:58 INFO TaskSetManager: Starting task 0.0 in stage 127.0 (TID 253, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO TaskSetManager: Starting task 1.0 in stage 127.0 (TID 254, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO Executor: Running task 0.0 in stage 127.0 (TID 253)
15/10/21 17:03:58 INFO Executor: Running task 1.0 in stage 127.0 (TID 254)
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:58 INFO PythonRDD: Times: total = 40, boot = -77, init = 117, finish = 0
15/10/21 17:03:58 INFO PythonRDD: Times: total = 40, boot = -75, init = 115, finish = 0
15/10/21 17:03:58 INFO Executor: Finished task 0.0 in stage 127.0 (TID 253). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO Executor: Finished task 1.0 in stage 127.0 (TID 254). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO TaskSetManager: Finished task 0.0 in stage 127.0 (TID 253) in 44 ms on localhost (1/2)
15/10/21 17:03:58 INFO TaskSetManager: Finished task 1.0 in stage 127.0 (TID 254) in 44 ms on localhost (2/2)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool 
15/10/21 17:03:58 INFO DAGScheduler: ResultStage 127 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:58 INFO DAGScheduler: Job 126 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053735 s
15/10/21 17:03:58 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:58 INFO DAGScheduler: Got job 127 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:58 INFO DAGScheduler: Final stage: ResultStage 128(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:58 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:58 INFO DAGScheduler: Submitting ResultStage 128 (PythonRDD[138] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=445366, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:58 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=452374, maxMem=278302556
15/10/21 17:03:58 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:58 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:58 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 128 (PythonRDD[138] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Adding task set 128.0 with 2 tasks
15/10/21 17:03:58 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 255, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO TaskSetManager: Starting task 1.0 in stage 128.0 (TID 256, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:58 INFO Executor: Running task 1.0 in stage 128.0 (TID 256)
15/10/21 17:03:58 INFO Executor: Running task 0.0 in stage 128.0 (TID 255)
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:58 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:58 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:03:58 INFO PythonRDD: Times: total = 40, boot = -75, init = 115, finish = 0
15/10/21 17:03:58 INFO Executor: Finished task 1.0 in stage 128.0 (TID 256). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO Executor: Finished task 0.0 in stage 128.0 (TID 255). 1870 bytes result sent to driver
15/10/21 17:03:58 INFO TaskSetManager: Finished task 1.0 in stage 128.0 (TID 256) in 44 ms on localhost (1/2)
15/10/21 17:03:58 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 255) in 44 ms on localhost (2/2)
15/10/21 17:03:58 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool 
15/10/21 17:03:58 INFO DAGScheduler: ResultStage 128 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:58 INFO DAGScheduler: Job 127 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053837 s
15/10/21 17:03:59 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:59 INFO DAGScheduler: Got job 128 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:59 INFO DAGScheduler: Final stage: ResultStage 129(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:59 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:59 INFO DAGScheduler: Submitting ResultStage 129 (PythonRDD[139] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=456330, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=463338, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:59 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 129 (PythonRDD[139] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Adding task set 129.0 with 2 tasks
15/10/21 17:03:59 INFO TaskSetManager: Starting task 0.0 in stage 129.0 (TID 257, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO TaskSetManager: Starting task 1.0 in stage 129.0 (TID 258, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO Executor: Running task 1.0 in stage 129.0 (TID 258)
15/10/21 17:03:59 INFO Executor: Running task 0.0 in stage 129.0 (TID 257)
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:59 INFO PythonRDD: Times: total = 41, boot = -75, init = 116, finish = 0
15/10/21 17:03:59 INFO PythonRDD: Times: total = 40, boot = -78, init = 118, finish = 0
15/10/21 17:03:59 INFO Executor: Finished task 1.0 in stage 129.0 (TID 258). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO Executor: Finished task 0.0 in stage 129.0 (TID 257). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO TaskSetManager: Finished task 1.0 in stage 129.0 (TID 258) in 45 ms on localhost (1/2)
15/10/21 17:03:59 INFO TaskSetManager: Finished task 0.0 in stage 129.0 (TID 257) in 45 ms on localhost (2/2)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool 
15/10/21 17:03:59 INFO DAGScheduler: ResultStage 129 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:59 INFO DAGScheduler: Job 128 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053535 s
15/10/21 17:03:59 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:59 INFO DAGScheduler: Got job 129 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:59 INFO DAGScheduler: Final stage: ResultStage 130(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:59 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:59 INFO DAGScheduler: Submitting ResultStage 130 (PythonRDD[140] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=467294, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=474302, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:59 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 130 (PythonRDD[140] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Adding task set 130.0 with 2 tasks
15/10/21 17:03:59 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 259, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO TaskSetManager: Starting task 1.0 in stage 130.0 (TID 260, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO Executor: Running task 1.0 in stage 130.0 (TID 260)
15/10/21 17:03:59 INFO Executor: Running task 0.0 in stage 130.0 (TID 259)
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:59 INFO PythonRDD: Times: total = 38, boot = -74, init = 112, finish = 0
15/10/21 17:03:59 INFO Executor: Finished task 1.0 in stage 130.0 (TID 260). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO TaskSetManager: Finished task 1.0 in stage 130.0 (TID 260) in 40 ms on localhost (1/2)
15/10/21 17:03:59 INFO PythonRDD: Times: total = 41, boot = -75, init = 116, finish = 0
15/10/21 17:03:59 INFO Executor: Finished task 0.0 in stage 130.0 (TID 259). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO TaskSetManager: Finished task 0.0 in stage 130.0 (TID 259) in 46 ms on localhost (2/2)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool 
15/10/21 17:03:59 INFO DAGScheduler: ResultStage 130 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:03:59 INFO DAGScheduler: Job 129 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053478 s
15/10/21 17:03:59 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:59 INFO DAGScheduler: Got job 130 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:59 INFO DAGScheduler: Final stage: ResultStage 131(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:59 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:59 INFO DAGScheduler: Submitting ResultStage 131 (PythonRDD[141] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=478258, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 6.8 KB, free 264.9 MB)
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=485266, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 3.9 KB, free 264.9 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:59 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 131 (PythonRDD[141] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Adding task set 131.0 with 2 tasks
15/10/21 17:03:59 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 261, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO TaskSetManager: Starting task 1.0 in stage 131.0 (TID 262, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO Executor: Running task 1.0 in stage 131.0 (TID 262)
15/10/21 17:03:59 INFO Executor: Running task 0.0 in stage 131.0 (TID 261)
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:59 INFO PythonRDD: Times: total = 37, boot = -75, init = 112, finish = 0
15/10/21 17:03:59 INFO Executor: Finished task 1.0 in stage 131.0 (TID 262). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO TaskSetManager: Finished task 1.0 in stage 131.0 (TID 262) in 40 ms on localhost (1/2)
15/10/21 17:03:59 INFO PythonRDD: Times: total = 41, boot = -75, init = 116, finish = 0
15/10/21 17:03:59 INFO Executor: Finished task 0.0 in stage 131.0 (TID 261). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 261) in 46 ms on localhost (2/2)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool 
15/10/21 17:03:59 INFO DAGScheduler: ResultStage 131 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:03:59 INFO DAGScheduler: Job 130 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053911 s
15/10/21 17:03:59 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:59 INFO DAGScheduler: Got job 131 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:59 INFO DAGScheduler: Final stage: ResultStage 132(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:59 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:59 INFO DAGScheduler: Submitting ResultStage 132 (PythonRDD[142] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=489222, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 6.8 KB, free 264.9 MB)
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=496230, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 3.9 KB, free 264.9 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:59 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 132 (PythonRDD[142] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Adding task set 132.0 with 2 tasks
15/10/21 17:03:59 INFO TaskSetManager: Starting task 0.0 in stage 132.0 (TID 263, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO TaskSetManager: Starting task 1.0 in stage 132.0 (TID 264, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO Executor: Running task 0.0 in stage 132.0 (TID 263)
15/10/21 17:03:59 INFO Executor: Running task 1.0 in stage 132.0 (TID 264)
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:59 INFO PythonRDD: Times: total = 41, boot = -75, init = 116, finish = 0
15/10/21 17:03:59 INFO PythonRDD: Times: total = 41, boot = -78, init = 119, finish = 0
15/10/21 17:03:59 INFO Executor: Finished task 1.0 in stage 132.0 (TID 264). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO Executor: Finished task 0.0 in stage 132.0 (TID 263). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO TaskSetManager: Finished task 1.0 in stage 132.0 (TID 264) in 49 ms on localhost (1/2)
15/10/21 17:03:59 INFO TaskSetManager: Finished task 0.0 in stage 132.0 (TID 263) in 50 ms on localhost (2/2)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Removed TaskSet 132.0, whose tasks have all completed, from pool 
15/10/21 17:03:59 INFO DAGScheduler: ResultStage 132 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.051 s
15/10/21 17:03:59 INFO DAGScheduler: Job 131 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.059454 s
15/10/21 17:03:59 INFO BlockManagerInfo: Removed broadcast_115_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Removed broadcast_133_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Removed broadcast_132_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Removed broadcast_131_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Removed broadcast_130_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Removed broadcast_129_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Removed broadcast_128_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:59 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:59 INFO BlockManagerInfo: Removed broadcast_127_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:59 INFO DAGScheduler: Got job 132 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:59 INFO DAGScheduler: Final stage: ResultStage 133(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:59 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:59 INFO BlockManagerInfo: Removed broadcast_123_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:59 INFO DAGScheduler: Submitting ResultStage 133 (PythonRDD[143] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=401510, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Removed broadcast_122_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=397554, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:59 INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:59 INFO BlockManagerInfo: Removed broadcast_121_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 133 (PythonRDD[143] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Adding task set 133.0 with 2 tasks
15/10/21 17:03:59 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 265, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO TaskSetManager: Starting task 1.0 in stage 133.0 (TID 266, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO BlockManagerInfo: Removed broadcast_120_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:59 INFO Executor: Running task 0.0 in stage 133.0 (TID 265)
15/10/21 17:03:59 INFO Executor: Running task 1.0 in stage 133.0 (TID 266)
15/10/21 17:03:59 INFO BlockManagerInfo: Removed broadcast_119_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:59 INFO BlockManagerInfo: Removed broadcast_118_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Removed broadcast_117_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Removed broadcast_116_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Removed broadcast_126_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Removed broadcast_125_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Removed broadcast_124_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:59 INFO PythonRDD: Times: total = 38, boot = -86, init = 124, finish = 0
15/10/21 17:03:59 INFO PythonRDD: Times: total = 37, boot = -82, init = 119, finish = 0
15/10/21 17:03:59 INFO Executor: Finished task 1.0 in stage 133.0 (TID 266). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO Executor: Finished task 0.0 in stage 133.0 (TID 265). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO TaskSetManager: Finished task 1.0 in stage 133.0 (TID 266) in 41 ms on localhost (1/2)
15/10/21 17:03:59 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 265) in 42 ms on localhost (2/2)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool 
15/10/21 17:03:59 INFO DAGScheduler: ResultStage 133 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.042 s
15/10/21 17:03:59 INFO DAGScheduler: Job 132 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.051174 s
15/10/21 17:03:59 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:59 INFO DAGScheduler: Got job 133 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:59 INFO DAGScheduler: Final stage: ResultStage 134(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:59 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:59 INFO DAGScheduler: Submitting ResultStage 134 (PythonRDD[144] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=302834, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=309842, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:59 INFO SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 134 (PythonRDD[144] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Adding task set 134.0 with 2 tasks
15/10/21 17:03:59 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 267, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO TaskSetManager: Starting task 1.0 in stage 134.0 (TID 268, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO Executor: Running task 0.0 in stage 134.0 (TID 267)
15/10/21 17:03:59 INFO Executor: Running task 1.0 in stage 134.0 (TID 268)
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:59 INFO PythonRDD: Times: total = 40, boot = -79, init = 119, finish = 0
15/10/21 17:03:59 INFO PythonRDD: Times: total = 40, boot = -80, init = 120, finish = 0
15/10/21 17:03:59 INFO Executor: Finished task 1.0 in stage 134.0 (TID 268). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO Executor: Finished task 0.0 in stage 134.0 (TID 267). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO TaskSetManager: Finished task 1.0 in stage 134.0 (TID 268) in 45 ms on localhost (1/2)
15/10/21 17:03:59 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 267) in 45 ms on localhost (2/2)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool 
15/10/21 17:03:59 INFO DAGScheduler: ResultStage 134 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:03:59 INFO DAGScheduler: Job 133 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.054410 s
15/10/21 17:03:59 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:59 INFO DAGScheduler: Got job 134 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:59 INFO DAGScheduler: Final stage: ResultStage 135(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:59 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:59 INFO DAGScheduler: Submitting ResultStage 135 (PythonRDD[145] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=313798, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=320806, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:59 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 135 (PythonRDD[145] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Adding task set 135.0 with 2 tasks
15/10/21 17:03:59 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 269, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO TaskSetManager: Starting task 1.0 in stage 135.0 (TID 270, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO Executor: Running task 0.0 in stage 135.0 (TID 269)
15/10/21 17:03:59 INFO Executor: Running task 1.0 in stage 135.0 (TID 270)
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:59 INFO PythonRDD: Times: total = 40, boot = -75, init = 115, finish = 0
15/10/21 17:03:59 INFO Executor: Finished task 1.0 in stage 135.0 (TID 270). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO TaskSetManager: Finished task 1.0 in stage 135.0 (TID 270) in 43 ms on localhost (1/2)
15/10/21 17:03:59 INFO PythonRDD: Times: total = 44, boot = -77, init = 121, finish = 0
15/10/21 17:03:59 INFO Executor: Finished task 0.0 in stage 135.0 (TID 269). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 269) in 48 ms on localhost (2/2)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool 
15/10/21 17:03:59 INFO DAGScheduler: ResultStage 135 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.049 s
15/10/21 17:03:59 INFO DAGScheduler: Job 134 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.056721 s
15/10/21 17:03:59 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:59 INFO DAGScheduler: Got job 135 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:59 INFO DAGScheduler: Final stage: ResultStage 136(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:59 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:59 INFO DAGScheduler: Submitting ResultStage 136 (PythonRDD[146] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=324762, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=331770, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:59 INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 136 (PythonRDD[146] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Adding task set 136.0 with 2 tasks
15/10/21 17:03:59 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 271, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO TaskSetManager: Starting task 1.0 in stage 136.0 (TID 272, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO Executor: Running task 1.0 in stage 136.0 (TID 272)
15/10/21 17:03:59 INFO Executor: Running task 0.0 in stage 136.0 (TID 271)
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:59 INFO PythonRDD: Times: total = 37, boot = -78, init = 115, finish = 0
15/10/21 17:03:59 INFO Executor: Finished task 1.0 in stage 136.0 (TID 272). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO TaskSetManager: Finished task 1.0 in stage 136.0 (TID 272) in 40 ms on localhost (1/2)
15/10/21 17:03:59 INFO PythonRDD: Times: total = 41, boot = -79, init = 120, finish = 0
15/10/21 17:03:59 INFO Executor: Finished task 0.0 in stage 136.0 (TID 271). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 271) in 46 ms on localhost (2/2)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool 
15/10/21 17:03:59 INFO DAGScheduler: ResultStage 136 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:03:59 INFO DAGScheduler: Job 135 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.054374 s
15/10/21 17:03:59 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:59 INFO DAGScheduler: Got job 136 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:59 INFO DAGScheduler: Final stage: ResultStage 137(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:59 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:59 INFO DAGScheduler: Submitting ResultStage 137 (PythonRDD[147] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=335726, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=342734, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:59 INFO SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 137 (PythonRDD[147] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Adding task set 137.0 with 2 tasks
15/10/21 17:03:59 INFO TaskSetManager: Starting task 0.0 in stage 137.0 (TID 273, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO TaskSetManager: Starting task 1.0 in stage 137.0 (TID 274, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO Executor: Running task 0.0 in stage 137.0 (TID 273)
15/10/21 17:03:59 INFO Executor: Running task 1.0 in stage 137.0 (TID 274)
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:59 INFO PythonRDD: Times: total = 41, boot = -75, init = 116, finish = 0
15/10/21 17:03:59 INFO PythonRDD: Times: total = 41, boot = -80, init = 121, finish = 0
15/10/21 17:03:59 INFO Executor: Finished task 1.0 in stage 137.0 (TID 274). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO Executor: Finished task 0.0 in stage 137.0 (TID 273). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO TaskSetManager: Finished task 1.0 in stage 137.0 (TID 274) in 45 ms on localhost (1/2)
15/10/21 17:03:59 INFO TaskSetManager: Finished task 0.0 in stage 137.0 (TID 273) in 45 ms on localhost (2/2)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool 
15/10/21 17:03:59 INFO DAGScheduler: ResultStage 137 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:03:59 INFO DAGScheduler: Job 136 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.054184 s
15/10/21 17:03:59 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:59 INFO DAGScheduler: Got job 137 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:59 INFO DAGScheduler: Final stage: ResultStage 138(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:59 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:59 INFO DAGScheduler: Submitting ResultStage 138 (PythonRDD[148] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=346690, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=353698, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:03:59 INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 138 (PythonRDD[148] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Adding task set 138.0 with 2 tasks
15/10/21 17:03:59 INFO TaskSetManager: Starting task 0.0 in stage 138.0 (TID 275, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO TaskSetManager: Starting task 1.0 in stage 138.0 (TID 276, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO Executor: Running task 0.0 in stage 138.0 (TID 275)
15/10/21 17:03:59 INFO Executor: Running task 1.0 in stage 138.0 (TID 276)
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:59 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:03:59 INFO PythonRDD: Times: total = 40, boot = -80, init = 120, finish = 0
15/10/21 17:03:59 INFO Executor: Finished task 0.0 in stage 138.0 (TID 275). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO Executor: Finished task 1.0 in stage 138.0 (TID 276). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO TaskSetManager: Finished task 0.0 in stage 138.0 (TID 275) in 45 ms on localhost (1/2)
15/10/21 17:03:59 INFO TaskSetManager: Finished task 1.0 in stage 138.0 (TID 276) in 45 ms on localhost (2/2)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Removed TaskSet 138.0, whose tasks have all completed, from pool 
15/10/21 17:03:59 INFO DAGScheduler: ResultStage 138 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:59 INFO DAGScheduler: Job 137 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.054069 s
15/10/21 17:03:59 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:59 INFO DAGScheduler: Got job 138 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:59 INFO DAGScheduler: Final stage: ResultStage 139(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:59 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:59 INFO DAGScheduler: Submitting ResultStage 139 (PythonRDD[149] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=357654, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=364662, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:59 INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 139 (PythonRDD[149] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Adding task set 139.0 with 2 tasks
15/10/21 17:03:59 INFO TaskSetManager: Starting task 0.0 in stage 139.0 (TID 277, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO TaskSetManager: Starting task 1.0 in stage 139.0 (TID 278, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO Executor: Running task 0.0 in stage 139.0 (TID 277)
15/10/21 17:03:59 INFO Executor: Running task 1.0 in stage 139.0 (TID 278)
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:59 INFO PythonRDD: Times: total = 40, boot = -75, init = 115, finish = 0
15/10/21 17:03:59 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:03:59 INFO Executor: Finished task 1.0 in stage 139.0 (TID 278). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO Executor: Finished task 0.0 in stage 139.0 (TID 277). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO TaskSetManager: Finished task 1.0 in stage 139.0 (TID 278) in 44 ms on localhost (1/2)
15/10/21 17:03:59 INFO TaskSetManager: Finished task 0.0 in stage 139.0 (TID 277) in 45 ms on localhost (2/2)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Removed TaskSet 139.0, whose tasks have all completed, from pool 
15/10/21 17:03:59 INFO DAGScheduler: ResultStage 139 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:03:59 INFO DAGScheduler: Job 138 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053476 s
15/10/21 17:03:59 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:59 INFO DAGScheduler: Got job 139 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:59 INFO DAGScheduler: Final stage: ResultStage 140(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:59 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:59 INFO DAGScheduler: Submitting ResultStage 140 (PythonRDD[150] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=368618, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=375626, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:59 INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 140 (PythonRDD[150] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Adding task set 140.0 with 2 tasks
15/10/21 17:03:59 INFO TaskSetManager: Starting task 0.0 in stage 140.0 (TID 279, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO TaskSetManager: Starting task 1.0 in stage 140.0 (TID 280, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO Executor: Running task 0.0 in stage 140.0 (TID 279)
15/10/21 17:03:59 INFO Executor: Running task 1.0 in stage 140.0 (TID 280)
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:59 INFO PythonRDD: Times: total = 40, boot = -75, init = 115, finish = 0
15/10/21 17:03:59 INFO PythonRDD: Times: total = 39, boot = -76, init = 115, finish = 0
15/10/21 17:03:59 INFO Executor: Finished task 1.0 in stage 140.0 (TID 280). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO Executor: Finished task 0.0 in stage 140.0 (TID 279). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO TaskSetManager: Finished task 1.0 in stage 140.0 (TID 280) in 44 ms on localhost (1/2)
15/10/21 17:03:59 INFO TaskSetManager: Finished task 0.0 in stage 140.0 (TID 279) in 44 ms on localhost (2/2)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Removed TaskSet 140.0, whose tasks have all completed, from pool 
15/10/21 17:03:59 INFO DAGScheduler: ResultStage 140 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:03:59 INFO DAGScheduler: Job 139 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053867 s
15/10/21 17:03:59 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:59 INFO DAGScheduler: Got job 140 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:59 INFO DAGScheduler: Final stage: ResultStage 141(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:59 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:59 INFO DAGScheduler: Submitting ResultStage 141 (PythonRDD[151] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=379582, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=386590, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:59 INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 141 (PythonRDD[151] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Adding task set 141.0 with 2 tasks
15/10/21 17:03:59 INFO TaskSetManager: Starting task 0.0 in stage 141.0 (TID 281, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO TaskSetManager: Starting task 1.0 in stage 141.0 (TID 282, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO Executor: Running task 0.0 in stage 141.0 (TID 281)
15/10/21 17:03:59 INFO Executor: Running task 1.0 in stage 141.0 (TID 282)
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:59 INFO PythonRDD: Times: total = 40, boot = -77, init = 117, finish = 0
15/10/21 17:03:59 INFO PythonRDD: Times: total = 39, boot = -76, init = 115, finish = 0
15/10/21 17:03:59 INFO Executor: Finished task 0.0 in stage 141.0 (TID 281). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO Executor: Finished task 1.0 in stage 141.0 (TID 282). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO TaskSetManager: Finished task 0.0 in stage 141.0 (TID 281) in 44 ms on localhost (1/2)
15/10/21 17:03:59 INFO TaskSetManager: Finished task 1.0 in stage 141.0 (TID 282) in 44 ms on localhost (2/2)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Removed TaskSet 141.0, whose tasks have all completed, from pool 
15/10/21 17:03:59 INFO DAGScheduler: ResultStage 141 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:03:59 INFO DAGScheduler: Job 140 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053894 s
15/10/21 17:03:59 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:59 INFO DAGScheduler: Got job 141 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:59 INFO DAGScheduler: Final stage: ResultStage 142(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:59 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:59 INFO DAGScheduler: Submitting ResultStage 142 (PythonRDD[152] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=390546, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=397554, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:59 INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 142 (PythonRDD[152] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Adding task set 142.0 with 2 tasks
15/10/21 17:03:59 INFO TaskSetManager: Starting task 0.0 in stage 142.0 (TID 283, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO TaskSetManager: Starting task 1.0 in stage 142.0 (TID 284, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO Executor: Running task 1.0 in stage 142.0 (TID 284)
15/10/21 17:03:59 INFO Executor: Running task 0.0 in stage 142.0 (TID 283)
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:03:59 INFO PythonRDD: Times: total = 40, boot = -77, init = 117, finish = 0
15/10/21 17:03:59 INFO PythonRDD: Times: total = 40, boot = -77, init = 117, finish = 0
15/10/21 17:03:59 INFO Executor: Finished task 1.0 in stage 142.0 (TID 284). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO Executor: Finished task 0.0 in stage 142.0 (TID 283). 1870 bytes result sent to driver
15/10/21 17:03:59 INFO TaskSetManager: Finished task 1.0 in stage 142.0 (TID 284) in 45 ms on localhost (1/2)
15/10/21 17:03:59 INFO TaskSetManager: Finished task 0.0 in stage 142.0 (TID 283) in 45 ms on localhost (2/2)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Removed TaskSet 142.0, whose tasks have all completed, from pool 
15/10/21 17:03:59 INFO DAGScheduler: ResultStage 142 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:03:59 INFO DAGScheduler: Job 141 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053870 s
15/10/21 17:03:59 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:03:59 INFO DAGScheduler: Got job 142 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:03:59 INFO DAGScheduler: Final stage: ResultStage 143(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:03:59 INFO DAGScheduler: Missing parents: List()
15/10/21 17:03:59 INFO DAGScheduler: Submitting ResultStage 143 (PythonRDD[153] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=401510, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:03:59 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=408518, maxMem=278302556
15/10/21 17:03:59 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:03:59 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:03:59 INFO SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:874
15/10/21 17:03:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 143 (PythonRDD[153] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:03:59 INFO TaskSchedulerImpl: Adding task set 143.0 with 2 tasks
15/10/21 17:03:59 INFO TaskSetManager: Starting task 0.0 in stage 143.0 (TID 285, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO TaskSetManager: Starting task 1.0 in stage 143.0 (TID 286, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:03:59 INFO Executor: Running task 0.0 in stage 143.0 (TID 285)
15/10/21 17:03:59 INFO Executor: Running task 1.0 in stage 143.0 (TID 286)
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:03:59 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:04:00 INFO PythonRDD: Times: total = 39, boot = -78, init = 117, finish = 0
15/10/21 17:04:00 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:04:00 INFO Executor: Finished task 1.0 in stage 143.0 (TID 286). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO Executor: Finished task 0.0 in stage 143.0 (TID 285). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO TaskSetManager: Finished task 1.0 in stage 143.0 (TID 286) in 44 ms on localhost (1/2)
15/10/21 17:04:00 INFO TaskSetManager: Finished task 0.0 in stage 143.0 (TID 285) in 44 ms on localhost (2/2)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Removed TaskSet 143.0, whose tasks have all completed, from pool 
15/10/21 17:04:00 INFO DAGScheduler: ResultStage 143 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:04:00 INFO DAGScheduler: Job 142 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053134 s
15/10/21 17:04:00 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:04:00 INFO DAGScheduler: Got job 143 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:04:00 INFO DAGScheduler: Final stage: ResultStage 144(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:04:00 INFO DAGScheduler: Missing parents: List()
15/10/21 17:04:00 INFO DAGScheduler: Submitting ResultStage 144 (PythonRDD[154] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=412474, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=419482, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:04:00 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:874
15/10/21 17:04:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 144 (PythonRDD[154] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Adding task set 144.0 with 2 tasks
15/10/21 17:04:00 INFO TaskSetManager: Starting task 0.0 in stage 144.0 (TID 287, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO TaskSetManager: Starting task 1.0 in stage 144.0 (TID 288, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO Executor: Running task 0.0 in stage 144.0 (TID 287)
15/10/21 17:04:00 INFO Executor: Running task 1.0 in stage 144.0 (TID 288)
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:04:00 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:04:00 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:04:00 INFO Executor: Finished task 1.0 in stage 144.0 (TID 288). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO Executor: Finished task 0.0 in stage 144.0 (TID 287). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO TaskSetManager: Finished task 1.0 in stage 144.0 (TID 288) in 44 ms on localhost (1/2)
15/10/21 17:04:00 INFO TaskSetManager: Finished task 0.0 in stage 144.0 (TID 287) in 45 ms on localhost (2/2)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Removed TaskSet 144.0, whose tasks have all completed, from pool 
15/10/21 17:04:00 INFO DAGScheduler: ResultStage 144 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:04:00 INFO DAGScheduler: Job 143 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053462 s
15/10/21 17:04:00 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:04:00 INFO DAGScheduler: Got job 144 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:04:00 INFO DAGScheduler: Final stage: ResultStage 145(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:04:00 INFO DAGScheduler: Missing parents: List()
15/10/21 17:04:00 INFO DAGScheduler: Submitting ResultStage 145 (PythonRDD[155] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=423438, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=430446, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:04:00 INFO SparkContext: Created broadcast 147 from broadcast at DAGScheduler.scala:874
15/10/21 17:04:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 145 (PythonRDD[155] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Adding task set 145.0 with 2 tasks
15/10/21 17:04:00 INFO TaskSetManager: Starting task 0.0 in stage 145.0 (TID 289, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO TaskSetManager: Starting task 1.0 in stage 145.0 (TID 290, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO Executor: Running task 0.0 in stage 145.0 (TID 289)
15/10/21 17:04:00 INFO Executor: Running task 1.0 in stage 145.0 (TID 290)
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:04:00 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:04:00 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:04:00 INFO Executor: Finished task 0.0 in stage 145.0 (TID 289). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO Executor: Finished task 1.0 in stage 145.0 (TID 290). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO TaskSetManager: Finished task 0.0 in stage 145.0 (TID 289) in 45 ms on localhost (1/2)
15/10/21 17:04:00 INFO TaskSetManager: Finished task 1.0 in stage 145.0 (TID 290) in 44 ms on localhost (2/2)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Removed TaskSet 145.0, whose tasks have all completed, from pool 
15/10/21 17:04:00 INFO DAGScheduler: ResultStage 145 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:04:00 INFO DAGScheduler: Job 144 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053701 s
15/10/21 17:04:00 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:04:00 INFO DAGScheduler: Got job 145 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:04:00 INFO DAGScheduler: Final stage: ResultStage 146(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:04:00 INFO DAGScheduler: Missing parents: List()
15/10/21 17:04:00 INFO DAGScheduler: Submitting ResultStage 146 (PythonRDD[156] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=434402, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=441410, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:04:00 INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:874
15/10/21 17:04:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 146 (PythonRDD[156] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Adding task set 146.0 with 2 tasks
15/10/21 17:04:00 INFO TaskSetManager: Starting task 0.0 in stage 146.0 (TID 291, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO TaskSetManager: Starting task 1.0 in stage 146.0 (TID 292, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO Executor: Running task 0.0 in stage 146.0 (TID 291)
15/10/21 17:04:00 INFO Executor: Running task 1.0 in stage 146.0 (TID 292)
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:04:00 INFO PythonRDD: Times: total = 41, boot = -76, init = 117, finish = 0
15/10/21 17:04:00 INFO PythonRDD: Times: total = 41, boot = -77, init = 118, finish = 0
15/10/21 17:04:00 INFO Executor: Finished task 1.0 in stage 146.0 (TID 292). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO Executor: Finished task 0.0 in stage 146.0 (TID 291). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO TaskSetManager: Finished task 1.0 in stage 146.0 (TID 292) in 45 ms on localhost (1/2)
15/10/21 17:04:00 INFO TaskSetManager: Finished task 0.0 in stage 146.0 (TID 291) in 45 ms on localhost (2/2)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Removed TaskSet 146.0, whose tasks have all completed, from pool 
15/10/21 17:04:00 INFO DAGScheduler: ResultStage 146 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:04:00 INFO DAGScheduler: Job 145 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053993 s
15/10/21 17:04:00 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:04:00 INFO DAGScheduler: Got job 146 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:04:00 INFO DAGScheduler: Final stage: ResultStage 147(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:04:00 INFO DAGScheduler: Missing parents: List()
15/10/21 17:04:00 INFO DAGScheduler: Submitting ResultStage 147 (PythonRDD[157] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=445366, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=452374, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:04:00 INFO SparkContext: Created broadcast 149 from broadcast at DAGScheduler.scala:874
15/10/21 17:04:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 147 (PythonRDD[157] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Adding task set 147.0 with 2 tasks
15/10/21 17:04:00 INFO TaskSetManager: Starting task 0.0 in stage 147.0 (TID 293, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO TaskSetManager: Starting task 1.0 in stage 147.0 (TID 294, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO Executor: Running task 0.0 in stage 147.0 (TID 293)
15/10/21 17:04:00 INFO Executor: Running task 1.0 in stage 147.0 (TID 294)
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:04:00 INFO PythonRDD: Times: total = 39, boot = -78, init = 117, finish = 0
15/10/21 17:04:00 INFO PythonRDD: Times: total = 39, boot = -79, init = 118, finish = 0
15/10/21 17:04:00 INFO Executor: Finished task 1.0 in stage 147.0 (TID 294). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO Executor: Finished task 0.0 in stage 147.0 (TID 293). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO TaskSetManager: Finished task 1.0 in stage 147.0 (TID 294) in 43 ms on localhost (1/2)
15/10/21 17:04:00 INFO TaskSetManager: Finished task 0.0 in stage 147.0 (TID 293) in 43 ms on localhost (2/2)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Removed TaskSet 147.0, whose tasks have all completed, from pool 
15/10/21 17:04:00 INFO DAGScheduler: ResultStage 147 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:04:00 INFO DAGScheduler: Job 146 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.052742 s
15/10/21 17:04:00 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:04:00 INFO DAGScheduler: Got job 147 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:04:00 INFO DAGScheduler: Final stage: ResultStage 148(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:04:00 INFO DAGScheduler: Missing parents: List()
15/10/21 17:04:00 INFO DAGScheduler: Submitting ResultStage 148 (PythonRDD[158] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=456330, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=463338, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:04:00 INFO SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:874
15/10/21 17:04:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 148 (PythonRDD[158] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Adding task set 148.0 with 2 tasks
15/10/21 17:04:00 INFO TaskSetManager: Starting task 0.0 in stage 148.0 (TID 295, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO TaskSetManager: Starting task 1.0 in stage 148.0 (TID 296, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO Executor: Running task 1.0 in stage 148.0 (TID 296)
15/10/21 17:04:00 INFO Executor: Running task 0.0 in stage 148.0 (TID 295)
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:04:00 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:04:00 INFO PythonRDD: Times: total = 40, boot = -77, init = 117, finish = 0
15/10/21 17:04:00 INFO Executor: Finished task 0.0 in stage 148.0 (TID 295). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO Executor: Finished task 1.0 in stage 148.0 (TID 296). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO TaskSetManager: Finished task 0.0 in stage 148.0 (TID 295) in 45 ms on localhost (1/2)
15/10/21 17:04:00 INFO TaskSetManager: Finished task 1.0 in stage 148.0 (TID 296) in 44 ms on localhost (2/2)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Removed TaskSet 148.0, whose tasks have all completed, from pool 
15/10/21 17:04:00 INFO DAGScheduler: ResultStage 148 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:04:00 INFO DAGScheduler: Job 147 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053821 s
15/10/21 17:04:00 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:04:00 INFO DAGScheduler: Got job 148 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:04:00 INFO DAGScheduler: Final stage: ResultStage 149(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:04:00 INFO DAGScheduler: Missing parents: List()
15/10/21 17:04:00 INFO DAGScheduler: Submitting ResultStage 149 (PythonRDD[159] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=467294, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 6.8 KB, free 265.0 MB)
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=474302, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:04:00 INFO SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:874
15/10/21 17:04:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 149 (PythonRDD[159] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Adding task set 149.0 with 2 tasks
15/10/21 17:04:00 INFO TaskSetManager: Starting task 0.0 in stage 149.0 (TID 297, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO TaskSetManager: Starting task 1.0 in stage 149.0 (TID 298, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO Executor: Running task 0.0 in stage 149.0 (TID 297)
15/10/21 17:04:00 INFO Executor: Running task 1.0 in stage 149.0 (TID 298)
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:04:00 INFO PythonRDD: Times: total = 41, boot = -76, init = 117, finish = 0
15/10/21 17:04:00 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:04:00 INFO Executor: Finished task 0.0 in stage 149.0 (TID 297). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO Executor: Finished task 1.0 in stage 149.0 (TID 298). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO TaskSetManager: Finished task 0.0 in stage 149.0 (TID 297) in 45 ms on localhost (1/2)
15/10/21 17:04:00 INFO TaskSetManager: Finished task 1.0 in stage 149.0 (TID 298) in 45 ms on localhost (2/2)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Removed TaskSet 149.0, whose tasks have all completed, from pool 
15/10/21 17:04:00 INFO DAGScheduler: ResultStage 149 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:04:00 INFO DAGScheduler: Job 148 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.054307 s
15/10/21 17:04:00 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:04:00 INFO DAGScheduler: Got job 149 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:04:00 INFO DAGScheduler: Final stage: ResultStage 150(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:04:00 INFO DAGScheduler: Missing parents: List()
15/10/21 17:04:00 INFO DAGScheduler: Submitting ResultStage 150 (PythonRDD[160] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=478258, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 6.8 KB, free 264.9 MB)
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=485266, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 3.9 KB, free 264.9 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:04:00 INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:874
15/10/21 17:04:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 150 (PythonRDD[160] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Adding task set 150.0 with 2 tasks
15/10/21 17:04:00 INFO TaskSetManager: Starting task 0.0 in stage 150.0 (TID 299, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO TaskSetManager: Starting task 1.0 in stage 150.0 (TID 300, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO Executor: Running task 0.0 in stage 150.0 (TID 299)
15/10/21 17:04:00 INFO Executor: Running task 1.0 in stage 150.0 (TID 300)
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:04:00 INFO PythonRDD: Times: total = 40, boot = -77, init = 117, finish = 0
15/10/21 17:04:00 INFO PythonRDD: Times: total = 41, boot = -77, init = 118, finish = 0
15/10/21 17:04:00 INFO Executor: Finished task 1.0 in stage 150.0 (TID 300). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO Executor: Finished task 0.0 in stage 150.0 (TID 299). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO TaskSetManager: Finished task 1.0 in stage 150.0 (TID 300) in 45 ms on localhost (1/2)
15/10/21 17:04:00 INFO TaskSetManager: Finished task 0.0 in stage 150.0 (TID 299) in 45 ms on localhost (2/2)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Removed TaskSet 150.0, whose tasks have all completed, from pool 
15/10/21 17:04:00 INFO DAGScheduler: ResultStage 150 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:04:00 INFO DAGScheduler: Job 149 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053951 s
15/10/21 17:04:00 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:04:00 INFO DAGScheduler: Got job 150 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:04:00 INFO DAGScheduler: Final stage: ResultStage 151(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:04:00 INFO DAGScheduler: Missing parents: List()
15/10/21 17:04:00 INFO DAGScheduler: Submitting ResultStage 151 (PythonRDD[161] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=489222, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 6.8 KB, free 264.9 MB)
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=496230, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 3.9 KB, free 264.9 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:04:00 INFO SparkContext: Created broadcast 153 from broadcast at DAGScheduler.scala:874
15/10/21 17:04:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 151 (PythonRDD[161] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Adding task set 151.0 with 2 tasks
15/10/21 17:04:00 INFO TaskSetManager: Starting task 0.0 in stage 151.0 (TID 301, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO TaskSetManager: Starting task 1.0 in stage 151.0 (TID 302, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO Executor: Running task 0.0 in stage 151.0 (TID 301)
15/10/21 17:04:00 INFO Executor: Running task 1.0 in stage 151.0 (TID 302)
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:04:00 INFO PythonRDD: Times: total = 39, boot = -77, init = 116, finish = 0
15/10/21 17:04:00 INFO Executor: Finished task 1.0 in stage 151.0 (TID 302). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO TaskSetManager: Finished task 1.0 in stage 151.0 (TID 302) in 42 ms on localhost (1/2)
15/10/21 17:04:00 INFO PythonRDD: Times: total = 43, boot = -76, init = 119, finish = 0
15/10/21 17:04:00 INFO Executor: Finished task 0.0 in stage 151.0 (TID 301). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO TaskSetManager: Finished task 0.0 in stage 151.0 (TID 301) in 47 ms on localhost (2/2)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Removed TaskSet 151.0, whose tasks have all completed, from pool 
15/10/21 17:04:00 INFO DAGScheduler: ResultStage 151 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.048 s
15/10/21 17:04:00 INFO DAGScheduler: Job 150 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.056438 s
15/10/21 17:04:00 INFO BlockManagerInfo: Removed broadcast_153_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:04:00 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:04:00 INFO DAGScheduler: Got job 151 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:04:00 INFO DAGScheduler: Final stage: ResultStage 152(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:04:00 INFO DAGScheduler: Missing parents: List()
15/10/21 17:04:00 INFO BlockManagerInfo: Removed broadcast_152_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:04:00 INFO DAGScheduler: Submitting ResultStage 152 (PythonRDD[162] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=478258, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 6.8 KB, free 264.9 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Removed broadcast_151_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=474302, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.0 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:04:00 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:874
15/10/21 17:04:00 INFO BlockManagerInfo: Removed broadcast_150_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:04:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 152 (PythonRDD[162] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Adding task set 152.0 with 2 tasks
15/10/21 17:04:00 INFO TaskSetManager: Starting task 0.0 in stage 152.0 (TID 303, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO TaskSetManager: Starting task 1.0 in stage 152.0 (TID 304, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO BlockManagerInfo: Removed broadcast_149_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:04:00 INFO Executor: Running task 0.0 in stage 152.0 (TID 303)
15/10/21 17:04:00 INFO Executor: Running task 1.0 in stage 152.0 (TID 304)
15/10/21 17:04:00 INFO BlockManagerInfo: Removed broadcast_148_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:04:00 INFO BlockManagerInfo: Removed broadcast_147_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Removed broadcast_146_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Removed broadcast_134_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Removed broadcast_142_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Removed broadcast_145_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Removed broadcast_144_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Removed broadcast_140_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.3 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Removed broadcast_143_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Removed broadcast_135_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Removed broadcast_136_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Removed broadcast_137_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Removed broadcast_138_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Removed broadcast_139_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Removed broadcast_141_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:04:00 INFO PythonRDD: Times: total = 39, boot = -84, init = 123, finish = 0
15/10/21 17:04:00 INFO PythonRDD: Times: total = 40, boot = -86, init = 126, finish = 0
15/10/21 17:04:00 INFO Executor: Finished task 0.0 in stage 152.0 (TID 303). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO Executor: Finished task 1.0 in stage 152.0 (TID 304). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO TaskSetManager: Finished task 0.0 in stage 152.0 (TID 303) in 44 ms on localhost (1/2)
15/10/21 17:04:00 INFO TaskSetManager: Finished task 1.0 in stage 152.0 (TID 304) in 44 ms on localhost (2/2)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Removed TaskSet 152.0, whose tasks have all completed, from pool 
15/10/21 17:04:00 INFO DAGScheduler: ResultStage 152 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.044 s
15/10/21 17:04:00 INFO DAGScheduler: Job 151 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.052587 s
15/10/21 17:04:00 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:04:00 INFO DAGScheduler: Got job 152 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:04:00 INFO DAGScheduler: Final stage: ResultStage 153(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:04:00 INFO DAGScheduler: Missing parents: List()
15/10/21 17:04:00 INFO DAGScheduler: Submitting ResultStage 153 (PythonRDD[163] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=291870, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=298878, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:04:00 INFO SparkContext: Created broadcast 155 from broadcast at DAGScheduler.scala:874
15/10/21 17:04:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 153 (PythonRDD[163] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Adding task set 153.0 with 2 tasks
15/10/21 17:04:00 INFO TaskSetManager: Starting task 0.0 in stage 153.0 (TID 305, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO TaskSetManager: Starting task 1.0 in stage 153.0 (TID 306, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO Executor: Running task 0.0 in stage 153.0 (TID 305)
15/10/21 17:04:00 INFO Executor: Running task 1.0 in stage 153.0 (TID 306)
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:04:00 INFO PythonRDD: Times: total = 41, boot = -82, init = 123, finish = 0
15/10/21 17:04:00 INFO PythonRDD: Times: total = 40, boot = -81, init = 121, finish = 0
15/10/21 17:04:00 INFO Executor: Finished task 0.0 in stage 153.0 (TID 305). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO Executor: Finished task 1.0 in stage 153.0 (TID 306). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO TaskSetManager: Finished task 0.0 in stage 153.0 (TID 305) in 44 ms on localhost (1/2)
15/10/21 17:04:00 INFO TaskSetManager: Finished task 1.0 in stage 153.0 (TID 306) in 44 ms on localhost (2/2)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Removed TaskSet 153.0, whose tasks have all completed, from pool 
15/10/21 17:04:00 INFO DAGScheduler: ResultStage 153 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:04:00 INFO DAGScheduler: Job 152 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053307 s
15/10/21 17:04:00 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:04:00 INFO DAGScheduler: Got job 153 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:04:00 INFO DAGScheduler: Final stage: ResultStage 154(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:04:00 INFO DAGScheduler: Missing parents: List()
15/10/21 17:04:00 INFO DAGScheduler: Submitting ResultStage 154 (PythonRDD[164] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=302834, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=309842, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:04:00 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:874
15/10/21 17:04:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 154 (PythonRDD[164] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Adding task set 154.0 with 2 tasks
15/10/21 17:04:00 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 307, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO TaskSetManager: Starting task 1.0 in stage 154.0 (TID 308, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO Executor: Running task 0.0 in stage 154.0 (TID 307)
15/10/21 17:04:00 INFO Executor: Running task 1.0 in stage 154.0 (TID 308)
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:04:00 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:04:00 INFO PythonRDD: Times: total = 40, boot = -77, init = 117, finish = 0
15/10/21 17:04:00 INFO Executor: Finished task 1.0 in stage 154.0 (TID 308). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO Executor: Finished task 0.0 in stage 154.0 (TID 307). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO TaskSetManager: Finished task 1.0 in stage 154.0 (TID 308) in 44 ms on localhost (1/2)
15/10/21 17:04:00 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 307) in 44 ms on localhost (2/2)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool 
15/10/21 17:04:00 INFO DAGScheduler: ResultStage 154 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.046 s
15/10/21 17:04:00 INFO DAGScheduler: Job 153 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.054074 s
15/10/21 17:04:00 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:04:00 INFO DAGScheduler: Got job 154 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:04:00 INFO DAGScheduler: Final stage: ResultStage 155(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:04:00 INFO DAGScheduler: Missing parents: List()
15/10/21 17:04:00 INFO DAGScheduler: Submitting ResultStage 155 (PythonRDD[165] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=313798, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=320806, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:04:00 INFO SparkContext: Created broadcast 157 from broadcast at DAGScheduler.scala:874
15/10/21 17:04:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 155 (PythonRDD[165] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Adding task set 155.0 with 2 tasks
15/10/21 17:04:00 INFO TaskSetManager: Starting task 0.0 in stage 155.0 (TID 309, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO TaskSetManager: Starting task 1.0 in stage 155.0 (TID 310, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO Executor: Running task 0.0 in stage 155.0 (TID 309)
15/10/21 17:04:00 INFO Executor: Running task 1.0 in stage 155.0 (TID 310)
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:04:00 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:04:00 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:04:00 INFO Executor: Finished task 1.0 in stage 155.0 (TID 310). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO Executor: Finished task 0.0 in stage 155.0 (TID 309). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO TaskSetManager: Finished task 1.0 in stage 155.0 (TID 310) in 44 ms on localhost (1/2)
15/10/21 17:04:00 INFO TaskSetManager: Finished task 0.0 in stage 155.0 (TID 309) in 44 ms on localhost (2/2)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool 
15/10/21 17:04:00 INFO DAGScheduler: ResultStage 155 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:04:00 INFO DAGScheduler: Job 154 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053455 s
15/10/21 17:04:00 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:04:00 INFO DAGScheduler: Got job 155 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:04:00 INFO DAGScheduler: Final stage: ResultStage 156(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:04:00 INFO DAGScheduler: Missing parents: List()
15/10/21 17:04:00 INFO DAGScheduler: Submitting ResultStage 156 (PythonRDD[166] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=324762, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=331770, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:04:00 INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:874
15/10/21 17:04:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 156 (PythonRDD[166] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Adding task set 156.0 with 2 tasks
15/10/21 17:04:00 INFO TaskSetManager: Starting task 0.0 in stage 156.0 (TID 311, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO TaskSetManager: Starting task 1.0 in stage 156.0 (TID 312, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO Executor: Running task 0.0 in stage 156.0 (TID 311)
15/10/21 17:04:00 INFO Executor: Running task 1.0 in stage 156.0 (TID 312)
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:04:00 INFO PythonRDD: Times: total = 41, boot = -73, init = 114, finish = 0
15/10/21 17:04:00 INFO PythonRDD: Times: total = 40, boot = -74, init = 114, finish = 0
15/10/21 17:04:00 INFO Executor: Finished task 0.0 in stage 156.0 (TID 311). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO Executor: Finished task 1.0 in stage 156.0 (TID 312). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO TaskSetManager: Finished task 0.0 in stage 156.0 (TID 311) in 44 ms on localhost (1/2)
15/10/21 17:04:00 INFO TaskSetManager: Finished task 1.0 in stage 156.0 (TID 312) in 44 ms on localhost (2/2)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool 
15/10/21 17:04:00 INFO DAGScheduler: ResultStage 156 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:04:00 INFO DAGScheduler: Job 155 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.052717 s
15/10/21 17:04:00 INFO SparkContext: Starting job: count at <ipython-input-19-d3fd33c73668>:3
15/10/21 17:04:00 INFO DAGScheduler: Got job 156 (count at <ipython-input-19-d3fd33c73668>:3) with 2 output partitions (allowLocal=false)
15/10/21 17:04:00 INFO DAGScheduler: Final stage: ResultStage 157(count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO DAGScheduler: Parents of final stage: List()
15/10/21 17:04:00 INFO DAGScheduler: Missing parents: List()
15/10/21 17:04:00 INFO DAGScheduler: Submitting ResultStage 157 (PythonRDD[167] at count at <ipython-input-19-d3fd33c73668>:3), which has no missing parents
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(7008) called with curMem=335726, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 6.8 KB, free 265.1 MB)
15/10/21 17:04:00 INFO MemoryStore: ensureFreeSpace(3956) called with curMem=342734, maxMem=278302556
15/10/21 17:04:00 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.1 MB)
15/10/21 17:04:00 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on localhost:45162 (size: 3.9 KB, free: 265.4 MB)
15/10/21 17:04:00 INFO SparkContext: Created broadcast 159 from broadcast at DAGScheduler.scala:874
15/10/21 17:04:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 157 (PythonRDD[167] at count at <ipython-input-19-d3fd33c73668>:3)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Adding task set 157.0 with 2 tasks
15/10/21 17:04:00 INFO TaskSetManager: Starting task 0.0 in stage 157.0 (TID 313, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO TaskSetManager: Starting task 1.0 in stage 157.0 (TID 314, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/21 17:04:00 INFO Executor: Running task 0.0 in stage 157.0 (TID 313)
15/10/21 17:04:00 INFO Executor: Running task 1.0 in stage 157.0 (TID 314)
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_0 locally
15/10/21 17:04:00 INFO BlockManager: Found block rdd_16_1 locally
15/10/21 17:04:00 INFO PythonRDD: Times: total = 40, boot = -76, init = 116, finish = 0
15/10/21 17:04:00 INFO PythonRDD: Times: total = 40, boot = -75, init = 115, finish = 0
15/10/21 17:04:00 INFO Executor: Finished task 1.0 in stage 157.0 (TID 314). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO Executor: Finished task 0.0 in stage 157.0 (TID 313). 1870 bytes result sent to driver
15/10/21 17:04:00 INFO TaskSetManager: Finished task 1.0 in stage 157.0 (TID 314) in 44 ms on localhost (1/2)
15/10/21 17:04:00 INFO TaskSetManager: Finished task 0.0 in stage 157.0 (TID 313) in 45 ms on localhost (2/2)
15/10/21 17:04:00 INFO TaskSchedulerImpl: Removed TaskSet 157.0, whose tasks have all completed, from pool 
15/10/21 17:04:00 INFO DAGScheduler: ResultStage 157 (count at <ipython-input-19-d3fd33c73668>:3) finished in 0.045 s
15/10/21 17:04:00 INFO DAGScheduler: Job 156 finished: count at <ipython-input-19-d3fd33c73668>:3, took 0.053930 s
[I 17:04:10.398 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
15/10/21 19:41:02 INFO BlockManagerInfo: Removed broadcast_156_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 19:41:02 INFO BlockManagerInfo: Removed broadcast_155_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 19:41:02 INFO BlockManagerInfo: Removed broadcast_154_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 19:41:02 INFO BlockManagerInfo: Removed broadcast_159_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 19:41:02 INFO BlockManagerInfo: Removed broadcast_158_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/21 19:41:02 INFO BlockManagerInfo: Removed broadcast_157_piece0 on localhost:45162 in memory (size: 3.9 KB, free: 265.4 MB)
[W 20:53:07.133 NotebookApp] WebSocket ping timeout after 119916 ms.
[W 20:53:12.134 NotebookApp] WebSocket ping timeout after 119885 ms.
[W 02:32:04.699 NotebookApp] zmq message arrived on closed channel
[W 02:32:04.699 NotebookApp] zmq message arrived on closed channel
[W 02:32:04.699 NotebookApp] zmq message arrived on closed channel
[W 02:32:04.700 NotebookApp] zmq message arrived on closed channel
[W 02:32:04.700 NotebookApp] zmq message arrived on closed channel
[W 02:32:04.700 NotebookApp] zmq message arrived on closed channel
[W 02:32:04.701 NotebookApp] zmq message arrived on closed channel
[W 02:32:04.701 NotebookApp] zmq message arrived on closed channel
[W 02:32:04.701 NotebookApp] zmq message arrived on closed channel
[W 02:32:04.701 NotebookApp] zmq message arrived on closed channel
[W 02:32:21.330 NotebookApp] Notebook Untitled0.ipynb is not trusted
[I 02:32:21.407 NotebookApp] Request start_kernel: kernel_id=None, kernel_name=python2, path="", **kwargs={}
[I 02:32:21.407 NotebookApp] Provisioning local kernel: python2
[I 02:32:21.456 NotebookApp] Kernel started: 9ab2bb2a-9020-44b0-a340-2de993f0e0ea
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/22 02:32:24 INFO SparkContext: Running Spark version 1.4.1
15/10/22 02:32:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/22 02:32:25 INFO SecurityManager: Changing view acls to: notebook
15/10/22 02:32:25 INFO SecurityManager: Changing modify acls to: notebook
15/10/22 02:32:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
15/10/22 02:32:26 INFO Slf4jLogger: Slf4jLogger started
15/10/22 02:32:26 INFO Remoting: Starting remoting
15/10/22 02:32:26 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.22:44439]
15/10/22 02:32:26 INFO Utils: Successfully started service 'sparkDriver' on port 44439.
15/10/22 02:32:26 INFO SparkEnv: Registering MapOutputTracker
15/10/22 02:32:26 INFO SparkEnv: Registering BlockManagerMaster
15/10/22 02:32:26 INFO DiskBlockManager: Created local directory at /tmp/spark-9b53112a-7587-40b2-875d-52372b9f0213/blockmgr-ff3b1fac-22e5-4969-8e3a-2aecbf2c0dcc
15/10/22 02:32:26 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/10/22 02:32:26 INFO HttpFileServer: HTTP File server directory is /tmp/spark-9b53112a-7587-40b2-875d-52372b9f0213/httpd-af60c2aa-69b8-4878-86e3-43b8fccdb6ac
15/10/22 02:32:26 INFO HttpServer: Starting HTTP Server
15/10/22 02:32:26 INFO Utils: Successfully started service 'HTTP file server' on port 36152.
15/10/22 02:32:26 INFO SparkEnv: Registering OutputCommitCoordinator
15/10/22 02:32:26 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/10/22 02:32:26 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
15/10/22 02:32:26 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
15/10/22 02:32:26 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
15/10/22 02:32:27 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
15/10/22 02:32:27 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
15/10/22 02:32:27 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.
15/10/22 02:32:27 WARN Utils: Service 'SparkUI' could not bind on port 4047. Attempting port 4048.
15/10/22 02:32:27 WARN Utils: Service 'SparkUI' could not bind on port 4048. Attempting port 4049.
15/10/22 02:32:27 WARN Utils: Service 'SparkUI' could not bind on port 4049. Attempting port 4050.
15/10/22 02:32:27 INFO Utils: Successfully started service 'SparkUI' on port 4050.
15/10/22 02:32:27 INFO SparkUI: Started SparkUI at http://172.17.0.22:4050
15/10/22 02:32:27 INFO Executor: Starting executor ID driver on host localhost
15/10/22 02:32:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59251.
15/10/22 02:32:27 INFO NettyBlockTransferService: Server created on 59251
15/10/22 02:32:27 INFO BlockManagerMaster: Trying to register BlockManager
15/10/22 02:32:27 INFO BlockManagerMasterEndpoint: Registering block manager localhost:59251 with 265.4 MB RAM, BlockManagerId(driver, localhost, 59251)
15/10/22 02:32:27 INFO BlockManagerMaster: Registered BlockManager
[W 02:33:15.828 NotebookApp] zmq message arrived on closed channel
[W 02:33:15.829 NotebookApp] zmq message arrived on closed channel
[I 02:34:21.821 NotebookApp] Saving file at /Untitled0.ipynb
[I 02:35:15.516 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[W 02:36:25.006 NotebookApp] zmq message arrived on closed channel
[W 02:36:25.007 NotebookApp] zmq message arrived on closed channel
[W 02:36:25.007 NotebookApp] zmq message arrived on closed channel
[W 02:36:25.008 NotebookApp] zmq message arrived on closed channel
[W 02:36:25.008 NotebookApp] zmq message arrived on closed channel
[W 02:36:25.008 NotebookApp] zmq message arrived on closed channel
[W 02:36:25.009 NotebookApp] zmq message arrived on closed channel
[W 02:36:25.009 NotebookApp] zmq message arrived on closed channel
[W 02:36:25.009 NotebookApp] zmq message arrived on closed channel
[W 02:36:25.009 NotebookApp] zmq message arrived on closed channel
[I 02:36:25.089 NotebookApp] Saving file at /Untitled0.ipynb
logFile: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[13] at textFile at <console>:15
[W 02:36:25.233 NotebookApp] zmq message arrived on closed channel
[W 02:36:25.233 NotebookApp] zmq message arrived on closed channel
[W 02:36:25.233 NotebookApp] zmq message arrived on closed channel
[W 02:36:25.234 NotebookApp] zmq message arrived on closed channel
[W 02:36:25.234 NotebookApp] zmq message arrived on closed channel
[I 02:38:04.588 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
<console>:1: error: illegal start of definition
       # Filter out the lines that contains INFO (or ERROR, if the particular log has it)
       ^
[W 02:38:09.558 NotebookApp] zmq message arrived on closed channel
[W 02:38:09.559 NotebookApp] zmq message arrived on closed channel
[W 02:38:09.559 NotebookApp] zmq message arrived on closed channel
[W 02:38:09.560 NotebookApp] zmq message arrived on closed channel
[W 02:38:09.560 NotebookApp] zmq message arrived on closed channel
[W 02:38:09.560 NotebookApp] zmq message arrived on closed channel
[W 02:38:09.561 NotebookApp] zmq message arrived on closed channel
[W 02:38:09.561 NotebookApp] zmq message arrived on closed channel
[W 02:38:09.561 NotebookApp] zmq message arrived on closed channel
[W 02:38:09.561 NotebookApp] zmq message arrived on closed channel
[W 02:38:09.563 NotebookApp] zmq message arrived on closed channel
[W 02:38:09.564 NotebookApp] zmq message arrived on closed channel
[W 02:38:09.564 NotebookApp] zmq message arrived on closed channel
[W 02:38:09.565 NotebookApp] zmq message arrived on closed channel
[W 02:38:09.565 NotebookApp] zmq message arrived on closed channel
[W 02:38:09.565 NotebookApp] zmq message arrived on closed channel
[W 02:38:09.565 NotebookApp] zmq message arrived on closed channel
[W 02:38:09.566 NotebookApp] zmq message arrived on closed channel
[W 02:38:09.566 NotebookApp] zmq message arrived on closed channel
[W 02:38:09.566 NotebookApp] zmq message arrived on closed channel
[W 02:38:27.915 NotebookApp] zmq message arrived on closed channel
[W 02:38:27.916 NotebookApp] zmq message arrived on closed channel
[W 02:38:27.916 NotebookApp] zmq message arrived on closed channel
[W 02:38:27.916 NotebookApp] zmq message arrived on closed channel
[W 02:38:27.917 NotebookApp] zmq message arrived on closed channel
[W 02:38:27.917 NotebookApp] zmq message arrived on closed channel
[W 02:38:27.917 NotebookApp] zmq message arrived on closed channel
[W 02:38:27.918 NotebookApp] zmq message arrived on closed channel
[W 02:38:27.918 NotebookApp] zmq message arrived on closed channel
[W 02:38:27.918 NotebookApp] zmq message arrived on closed channel
info: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[14] at filter at <console>:17
[W 02:38:28.087 NotebookApp] zmq message arrived on closed channel
[W 02:38:28.087 NotebookApp] zmq message arrived on closed channel
[W 02:38:28.087 NotebookApp] zmq message arrived on closed channel
[W 02:38:28.088 NotebookApp] zmq message arrived on closed channel
[W 02:38:28.088 NotebookApp] zmq message arrived on closed channel
[W 02:38:50.685 NotebookApp] zmq message arrived on closed channel
[W 02:38:50.686 NotebookApp] zmq message arrived on closed channel
[W 02:38:50.686 NotebookApp] zmq message arrived on closed channel
[W 02:38:50.687 NotebookApp] zmq message arrived on closed channel
[W 02:38:50.687 NotebookApp] zmq message arrived on closed channel
[W 02:38:50.687 NotebookApp] zmq message arrived on closed channel
[W 02:38:50.687 NotebookApp] zmq message arrived on closed channel
[W 02:38:50.688 NotebookApp] zmq message arrived on closed channel
[W 02:38:50.688 NotebookApp] zmq message arrived on closed channel
[W 02:38:50.688 NotebookApp] zmq message arrived on closed channel
res39: Long = 12431
[W 02:38:51.024 NotebookApp] zmq message arrived on closed channel
[W 02:38:51.024 NotebookApp] zmq message arrived on closed channel
[W 02:38:51.025 NotebookApp] zmq message arrived on closed channel
[W 02:38:51.026 NotebookApp] zmq message arrived on closed channel
[W 02:38:51.026 NotebookApp] zmq message arrived on closed channel
[W 02:38:51.026 NotebookApp] zmq message arrived on closed channel
[W 02:38:51.026 NotebookApp] zmq message arrived on closed channel
[W 02:38:51.027 NotebookApp] zmq message arrived on closed channel
[W 02:38:51.027 NotebookApp] zmq message arrived on closed channel
[W 02:38:51.027 NotebookApp] zmq message arrived on closed channel
[W 02:39:06.127 NotebookApp] zmq message arrived on closed channel
[W 02:39:06.128 NotebookApp] zmq message arrived on closed channel
[W 02:39:06.128 NotebookApp] zmq message arrived on closed channel
[W 02:39:06.128 NotebookApp] zmq message arrived on closed channel
[W 02:39:06.128 NotebookApp] zmq message arrived on closed channel
[W 02:39:06.129 NotebookApp] zmq message arrived on closed channel
[W 02:39:06.129 NotebookApp] zmq message arrived on closed channel
[W 02:39:06.129 NotebookApp] zmq message arrived on closed channel
[W 02:39:06.130 NotebookApp] zmq message arrived on closed channel
[W 02:39:06.130 NotebookApp] zmq message arrived on closed channel
res40: Long = 109
[W 02:39:06.341 NotebookApp] zmq message arrived on closed channel
[W 02:39:06.341 NotebookApp] zmq message arrived on closed channel
[W 02:39:06.341 NotebookApp] zmq message arrived on closed channel
[W 02:39:06.342 NotebookApp] zmq message arrived on closed channel
[W 02:39:06.342 NotebookApp] zmq message arrived on closed channel
[W 02:39:06.342 NotebookApp] zmq message arrived on closed channel
[W 02:39:06.343 NotebookApp] zmq message arrived on closed channel
[W 02:39:06.343 NotebookApp] zmq message arrived on closed channel
[W 02:39:06.344 NotebookApp] zmq message arrived on closed channel
[W 02:39:06.344 NotebookApp] zmq message arrived on closed channel
[W 02:39:45.151 NotebookApp] zmq message arrived on closed channel
[W 02:39:45.152 NotebookApp] zmq message arrived on closed channel
[W 02:39:45.152 NotebookApp] zmq message arrived on closed channel
[W 02:39:45.152 NotebookApp] zmq message arrived on closed channel
[W 02:39:45.152 NotebookApp] zmq message arrived on closed channel
[W 02:39:45.153 NotebookApp] zmq message arrived on closed channel
[W 02:39:45.153 NotebookApp] zmq message arrived on closed channel
[W 02:39:45.153 NotebookApp] zmq message arrived on closed channel
[W 02:39:45.153 NotebookApp] zmq message arrived on closed channel
[W 02:39:45.154 NotebookApp] zmq message arrived on closed channel
<console>:20: error: value ￼ is not a member of Array[String]
              info.filter(line => line.contains("spark")).collect()￼
                                                                   ^
[W 02:39:45.217 NotebookApp] zmq message arrived on closed channel
[W 02:39:45.217 NotebookApp] zmq message arrived on closed channel
[W 02:39:45.218 NotebookApp] zmq message arrived on closed channel
[W 02:39:45.218 NotebookApp] zmq message arrived on closed channel
[W 02:39:45.219 NotebookApp] zmq message arrived on closed channel
[W 02:39:45.220 NotebookApp] zmq message arrived on closed channel
[W 02:39:45.220 NotebookApp] zmq message arrived on closed channel
[W 02:39:45.220 NotebookApp] zmq message arrived on closed channel
[W 02:39:45.220 NotebookApp] zmq message arrived on closed channel
[W 02:39:45.221 NotebookApp] zmq message arrived on closed channel
[I 02:40:04.737 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 02:40:06.564 NotebookApp] zmq message arrived on closed channel
[W 02:40:06.564 NotebookApp] zmq message arrived on closed channel
[W 02:40:06.565 NotebookApp] zmq message arrived on closed channel
[W 02:40:06.565 NotebookApp] zmq message arrived on closed channel
[W 02:40:06.565 NotebookApp] zmq message arrived on closed channel
[W 02:40:06.566 NotebookApp] zmq message arrived on closed channel
[W 02:40:06.566 NotebookApp] zmq message arrived on closed channel
[W 02:40:06.566 NotebookApp] zmq message arrived on closed channel
[W 02:40:06.566 NotebookApp] zmq message arrived on closed channel
[W 02:40:06.567 NotebookApp] zmq message arrived on closed channel
res42: String = 
(2) MapPartitionsRDD[14] at filter at <console>:17 []
 |  MapPartitionsRDD[13] at textFile at <console>:15 []
 |  /var/log/supervisor/notebook.log HadoopRDD[12] at textFile at <console>:15 []
[W 02:40:06.730 NotebookApp] zmq message arrived on closed channel
[W 02:40:06.730 NotebookApp] zmq message arrived on closed channel
[W 02:40:06.731 NotebookApp] zmq message arrived on closed channel
[W 02:40:06.731 NotebookApp] zmq message arrived on closed channel
[W 02:40:06.731 NotebookApp] zmq message arrived on closed channel
[W 02:40:18.398 NotebookApp] zmq message arrived on closed channel
[W 02:40:18.399 NotebookApp] zmq message arrived on closed channel
[W 02:40:18.399 NotebookApp] zmq message arrived on closed channel
[W 02:40:18.400 NotebookApp] zmq message arrived on closed channel
[W 02:40:18.400 NotebookApp] zmq message arrived on closed channel
[W 02:40:18.400 NotebookApp] zmq message arrived on closed channel
[W 02:40:18.400 NotebookApp] zmq message arrived on closed channel
[W 02:40:18.401 NotebookApp] zmq message arrived on closed channel
[W 02:40:18.401 NotebookApp] zmq message arrived on closed channel
[W 02:40:18.401 NotebookApp] zmq message arrived on closed channel
res43: Long = 109
[W 02:40:18.612 NotebookApp] zmq message arrived on closed channel
[W 02:40:18.613 NotebookApp] zmq message arrived on closed channel
[W 02:40:18.613 NotebookApp] zmq message arrived on closed channel
[W 02:40:18.614 NotebookApp] zmq message arrived on closed channel
[W 02:40:18.614 NotebookApp] zmq message arrived on closed channel
[W 02:40:18.614 NotebookApp] zmq message arrived on closed channel
[W 02:40:18.614 NotebookApp] zmq message arrived on closed channel
[W 02:40:18.615 NotebookApp] zmq message arrived on closed channel
[W 02:40:18.615 NotebookApp] zmq message arrived on closed channel
[W 02:40:18.615 NotebookApp] zmq message arrived on closed channel
[W 02:40:20.113 NotebookApp] zmq message arrived on closed channel
[W 02:40:20.113 NotebookApp] zmq message arrived on closed channel
[W 02:40:20.113 NotebookApp] zmq message arrived on closed channel
[W 02:40:20.114 NotebookApp] zmq message arrived on closed channel
[W 02:40:20.114 NotebookApp] zmq message arrived on closed channel
[W 02:40:20.114 NotebookApp] zmq message arrived on closed channel
[W 02:40:20.114 NotebookApp] zmq message arrived on closed channel
[W 02:40:20.115 NotebookApp] zmq message arrived on closed channel
[W 02:40:20.115 NotebookApp] zmq message arrived on closed channel
[W 02:40:20.115 NotebookApp] zmq message arrived on closed channel
<console>:20: error: value ￼ is not a member of Array[String]
              info.filter(line => line.contains("spark")).collect()￼
                                                                   ^
[W 02:40:20.171 NotebookApp] zmq message arrived on closed channel
[W 02:40:20.172 NotebookApp] zmq message arrived on closed channel
[W 02:40:20.173 NotebookApp] zmq message arrived on closed channel
[W 02:40:20.173 NotebookApp] zmq message arrived on closed channel
[W 02:40:20.173 NotebookApp] zmq message arrived on closed channel
[W 02:40:20.173 NotebookApp] zmq message arrived on closed channel
[W 02:40:20.173 NotebookApp] zmq message arrived on closed channel
[W 02:40:20.174 NotebookApp] zmq message arrived on closed channel
[W 02:40:20.174 NotebookApp] zmq message arrived on closed channel
[W 02:40:20.174 NotebookApp] zmq message arrived on closed channel
[W 02:40:38.347 NotebookApp] zmq message arrived on closed channel
[W 02:40:38.348 NotebookApp] zmq message arrived on closed channel
[W 02:40:38.348 NotebookApp] zmq message arrived on closed channel
[W 02:40:38.349 NotebookApp] zmq message arrived on closed channel
[W 02:40:38.349 NotebookApp] zmq message arrived on closed channel
[W 02:40:38.349 NotebookApp] zmq message arrived on closed channel
[W 02:40:38.349 NotebookApp] zmq message arrived on closed channel
[W 02:40:38.350 NotebookApp] zmq message arrived on closed channel
[W 02:40:38.350 NotebookApp] zmq message arrived on closed channel
[W 02:40:38.350 NotebookApp] zmq message arrived on closed channel
res45: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[17] at filter at <console>:20
[W 02:40:38.519 NotebookApp] zmq message arrived on closed channel
[W 02:40:38.519 NotebookApp] zmq message arrived on closed channel
[W 02:40:38.519 NotebookApp] zmq message arrived on closed channel
[W 02:40:38.520 NotebookApp] zmq message arrived on closed channel
[W 02:40:38.520 NotebookApp] zmq message arrived on closed channel
[W 02:40:38.521 NotebookApp] zmq message arrived on closed channel
[W 02:40:38.521 NotebookApp] zmq message arrived on closed channel
[W 02:40:38.522 NotebookApp] zmq message arrived on closed channel
[W 02:40:38.522 NotebookApp] zmq message arrived on closed channel
[W 02:40:38.522 NotebookApp] zmq message arrived on closed channel
[W 02:40:44.400 NotebookApp] zmq message arrived on closed channel
[W 02:40:44.401 NotebookApp] zmq message arrived on closed channel
[W 02:40:44.402 NotebookApp] zmq message arrived on closed channel
[W 02:40:44.402 NotebookApp] zmq message arrived on closed channel
[W 02:40:44.403 NotebookApp] zmq message arrived on closed channel
[W 02:40:44.403 NotebookApp] zmq message arrived on closed channel
[W 02:40:44.403 NotebookApp] zmq message arrived on closed channel
[W 02:40:44.404 NotebookApp] zmq message arrived on closed channel
[W 02:40:44.404 NotebookApp] zmq message arrived on closed channel
[W 02:40:44.404 NotebookApp] zmq message arrived on closed channel
<console>:20: error: value ￼ is not a member of Array[String]
              info.filter(line => line.contains("spark")).collect()￼
                                                                   ^
[W 02:40:44.464 NotebookApp] zmq message arrived on closed channel
[W 02:40:44.465 NotebookApp] zmq message arrived on closed channel
[W 02:40:44.465 NotebookApp] zmq message arrived on closed channel
[W 02:40:44.466 NotebookApp] zmq message arrived on closed channel
[W 02:40:44.466 NotebookApp] zmq message arrived on closed channel
[W 02:40:44.467 NotebookApp] zmq message arrived on closed channel
[W 02:40:44.467 NotebookApp] zmq message arrived on closed channel
[W 02:40:44.467 NotebookApp] zmq message arrived on closed channel
[W 02:40:44.467 NotebookApp] zmq message arrived on closed channel
[W 02:40:44.468 NotebookApp] zmq message arrived on closed channel
[W 02:40:51.144 NotebookApp] zmq message arrived on closed channel
[W 02:40:51.144 NotebookApp] zmq message arrived on closed channel
[W 02:40:51.145 NotebookApp] zmq message arrived on closed channel
[W 02:40:51.145 NotebookApp] zmq message arrived on closed channel
[W 02:40:51.145 NotebookApp] zmq message arrived on closed channel
[W 02:40:51.146 NotebookApp] zmq message arrived on closed channel
[W 02:40:51.146 NotebookApp] zmq message arrived on closed channel
[W 02:40:51.146 NotebookApp] zmq message arrived on closed channel
[W 02:40:51.146 NotebookApp] zmq message arrived on closed channel
[W 02:40:51.147 NotebookApp] zmq message arrived on closed channel
a: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[18] at filter at <console>:19
<console>:22: error: value ￼ is not a member of Array[String]
              a.collect()￼
                         ^
[W 02:40:51.362 NotebookApp] zmq message arrived on closed channel
[W 02:40:51.362 NotebookApp] zmq message arrived on closed channel
[W 02:40:51.363 NotebookApp] zmq message arrived on closed channel
[W 02:40:51.363 NotebookApp] zmq message arrived on closed channel
[W 02:40:51.364 NotebookApp] zmq message arrived on closed channel
[W 02:40:51.365 NotebookApp] zmq message arrived on closed channel
[W 02:40:51.365 NotebookApp] zmq message arrived on closed channel
[W 02:40:51.365 NotebookApp] zmq message arrived on closed channel
[W 02:40:51.365 NotebookApp] zmq message arrived on closed channel
[W 02:40:51.365 NotebookApp] zmq message arrived on closed channel
[W 02:41:06.109 NotebookApp] zmq message arrived on closed channel
[W 02:41:06.110 NotebookApp] zmq message arrived on closed channel
[W 02:41:06.110 NotebookApp] zmq message arrived on closed channel
[W 02:41:06.111 NotebookApp] zmq message arrived on closed channel
[W 02:41:06.111 NotebookApp] zmq message arrived on closed channel
[W 02:41:06.112 NotebookApp] zmq message arrived on closed channel
[W 02:41:06.112 NotebookApp] zmq message arrived on closed channel
[W 02:41:06.112 NotebookApp] zmq message arrived on closed channel
[W 02:41:06.113 NotebookApp] zmq message arrived on closed channel
[W 02:41:06.113 NotebookApp] zmq message arrived on closed channel
<console>:20: error: value ￼ is not a member of Array[String]
              info.filter(line => line.contains("spark")).collect()￼
                                                                   ^
[W 02:41:06.166 NotebookApp] zmq message arrived on closed channel
[W 02:41:06.167 NotebookApp] zmq message arrived on closed channel
[W 02:41:06.167 NotebookApp] zmq message arrived on closed channel
[W 02:41:06.167 NotebookApp] zmq message arrived on closed channel
[W 02:41:06.167 NotebookApp] zmq message arrived on closed channel
[W 02:41:06.168 NotebookApp] zmq message arrived on closed channel
[W 02:41:06.169 NotebookApp] zmq message arrived on closed channel
[W 02:41:06.169 NotebookApp] zmq message arrived on closed channel
[W 02:41:06.169 NotebookApp] zmq message arrived on closed channel
[W 02:41:06.169 NotebookApp] zmq message arrived on closed channel
[W 02:41:11.113 NotebookApp] zmq message arrived on closed channel
[W 02:41:11.114 NotebookApp] zmq message arrived on closed channel
[W 02:41:11.115 NotebookApp] zmq message arrived on closed channel
[W 02:41:11.115 NotebookApp] zmq message arrived on closed channel
[W 02:41:11.116 NotebookApp] zmq message arrived on closed channel
[W 02:41:11.116 NotebookApp] zmq message arrived on closed channel
[W 02:41:11.116 NotebookApp] zmq message arrived on closed channel
[W 02:41:11.117 NotebookApp] zmq message arrived on closed channel
[W 02:41:11.117 NotebookApp] zmq message arrived on closed channel
[W 02:41:11.117 NotebookApp] zmq message arrived on closed channel
<console>:20: error: value ￼ is not a member of Array[String]
              info.filter(line => line.contains("spark")).collect()￼
                                                                   ^
[W 02:41:11.169 NotebookApp] zmq message arrived on closed channel
[W 02:41:11.170 NotebookApp] zmq message arrived on closed channel
[W 02:41:11.170 NotebookApp] zmq message arrived on closed channel
[W 02:41:11.170 NotebookApp] zmq message arrived on closed channel
[W 02:41:11.170 NotebookApp] zmq message arrived on closed channel
[W 02:41:11.171 NotebookApp] zmq message arrived on closed channel
[W 02:41:11.172 NotebookApp] zmq message arrived on closed channel
[W 02:41:11.172 NotebookApp] zmq message arrived on closed channel
[W 02:41:11.172 NotebookApp] zmq message arrived on closed channel
[W 02:41:11.172 NotebookApp] zmq message arrived on closed channel
[W 02:41:19.701 NotebookApp] zmq message arrived on closed channel
[W 02:41:19.702 NotebookApp] zmq message arrived on closed channel
[W 02:41:19.702 NotebookApp] zmq message arrived on closed channel
[W 02:41:19.703 NotebookApp] zmq message arrived on closed channel
[W 02:41:19.703 NotebookApp] zmq message arrived on closed channel
[W 02:41:19.703 NotebookApp] zmq message arrived on closed channel
[W 02:41:19.704 NotebookApp] zmq message arrived on closed channel
[W 02:41:19.704 NotebookApp] zmq message arrived on closed channel
[W 02:41:19.704 NotebookApp] zmq message arrived on closed channel
[W 02:41:19.704 NotebookApp] zmq message arrived on closed channel
<console>:20: error: not enough arguments for method apply: (index: Int)Char in class StringOps.
Unspecified value parameter index.
              info.toDebugString()
                                ^
[W 02:41:19.789 NotebookApp] zmq message arrived on closed channel
[W 02:41:19.790 NotebookApp] zmq message arrived on closed channel
[W 02:41:19.790 NotebookApp] zmq message arrived on closed channel
[W 02:41:19.790 NotebookApp] zmq message arrived on closed channel
[W 02:41:19.790 NotebookApp] zmq message arrived on closed channel
[W 02:41:19.791 NotebookApp] zmq message arrived on closed channel
[W 02:41:19.791 NotebookApp] zmq message arrived on closed channel
[W 02:41:19.792 NotebookApp] zmq message arrived on closed channel
[W 02:41:19.792 NotebookApp] zmq message arrived on closed channel
[W 02:41:19.792 NotebookApp] zmq message arrived on closed channel
[W 02:41:25.601 NotebookApp] zmq message arrived on closed channel
[W 02:41:25.602 NotebookApp] zmq message arrived on closed channel
[W 02:41:25.602 NotebookApp] zmq message arrived on closed channel
[W 02:41:25.603 NotebookApp] zmq message arrived on closed channel
[W 02:41:25.603 NotebookApp] zmq message arrived on closed channel
[W 02:41:25.603 NotebookApp] zmq message arrived on closed channel
[W 02:41:25.604 NotebookApp] zmq message arrived on closed channel
[W 02:41:25.604 NotebookApp] zmq message arrived on closed channel
[W 02:41:25.604 NotebookApp] zmq message arrived on closed channel
[W 02:41:25.604 NotebookApp] zmq message arrived on closed channel
res51: Char = (
[W 02:41:25.818 NotebookApp] zmq message arrived on closed channel
[W 02:41:25.818 NotebookApp] zmq message arrived on closed channel
[W 02:41:25.819 NotebookApp] zmq message arrived on closed channel
[W 02:41:25.820 NotebookApp] zmq message arrived on closed channel
[W 02:41:25.820 NotebookApp] zmq message arrived on closed channel
[W 02:41:25.820 NotebookApp] zmq message arrived on closed channel
[W 02:41:25.820 NotebookApp] zmq message arrived on closed channel
[W 02:41:25.821 NotebookApp] zmq message arrived on closed channel
[W 02:41:25.821 NotebookApp] zmq message arrived on closed channel
[W 02:41:25.821 NotebookApp] zmq message arrived on closed channel
[W 02:41:28.219 NotebookApp] zmq message arrived on closed channel
[W 02:41:28.219 NotebookApp] zmq message arrived on closed channel
[W 02:41:28.219 NotebookApp] zmq message arrived on closed channel
[W 02:41:28.220 NotebookApp] zmq message arrived on closed channel
[W 02:41:28.220 NotebookApp] zmq message arrived on closed channel
[W 02:41:28.221 NotebookApp] zmq message arrived on closed channel
[W 02:41:28.221 NotebookApp] zmq message arrived on closed channel
[W 02:41:28.221 NotebookApp] zmq message arrived on closed channel
[W 02:41:28.221 NotebookApp] zmq message arrived on closed channel
[W 02:41:28.221 NotebookApp] zmq message arrived on closed channel
res52: Char = 2
[W 02:41:28.389 NotebookApp] zmq message arrived on closed channel
[W 02:41:28.389 NotebookApp] zmq message arrived on closed channel
[W 02:41:28.390 NotebookApp] zmq message arrived on closed channel
[W 02:41:28.390 NotebookApp] zmq message arrived on closed channel
[W 02:41:28.391 NotebookApp] zmq message arrived on closed channel
[W 02:41:28.391 NotebookApp] zmq message arrived on closed channel
[W 02:41:28.391 NotebookApp] zmq message arrived on closed channel
[W 02:41:28.392 NotebookApp] zmq message arrived on closed channel
[W 02:41:28.392 NotebookApp] zmq message arrived on closed channel
[W 02:41:28.392 NotebookApp] zmq message arrived on closed channel
<console>:1: error: ';' expected but '.' found.
       print info.toDebugString
                 ^
[W 02:41:33.450 NotebookApp] zmq message arrived on closed channel
[W 02:41:33.450 NotebookApp] zmq message arrived on closed channel
[W 02:41:33.451 NotebookApp] zmq message arrived on closed channel
[W 02:41:33.451 NotebookApp] zmq message arrived on closed channel
[W 02:41:33.451 NotebookApp] zmq message arrived on closed channel
[W 02:41:33.452 NotebookApp] zmq message arrived on closed channel
[W 02:41:33.452 NotebookApp] zmq message arrived on closed channel
[W 02:41:33.452 NotebookApp] zmq message arrived on closed channel
[W 02:41:33.452 NotebookApp] zmq message arrived on closed channel
[W 02:41:33.453 NotebookApp] zmq message arrived on closed channel
[W 02:41:33.454 NotebookApp] zmq message arrived on closed channel
[W 02:41:33.455 NotebookApp] zmq message arrived on closed channel
[W 02:41:33.455 NotebookApp] zmq message arrived on closed channel
[W 02:41:33.456 NotebookApp] zmq message arrived on closed channel
[W 02:41:33.457 NotebookApp] zmq message arrived on closed channel
[W 02:41:33.457 NotebookApp] zmq message arrived on closed channel
[W 02:41:33.457 NotebookApp] zmq message arrived on closed channel
[W 02:41:33.458 NotebookApp] zmq message arrived on closed channel
[W 02:41:33.458 NotebookApp] zmq message arrived on closed channel
[W 02:41:33.458 NotebookApp] zmq message arrived on closed channel
[W 02:41:42.208 NotebookApp] zmq message arrived on closed channel
[W 02:41:42.209 NotebookApp] zmq message arrived on closed channel
[W 02:41:42.209 NotebookApp] zmq message arrived on closed channel
[W 02:41:42.209 NotebookApp] zmq message arrived on closed channel
[W 02:41:42.210 NotebookApp] zmq message arrived on closed channel
[W 02:41:42.210 NotebookApp] zmq message arrived on closed channel
[W 02:41:42.210 NotebookApp] zmq message arrived on closed channel
[W 02:41:42.211 NotebookApp] zmq message arrived on closed channel
[W 02:41:42.211 NotebookApp] zmq message arrived on closed channel
[W 02:41:42.211 NotebookApp] zmq message arrived on closed channel
[W 02:41:42.360 NotebookApp] zmq message arrived on closed channel
[W 02:41:42.360 NotebookApp] zmq message arrived on closed channel
[W 02:41:42.360 NotebookApp] zmq message arrived on closed channel
[W 02:41:42.361 NotebookApp] zmq message arrived on closed channel
[W 02:41:42.361 NotebookApp] zmq message arrived on closed channel
[W 02:41:42.369 NotebookApp] zmq message arrived on closed channel
[W 02:41:42.369 NotebookApp] zmq message arrived on closed channel
[W 02:41:42.370 NotebookApp] zmq message arrived on closed channel
[W 02:41:42.370 NotebookApp] zmq message arrived on closed channel
[W 02:41:42.370 NotebookApp] zmq message arrived on closed channel
[I 02:42:04.424 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 02:42:07.044 NotebookApp] zmq message arrived on closed channel
[W 02:42:07.044 NotebookApp] zmq message arrived on closed channel
[W 02:42:07.045 NotebookApp] zmq message arrived on closed channel
[W 02:42:07.045 NotebookApp] zmq message arrived on closed channel
[W 02:42:07.045 NotebookApp] zmq message arrived on closed channel
[W 02:42:07.046 NotebookApp] zmq message arrived on closed channel
[W 02:42:07.046 NotebookApp] zmq message arrived on closed channel
[W 02:42:07.046 NotebookApp] zmq message arrived on closed channel
[W 02:42:07.046 NotebookApp] zmq message arrived on closed channel
[W 02:42:07.047 NotebookApp] zmq message arrived on closed channel
<console>:20: error: value ￼ is not a member of Array[String]
              info.filter(line => line.contains("spark")).collect()￼
                                                                   ^
[W 02:42:07.107 NotebookApp] zmq message arrived on closed channel
[W 02:42:07.108 NotebookApp] zmq message arrived on closed channel
[W 02:42:07.108 NotebookApp] zmq message arrived on closed channel
[W 02:42:07.109 NotebookApp] zmq message arrived on closed channel
[W 02:42:07.109 NotebookApp] zmq message arrived on closed channel
[W 02:42:07.109 NotebookApp] zmq message arrived on closed channel
[W 02:42:07.110 NotebookApp] zmq message arrived on closed channel
[W 02:42:07.110 NotebookApp] zmq message arrived on closed channel
[W 02:42:07.110 NotebookApp] zmq message arrived on closed channel
[W 02:42:07.110 NotebookApp] zmq message arrived on closed channel
[W 02:42:25.755 NotebookApp] zmq message arrived on closed channel
[W 02:42:25.756 NotebookApp] zmq message arrived on closed channel
[W 02:42:25.756 NotebookApp] zmq message arrived on closed channel
[W 02:42:25.757 NotebookApp] zmq message arrived on closed channel
[W 02:42:25.757 NotebookApp] zmq message arrived on closed channel
[W 02:42:25.757 NotebookApp] zmq message arrived on closed channel
[W 02:42:25.758 NotebookApp] zmq message arrived on closed channel
[W 02:42:25.758 NotebookApp] zmq message arrived on closed channel
[W 02:42:25.758 NotebookApp] zmq message arrived on closed channel
[W 02:42:25.758 NotebookApp] zmq message arrived on closed channel
<console>:21: error: value ￼ is not a member of Array[String]
              info.filter(line => line.contains("spark")).collect()￼
                                                                   ^
[W 02:42:25.813 NotebookApp] zmq message arrived on closed channel
[W 02:42:25.813 NotebookApp] zmq message arrived on closed channel
[W 02:42:25.814 NotebookApp] zmq message arrived on closed channel
[W 02:42:25.814 NotebookApp] zmq message arrived on closed channel
[W 02:42:25.815 NotebookApp] zmq message arrived on closed channel
[W 02:42:25.815 NotebookApp] zmq message arrived on closed channel
[W 02:42:25.815 NotebookApp] zmq message arrived on closed channel
[W 02:42:25.815 NotebookApp] zmq message arrived on closed channel
[W 02:42:25.816 NotebookApp] zmq message arrived on closed channel
[W 02:42:25.816 NotebookApp] zmq message arrived on closed channel
[W 02:43:25.105 NotebookApp] zmq message arrived on closed channel
[W 02:43:25.105 NotebookApp] zmq message arrived on closed channel
[W 02:43:25.105 NotebookApp] zmq message arrived on closed channel
[W 02:43:25.106 NotebookApp] zmq message arrived on closed channel
[W 02:43:25.106 NotebookApp] zmq message arrived on closed channel
[W 02:43:25.107 NotebookApp] zmq message arrived on closed channel
[W 02:43:25.107 NotebookApp] zmq message arrived on closed channel
[W 02:43:25.107 NotebookApp] zmq message arrived on closed channel
[W 02:43:25.107 NotebookApp] zmq message arrived on closed channel
[W 02:43:25.107 NotebookApp] zmq message arrived on closed channel
<console>:14: error: value Joining is not a member of Int
              ## Joining RDDs
                 ^
[W 02:43:25.149 NotebookApp] zmq message arrived on closed channel
[W 02:43:25.149 NotebookApp] zmq message arrived on closed channel
[W 02:43:25.150 NotebookApp] zmq message arrived on closed channel
[W 02:43:25.150 NotebookApp] zmq message arrived on closed channel
[W 02:43:25.151 NotebookApp] zmq message arrived on closed channel
[W 02:43:25.152 NotebookApp] zmq message arrived on closed channel
[W 02:43:25.152 NotebookApp] zmq message arrived on closed channel
[W 02:43:25.152 NotebookApp] zmq message arrived on closed channel
[W 02:43:25.153 NotebookApp] zmq message arrived on closed channel
[W 02:43:25.153 NotebookApp] zmq message arrived on closed channel
[I 02:44:05.460 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 02:48:54.854 NotebookApp] zmq message arrived on closed channel
[W 02:48:54.854 NotebookApp] zmq message arrived on closed channel
[W 02:48:54.855 NotebookApp] zmq message arrived on closed channel
[W 02:48:54.855 NotebookApp] zmq message arrived on closed channel
[W 02:48:54.855 NotebookApp] zmq message arrived on closed channel
[W 02:48:54.856 NotebookApp] zmq message arrived on closed channel
[W 02:48:54.856 NotebookApp] zmq message arrived on closed channel
[W 02:48:54.856 NotebookApp] zmq message arrived on closed channel
[W 02:48:54.856 NotebookApp] zmq message arrived on closed channel
[W 02:48:54.856 NotebookApp] zmq message arrived on closed channel
readmeFile: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[20] at textFile at <console>:15
pom: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[22] at textFile at <console>:15
[W 02:48:55.217 NotebookApp] zmq message arrived on closed channel
[W 02:48:55.217 NotebookApp] zmq message arrived on closed channel
[W 02:48:55.218 NotebookApp] zmq message arrived on closed channel
[W 02:48:55.218 NotebookApp] zmq message arrived on closed channel
[W 02:48:55.219 NotebookApp] zmq message arrived on closed channel
[W 02:48:56.390 NotebookApp] zmq message arrived on closed channel
[W 02:48:56.390 NotebookApp] zmq message arrived on closed channel
[W 02:48:56.391 NotebookApp] zmq message arrived on closed channel
[W 02:48:56.391 NotebookApp] zmq message arrived on closed channel
[W 02:48:56.391 NotebookApp] zmq message arrived on closed channel
[W 02:48:56.391 NotebookApp] zmq message arrived on closed channel
[W 02:48:56.392 NotebookApp] zmq message arrived on closed channel
[W 02:48:56.392 NotebookApp] zmq message arrived on closed channel
[W 02:48:56.392 NotebookApp] zmq message arrived on closed channel
[W 02:48:56.393 NotebookApp] zmq message arrived on closed channel
res58: Long = 18
<console>:14: error: not found: value changesFile
              changesFile.filter(line => line.contains("Spark")).count()
              ^
[W 02:48:56.611 NotebookApp] zmq message arrived on closed channel
[W 02:48:56.612 NotebookApp] zmq message arrived on closed channel
[W 02:48:56.612 NotebookApp] zmq message arrived on closed channel
[W 02:48:56.612 NotebookApp] zmq message arrived on closed channel
[W 02:48:56.612 NotebookApp] zmq message arrived on closed channel
[W 02:48:56.619 NotebookApp] zmq message arrived on closed channel
[W 02:48:56.620 NotebookApp] zmq message arrived on closed channel
[W 02:48:56.621 NotebookApp] zmq message arrived on closed channel
[W 02:48:56.622 NotebookApp] zmq message arrived on closed channel
[W 02:48:56.622 NotebookApp] zmq message arrived on closed channel
[W 02:49:02.064 NotebookApp] zmq message arrived on closed channel
[W 02:49:02.065 NotebookApp] zmq message arrived on closed channel
[W 02:49:02.065 NotebookApp] zmq message arrived on closed channel
[W 02:49:02.065 NotebookApp] zmq message arrived on closed channel
[W 02:49:02.066 NotebookApp] zmq message arrived on closed channel
[W 02:49:02.066 NotebookApp] zmq message arrived on closed channel
[W 02:49:02.066 NotebookApp] zmq message arrived on closed channel
[W 02:49:02.066 NotebookApp] zmq message arrived on closed channel
[W 02:49:02.067 NotebookApp] zmq message arrived on closed channel
[W 02:49:02.067 NotebookApp] zmq message arrived on closed channel
res60: Long = 18
res61: Long = 2
[W 02:49:02.446 NotebookApp] zmq message arrived on closed channel
[W 02:49:02.447 NotebookApp] zmq message arrived on closed channel
[W 02:49:02.448 NotebookApp] zmq message arrived on closed channel
[W 02:49:02.448 NotebookApp] zmq message arrived on closed channel
[W 02:49:02.448 NotebookApp] zmq message arrived on closed channel
[W 02:49:02.449 NotebookApp] zmq message arrived on closed channel
[W 02:49:02.449 NotebookApp] zmq message arrived on closed channel
[W 02:49:02.449 NotebookApp] zmq message arrived on closed channel
[W 02:49:02.449 NotebookApp] zmq message arrived on closed channel
[W 02:49:02.450 NotebookApp] zmq message arrived on closed channel
<console>:1: error: ';' expected but '.' found.
       print readmeFile.filter(line => line.contains("Spark")).count()
                       ^
[W 02:49:07.422 NotebookApp] zmq message arrived on closed channel
[W 02:49:07.422 NotebookApp] zmq message arrived on closed channel
[W 02:49:07.422 NotebookApp] zmq message arrived on closed channel
[W 02:49:07.423 NotebookApp] zmq message arrived on closed channel
[W 02:49:07.423 NotebookApp] zmq message arrived on closed channel
[W 02:49:07.423 NotebookApp] zmq message arrived on closed channel
[W 02:49:07.423 NotebookApp] zmq message arrived on closed channel
[W 02:49:07.424 NotebookApp] zmq message arrived on closed channel
[W 02:49:07.424 NotebookApp] zmq message arrived on closed channel
[W 02:49:07.424 NotebookApp] zmq message arrived on closed channel
[W 02:49:07.425 NotebookApp] zmq message arrived on closed channel
[W 02:49:07.425 NotebookApp] zmq message arrived on closed channel
[W 02:49:07.425 NotebookApp] zmq message arrived on closed channel
[W 02:49:07.426 NotebookApp] zmq message arrived on closed channel
[W 02:49:07.426 NotebookApp] zmq message arrived on closed channel
[W 02:49:07.426 NotebookApp] zmq message arrived on closed channel
[W 02:49:07.427 NotebookApp] zmq message arrived on closed channel
[W 02:49:07.427 NotebookApp] zmq message arrived on closed channel
[W 02:49:07.428 NotebookApp] zmq message arrived on closed channel
[W 02:49:07.428 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.111 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.112 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.113 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.113 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.113 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.114 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.114 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.114 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.115 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.115 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.310 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.310 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.311 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.311 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.311 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.478 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.478 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.479 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.479 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.479 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.486 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.486 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.487 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.487 NotebookApp] zmq message arrived on closed channel
[W 02:49:17.487 NotebookApp] zmq message arrived on closed channel
[W 02:49:58.304 NotebookApp] zmq message arrived on closed channel
[W 02:49:58.305 NotebookApp] zmq message arrived on closed channel
[W 02:49:58.305 NotebookApp] zmq message arrived on closed channel
[W 02:49:58.305 NotebookApp] zmq message arrived on closed channel
[W 02:49:58.306 NotebookApp] zmq message arrived on closed channel
[W 02:49:58.306 NotebookApp] zmq message arrived on closed channel
[W 02:49:58.306 NotebookApp] zmq message arrived on closed channel
[W 02:49:58.306 NotebookApp] zmq message arrived on closed channel
[W 02:49:58.307 NotebookApp] zmq message arrived on closed channel
[W 02:49:58.307 NotebookApp] zmq message arrived on closed channel
readmeCount: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[30] at reduceByKey at <console>:17
pomCount: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[33] at reduceByKey at <console>:17
[W 02:49:58.862 NotebookApp] zmq message arrived on closed channel
[W 02:49:58.863 NotebookApp] zmq message arrived on closed channel
[W 02:49:58.863 NotebookApp] zmq message arrived on closed channel
[W 02:49:58.863 NotebookApp] zmq message arrived on closed channel
[W 02:49:58.864 NotebookApp] zmq message arrived on closed channel
[I 02:50:07.094 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 02:50:17.710 NotebookApp] zmq message arrived on closed channel
[W 02:50:17.710 NotebookApp] zmq message arrived on closed channel
[W 02:50:17.711 NotebookApp] zmq message arrived on closed channel
[W 02:50:17.711 NotebookApp] zmq message arrived on closed channel
[W 02:50:17.711 NotebookApp] zmq message arrived on closed channel
[W 02:50:17.712 NotebookApp] zmq message arrived on closed channel
[W 02:50:17.712 NotebookApp] zmq message arrived on closed channel
[W 02:50:17.712 NotebookApp] zmq message arrived on closed channel
[W 02:50:17.712 NotebookApp] zmq message arrived on closed channel
[W 02:50:17.713 NotebookApp] zmq message arrived on closed channel
res64: Array[(String, Int)] = Array((package,1), (this,1), (Version"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version),1), (Because,1), (Python,2), (cluster.,1), (its,1), ([run,1), (general,2), (have,1), (pre-built,1), (locally.,1), (locally,2), (changed,1), (sc.parallelize(1,1), (only,1), (several,1), (This,2), (basic,1), (Configuration,1), (learning,,1), (documentation,3), (YARN,,1), (graph,1), (Hive,2), (first,1), (["Specifying,1), ("yarn",1), (page](http://spark.apache.org/documentation.html),1), ([params]`.,1), (application,1), ([project,2), (prefer,1), (SparkPi,2), (<http://spark.apache.org/>,1), (engine,1), (version,1), (file,1), (documentation,,1), (MASTER,1), (example,3), (distribution.,1), (are,1), (params,1), (scala>,1), (DataFrames,,1), ...[W 02:50:17.990 NotebookApp] zmq message arrived on closed channel
[W 02:50:17.990 NotebookApp] zmq message arrived on closed channel
[W 02:50:17.991 NotebookApp] zmq message arrived on closed channel
[W 02:50:17.991 NotebookApp] zmq message arrived on closed channel
[W 02:50:17.992 NotebookApp] zmq message arrived on closed channel
[W 02:50:21.241 NotebookApp] zmq message arrived on closed channel
[W 02:50:21.242 NotebookApp] zmq message arrived on closed channel
[W 02:50:21.242 NotebookApp] zmq message arrived on closed channel
[W 02:50:21.242 NotebookApp] zmq message arrived on closed channel
[W 02:50:21.243 NotebookApp] zmq message arrived on closed channel
[W 02:50:21.243 NotebookApp] zmq message arrived on closed channel
[W 02:50:21.243 NotebookApp] zmq message arrived on closed channel
[W 02:50:21.243 NotebookApp] zmq message arrived on closed channel
[W 02:50:21.244 NotebookApp] zmq message arrived on closed channel
[W 02:50:21.244 NotebookApp] zmq message arrived on closed channel
[W 02:50:21.435 NotebookApp] zmq message arrived on closed channel
[W 02:50:21.436 NotebookApp] zmq message arrived on closed channel
[W 02:50:21.437 NotebookApp] zmq message arrived on closed channel
[W 02:50:21.437 NotebookApp] zmq message arrived on closed channel
[W 02:50:21.438 NotebookApp] zmq message arrived on closed channel
[W 02:50:21.444 NotebookApp] zmq message arrived on closed channel
[W 02:50:21.445 NotebookApp] zmq message arrived on closed channel
[W 02:50:21.445 NotebookApp] zmq message arrived on closed channel
[W 02:50:21.446 NotebookApp] zmq message arrived on closed channel
[W 02:50:21.446 NotebookApp] zmq message arrived on closed channel
[W 02:51:01.667 NotebookApp] zmq message arrived on closed channel
[W 02:51:01.668 NotebookApp] zmq message arrived on closed channel
[W 02:51:01.668 NotebookApp] zmq message arrived on closed channel
[W 02:51:01.668 NotebookApp] zmq message arrived on closed channel
[W 02:51:01.668 NotebookApp] zmq message arrived on closed channel
[W 02:51:01.669 NotebookApp] zmq message arrived on closed channel
[W 02:51:01.669 NotebookApp] zmq message arrived on closed channel
[W 02:51:01.669 NotebookApp] zmq message arrived on closed channel
[W 02:51:01.670 NotebookApp] zmq message arrived on closed channel
[W 02:51:01.670 NotebookApp] zmq message arrived on closed channel
[W 02:51:01.948 NotebookApp] zmq message arrived on closed channel
[W 02:51:01.949 NotebookApp] zmq message arrived on closed channel
[W 02:51:01.949 NotebookApp] zmq message arrived on closed channel
[W 02:51:01.949 NotebookApp] zmq message arrived on closed channel
[W 02:51:01.950 NotebookApp] zmq message arrived on closed channel
[W 02:51:01.953 NotebookApp] zmq message arrived on closed channel
[W 02:51:01.953 NotebookApp] zmq message arrived on closed channel
[W 02:51:01.953 NotebookApp] zmq message arrived on closed channel
[W 02:51:01.954 NotebookApp] zmq message arrived on closed channel
[W 02:51:01.954 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.133 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.133 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.133 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.134 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.134 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.135 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.135 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.135 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.135 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.136 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.410 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.411 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.412 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.412 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.412 NotebookApp] zmq message arrived on closed channel
<console>:15: error: not found: value changesCount
              changesCount.collect()
              ^
[W 02:51:11.430 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.430 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.430 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.431 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.431 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.431 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.431 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.432 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.432 NotebookApp] zmq message arrived on closed channel
[W 02:51:11.432 NotebookApp] zmq message arrived on closed channel
[W 02:51:20.008 NotebookApp] zmq message arrived on closed channel
[W 02:51:20.009 NotebookApp] zmq message arrived on closed channel
[W 02:51:20.009 NotebookApp] zmq message arrived on closed channel
[W 02:51:20.009 NotebookApp] zmq message arrived on closed channel
[W 02:51:20.010 NotebookApp] zmq message arrived on closed channel
[W 02:51:20.010 NotebookApp] zmq message arrived on closed channel
[W 02:51:20.010 NotebookApp] zmq message arrived on closed channel
[W 02:51:20.011 NotebookApp] zmq message arrived on closed channel
[W 02:51:20.011 NotebookApp] zmq message arrived on closed channel
[W 02:51:20.011 NotebookApp] zmq message arrived on closed channel
[W 02:51:20.285 NotebookApp] zmq message arrived on closed channel
[W 02:51:20.285 NotebookApp] zmq message arrived on closed channel
[W 02:51:20.287 NotebookApp] zmq message arrived on closed channel
[W 02:51:20.287 NotebookApp] zmq message arrived on closed channel
[W 02:51:20.287 NotebookApp] zmq message arrived on closed channel
res72: Array[(String, Int)] = Array((<id>kinesis-asl</id>,1), (Unless,1), (this,3), (under,4), (implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer",1), (<scope>provided</scope>,8), (</properties>,6), (version="1.0",1), (<artifactId>maven-install-plugin</artifactId>,1), (<plugins>,1), (express,1), (</transformer>,2), (<version>3.2.0</version>,1), (we,1), (WITHOUT,1), (<groupId>commons-io</groupId>,1), (<artifactId>commons-math</artifactId>,1), ("AS,1), (<artifactId>compress-lzf</artifactId>,1), (<scope>${hbase.deps.scope}</scope>,6), (<artifactId>jersey-json</artifactId>,1), (<id>flume-provided</id>,1), (IS",1), (already,1), (...-->,1), (ANY,1), (disable,1), (<configuration>,3), (<packaging>jar</packaging>,1), (2.0,1), (<groupId>org.scala-lang</groupId>,1...[W 02:51:20.539 NotebookApp] zmq message arrived on closed channel
[W 02:51:20.540 NotebookApp] zmq message arrived on closed channel
[W 02:51:20.540 NotebookApp] zmq message arrived on closed channel
[W 02:51:20.540 NotebookApp] zmq message arrived on closed channel
[W 02:51:20.540 NotebookApp] zmq message arrived on closed channel
[W 02:51:42.533 NotebookApp] zmq message arrived on closed channel
[W 02:51:42.534 NotebookApp] zmq message arrived on closed channel
[W 02:51:42.535 NotebookApp] zmq message arrived on closed channel
[W 02:51:42.535 NotebookApp] zmq message arrived on closed channel
[W 02:51:42.535 NotebookApp] zmq message arrived on closed channel
[W 02:51:42.536 NotebookApp] zmq message arrived on closed channel
[W 02:51:42.536 NotebookApp] zmq message arrived on closed channel
[W 02:51:42.536 NotebookApp] zmq message arrived on closed channel
[W 02:51:42.537 NotebookApp] zmq message arrived on closed channel
[W 02:51:42.537 NotebookApp] zmq message arrived on closed channel
[W 02:51:42.802 NotebookApp] zmq message arrived on closed channel
[W 02:51:42.802 NotebookApp] zmq message arrived on closed channel
[W 02:51:42.803 NotebookApp] zmq message arrived on closed channel
[W 02:51:42.804 NotebookApp] zmq message arrived on closed channel
[W 02:51:42.804 NotebookApp] zmq message arrived on closed channel
[W 02:51:43.056 NotebookApp] zmq message arrived on closed channel
[W 02:51:43.057 NotebookApp] zmq message arrived on closed channel
[W 02:51:43.057 NotebookApp] zmq message arrived on closed channel
[W 02:51:43.057 NotebookApp] zmq message arrived on closed channel
[W 02:51:43.057 NotebookApp] zmq message arrived on closed channel
[W 02:51:43.061 NotebookApp] zmq message arrived on closed channel
[W 02:51:43.062 NotebookApp] zmq message arrived on closed channel
[W 02:51:43.062 NotebookApp] zmq message arrived on closed channel
[W 02:51:43.062 NotebookApp] zmq message arrived on closed channel
[W 02:51:43.063 NotebookApp] zmq message arrived on closed channel
[I 02:52:05.534 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 02:52:06.816 NotebookApp] zmq message arrived on closed channel
[W 02:52:06.817 NotebookApp] zmq message arrived on closed channel
[W 02:52:06.817 NotebookApp] zmq message arrived on closed channel
[W 02:52:06.818 NotebookApp] zmq message arrived on closed channel
[W 02:52:06.818 NotebookApp] zmq message arrived on closed channel
[W 02:52:06.818 NotebookApp] zmq message arrived on closed channel
[W 02:52:06.819 NotebookApp] zmq message arrived on closed channel
[W 02:52:06.819 NotebookApp] zmq message arrived on closed channel
[W 02:52:06.819 NotebookApp] zmq message arrived on closed channel
[W 02:52:06.819 NotebookApp] zmq message arrived on closed channel
[W 02:52:06.952 NotebookApp] zmq message arrived on closed channel
[W 02:52:06.952 NotebookApp] zmq message arrived on closed channel
[W 02:52:06.953 NotebookApp] zmq message arrived on closed channel
[W 02:52:06.953 NotebookApp] zmq message arrived on closed channel
[W 02:52:06.954 NotebookApp] zmq message arrived on closed channel
[W 02:52:07.192 NotebookApp] zmq message arrived on closed channel
[W 02:52:07.192 NotebookApp] zmq message arrived on closed channel
[W 02:52:07.192 NotebookApp] zmq message arrived on closed channel
[W 02:52:07.193 NotebookApp] zmq message arrived on closed channel
[W 02:52:07.193 NotebookApp] zmq message arrived on closed channel
[W 02:52:07.315 NotebookApp] zmq message arrived on closed channel
[W 02:52:07.316 NotebookApp] zmq message arrived on closed channel
[W 02:52:07.316 NotebookApp] zmq message arrived on closed channel
[W 02:52:07.316 NotebookApp] zmq message arrived on closed channel
[W 02:52:07.316 NotebookApp] zmq message arrived on closed channel
[W 02:52:07.547 NotebookApp] zmq message arrived on closed channel
[W 02:52:07.547 NotebookApp] zmq message arrived on closed channel
[W 02:52:07.548 NotebookApp] zmq message arrived on closed channel
[W 02:52:07.548 NotebookApp] zmq message arrived on closed channel
[W 02:52:07.548 NotebookApp] zmq message arrived on closed channel
[W 02:52:07.552 NotebookApp] zmq message arrived on closed channel
[W 02:52:07.552 NotebookApp] zmq message arrived on closed channel
[W 02:52:07.553 NotebookApp] zmq message arrived on closed channel
[W 02:52:07.553 NotebookApp] zmq message arrived on closed channel
[W 02:52:07.553 NotebookApp] zmq message arrived on closed channel
[W 02:52:14.949 NotebookApp] zmq message arrived on closed channel
[W 02:52:14.949 NotebookApp] zmq message arrived on closed channel
[W 02:52:14.950 NotebookApp] zmq message arrived on closed channel
[W 02:52:14.950 NotebookApp] zmq message arrived on closed channel
[W 02:52:14.951 NotebookApp] zmq message arrived on closed channel
[W 02:52:14.951 NotebookApp] zmq message arrived on closed channel
[W 02:52:14.951 NotebookApp] zmq message arrived on closed channel
[W 02:52:14.952 NotebookApp] zmq message arrived on closed channel
[W 02:52:14.952 NotebookApp] zmq message arrived on closed channel
[W 02:52:14.952 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.095 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.095 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.096 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.097 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.097 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.318 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.319 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.320 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.320 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.320 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.432 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.432 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.433 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.433 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.433 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.657 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.658 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.658 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.658 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.659 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.663 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.663 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.663 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.663 NotebookApp] zmq message arrived on closed channel
[W 02:52:15.664 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.261 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.261 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.262 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.262 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.262 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.263 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.263 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.263 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.263 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.264 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.396 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.396 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.397 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.397 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.397 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.609 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.609 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.609 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.610 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.610 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.717 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.717 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.718 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.718 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.719 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.929 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.930 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.930 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.930 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.931 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.934 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.934 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.934 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.935 NotebookApp] zmq message arrived on closed channel
[W 02:52:41.936 NotebookApp] zmq message arrived on closed channel
[W 02:53:21.698 NotebookApp] zmq message arrived on closed channel
[W 02:53:21.698 NotebookApp] zmq message arrived on closed channel
[W 02:53:21.699 NotebookApp] zmq message arrived on closed channel
[W 02:53:21.699 NotebookApp] zmq message arrived on closed channel
[W 02:53:21.700 NotebookApp] zmq message arrived on closed channel
[W 02:53:21.700 NotebookApp] zmq message arrived on closed channel
[W 02:53:21.700 NotebookApp] zmq message arrived on closed channel
[W 02:53:21.700 NotebookApp] zmq message arrived on closed channel
[W 02:53:21.701 NotebookApp] zmq message arrived on closed channel
[W 02:53:21.701 NotebookApp] zmq message arrived on closed channel
joined: org.apache.spark.rdd.RDD[(String, (Int, Int))] = MapPartitionsRDD[36] at join at <console>:23
[W 02:53:21.891 NotebookApp] zmq message arrived on closed channel
[W 02:53:21.892 NotebookApp] zmq message arrived on closed channel
[W 02:53:21.892 NotebookApp] zmq message arrived on closed channel
[W 02:53:21.892 NotebookApp] zmq message arrived on closed channel
[W 02:53:21.893 NotebookApp] zmq message arrived on closed channel
[W 02:53:43.692 NotebookApp] zmq message arrived on closed channel
[W 02:53:43.692 NotebookApp] zmq message arrived on closed channel
[W 02:53:43.693 NotebookApp] zmq message arrived on closed channel
[W 02:53:43.693 NotebookApp] zmq message arrived on closed channel
[W 02:53:43.693 NotebookApp] zmq message arrived on closed channel
[W 02:53:43.694 NotebookApp] zmq message arrived on closed channel
[W 02:53:43.694 NotebookApp] zmq message arrived on closed channel
[W 02:53:43.694 NotebookApp] zmq message arrived on closed channel
[W 02:53:43.694 NotebookApp] zmq message arrived on closed channel
[W 02:53:43.695 NotebookApp] zmq message arrived on closed channel
joined: org.apache.spark.rdd.RDD[(String, (Int, Int))] = MapPartitionsRDD[39] at join at <console>:23
res91: joined.type = MapPartitionsRDD[39] at join at <console>:23
[W 02:53:44.010 NotebookApp] zmq message arrived on closed channel
[W 02:53:44.010 NotebookApp] zmq message arrived on closed channel
[W 02:53:44.011 NotebookApp] zmq message arrived on closed channel
[W 02:53:44.012 NotebookApp] zmq message arrived on closed channel
[W 02:53:44.012 NotebookApp] zmq message arrived on closed channel
[W 02:53:44.012 NotebookApp] zmq message arrived on closed channel
[W 02:53:44.012 NotebookApp] zmq message arrived on closed channel
[W 02:53:44.013 NotebookApp] zmq message arrived on closed channel
[W 02:53:44.013 NotebookApp] zmq message arrived on closed channel
[W 02:53:44.013 NotebookApp] zmq message arrived on closed channel
[W 02:54:01.122 NotebookApp] zmq message arrived on closed channel
[W 02:54:01.123 NotebookApp] zmq message arrived on closed channel
[W 02:54:01.123 NotebookApp] zmq message arrived on closed channel
[W 02:54:01.123 NotebookApp] zmq message arrived on closed channel
[W 02:54:01.124 NotebookApp] zmq message arrived on closed channel
[W 02:54:01.124 NotebookApp] zmq message arrived on closed channel
[W 02:54:01.124 NotebookApp] zmq message arrived on closed channel
[W 02:54:01.125 NotebookApp] zmq message arrived on closed channel
[W 02:54:01.125 NotebookApp] zmq message arrived on closed channel
[W 02:54:01.125 NotebookApp] zmq message arrived on closed channel
[W 02:54:01.441 NotebookApp] zmq message arrived on closed channel
[W 02:54:01.442 NotebookApp] zmq message arrived on closed channel
[W 02:54:01.442 NotebookApp] zmq message arrived on closed channel
[W 02:54:01.443 NotebookApp] zmq message arrived on closed channel
[W 02:54:01.443 NotebookApp] zmq message arrived on closed channel
[W 02:54:01.448 NotebookApp] zmq message arrived on closed channel
[W 02:54:01.448 NotebookApp] zmq message arrived on closed channel
[W 02:54:01.449 NotebookApp] zmq message arrived on closed channel
[W 02:54:01.449 NotebookApp] zmq message arrived on closed channel
[W 02:54:01.449 NotebookApp] zmq message arrived on closed channel
[I 02:54:06.460 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 02:55:04.815 NotebookApp] zmq message arrived on closed channel
[W 02:55:04.816 NotebookApp] zmq message arrived on closed channel
[W 02:55:04.816 NotebookApp] zmq message arrived on closed channel
[W 02:55:04.816 NotebookApp] zmq message arrived on closed channel
[W 02:55:04.817 NotebookApp] zmq message arrived on closed channel
[W 02:55:04.817 NotebookApp] zmq message arrived on closed channel
[W 02:55:04.817 NotebookApp] zmq message arrived on closed channel
[W 02:55:04.818 NotebookApp] zmq message arrived on closed channel
[W 02:55:04.818 NotebookApp] zmq message arrived on closed channel
[W 02:55:04.818 NotebookApp] zmq message arrived on closed channel
joinedSum: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[40] at map at <console>:25
[W 02:55:05.213 NotebookApp] zmq message arrived on closed channel
[W 02:55:05.213 NotebookApp] zmq message arrived on closed channel
[W 02:55:05.213 NotebookApp] zmq message arrived on closed channel
[W 02:55:05.213 NotebookApp] zmq message arrived on closed channel
[W 02:55:05.213 NotebookApp] zmq message arrived on closed channel
[W 02:55:05.220 NotebookApp] zmq message arrived on closed channel
[W 02:55:05.220 NotebookApp] zmq message arrived on closed channel
[W 02:55:05.220 NotebookApp] zmq message arrived on closed channel
[W 02:55:05.220 NotebookApp] zmq message arrived on closed channel
[W 02:55:05.221 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.548 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.549 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.549 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.549 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.550 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.550 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.551 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.551 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.551 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.552 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.776 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.777 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.777 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.777 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.777 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.988 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.989 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.990 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.990 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.990 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.996 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.996 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.997 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.997 NotebookApp] zmq message arrived on closed channel
[W 02:55:28.997 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.524 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.525 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.526 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.526 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.526 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.527 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.527 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.527 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.528 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.528 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.646 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.646 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.647 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.647 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.647 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.857 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.857 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.858 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.858 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.858 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.964 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.965 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.965 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.965 NotebookApp] zmq message arrived on closed channel
[W 02:55:54.966 NotebookApp] zmq message arrived on closed channel
[W 02:55:55.163 NotebookApp] zmq message arrived on closed channel
[W 02:55:55.164 NotebookApp] zmq message arrived on closed channel
[W 02:55:55.164 NotebookApp] zmq message arrived on closed channel
[W 02:55:55.165 NotebookApp] zmq message arrived on closed channel
[W 02:55:55.165 NotebookApp] zmq message arrived on closed channel
[W 02:55:55.171 NotebookApp] zmq message arrived on closed channel
[W 02:55:55.171 NotebookApp] zmq message arrived on closed channel
[W 02:55:55.172 NotebookApp] zmq message arrived on closed channel
[W 02:55:55.172 NotebookApp] zmq message arrived on closed channel
[W 02:55:55.172 NotebookApp] zmq message arrived on closed channel
[I 02:56:05.833 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 02:57:22.210 NotebookApp] zmq message arrived on closed channel
[W 02:57:22.211 NotebookApp] zmq message arrived on closed channel
[W 02:57:22.212 NotebookApp] zmq message arrived on closed channel
[W 02:57:22.212 NotebookApp] zmq message arrived on closed channel
[W 02:57:22.212 NotebookApp] zmq message arrived on closed channel
[W 02:57:22.213 NotebookApp] zmq message arrived on closed channel
[W 02:57:22.213 NotebookApp] zmq message arrived on closed channel
[W 02:57:22.213 NotebookApp] zmq message arrived on closed channel
[W 02:57:22.213 NotebookApp] zmq message arrived on closed channel
[W 02:57:22.214 NotebookApp] zmq message arrived on closed channel
<console>:18: error: not found: value broadcastVar
val $ires25 = broadcastVar
              ^
<console>:15: error: not found: value broadcastVar
       broadcastVar = sc.broadcast(list(range(1,4)))
       ^
[W 02:57:22.241 NotebookApp] zmq message arrived on closed channel
[W 02:57:22.241 NotebookApp] zmq message arrived on closed channel
[W 02:57:22.242 NotebookApp] zmq message arrived on closed channel
[W 02:57:22.242 NotebookApp] zmq message arrived on closed channel
[W 02:57:22.243 NotebookApp] zmq message arrived on closed channel
[W 02:57:22.243 NotebookApp] zmq message arrived on closed channel
[W 02:57:22.244 NotebookApp] zmq message arrived on closed channel
[W 02:57:22.244 NotebookApp] zmq message arrived on closed channel
[W 02:57:22.244 NotebookApp] zmq message arrived on closed channel
[W 02:57:22.244 NotebookApp] zmq message arrived on closed channel
[W 02:57:51.434 NotebookApp] zmq message arrived on closed channel
[W 02:57:51.435 NotebookApp] zmq message arrived on closed channel
[W 02:57:51.436 NotebookApp] zmq message arrived on closed channel
[W 02:57:51.436 NotebookApp] zmq message arrived on closed channel
[W 02:57:51.436 NotebookApp] zmq message arrived on closed channel
[W 02:57:51.437 NotebookApp] zmq message arrived on closed channel
[W 02:57:51.437 NotebookApp] zmq message arrived on closed channel
[W 02:57:51.437 NotebookApp] zmq message arrived on closed channel
[W 02:57:51.438 NotebookApp] zmq message arrived on closed channel
[W 02:57:51.438 NotebookApp] zmq message arrived on closed channel
<console>:15: error: not found: value list
       val broadcastVar = sc.broadcast(list(range(1,4)))
                                       ^
[W 02:57:51.465 NotebookApp] zmq message arrived on closed channel
[W 02:57:51.465 NotebookApp] zmq message arrived on closed channel
[W 02:57:51.466 NotebookApp] zmq message arrived on closed channel
[W 02:57:51.466 NotebookApp] zmq message arrived on closed channel
[W 02:57:51.467 NotebookApp] zmq message arrived on closed channel
[W 02:57:51.467 NotebookApp] zmq message arrived on closed channel
[W 02:57:51.468 NotebookApp] zmq message arrived on closed channel
[W 02:57:51.468 NotebookApp] zmq message arrived on closed channel
[W 02:57:51.468 NotebookApp] zmq message arrived on closed channel
[W 02:57:51.468 NotebookApp] zmq message arrived on closed channel
[I 02:58:05.287 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 02:58:45.009 NotebookApp] zmq message arrived on closed channel
[W 02:58:45.010 NotebookApp] zmq message arrived on closed channel
[W 02:58:45.010 NotebookApp] zmq message arrived on closed channel
[W 02:58:45.010 NotebookApp] zmq message arrived on closed channel
[W 02:58:45.011 NotebookApp] zmq message arrived on closed channel
[W 02:58:45.011 NotebookApp] zmq message arrived on closed channel
[W 02:58:45.011 NotebookApp] zmq message arrived on closed channel
[W 02:58:45.012 NotebookApp] zmq message arrived on closed channel
[W 02:58:45.012 NotebookApp] zmq message arrived on closed channel
[W 02:58:45.012 NotebookApp] zmq message arrived on closed channel
broadcastVar: org.apache.spark.broadcast.Broadcast[Array[Int]] = Broadcast(52)
[W 02:58:45.227 NotebookApp] zmq message arrived on closed channel
[W 02:58:45.228 NotebookApp] zmq message arrived on closed channel
[W 02:58:45.228 NotebookApp] zmq message arrived on closed channel
[W 02:58:45.228 NotebookApp] zmq message arrived on closed channel
[W 02:58:45.228 NotebookApp] zmq message arrived on closed channel
[I 02:59:04.940 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 02:59:18.702 NotebookApp] zmq message arrived on closed channel
[W 02:59:18.703 NotebookApp] zmq message arrived on closed channel
[W 02:59:18.703 NotebookApp] zmq message arrived on closed channel
[W 02:59:18.703 NotebookApp] zmq message arrived on closed channel
[W 02:59:18.704 NotebookApp] zmq message arrived on closed channel
[W 02:59:18.704 NotebookApp] zmq message arrived on closed channel
[W 02:59:18.704 NotebookApp] zmq message arrived on closed channel
[W 02:59:18.705 NotebookApp] zmq message arrived on closed channel
[W 02:59:18.705 NotebookApp] zmq message arrived on closed channel
[W 02:59:18.705 NotebookApp] zmq message arrived on closed channel
res101: Array[Int] = Array(1, 2, 3)
[W 02:59:18.847 NotebookApp] zmq message arrived on closed channel
[W 02:59:18.847 NotebookApp] zmq message arrived on closed channel
[W 02:59:18.848 NotebookApp] zmq message arrived on closed channel
[W 02:59:18.848 NotebookApp] zmq message arrived on closed channel
[W 02:59:18.848 NotebookApp] zmq message arrived on closed channel
[W 02:59:18.849 NotebookApp] zmq message arrived on closed channel
[W 02:59:18.849 NotebookApp] zmq message arrived on closed channel
[W 02:59:18.849 NotebookApp] zmq message arrived on closed channel
[W 02:59:18.849 NotebookApp] zmq message arrived on closed channel
[W 02:59:18.849 NotebookApp] zmq message arrived on closed channel
[I 03:00:05.291 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 03:00:05.926 NotebookApp] zmq message arrived on closed channel
[W 03:00:05.926 NotebookApp] zmq message arrived on closed channel
[W 03:00:05.927 NotebookApp] zmq message arrived on closed channel
[W 03:00:05.927 NotebookApp] zmq message arrived on closed channel
[W 03:00:05.928 NotebookApp] zmq message arrived on closed channel
[W 03:00:05.928 NotebookApp] zmq message arrived on closed channel
[W 03:00:05.928 NotebookApp] zmq message arrived on closed channel
[W 03:00:05.928 NotebookApp] zmq message arrived on closed channel
[W 03:00:05.929 NotebookApp] zmq message arrived on closed channel
[W 03:00:05.929 NotebookApp] zmq message arrived on closed channel
accum: org.apache.spark.Accumulator[Int] = 0
[W 03:00:06.080 NotebookApp] zmq message arrived on closed channel
[W 03:00:06.080 NotebookApp] zmq message arrived on closed channel
[W 03:00:06.080 NotebookApp] zmq message arrived on closed channel
[W 03:00:06.080 NotebookApp] zmq message arrived on closed channel
[W 03:00:06.081 NotebookApp] zmq message arrived on closed channel
[W 03:00:11.920 NotebookApp] zmq message arrived on closed channel
[W 03:00:11.921 NotebookApp] zmq message arrived on closed channel
[W 03:00:11.921 NotebookApp] zmq message arrived on closed channel
[W 03:00:11.922 NotebookApp] zmq message arrived on closed channel
[W 03:00:11.922 NotebookApp] zmq message arrived on closed channel
[W 03:00:11.922 NotebookApp] zmq message arrived on closed channel
[W 03:00:11.923 NotebookApp] zmq message arrived on closed channel
[W 03:00:11.923 NotebookApp] zmq message arrived on closed channel
[W 03:00:11.924 NotebookApp] zmq message arrived on closed channel
[W 03:00:11.924 NotebookApp] zmq message arrived on closed channel
[W 03:00:12.326 NotebookApp] zmq message arrived on closed channel
[W 03:00:12.327 NotebookApp] zmq message arrived on closed channel
[W 03:00:12.327 NotebookApp] zmq message arrived on closed channel
[W 03:00:12.327 NotebookApp] zmq message arrived on closed channel
[W 03:00:12.328 NotebookApp] zmq message arrived on closed channel
[W 03:00:33.642 NotebookApp] zmq message arrived on closed channel
[W 03:00:33.643 NotebookApp] zmq message arrived on closed channel
[W 03:00:33.643 NotebookApp] zmq message arrived on closed channel
[W 03:00:33.644 NotebookApp] zmq message arrived on closed channel
[W 03:00:33.644 NotebookApp] zmq message arrived on closed channel
[W 03:00:33.644 NotebookApp] zmq message arrived on closed channel
[W 03:00:33.645 NotebookApp] zmq message arrived on closed channel
[W 03:00:33.645 NotebookApp] zmq message arrived on closed channel
[W 03:00:33.645 NotebookApp] zmq message arrived on closed channel
[W 03:00:33.645 NotebookApp] zmq message arrived on closed channel
res103: Int = 10
[W 03:00:33.774 NotebookApp] zmq message arrived on closed channel
[W 03:00:33.774 NotebookApp] zmq message arrived on closed channel
[W 03:00:33.774 NotebookApp] zmq message arrived on closed channel
[W 03:00:33.775 NotebookApp] zmq message arrived on closed channel
[W 03:00:33.776 NotebookApp] zmq message arrived on closed channel
[W 03:00:33.776 NotebookApp] zmq message arrived on closed channel
[W 03:00:33.776 NotebookApp] zmq message arrived on closed channel
[W 03:00:33.776 NotebookApp] zmq message arrived on closed channel
[W 03:00:33.777 NotebookApp] zmq message arrived on closed channel
[W 03:00:33.777 NotebookApp] zmq message arrived on closed channel
[W 03:01:35.129 NotebookApp] zmq message arrived on closed channel
[W 03:01:35.130 NotebookApp] zmq message arrived on closed channel
[W 03:01:35.131 NotebookApp] zmq message arrived on closed channel
[W 03:01:35.131 NotebookApp] zmq message arrived on closed channel
[W 03:01:35.131 NotebookApp] zmq message arrived on closed channel
[W 03:01:35.132 NotebookApp] zmq message arrived on closed channel
[W 03:01:35.132 NotebookApp] zmq message arrived on closed channel
[W 03:01:35.132 NotebookApp] zmq message arrived on closed channel
[W 03:01:35.132 NotebookApp] zmq message arrived on closed channel
[W 03:01:35.133 NotebookApp] zmq message arrived on closed channel
pair: (Char, Char) = (a,b)
[W 03:01:35.255 NotebookApp] zmq message arrived on closed channel
[W 03:01:35.255 NotebookApp] zmq message arrived on closed channel
[W 03:01:35.256 NotebookApp] zmq message arrived on closed channel
[W 03:01:35.256 NotebookApp] zmq message arrived on closed channel
[W 03:01:35.257 NotebookApp] zmq message arrived on closed channel
[I 03:02:05.762 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 03:02:35.284 NotebookApp] zmq message arrived on closed channel
[W 03:02:35.285 NotebookApp] zmq message arrived on closed channel
[W 03:02:35.285 NotebookApp] zmq message arrived on closed channel
[W 03:02:35.286 NotebookApp] zmq message arrived on closed channel
[W 03:02:35.286 NotebookApp] zmq message arrived on closed channel
[W 03:02:35.286 NotebookApp] zmq message arrived on closed channel
[W 03:02:35.287 NotebookApp] zmq message arrived on closed channel
[W 03:02:35.287 NotebookApp] zmq message arrived on closed channel
[W 03:02:35.287 NotebookApp] zmq message arrived on closed channel
[W 03:02:35.288 NotebookApp] zmq message arrived on closed channel
res104: Char = a
[W 03:02:35.410 NotebookApp] zmq message arrived on closed channel
[W 03:02:35.410 NotebookApp] zmq message arrived on closed channel
[W 03:02:35.411 NotebookApp] zmq message arrived on closed channel
[W 03:02:35.411 NotebookApp] zmq message arrived on closed channel
[W 03:02:35.412 NotebookApp] zmq message arrived on closed channel
[W 03:02:35.412 NotebookApp] zmq message arrived on closed channel
[W 03:02:35.412 NotebookApp] zmq message arrived on closed channel
[W 03:02:35.413 NotebookApp] zmq message arrived on closed channel
[W 03:02:35.413 NotebookApp] zmq message arrived on closed channel
[W 03:02:35.413 NotebookApp] zmq message arrived on closed channel
[W 03:02:37.790 NotebookApp] zmq message arrived on closed channel
[W 03:02:37.790 NotebookApp] zmq message arrived on closed channel
[W 03:02:37.791 NotebookApp] zmq message arrived on closed channel
[W 03:02:37.791 NotebookApp] zmq message arrived on closed channel
[W 03:02:37.792 NotebookApp] zmq message arrived on closed channel
[W 03:02:37.792 NotebookApp] zmq message arrived on closed channel
[W 03:02:37.792 NotebookApp] zmq message arrived on closed channel
[W 03:02:37.793 NotebookApp] zmq message arrived on closed channel
[W 03:02:37.793 NotebookApp] zmq message arrived on closed channel
[W 03:02:37.793 NotebookApp] zmq message arrived on closed channel
res105: Char = b
[W 03:02:37.921 NotebookApp] zmq message arrived on closed channel
[W 03:02:37.921 NotebookApp] zmq message arrived on closed channel
[W 03:02:37.921 NotebookApp] zmq message arrived on closed channel
[W 03:02:37.922 NotebookApp] zmq message arrived on closed channel
[W 03:02:37.922 NotebookApp] zmq message arrived on closed channel
[W 03:02:37.923 NotebookApp] zmq message arrived on closed channel
[W 03:02:37.923 NotebookApp] zmq message arrived on closed channel
[W 03:02:37.923 NotebookApp] zmq message arrived on closed channel
[W 03:02:37.924 NotebookApp] zmq message arrived on closed channel
[W 03:02:37.924 NotebookApp] zmq message arrived on closed channel
[W 03:02:46.938 NotebookApp] zmq message arrived on closed channel
[W 03:02:46.939 NotebookApp] zmq message arrived on closed channel
[W 03:02:46.940 NotebookApp] zmq message arrived on closed channel
[W 03:02:46.940 NotebookApp] zmq message arrived on closed channel
[W 03:02:46.940 NotebookApp] zmq message arrived on closed channel
[W 03:02:46.941 NotebookApp] zmq message arrived on closed channel
[W 03:02:46.941 NotebookApp] zmq message arrived on closed channel
[W 03:02:46.941 NotebookApp] zmq message arrived on closed channel
[W 03:02:46.942 NotebookApp] zmq message arrived on closed channel
[W 03:02:46.942 NotebookApp] zmq message arrived on closed channel
res106: Char = a
[W 03:02:47.069 NotebookApp] zmq message arrived on closed channel
[W 03:02:47.069 NotebookApp] zmq message arrived on closed channel
[W 03:02:47.070 NotebookApp] zmq message arrived on closed channel
[W 03:02:47.070 NotebookApp] zmq message arrived on closed channel
[W 03:02:47.071 NotebookApp] zmq message arrived on closed channel
[W 03:02:47.071 NotebookApp] zmq message arrived on closed channel
[W 03:02:47.072 NotebookApp] zmq message arrived on closed channel
[W 03:02:47.072 NotebookApp] zmq message arrived on closed channel
[W 03:02:47.072 NotebookApp] zmq message arrived on closed channel
[W 03:02:47.073 NotebookApp] zmq message arrived on closed channel
[W 03:02:49.954 NotebookApp] zmq message arrived on closed channel
[W 03:02:49.955 NotebookApp] zmq message arrived on closed channel
[W 03:02:49.955 NotebookApp] zmq message arrived on closed channel
[W 03:02:49.955 NotebookApp] zmq message arrived on closed channel
[W 03:02:49.956 NotebookApp] zmq message arrived on closed channel
[W 03:02:49.956 NotebookApp] zmq message arrived on closed channel
[W 03:02:49.956 NotebookApp] zmq message arrived on closed channel
[W 03:02:49.957 NotebookApp] zmq message arrived on closed channel
[W 03:02:49.957 NotebookApp] zmq message arrived on closed channel
[W 03:02:49.957 NotebookApp] zmq message arrived on closed channel
<console>:16: error: value _3 is not a member of (Char, Char)
              pair._3
                   ^
[W 03:02:49.996 NotebookApp] zmq message arrived on closed channel
[W 03:02:49.996 NotebookApp] zmq message arrived on closed channel
[W 03:02:49.996 NotebookApp] zmq message arrived on closed channel
[W 03:02:49.997 NotebookApp] zmq message arrived on closed channel
[W 03:02:49.997 NotebookApp] zmq message arrived on closed channel
[W 03:02:49.998 NotebookApp] zmq message arrived on closed channel
[W 03:02:49.998 NotebookApp] zmq message arrived on closed channel
[W 03:02:49.999 NotebookApp] zmq message arrived on closed channel
[W 03:02:49.999 NotebookApp] zmq message arrived on closed channel
[W 03:02:50.000 NotebookApp] zmq message arrived on closed channel
[W 03:02:52.655 NotebookApp] zmq message arrived on closed channel
[W 03:02:52.656 NotebookApp] zmq message arrived on closed channel
[W 03:02:52.656 NotebookApp] zmq message arrived on closed channel
[W 03:02:52.657 NotebookApp] zmq message arrived on closed channel
[W 03:02:52.657 NotebookApp] zmq message arrived on closed channel
[W 03:02:52.657 NotebookApp] zmq message arrived on closed channel
[W 03:02:52.658 NotebookApp] zmq message arrived on closed channel
[W 03:02:52.658 NotebookApp] zmq message arrived on closed channel
[W 03:02:52.658 NotebookApp] zmq message arrived on closed channel
[W 03:02:52.658 NotebookApp] zmq message arrived on closed channel
res108: Char = b
[W 03:02:52.780 NotebookApp] zmq message arrived on closed channel
[W 03:02:52.781 NotebookApp] zmq message arrived on closed channel
[W 03:02:52.781 NotebookApp] zmq message arrived on closed channel
[W 03:02:52.782 NotebookApp] zmq message arrived on closed channel
[W 03:02:52.782 NotebookApp] zmq message arrived on closed channel
[W 03:02:52.782 NotebookApp] zmq message arrived on closed channel
[W 03:02:52.783 NotebookApp] zmq message arrived on closed channel
[W 03:02:52.783 NotebookApp] zmq message arrived on closed channel
[W 03:02:52.783 NotebookApp] zmq message arrived on closed channel
[W 03:02:52.783 NotebookApp] zmq message arrived on closed channel
[I 03:03:49.008 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[I 03:04:05.945 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 03:42:58.182 NotebookApp] WebSocket ping timeout after 119869 ms.
[W 03:43:04.622 NotebookApp] WebSocket ping timeout after 119959 ms.
[W 03:43:15.793 NotebookApp] WebSocket ping timeout after 119796 ms.
[I 04:29:30.514 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[I 04:33:47.839 NotebookApp] Kernel interrupted: e85064b7-a07a-452b-8f29-ac7f2b8cb557
15/10/22 04:33:47 [INFO] c.i.s.SparkKernel$$anon$1 - Resetting code execution!
15/10/22 04:33:47 [INFO] c.i.s.SparkKernel$$anon$1 - Enter Ctrl-C twice to shutdown!
[I 04:34:20.209 NotebookApp] Kernel interrupted: e85064b7-a07a-452b-8f29-ac7f2b8cb557
15/10/22 04:34:20 [INFO] c.i.s.SparkKernel$$anon$1 - Resetting code execution!
15/10/22 04:34:20 [INFO] c.i.s.SparkKernel$$anon$1 - Enter Ctrl-C twice to shutdown!
[I 04:34:26.076 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[I 04:35:51.827 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[I 04:36:24.131 NotebookApp] Kernel interrupted: 66656a3b-1fea-4dac-b8a8-45cef547f01d
[I 04:36:27.863 NotebookApp] Kernel interrupted: 66656a3b-1fea-4dac-b8a8-45cef547f01d
[I 04:36:31.862 NotebookApp] Request restart_kernel: 66656a3b-1fea-4dac-b8a8-45cef547f01d, <IPython.kernel.ioloop.manager.IOLoopKernelManager object at 0x7fd6317fbdd0>
15/10/22 04:36:32 INFO SparkUI: Stopped Spark web UI at http://172.17.0.22:4049
15/10/22 04:36:32 INFO DAGScheduler: Stopping DAGScheduler
15/10/22 04:36:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/10/22 04:36:32 INFO Utils: path = /tmp/spark-dc939ed3-9bec-4751-8e83-df927a97a500/blockmgr-264e8036-5ed0-4b03-b896-6ff04e27f572, already present as root for deletion.
15/10/22 04:36:32 INFO MemoryStore: MemoryStore cleared
15/10/22 04:36:32 INFO BlockManager: BlockManager stopped
15/10/22 04:36:32 INFO BlockManagerMaster: BlockManagerMaster stopped
15/10/22 04:36:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/10/22 04:36:32 INFO SparkContext: Successfully stopped SparkContext
15/10/22 04:36:32 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/10/22 04:36:32 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/10/22 04:36:32 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
15/10/22 04:36:32 INFO Utils: Shutdown hook called
15/10/22 04:36:32 INFO Utils: Deleting directory /tmp/spark-dc939ed3-9bec-4751-8e83-df927a97a500
[I 04:36:32.933 NotebookApp] Kernel restarted: 66656a3b-1fea-4dac-b8a8-45cef547f01d
[W 04:36:32.937 NotebookApp] zmq message arrived on closed channel
[W 04:36:32.937 NotebookApp] zmq message arrived on closed channel
[W 04:36:32.937 NotebookApp] zmq message arrived on closed channel
[W 04:36:32.938 NotebookApp] zmq message arrived on closed channel
[W 04:36:32.938 NotebookApp] zmq message arrived on closed channel
[W 04:36:32.938 NotebookApp] zmq message arrived on closed channel
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/22 04:36:36 INFO SparkContext: Running Spark version 1.4.1
15/10/22 04:36:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/22 04:36:36 INFO SecurityManager: Changing view acls to: notebook
15/10/22 04:36:36 INFO SecurityManager: Changing modify acls to: notebook
15/10/22 04:36:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
[I 04:36:36.701 NotebookApp] Kernel interrupted: 66656a3b-1fea-4dac-b8a8-45cef547f01d
[I 04:36:37.012 NotebookApp] Kernel interrupted: 66656a3b-1fea-4dac-b8a8-45cef547f01d
15/10/22 04:36:37 INFO Slf4jLogger: Slf4jLogger started
15/10/22 04:36:37 INFO Remoting: Starting remoting
15/10/22 04:36:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.22:57259]
15/10/22 04:36:37 INFO Utils: Successfully started service 'sparkDriver' on port 57259.
15/10/22 04:36:37 INFO SparkEnv: Registering MapOutputTracker
15/10/22 04:36:37 INFO SparkEnv: Registering BlockManagerMaster
15/10/22 04:36:37 INFO DiskBlockManager: Created local directory at /tmp/spark-6ffd920e-2dd5-43d4-a2b8-6b3c3a1ae0c7/blockmgr-f28c1757-42ed-4495-bca7-f4693f2f1846
15/10/22 04:36:38 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
[I 04:36:38.053 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
15/10/22 04:36:38 INFO HttpFileServer: HTTP File server directory is /tmp/spark-6ffd920e-2dd5-43d4-a2b8-6b3c3a1ae0c7/httpd-8bda8744-f6f5-481c-9dd9-065b7bf0f7b9
15/10/22 04:36:38 INFO HttpServer: Starting HTTP Server
15/10/22 04:36:38 INFO Utils: Successfully started service 'HTTP file server' on port 52841.
15/10/22 04:36:38 INFO SparkEnv: Registering OutputCommitCoordinator
15/10/22 04:36:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/10/22 04:36:38 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
15/10/22 04:36:38 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
15/10/22 04:36:38 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
15/10/22 04:36:38 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
15/10/22 04:36:38 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
15/10/22 04:36:38 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.
15/10/22 04:36:38 WARN Utils: Service 'SparkUI' could not bind on port 4047. Attempting port 4048.
15/10/22 04:36:38 WARN Utils: Service 'SparkUI' could not bind on port 4048. Attempting port 4049.
15/10/22 04:36:38 INFO Utils: Successfully started service 'SparkUI' on port 4049.
15/10/22 04:36:38 INFO SparkUI: Started SparkUI at http://172.17.0.22:4049
15/10/22 04:36:38 INFO Executor: Starting executor ID driver on host localhost
15/10/22 04:36:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34923.
15/10/22 04:36:39 INFO NettyBlockTransferService: Server created on 34923
15/10/22 04:36:39 INFO BlockManagerMaster: Trying to register BlockManager
15/10/22 04:36:39 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34923 with 265.4 MB RAM, BlockManagerId(driver, localhost, 34923)
15/10/22 04:36:39 INFO BlockManagerMaster: Registered BlockManager
[W 04:36:39.683 NotebookApp] zmq message arrived on closed channel
[W 04:36:39.684 NotebookApp] zmq message arrived on closed channel
[W 04:36:39.684 NotebookApp] zmq message arrived on closed channel
[W 04:36:39.684 NotebookApp] zmq message arrived on closed channel
[W 04:36:39.685 NotebookApp] zmq message arrived on closed channel
[W 04:36:39.685 NotebookApp] zmq message arrived on closed channel
[W 04:36:39.686 NotebookApp] zmq message arrived on closed channel
[W 04:36:39.687 NotebookApp] zmq message arrived on closed channel
[W 04:36:39.687 NotebookApp] zmq message arrived on closed channel
[W 04:36:39.688 NotebookApp] zmq message arrived on closed channel
[W 04:36:39.688 NotebookApp] zmq message arrived on closed channel
[W 04:36:39.689 NotebookApp] zmq message arrived on closed channel
[W 04:36:39.689 NotebookApp] zmq message arrived on closed channel
[W 04:36:39.690 NotebookApp] zmq message arrived on closed channel
[W 04:36:39.691 NotebookApp] zmq message arrived on closed channel
[W 04:36:39.692 NotebookApp] zmq message arrived on closed channel
[W 04:36:41.288 NotebookApp] zmq message arrived on closed channel
[W 04:36:41.288 NotebookApp] zmq message arrived on closed channel
[W 04:36:41.290 NotebookApp] zmq message arrived on closed channel
[W 04:36:41.290 NotebookApp] zmq message arrived on closed channel
[I 04:36:42.477 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[I 04:36:42.548 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[W 04:36:48.306 NotebookApp] Notebook Spark Fundamentals - Python.ipynb is not trusted
[W 04:36:48.924 NotebookApp] zmq message arrived on closed channel
[W 04:36:48.924 NotebookApp] zmq message arrived on closed channel
[W 04:36:48.926 NotebookApp] zmq message arrived on closed channel
[W 04:36:48.926 NotebookApp] zmq message arrived on closed channel
[W 04:36:54.739 NotebookApp] zmq message arrived on closed channel
[W 04:36:54.740 NotebookApp] zmq message arrived on closed channel
[W 04:36:54.741 NotebookApp] zmq message arrived on closed channel
[W 04:36:54.741 NotebookApp] zmq message arrived on closed channel
15/10/22 04:36:55 INFO MemoryStore: ensureFreeSpace(157248) called with curMem=0, maxMem=278302556
15/10/22 04:36:55 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 153.6 KB, free 265.3 MB)
15/10/22 04:36:55 INFO MemoryStore: ensureFreeSpace(14257) called with curMem=157248, maxMem=278302556
15/10/22 04:36:55 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 13.9 KB, free 265.2 MB)
15/10/22 04:36:55 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34923 (size: 13.9 KB, free: 265.4 MB)
15/10/22 04:36:55 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2
[W 04:36:55.452 NotebookApp] zmq message arrived on closed channel
[W 04:36:55.452 NotebookApp] zmq message arrived on closed channel
[W 04:38:42.801 NotebookApp] zmq message arrived on closed channel
[W 04:38:42.801 NotebookApp] zmq message arrived on closed channel
[W 04:38:42.802 NotebookApp] zmq message arrived on closed channel
[W 04:38:42.803 NotebookApp] zmq message arrived on closed channel
[W 04:38:42.805 NotebookApp] zmq message arrived on closed channel
[W 04:38:42.806 NotebookApp] zmq message arrived on closed channel
[I 04:38:49.017 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[W 04:39:18.351 NotebookApp] zmq message arrived on closed channel
[W 04:39:18.351 NotebookApp] zmq message arrived on closed channel
[W 04:39:18.352 NotebookApp] zmq message arrived on closed channel
[W 04:39:18.352 NotebookApp] zmq message arrived on closed channel
15/10/22 04:39:18 INFO FileInputFormat: Total input paths to process : 1
15/10/22 04:39:18 INFO SparkContext: Starting job: count at <ipython-input-3-56dd8aca435b>:1
15/10/22 04:39:18 INFO DAGScheduler: Got job 0 (count at <ipython-input-3-56dd8aca435b>:1) with 2 output partitions (allowLocal=false)
15/10/22 04:39:18 INFO DAGScheduler: Final stage: ResultStage 0(count at <ipython-input-3-56dd8aca435b>:1)
15/10/22 04:39:18 INFO DAGScheduler: Parents of final stage: List()
15/10/22 04:39:18 INFO DAGScheduler: Missing parents: List()
15/10/22 04:39:18 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at count at <ipython-input-3-56dd8aca435b>:1), which has no missing parents
15/10/22 04:39:18 INFO MemoryStore: ensureFreeSpace(6408) called with curMem=171505, maxMem=278302556
15/10/22 04:39:18 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.3 KB, free 265.2 MB)
15/10/22 04:39:18 INFO MemoryStore: ensureFreeSpace(3808) called with curMem=177913, maxMem=278302556
15/10/22 04:39:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KB, free 265.2 MB)
15/10/22 04:39:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34923 (size: 3.7 KB, free: 265.4 MB)
15/10/22 04:39:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:874
15/10/22 04:39:18 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at count at <ipython-input-3-56dd8aca435b>:1)
15/10/22 04:39:18 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/10/22 04:39:18 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 1410 bytes)
15/10/22 04:39:18 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 1410 bytes)
15/10/22 04:39:18 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/10/22 04:39:18 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/10/22 04:39:22 INFO HadoopRDD: Input split: file:/var/log/supervisor/notebook.log:0+768082
15/10/22 04:39:22 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
15/10/22 04:39:22 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
15/10/22 04:39:22 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
15/10/22 04:39:22 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
15/10/22 04:39:22 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
15/10/22 04:39:22 INFO HadoopRDD: Input split: file:/var/log/supervisor/notebook.log:768082+768082
15/10/22 04:39:22 INFO PythonRDD: Times: total = 3939, boot = 3679, init = 62, finish = 198
15/10/22 04:39:22 INFO PythonRDD: Times: total = 3944, boot = 3734, init = 75, finish = 135
15/10/22 04:39:22 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1871 bytes result sent to driver
15/10/22 04:39:22 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1871 bytes result sent to driver
15/10/22 04:39:22 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 4012 ms on localhost (1/2)
15/10/22 04:39:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4027 ms on localhost (2/2)
15/10/22 04:39:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/10/22 04:39:22 INFO DAGScheduler: ResultStage 0 (count at <ipython-input-3-56dd8aca435b>:1) finished in 4.046 s
15/10/22 04:39:22 INFO DAGScheduler: Job 0 finished: count at <ipython-input-3-56dd8aca435b>:1, took 4.133274 s
[W 04:39:22.698 NotebookApp] zmq message arrived on closed channel
[W 04:39:22.699 NotebookApp] zmq message arrived on closed channel
[W 04:39:22.700 NotebookApp] zmq message arrived on closed channel
[W 04:39:22.700 NotebookApp] zmq message arrived on closed channel
[W 04:39:24.017 NotebookApp] zmq message arrived on closed channel
[W 04:39:24.017 NotebookApp] zmq message arrived on closed channel
[W 04:39:24.018 NotebookApp] zmq message arrived on closed channel
[W 04:39:24.018 NotebookApp] zmq message arrived on closed channel
15/10/22 04:39:24 INFO SparkContext: Starting job: count at <ipython-input-4-0f2b4135c7bb>:1
15/10/22 04:39:24 INFO DAGScheduler: Got job 1 (count at <ipython-input-4-0f2b4135c7bb>:1) with 2 output partitions (allowLocal=false)
15/10/22 04:39:24 INFO DAGScheduler: Final stage: ResultStage 1(count at <ipython-input-4-0f2b4135c7bb>:1)
15/10/22 04:39:24 INFO DAGScheduler: Parents of final stage: List()
15/10/22 04:39:24 INFO DAGScheduler: Missing parents: List()
15/10/22 04:39:24 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[3] at count at <ipython-input-4-0f2b4135c7bb>:1), which has no missing parents
15/10/22 04:39:24 INFO MemoryStore: ensureFreeSpace(6616) called with curMem=181721, maxMem=278302556
15/10/22 04:39:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 6.5 KB, free 265.2 MB)
15/10/22 04:39:24 INFO MemoryStore: ensureFreeSpace(3952) called with curMem=188337, maxMem=278302556
15/10/22 04:39:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.9 KB, free 265.2 MB)
15/10/22 04:39:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34923 (size: 3.9 KB, free: 265.4 MB)
15/10/22 04:39:24 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:874
15/10/22 04:39:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[3] at count at <ipython-input-4-0f2b4135c7bb>:1)
15/10/22 04:39:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/10/22 04:39:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 1410 bytes)
15/10/22 04:39:24 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 1410 bytes)
15/10/22 04:39:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/10/22 04:39:24 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/10/22 04:39:24 INFO HadoopRDD: Input split: file:/var/log/supervisor/notebook.log:0+768082
15/10/22 04:39:24 INFO HadoopRDD: Input split: file:/var/log/supervisor/notebook.log:768082+768082
15/10/22 04:39:24 INFO PythonRDD: Times: total = 33, boot = -1368, init = 1375, finish = 26
15/10/22 04:39:24 INFO PythonRDD: Times: total = 32, boot = -1368, init = 1374, finish = 26
15/10/22 04:39:24 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1870 bytes result sent to driver
15/10/22 04:39:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1870 bytes result sent to driver
15/10/22 04:39:24 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 47 ms on localhost (1/2)
15/10/22 04:39:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 49 ms on localhost (2/2)
15/10/22 04:39:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/10/22 04:39:24 INFO DAGScheduler: ResultStage 1 (count at <ipython-input-4-0f2b4135c7bb>:1) finished in 0.050 s
15/10/22 04:39:24 INFO DAGScheduler: Job 1 finished: count at <ipython-input-4-0f2b4135c7bb>:1, took 0.071446 s
[W 04:39:24.115 NotebookApp] zmq message arrived on closed channel
[W 04:39:24.115 NotebookApp] zmq message arrived on closed channel
[W 04:39:24.117 NotebookApp] zmq message arrived on closed channel
[W 04:39:24.117 NotebookApp] zmq message arrived on closed channel
[W 04:39:46.290 NotebookApp] zmq message arrived on closed channel
[W 04:39:46.291 NotebookApp] zmq message arrived on closed channel
[W 04:39:46.292 NotebookApp] zmq message arrived on closed channel
[W 04:39:46.292 NotebookApp] zmq message arrived on closed channel
15/10/22 04:39:46 INFO SparkContext: Starting job: collect at <ipython-input-5-5847845694c6>:1
15/10/22 04:39:46 INFO DAGScheduler: Got job 2 (collect at <ipython-input-5-5847845694c6>:1) with 2 output partitions (allowLocal=false)
15/10/22 04:39:46 INFO DAGScheduler: Final stage: ResultStage 2(collect at <ipython-input-5-5847845694c6>:1)
15/10/22 04:39:46 INFO DAGScheduler: Parents of final stage: List()
15/10/22 04:39:46 INFO DAGScheduler: Missing parents: List()
15/10/22 04:39:46 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[4] at collect at <ipython-input-5-5847845694c6>:1), which has no missing parents
15/10/22 04:39:46 INFO MemoryStore: ensureFreeSpace(5728) called with curMem=192289, maxMem=278302556
15/10/22 04:39:46 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 5.6 KB, free 265.2 MB)
15/10/22 04:39:46 INFO MemoryStore: ensureFreeSpace(3417) called with curMem=198017, maxMem=278302556
15/10/22 04:39:46 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.3 KB, free 265.2 MB)
15/10/22 04:39:46 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:34923 (size: 3.3 KB, free: 265.4 MB)
15/10/22 04:39:46 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:874
15/10/22 04:39:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 2 (PythonRDD[4] at collect at <ipython-input-5-5847845694c6>:1)
15/10/22 04:39:46 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/10/22 04:39:46 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 1410 bytes)
15/10/22 04:39:46 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 1410 bytes)
15/10/22 04:39:46 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/10/22 04:39:46 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/10/22 04:39:46 INFO HadoopRDD: Input split: file:/var/log/supervisor/notebook.log:768082+768082
15/10/22 04:39:46 INFO HadoopRDD: Input split: file:/var/log/supervisor/notebook.log:0+768082
15/10/22 04:39:46 INFO PythonRDD: Times: total = 31, boot = -22216, init = 22221, finish = 26
15/10/22 04:39:46 INFO PythonRDD: Times: total = 32, boot = -22216, init = 22221, finish = 27
15/10/22 04:39:46 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 4584 bytes result sent to driver
15/10/22 04:39:46 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 15476 bytes result sent to driver
15/10/22 04:39:46 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 46 ms on localhost (1/2)
15/10/22 04:39:46 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 47 ms on localhost (2/2)
15/10/22 04:39:46 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/10/22 04:39:46 INFO DAGScheduler: ResultStage 2 (collect at <ipython-input-5-5847845694c6>:1) finished in 0.048 s
15/10/22 04:39:46 INFO DAGScheduler: Job 2 finished: collect at <ipython-input-5-5847845694c6>:1, took 0.064619 s
[W 04:39:46.381 NotebookApp] zmq message arrived on closed channel
[W 04:39:46.382 NotebookApp] zmq message arrived on closed channel
[W 04:39:46.384 NotebookApp] zmq message arrived on closed channel
[W 04:39:46.384 NotebookApp] zmq message arrived on closed channel
[W 04:40:18.470 NotebookApp] zmq message arrived on closed channel
[W 04:40:18.471 NotebookApp] zmq message arrived on closed channel
[W 04:40:18.471 NotebookApp] zmq message arrived on closed channel
[W 04:40:18.472 NotebookApp] zmq message arrived on closed channel
[W 04:40:18.479 NotebookApp] zmq message arrived on closed channel
[W 04:40:18.479 NotebookApp] zmq message arrived on closed channel
[W 04:40:18.481 NotebookApp] zmq message arrived on closed channel
[W 04:40:18.481 NotebookApp] zmq message arrived on closed channel
[W 04:40:34.980 NotebookApp] zmq message arrived on closed channel
[W 04:40:34.980 NotebookApp] zmq message arrived on closed channel
[W 04:40:34.981 NotebookApp] zmq message arrived on closed channel
[W 04:40:34.981 NotebookApp] zmq message arrived on closed channel
[W 04:40:35.004 NotebookApp] zmq message arrived on closed channel
[W 04:40:35.004 NotebookApp] zmq message arrived on closed channel
[W 04:40:35.006 NotebookApp] zmq message arrived on closed channel
[W 04:40:35.006 NotebookApp] zmq message arrived on closed channel
[W 04:40:42.947 NotebookApp] zmq message arrived on closed channel
[W 04:40:42.947 NotebookApp] zmq message arrived on closed channel
[W 04:40:42.948 NotebookApp] zmq message arrived on closed channel
[W 04:40:42.949 NotebookApp] zmq message arrived on closed channel
[W 04:40:42.950 NotebookApp] zmq message arrived on closed channel
[W 04:40:42.951 NotebookApp] zmq message arrived on closed channel
[W 04:40:42.952 NotebookApp] zmq message arrived on closed channel
[W 04:40:42.953 NotebookApp] zmq message arrived on closed channel
[W 04:40:48.009 NotebookApp] zmq message arrived on closed channel
[W 04:40:48.010 NotebookApp] zmq message arrived on closed channel
[W 04:40:48.011 NotebookApp] zmq message arrived on closed channel
[W 04:40:48.011 NotebookApp] zmq message arrived on closed channel
[W 04:40:48.018 NotebookApp] zmq message arrived on closed channel
[W 04:40:48.018 NotebookApp] zmq message arrived on closed channel
[W 04:40:48.020 NotebookApp] zmq message arrived on closed channel
[W 04:40:48.020 NotebookApp] zmq message arrived on closed channel
[I 04:40:49.082 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[W 04:40:56.547 NotebookApp] zmq message arrived on closed channel
[W 04:40:56.548 NotebookApp] zmq message arrived on closed channel
[W 04:40:56.549 NotebookApp] zmq message arrived on closed channel
[W 04:40:56.549 NotebookApp] zmq message arrived on closed channel
[W 04:40:56.555 NotebookApp] zmq message arrived on closed channel
[W 04:40:56.556 NotebookApp] zmq message arrived on closed channel
[W 04:40:56.557 NotebookApp] zmq message arrived on closed channel
[W 04:40:56.558 NotebookApp] zmq message arrived on closed channel
[I 04:41:13.860 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[I 04:42:48.996 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[W 04:44:26.067 NotebookApp] Notebook Spark Fundamentals - Scala.ipynb is not trusted
[W 04:44:27.189 NotebookApp] zmq message arrived on closed channel
[W 04:44:27.190 NotebookApp] zmq message arrived on closed channel
[W 04:44:27.190 NotebookApp] zmq message arrived on closed channel
[W 04:44:27.191 NotebookApp] zmq message arrived on closed channel
[W 04:44:27.191 NotebookApp] zmq message arrived on closed channel
[W 04:44:27.191 NotebookApp] zmq message arrived on closed channel
[W 04:44:27.191 NotebookApp] zmq message arrived on closed channel
[W 04:44:27.192 NotebookApp] zmq message arrived on closed channel
[W 04:44:27.192 NotebookApp] zmq message arrived on closed channel
[W 04:44:27.193 NotebookApp] zmq message arrived on closed channel
[W 04:44:27.193 NotebookApp] zmq message arrived on closed channel
[W 04:44:27.193 NotebookApp] zmq message arrived on closed channel
[I 04:44:48.905 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[W 04:45:28.351 NotebookApp] zmq message arrived on closed channel
[W 04:45:28.352 NotebookApp] zmq message arrived on closed channel
[W 04:45:28.352 NotebookApp] zmq message arrived on closed channel
[W 04:45:28.353 NotebookApp] zmq message arrived on closed channel
15/10/22 04:45:28 INFO MemoryStore: ensureFreeSpace(88472) called with curMem=201434, maxMem=278302556
15/10/22 04:45:28 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 86.4 KB, free 265.1 MB)
15/10/22 04:45:28 INFO MemoryStore: ensureFreeSpace(19750) called with curMem=289906, maxMem=278302556
15/10/22 04:45:28 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 19.3 KB, free 265.1 MB)
15/10/22 04:45:28 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:34923 (size: 19.3 KB, free: 265.4 MB)
15/10/22 04:45:28 INFO SparkContext: Created broadcast 4 from textFile at NativeMethodAccessorImpl.java:-2
15/10/22 04:45:28 INFO MemoryStore: ensureFreeSpace(230688) called with curMem=309656, maxMem=278302556
15/10/22 04:45:28 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 225.3 KB, free 264.9 MB)
15/10/22 04:45:28 INFO MemoryStore: ensureFreeSpace(19750) called with curMem=540344, maxMem=278302556
15/10/22 04:45:28 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 19.3 KB, free 264.9 MB)
15/10/22 04:45:28 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:34923 (size: 19.3 KB, free: 265.3 MB)
15/10/22 04:45:28 INFO SparkContext: Created broadcast 5 from textFile at NativeMethodAccessorImpl.java:-2
[W 04:45:28.531 NotebookApp] zmq message arrived on closed channel
[W 04:45:28.531 NotebookApp] zmq message arrived on closed channel
[W 04:45:31.497 NotebookApp] zmq message arrived on closed channel
[W 04:45:31.497 NotebookApp] zmq message arrived on closed channel
[W 04:45:31.498 NotebookApp] zmq message arrived on closed channel
[W 04:45:31.498 NotebookApp] zmq message arrived on closed channel
15/10/22 04:45:31 INFO FileInputFormat: Total input paths to process : 1
15/10/22 04:45:31 INFO SparkContext: Starting job: count at <ipython-input-12-d9e293e04b5c>:1
15/10/22 04:45:31 INFO DAGScheduler: Got job 3 (count at <ipython-input-12-d9e293e04b5c>:1) with 2 output partitions (allowLocal=false)
15/10/22 04:45:31 INFO DAGScheduler: Final stage: ResultStage 3(count at <ipython-input-12-d9e293e04b5c>:1)
15/10/22 04:45:31 INFO DAGScheduler: Parents of final stage: List()
15/10/22 04:45:31 INFO DAGScheduler: Missing parents: List()
15/10/22 04:45:31 INFO DAGScheduler: Submitting ResultStage 3 (PythonRDD[10] at count at <ipython-input-12-d9e293e04b5c>:1), which has no missing parents
15/10/22 04:45:31 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=560094, maxMem=278302556
15/10/22 04:45:31 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 6.2 KB, free 264.9 MB)
15/10/22 04:45:31 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=566486, maxMem=278302556
15/10/22 04:45:31 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.9 MB)
15/10/22 04:45:31 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:34923 (size: 3.7 KB, free: 265.3 MB)
15/10/22 04:45:31 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:874
15/10/22 04:45:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (PythonRDD[10] at count at <ipython-input-12-d9e293e04b5c>:1)
15/10/22 04:45:31 INFO TaskSchedulerImpl: Adding task set 3.0 with 2 tasks
15/10/22 04:45:31 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/22 04:45:31 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/22 04:45:31 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
15/10/22 04:45:31 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
15/10/22 04:45:31 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/22 04:45:31 INFO PythonRDD: Times: total = 68, boot = 63, init = 5, finish = 0
15/10/22 04:45:31 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/22 04:45:31 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 1870 bytes result sent to driver
15/10/22 04:45:31 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 139 ms on localhost (1/2)
15/10/22 04:45:31 INFO PythonRDD: Times: total = 130, boot = 125, init = 5, finish = 0
15/10/22 04:45:31 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 1870 bytes result sent to driver
15/10/22 04:45:31 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 146 ms on localhost (2/2)
15/10/22 04:45:31 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
15/10/22 04:45:31 INFO DAGScheduler: ResultStage 3 (count at <ipython-input-12-d9e293e04b5c>:1) finished in 0.147 s
15/10/22 04:45:31 INFO DAGScheduler: Job 3 finished: count at <ipython-input-12-d9e293e04b5c>:1, took 0.162394 s
15/10/22 04:45:31 INFO FileInputFormat: Total input paths to process : 1
15/10/22 04:45:31 INFO SparkContext: Starting job: count at <ipython-input-12-d9e293e04b5c>:2
15/10/22 04:45:31 INFO DAGScheduler: Got job 4 (count at <ipython-input-12-d9e293e04b5c>:2) with 2 output partitions (allowLocal=false)
15/10/22 04:45:31 INFO DAGScheduler: Final stage: ResultStage 4(count at <ipython-input-12-d9e293e04b5c>:2)
15/10/22 04:45:31 INFO DAGScheduler: Parents of final stage: List()
15/10/22 04:45:31 INFO DAGScheduler: Missing parents: List()
15/10/22 04:45:31 INFO DAGScheduler: Submitting ResultStage 4 (PythonRDD[11] at count at <ipython-input-12-d9e293e04b5c>:2), which has no missing parents
15/10/22 04:45:31 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=570293, maxMem=278302556
15/10/22 04:45:31 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 6.2 KB, free 264.9 MB)
15/10/22 04:45:31 INFO MemoryStore: ensureFreeSpace(3803) called with curMem=576685, maxMem=278302556
15/10/22 04:45:31 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.9 MB)
15/10/22 04:45:31 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:34923 (size: 3.7 KB, free: 265.3 MB)
15/10/22 04:45:31 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:874
15/10/22 04:45:31 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (PythonRDD[11] at count at <ipython-input-12-d9e293e04b5c>:2)
15/10/22 04:45:31 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks
15/10/22 04:45:31 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 8, localhost, PROCESS_LOCAL, 1396 bytes)
15/10/22 04:45:31 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 9, localhost, PROCESS_LOCAL, 1396 bytes)
15/10/22 04:45:31 INFO Executor: Running task 0.0 in stage 4.0 (TID 8)
15/10/22 04:45:31 INFO Executor: Running task 1.0 in stage 4.0 (TID 9)
15/10/22 04:45:31 INFO HadoopRDD: Input split: file:/resources/pom.xml:0+7438
15/10/22 04:45:31 INFO HadoopRDD: Input split: file:/resources/pom.xml:7438+7438
15/10/22 04:45:31 INFO PythonRDD: Times: total = 41, boot = -44, init = 84, finish = 1
15/10/22 04:45:31 INFO PythonRDD: Times: total = 40, boot = 20, init = 19, finish = 1
15/10/22 04:45:31 INFO Executor: Finished task 0.0 in stage 4.0 (TID 8). 1870 bytes result sent to driver
15/10/22 04:45:31 INFO Executor: Finished task 1.0 in stage 4.0 (TID 9). 1870 bytes result sent to driver
15/10/22 04:45:31 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 8) in 52 ms on localhost (1/2)
15/10/22 04:45:31 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 9) in 52 ms on localhost (2/2)
15/10/22 04:45:31 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
15/10/22 04:45:31 INFO DAGScheduler: ResultStage 4 (count at <ipython-input-12-d9e293e04b5c>:2) finished in 0.053 s
15/10/22 04:45:31 INFO DAGScheduler: Job 4 finished: count at <ipython-input-12-d9e293e04b5c>:2, took 0.066957 s
[W 04:45:31.776 NotebookApp] zmq message arrived on closed channel
[W 04:45:31.777 NotebookApp] zmq message arrived on closed channel
[W 04:45:31.778 NotebookApp] zmq message arrived on closed channel
[W 04:45:31.778 NotebookApp] zmq message arrived on closed channel
[W 04:45:36.978 NotebookApp] zmq message arrived on closed channel
[W 04:45:36.979 NotebookApp] zmq message arrived on closed channel
[W 04:45:36.980 NotebookApp] zmq message arrived on closed channel
[W 04:45:36.980 NotebookApp] zmq message arrived on closed channel
15/10/22 04:45:36 INFO SparkContext: Starting job: count at <ipython-input-13-0cc46bcb9836>:1
15/10/22 04:45:37 INFO DAGScheduler: Got job 5 (count at <ipython-input-13-0cc46bcb9836>:1) with 2 output partitions (allowLocal=false)
15/10/22 04:45:37 INFO DAGScheduler: Final stage: ResultStage 5(count at <ipython-input-13-0cc46bcb9836>:1)
15/10/22 04:45:37 INFO DAGScheduler: Parents of final stage: List()
15/10/22 04:45:37 INFO DAGScheduler: Missing parents: List()
15/10/22 04:45:37 INFO DAGScheduler: Submitting ResultStage 5 (PythonRDD[12] at count at <ipython-input-13-0cc46bcb9836>:1), which has no missing parents
15/10/22 04:45:37 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=580488, maxMem=278302556
15/10/22 04:45:37 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 6.2 KB, free 264.9 MB)
15/10/22 04:45:37 INFO MemoryStore: ensureFreeSpace(3807) called with curMem=586880, maxMem=278302556
15/10/22 04:45:37 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.8 MB)
15/10/22 04:45:37 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:34923 (size: 3.7 KB, free: 265.3 MB)
15/10/22 04:45:37 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:874
15/10/22 04:45:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 5 (PythonRDD[12] at count at <ipython-input-13-0cc46bcb9836>:1)
15/10/22 04:45:37 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks
15/10/22 04:45:37 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 10, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/22 04:45:37 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 11, localhost, PROCESS_LOCAL, 1398 bytes)
15/10/22 04:45:37 INFO Executor: Running task 0.0 in stage 5.0 (TID 10)
15/10/22 04:45:37 INFO Executor: Running task 1.0 in stage 5.0 (TID 11)
15/10/22 04:45:37 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/22 04:45:37 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/22 04:45:37 INFO PythonRDD: Times: total = 38, boot = -5236, init = 5274, finish = 0
15/10/22 04:45:37 INFO Executor: Finished task 1.0 in stage 5.0 (TID 11). 1870 bytes result sent to driver
15/10/22 04:45:37 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 11) in 49 ms on localhost (1/2)
15/10/22 04:45:37 INFO PythonRDD: Times: total = 41, boot = -5240, init = 5281, finish = 0
15/10/22 04:45:37 INFO Executor: Finished task 0.0 in stage 5.0 (TID 10). 1870 bytes result sent to driver
15/10/22 04:45:37 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 10) in 54 ms on localhost (2/2)
15/10/22 04:45:37 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
15/10/22 04:45:37 INFO DAGScheduler: ResultStage 5 (count at <ipython-input-13-0cc46bcb9836>:1) finished in 0.054 s
15/10/22 04:45:37 INFO DAGScheduler: Job 5 finished: count at <ipython-input-13-0cc46bcb9836>:1, took 0.069696 s
15/10/22 04:45:37 INFO SparkContext: Starting job: count at <ipython-input-13-0cc46bcb9836>:2
15/10/22 04:45:37 INFO DAGScheduler: Got job 6 (count at <ipython-input-13-0cc46bcb9836>:2) with 2 output partitions (allowLocal=false)
15/10/22 04:45:37 INFO DAGScheduler: Final stage: ResultStage 6(count at <ipython-input-13-0cc46bcb9836>:2)
15/10/22 04:45:37 INFO DAGScheduler: Parents of final stage: List()
15/10/22 04:45:37 INFO DAGScheduler: Missing parents: List()
15/10/22 04:45:37 INFO DAGScheduler: Submitting ResultStage 6 (PythonRDD[13] at count at <ipython-input-13-0cc46bcb9836>:2), which has no missing parents
15/10/22 04:45:37 INFO MemoryStore: ensureFreeSpace(6392) called with curMem=590687, maxMem=278302556
15/10/22 04:45:37 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 6.2 KB, free 264.8 MB)
15/10/22 04:45:37 INFO MemoryStore: ensureFreeSpace(3803) called with curMem=597079, maxMem=278302556
15/10/22 04:45:37 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.8 MB)
15/10/22 04:45:37 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:34923 (size: 3.7 KB, free: 265.3 MB)
15/10/22 04:45:37 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:874
15/10/22 04:45:37 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 6 (PythonRDD[13] at count at <ipython-input-13-0cc46bcb9836>:2)
15/10/22 04:45:37 INFO TaskSchedulerImpl: Adding task set 6.0 with 2 tasks
15/10/22 04:45:37 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12, localhost, PROCESS_LOCAL, 1396 bytes)
15/10/22 04:45:37 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 13, localhost, PROCESS_LOCAL, 1396 bytes)
15/10/22 04:45:37 INFO Executor: Running task 0.0 in stage 6.0 (TID 12)
15/10/22 04:45:37 INFO Executor: Running task 1.0 in stage 6.0 (TID 13)
15/10/22 04:45:37 INFO HadoopRDD: Input split: file:/resources/pom.xml:0+7438
15/10/22 04:45:37 INFO HadoopRDD: Input split: file:/resources/pom.xml:7438+7438
15/10/22 04:45:37 INFO PythonRDD: Times: total = 41, boot = -31, init = 72, finish = 0
15/10/22 04:45:37 INFO PythonRDD: Times: total = 42, boot = -28, init = 69, finish = 1
15/10/22 04:45:37 INFO Executor: Finished task 1.0 in stage 6.0 (TID 13). 1870 bytes result sent to driver
15/10/22 04:45:37 INFO Executor: Finished task 0.0 in stage 6.0 (TID 12). 1870 bytes result sent to driver
15/10/22 04:45:37 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 13) in 53 ms on localhost (1/2)
15/10/22 04:45:37 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 54 ms on localhost (2/2)
15/10/22 04:45:37 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
15/10/22 04:45:37 INFO DAGScheduler: ResultStage 6 (count at <ipython-input-13-0cc46bcb9836>:2) finished in 0.055 s
15/10/22 04:45:37 INFO DAGScheduler: Job 6 finished: count at <ipython-input-13-0cc46bcb9836>:2, took 0.069862 s
[W 04:45:37.160 NotebookApp] zmq message arrived on closed channel
[W 04:45:37.161 NotebookApp] zmq message arrived on closed channel
[W 04:45:37.162 NotebookApp] zmq message arrived on closed channel
[W 04:45:37.162 NotebookApp] zmq message arrived on closed channel
[W 04:45:37.163 NotebookApp] zmq message arrived on closed channel
[W 04:45:37.163 NotebookApp] zmq message arrived on closed channel
[W 04:45:45.771 NotebookApp] zmq message arrived on closed channel
[W 04:45:45.771 NotebookApp] zmq message arrived on closed channel
[W 04:45:45.772 NotebookApp] zmq message arrived on closed channel
[W 04:45:45.772 NotebookApp] zmq message arrived on closed channel
[W 04:45:45.834 NotebookApp] zmq message arrived on closed channel
[W 04:45:45.834 NotebookApp] zmq message arrived on closed channel
[W 04:45:55.944 NotebookApp] zmq message arrived on closed channel
[W 04:45:55.945 NotebookApp] zmq message arrived on closed channel
[W 04:45:55.945 NotebookApp] zmq message arrived on closed channel
[W 04:45:55.946 NotebookApp] zmq message arrived on closed channel
15/10/22 04:45:55 INFO SparkContext: Starting job: collect at <ipython-input-15-a70e3dd1f4f6>:1
15/10/22 04:45:55 INFO DAGScheduler: Registering RDD 15 (reduceByKey at <ipython-input-14-67905e6fcecd>:1)
15/10/22 04:45:55 INFO DAGScheduler: Got job 7 (collect at <ipython-input-15-a70e3dd1f4f6>:1) with 2 output partitions (allowLocal=false)
15/10/22 04:45:55 INFO DAGScheduler: Final stage: ResultStage 8(collect at <ipython-input-15-a70e3dd1f4f6>:1)
15/10/22 04:45:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
15/10/22 04:45:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
15/10/22 04:45:55 INFO DAGScheduler: Submitting ShuffleMapStage 7 (PairwiseRDD[15] at reduceByKey at <ipython-input-14-67905e6fcecd>:1), which has no missing parents
15/10/22 04:45:55 INFO MemoryStore: ensureFreeSpace(8568) called with curMem=600882, maxMem=278302556
15/10/22 04:45:55 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 8.4 KB, free 264.8 MB)
15/10/22 04:45:55 INFO MemoryStore: ensureFreeSpace(5271) called with curMem=609450, maxMem=278302556
15/10/22 04:45:55 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.1 KB, free 264.8 MB)
15/10/22 04:45:55 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:34923 (size: 5.1 KB, free: 265.3 MB)
15/10/22 04:45:55 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:874
15/10/22 04:45:56 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 7 (PairwiseRDD[15] at reduceByKey at <ipython-input-14-67905e6fcecd>:1)
15/10/22 04:45:56 INFO TaskSchedulerImpl: Adding task set 7.0 with 2 tasks
15/10/22 04:45:56 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 14, localhost, PROCESS_LOCAL, 1387 bytes)
15/10/22 04:45:56 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 15, localhost, PROCESS_LOCAL, 1387 bytes)
15/10/22 04:45:56 INFO Executor: Running task 0.0 in stage 7.0 (TID 14)
15/10/22 04:45:56 INFO Executor: Running task 1.0 in stage 7.0 (TID 15)
15/10/22 04:45:56 INFO HadoopRDD: Input split: file:/resources/README.md:1784+1784
15/10/22 04:45:56 INFO HadoopRDD: Input split: file:/resources/README.md:0+1784
15/10/22 04:45:56 INFO PythonRDD: Times: total = 42, boot = -18845, init = 18885, finish = 2
15/10/22 04:45:56 INFO PythonRDD: Times: total = 42, boot = -18846, init = 18886, finish = 2
15/10/22 04:45:56 INFO Executor: Finished task 1.0 in stage 7.0 (TID 15). 2064 bytes result sent to driver
15/10/22 04:45:56 INFO Executor: Finished task 0.0 in stage 7.0 (TID 14). 2064 bytes result sent to driver
15/10/22 04:45:56 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 14) in 113 ms on localhost (1/2)
15/10/22 04:45:56 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 15) in 110 ms on localhost (2/2)
15/10/22 04:45:56 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
15/10/22 04:45:56 INFO DAGScheduler: ShuffleMapStage 7 (reduceByKey at <ipython-input-14-67905e6fcecd>:1) finished in 0.115 s
15/10/22 04:45:56 INFO DAGScheduler: looking for newly runnable stages
15/10/22 04:45:56 INFO DAGScheduler: running: Set()
15/10/22 04:45:56 INFO DAGScheduler: waiting: Set(ResultStage 8)
15/10/22 04:45:56 INFO DAGScheduler: failed: Set()
15/10/22 04:45:56 INFO DAGScheduler: Missing parents for ResultStage 8: List()
15/10/22 04:45:56 INFO DAGScheduler: Submitting ResultStage 8 (PythonRDD[22] at collect at <ipython-input-15-a70e3dd1f4f6>:1), which is now runnable
15/10/22 04:45:56 INFO MemoryStore: ensureFreeSpace(5136) called with curMem=614721, maxMem=278302556
15/10/22 04:45:56 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 5.0 KB, free 264.8 MB)
15/10/22 04:45:56 INFO MemoryStore: ensureFreeSpace(3082) called with curMem=619857, maxMem=278302556
15/10/22 04:45:56 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.0 KB, free 264.8 MB)
15/10/22 04:45:56 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:34923 (size: 3.0 KB, free: 265.3 MB)
15/10/22 04:45:56 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:874
15/10/22 04:45:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 8 (PythonRDD[22] at collect at <ipython-input-15-a70e3dd1f4f6>:1)
15/10/22 04:45:56 INFO TaskSchedulerImpl: Adding task set 8.0 with 2 tasks
15/10/22 04:45:56 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 16, localhost, PROCESS_LOCAL, 1165 bytes)
15/10/22 04:45:56 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 17, localhost, PROCESS_LOCAL, 1165 bytes)
15/10/22 04:45:56 INFO Executor: Running task 0.0 in stage 8.0 (TID 16)
15/10/22 04:45:56 INFO Executor: Running task 1.0 in stage 8.0 (TID 17)
15/10/22 04:45:56 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/10/22 04:45:56 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/10/22 04:45:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
15/10/22 04:45:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
15/10/22 04:45:56 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:34923 in memory (size: 5.1 KB, free: 265.3 MB)
15/10/22 04:45:56 INFO BlockManagerInfo: Removed broadcast_9_piece0 on localhost:34923 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/22 04:45:56 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:34923 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/22 04:45:56 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:34923 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/22 04:45:56 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:34923 in memory (size: 3.7 KB, free: 265.3 MB)
15/10/22 04:45:56 INFO PythonRDD: Times: total = 61, boot = -66, init = 126, finish = 1
15/10/22 04:45:56 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:34923 in memory (size: 3.3 KB, free: 265.3 MB)
15/10/22 04:45:56 INFO Executor: Finished task 0.0 in stage 8.0 (TID 16). 3695 bytes result sent to driver
15/10/22 04:45:56 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:34923 in memory (size: 3.9 KB, free: 265.4 MB)
15/10/22 04:45:56 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 16) in 74 ms on localhost (1/2)
15/10/22 04:45:56 INFO PythonRDD: Times: total = 67, boot = -66, init = 132, finish = 1
15/10/22 04:45:56 INFO Executor: Finished task 1.0 in stage 8.0 (TID 17). 3461 bytes result sent to driver
15/10/22 04:45:56 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 17) in 76 ms on localhost (2/2)
15/10/22 04:45:56 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
15/10/22 04:45:56 INFO DAGScheduler: ResultStage 8 (collect at <ipython-input-15-a70e3dd1f4f6>:1) finished in 0.078 s
15/10/22 04:45:56 INFO DAGScheduler: Job 7 finished: collect at <ipython-input-15-a70e3dd1f4f6>:1, took 0.249617 s
15/10/22 04:45:56 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:34923 in memory (size: 3.7 KB, free: 265.4 MB)
15/10/22 04:45:56 INFO SparkContext: Starting job: collect at <ipython-input-15-a70e3dd1f4f6>:2
15/10/22 04:45:56 INFO DAGScheduler: Registering RDD 19 (reduceByKey at <ipython-input-14-67905e6fcecd>:2)
15/10/22 04:45:56 INFO DAGScheduler: Got job 8 (collect at <ipython-input-15-a70e3dd1f4f6>:2) with 2 output partitions (allowLocal=false)
15/10/22 04:45:56 INFO DAGScheduler: Final stage: ResultStage 10(collect at <ipython-input-15-a70e3dd1f4f6>:2)
15/10/22 04:45:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
15/10/22 04:45:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
15/10/22 04:45:56 INFO DAGScheduler: Submitting ShuffleMapStage 9 (PairwiseRDD[19] at reduceByKey at <ipython-input-14-67905e6fcecd>:2), which has no missing parents
15/10/22 04:45:56 INFO MemoryStore: ensureFreeSpace(8568) called with curMem=538383, maxMem=278302556
15/10/22 04:45:56 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.4 KB, free 264.9 MB)
15/10/22 04:45:56 INFO MemoryStore: ensureFreeSpace(5267) called with curMem=546951, maxMem=278302556
15/10/22 04:45:56 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.1 KB, free 264.9 MB)
15/10/22 04:45:56 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:34923 (size: 5.1 KB, free: 265.4 MB)
15/10/22 04:45:56 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:874
15/10/22 04:45:56 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (PairwiseRDD[19] at reduceByKey at <ipython-input-14-67905e6fcecd>:2)
15/10/22 04:45:56 INFO TaskSchedulerImpl: Adding task set 9.0 with 2 tasks
15/10/22 04:45:56 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 18, localhost, PROCESS_LOCAL, 1385 bytes)
15/10/22 04:45:56 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 19, localhost, PROCESS_LOCAL, 1385 bytes)
15/10/22 04:45:56 INFO Executor: Running task 0.0 in stage 9.0 (TID 18)
15/10/22 04:45:56 INFO Executor: Running task 1.0 in stage 9.0 (TID 19)
15/10/22 04:45:56 INFO HadoopRDD: Input split: file:/resources/pom.xml:0+7438
15/10/22 04:45:56 INFO HadoopRDD: Input split: file:/resources/pom.xml:7438+7438
15/10/22 04:45:56 INFO PythonRDD: Times: total = 42, boot = -33, init = 73, finish = 2
15/10/22 04:45:56 INFO PythonRDD: Times: total = 43, boot = -27, init = 67, finish = 3
15/10/22 04:45:56 INFO Executor: Finished task 0.0 in stage 9.0 (TID 18). 2064 bytes result sent to driver
15/10/22 04:45:56 INFO Executor: Finished task 1.0 in stage 9.0 (TID 19). 2064 bytes result sent to driver
15/10/22 04:45:56 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 18) in 60 ms on localhost (1/2)
15/10/22 04:45:56 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 19) in 60 ms on localhost (2/2)
15/10/22 04:45:56 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
15/10/22 04:45:56 INFO DAGScheduler: ShuffleMapStage 9 (reduceByKey at <ipython-input-14-67905e6fcecd>:2) finished in 0.062 s
15/10/22 04:45:56 INFO DAGScheduler: looking for newly runnable stages
15/10/22 04:45:56 INFO DAGScheduler: running: Set()
15/10/22 04:45:56 INFO DAGScheduler: waiting: Set(ResultStage 10)
15/10/22 04:45:56 INFO DAGScheduler: failed: Set()
15/10/22 04:45:56 INFO DAGScheduler: Missing parents for ResultStage 10: List()
15/10/22 04:45:56 INFO DAGScheduler: Submitting ResultStage 10 (PythonRDD[23] at collect at <ipython-input-15-a70e3dd1f4f6>:2), which is now runnable
15/10/22 04:45:56 INFO MemoryStore: ensureFreeSpace(5136) called with curMem=552218, maxMem=278302556
15/10/22 04:45:56 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 5.0 KB, free 264.9 MB)
15/10/22 04:45:56 INFO MemoryStore: ensureFreeSpace(3090) called with curMem=557354, maxMem=278302556
15/10/22 04:45:56 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.0 KB, free 264.9 MB)
15/10/22 04:45:56 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:34923 (size: 3.0 KB, free: 265.3 MB)
15/10/22 04:45:56 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:874
15/10/22 04:45:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 10 (PythonRDD[23] at collect at <ipython-input-15-a70e3dd1f4f6>:2)
15/10/22 04:45:56 INFO TaskSchedulerImpl: Adding task set 10.0 with 2 tasks
15/10/22 04:45:56 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 20, localhost, PROCESS_LOCAL, 1165 bytes)
15/10/22 04:45:56 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 21, localhost, PROCESS_LOCAL, 1165 bytes)
15/10/22 04:45:56 INFO Executor: Running task 1.0 in stage 10.0 (TID 21)
15/10/22 04:45:56 INFO Executor: Running task 0.0 in stage 10.0 (TID 20)
15/10/22 04:45:56 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/10/22 04:45:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/10/22 04:45:56 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/10/22 04:45:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/10/22 04:45:56 INFO PythonRDD: Times: total = 39, boot = -11, init = 50, finish = 0
15/10/22 04:45:56 INFO PythonRDD: Times: total = 41, boot = -10, init = 50, finish = 1
15/10/22 04:45:56 INFO Executor: Finished task 0.0 in stage 10.0 (TID 20). 4975 bytes result sent to driver
15/10/22 04:45:56 INFO Executor: Finished task 1.0 in stage 10.0 (TID 21). 6758 bytes result sent to driver
15/10/22 04:45:56 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 20) in 49 ms on localhost (1/2)
15/10/22 04:45:56 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 21) in 49 ms on localhost (2/2)
15/10/22 04:45:56 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
15/10/22 04:45:56 INFO DAGScheduler: ResultStage 10 (collect at <ipython-input-15-a70e3dd1f4f6>:2) finished in 0.051 s
15/10/22 04:45:56 INFO DAGScheduler: Job 8 finished: collect at <ipython-input-15-a70e3dd1f4f6>:2, took 0.143045 s
[W 04:45:56.396 NotebookApp] zmq message arrived on closed channel
[W 04:45:56.396 NotebookApp] zmq message arrived on closed channel
[W 04:45:56.398 NotebookApp] zmq message arrived on closed channel
[W 04:45:56.398 NotebookApp] zmq message arrived on closed channel
[W 04:46:19.251 NotebookApp] zmq message arrived on closed channel
[W 04:46:19.251 NotebookApp] zmq message arrived on closed channel
[W 04:46:19.252 NotebookApp] zmq message arrived on closed channel
[W 04:46:19.253 NotebookApp] zmq message arrived on closed channel
15/10/22 04:46:19 INFO SparkContext: Starting job: collect at <ipython-input-16-ffb8c091631a>:1
15/10/22 04:46:19 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 152 bytes
15/10/22 04:46:19 INFO DAGScheduler: Got job 9 (collect at <ipython-input-16-ffb8c091631a>:1) with 2 output partitions (allowLocal=false)
15/10/22 04:46:19 INFO DAGScheduler: Final stage: ResultStage 12(collect at <ipython-input-16-ffb8c091631a>:1)
15/10/22 04:46:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
15/10/22 04:46:19 INFO DAGScheduler: Missing parents: List()
15/10/22 04:46:19 INFO DAGScheduler: Submitting ResultStage 12 (PythonRDD[22] at collect at <ipython-input-15-a70e3dd1f4f6>:1), which has no missing parents
15/10/22 04:46:19 INFO MemoryStore: ensureFreeSpace(5136) called with curMem=560444, maxMem=278302556
15/10/22 04:46:19 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 5.0 KB, free 264.9 MB)
15/10/22 04:46:19 INFO MemoryStore: ensureFreeSpace(3082) called with curMem=565580, maxMem=278302556
15/10/22 04:46:19 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.0 KB, free 264.9 MB)
15/10/22 04:46:19 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:34923 (size: 3.0 KB, free: 265.3 MB)
15/10/22 04:46:19 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:874
15/10/22 04:46:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 12 (PythonRDD[22] at collect at <ipython-input-15-a70e3dd1f4f6>:1)
15/10/22 04:46:19 INFO TaskSchedulerImpl: Adding task set 12.0 with 2 tasks
15/10/22 04:46:19 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 22, localhost, PROCESS_LOCAL, 1165 bytes)
15/10/22 04:46:19 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 23, localhost, PROCESS_LOCAL, 1165 bytes)
15/10/22 04:46:19 INFO Executor: Running task 0.0 in stage 12.0 (TID 22)
15/10/22 04:46:19 INFO Executor: Running task 1.0 in stage 12.0 (TID 23)
15/10/22 04:46:19 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/10/22 04:46:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/10/22 04:46:19 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/10/22 04:46:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/10/22 04:46:19 INFO PythonRDD: Times: total = 39, boot = -22904, init = 22942, finish = 1
15/10/22 04:46:19 INFO Executor: Finished task 1.0 in stage 12.0 (TID 23). 3461 bytes result sent to driver
15/10/22 04:46:19 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 23) in 48 ms on localhost (1/2)
15/10/22 04:46:19 INFO PythonRDD: Times: total = 41, boot = -22905, init = 22946, finish = 0
15/10/22 04:46:19 INFO Executor: Finished task 0.0 in stage 12.0 (TID 22). 3695 bytes result sent to driver
15/10/22 04:46:19 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 22) in 52 ms on localhost (2/2)
15/10/22 04:46:19 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
15/10/22 04:46:19 INFO DAGScheduler: ResultStage 12 (collect at <ipython-input-16-ffb8c091631a>:1) finished in 0.053 s
15/10/22 04:46:19 INFO DAGScheduler: Job 9 finished: collect at <ipython-input-16-ffb8c091631a>:1, took 0.075009 s
15/10/22 04:46:19 INFO SparkContext: Starting job: collect at <ipython-input-16-ffb8c091631a>:2
15/10/22 04:46:19 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 154 bytes
15/10/22 04:46:19 INFO DAGScheduler: Got job 10 (collect at <ipython-input-16-ffb8c091631a>:2) with 2 output partitions (allowLocal=false)
15/10/22 04:46:19 INFO DAGScheduler: Final stage: ResultStage 14(collect at <ipython-input-16-ffb8c091631a>:2)
15/10/22 04:46:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
15/10/22 04:46:19 INFO DAGScheduler: Missing parents: List()
15/10/22 04:46:19 INFO DAGScheduler: Submitting ResultStage 14 (PythonRDD[23] at collect at <ipython-input-15-a70e3dd1f4f6>:2), which has no missing parents
15/10/22 04:46:19 INFO MemoryStore: ensureFreeSpace(5136) called with curMem=568662, maxMem=278302556
15/10/22 04:46:19 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 5.0 KB, free 264.9 MB)
15/10/22 04:46:19 INFO MemoryStore: ensureFreeSpace(3090) called with curMem=573798, maxMem=278302556
15/10/22 04:46:19 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.0 KB, free 264.9 MB)
15/10/22 04:46:19 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:34923 (size: 3.0 KB, free: 265.3 MB)
15/10/22 04:46:19 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:874
15/10/22 04:46:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 14 (PythonRDD[23] at collect at <ipython-input-15-a70e3dd1f4f6>:2)
15/10/22 04:46:19 INFO TaskSchedulerImpl: Adding task set 14.0 with 2 tasks
15/10/22 04:46:19 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 24, localhost, PROCESS_LOCAL, 1165 bytes)
15/10/22 04:46:19 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 25, localhost, PROCESS_LOCAL, 1165 bytes)
15/10/22 04:46:19 INFO Executor: Running task 1.0 in stage 14.0 (TID 25)
15/10/22 04:46:19 INFO Executor: Running task 0.0 in stage 14.0 (TID 24)
15/10/22 04:46:19 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/10/22 04:46:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/10/22 04:46:19 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/10/22 04:46:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/10/22 04:46:19 INFO PythonRDD: Times: total = 44, boot = -20, init = 64, finish = 0
15/10/22 04:46:19 INFO PythonRDD: Times: total = 46, boot = -22, init = 67, finish = 1
15/10/22 04:46:19 INFO Executor: Finished task 0.0 in stage 14.0 (TID 24). 4975 bytes result sent to driver
15/10/22 04:46:19 INFO Executor: Finished task 1.0 in stage 14.0 (TID 25). 6758 bytes result sent to driver
15/10/22 04:46:19 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 24) in 54 ms on localhost (1/2)
15/10/22 04:46:19 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 25) in 54 ms on localhost (2/2)
15/10/22 04:46:19 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
15/10/22 04:46:19 INFO DAGScheduler: ResultStage 14 (collect at <ipython-input-16-ffb8c091631a>:2) finished in 0.055 s
15/10/22 04:46:19 INFO DAGScheduler: Job 10 finished: collect at <ipython-input-16-ffb8c091631a>:2, took 0.071690 s
[W 04:46:19.429 NotebookApp] zmq message arrived on closed channel
[W 04:46:19.430 NotebookApp] zmq message arrived on closed channel
[W 04:46:19.432 NotebookApp] zmq message arrived on closed channel
[W 04:46:19.432 NotebookApp] zmq message arrived on closed channel
[W 04:46:19.433 NotebookApp] zmq message arrived on closed channel
[W 04:46:19.433 NotebookApp] zmq message arrived on closed channel
[I 04:46:49.102 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[W 04:46:49.951 NotebookApp] zmq message arrived on closed channel
[W 04:46:49.951 NotebookApp] zmq message arrived on closed channel
[W 04:46:49.952 NotebookApp] zmq message arrived on closed channel
[W 04:46:49.952 NotebookApp] zmq message arrived on closed channel
15/10/22 04:46:49 INFO SparkContext: Starting job: collect at <ipython-input-17-ba9bc58c04b9>:2
15/10/22 04:46:49 INFO DAGScheduler: Got job 11 (collect at <ipython-input-17-ba9bc58c04b9>:2) with 2 output partitions (allowLocal=false)
15/10/22 04:46:49 INFO DAGScheduler: Final stage: ResultStage 16(collect at <ipython-input-17-ba9bc58c04b9>:2)
15/10/22 04:46:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
15/10/22 04:46:49 INFO DAGScheduler: Missing parents: List()
15/10/22 04:46:49 INFO DAGScheduler: Submitting ResultStage 16 (PythonRDD[22] at collect at <ipython-input-15-a70e3dd1f4f6>:1), which has no missing parents
15/10/22 04:46:49 INFO MemoryStore: ensureFreeSpace(5136) called with curMem=576888, maxMem=278302556
15/10/22 04:46:49 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 5.0 KB, free 264.9 MB)
15/10/22 04:46:49 INFO MemoryStore: ensureFreeSpace(3082) called with curMem=582024, maxMem=278302556
15/10/22 04:46:49 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.0 KB, free 264.9 MB)
15/10/22 04:46:49 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:34923 (size: 3.0 KB, free: 265.3 MB)
15/10/22 04:46:49 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:874
15/10/22 04:46:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 16 (PythonRDD[22] at collect at <ipython-input-15-a70e3dd1f4f6>:1)
15/10/22 04:46:49 INFO TaskSchedulerImpl: Adding task set 16.0 with 2 tasks
15/10/22 04:46:49 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 26, localhost, PROCESS_LOCAL, 1165 bytes)
15/10/22 04:46:49 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 27, localhost, PROCESS_LOCAL, 1165 bytes)
15/10/22 04:46:49 INFO Executor: Running task 0.0 in stage 16.0 (TID 26)
15/10/22 04:46:49 INFO Executor: Running task 1.0 in stage 16.0 (TID 27)
15/10/22 04:46:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/10/22 04:46:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/10/22 04:46:49 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/10/22 04:46:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/10/22 04:46:50 INFO PythonRDD: Times: total = 41, boot = -30550, init = 30590, finish = 1
15/10/22 04:46:50 INFO Executor: Finished task 0.0 in stage 16.0 (TID 26). 3695 bytes result sent to driver
15/10/22 04:46:50 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 26) in 49 ms on localhost (1/2)
15/10/22 04:46:50 INFO PythonRDD: Times: total = 45, boot = -30550, init = 30594, finish = 1
15/10/22 04:46:50 INFO Executor: Finished task 1.0 in stage 16.0 (TID 27). 3461 bytes result sent to driver
15/10/22 04:46:50 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 27) in 52 ms on localhost (2/2)
15/10/22 04:46:50 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
15/10/22 04:46:50 INFO DAGScheduler: ResultStage 16 (collect at <ipython-input-17-ba9bc58c04b9>:2) finished in 0.055 s
15/10/22 04:46:50 INFO DAGScheduler: Job 11 finished: collect at <ipython-input-17-ba9bc58c04b9>:2, took 0.070783 s
[W 04:46:50.040 NotebookApp] zmq message arrived on closed channel
[W 04:46:50.041 NotebookApp] zmq message arrived on closed channel
15/10/22 04:46:50 INFO SparkContext: Starting job: collect at <ipython-input-17-ba9bc58c04b9>:5
15/10/22 04:46:50 INFO DAGScheduler: Got job 12 (collect at <ipython-input-17-ba9bc58c04b9>:5) with 2 output partitions (allowLocal=false)
15/10/22 04:46:50 INFO DAGScheduler: Final stage: ResultStage 18(collect at <ipython-input-17-ba9bc58c04b9>:5)
15/10/22 04:46:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
15/10/22 04:46:50 INFO DAGScheduler: Missing parents: List()
15/10/22 04:46:50 INFO DAGScheduler: Submitting ResultStage 18 (PythonRDD[23] at collect at <ipython-input-15-a70e3dd1f4f6>:2), which has no missing parents
15/10/22 04:46:50 INFO MemoryStore: ensureFreeSpace(5136) called with curMem=585106, maxMem=278302556
15/10/22 04:46:50 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 5.0 KB, free 264.8 MB)
15/10/22 04:46:50 INFO MemoryStore: ensureFreeSpace(3090) called with curMem=590242, maxMem=278302556
15/10/22 04:46:50 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.0 KB, free 264.8 MB)
15/10/22 04:46:50 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:34923 (size: 3.0 KB, free: 265.3 MB)
15/10/22 04:46:50 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:874
15/10/22 04:46:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 18 (PythonRDD[23] at collect at <ipython-input-15-a70e3dd1f4f6>:2)
15/10/22 04:46:50 INFO TaskSchedulerImpl: Adding task set 18.0 with 2 tasks
15/10/22 04:46:50 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 28, localhost, PROCESS_LOCAL, 1165 bytes)
15/10/22 04:46:50 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 29, localhost, PROCESS_LOCAL, 1165 bytes)
15/10/22 04:46:50 INFO Executor: Running task 0.0 in stage 18.0 (TID 28)
15/10/22 04:46:50 INFO Executor: Running task 1.0 in stage 18.0 (TID 29)
15/10/22 04:46:50 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/10/22 04:46:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/10/22 04:46:50 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/10/22 04:46:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/10/22 04:46:50 INFO PythonRDD: Times: total = 42, boot = -21, init = 62, finish = 1
15/10/22 04:46:50 INFO PythonRDD: Times: total = 41, boot = -18, init = 58, finish = 1
15/10/22 04:46:50 INFO Executor: Finished task 0.0 in stage 18.0 (TID 28). 4975 bytes result sent to driver
15/10/22 04:46:50 INFO Executor: Finished task 1.0 in stage 18.0 (TID 29). 6758 bytes result sent to driver
15/10/22 04:46:50 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 28) in 50 ms on localhost (1/2)
15/10/22 04:46:50 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 29) in 50 ms on localhost (2/2)
15/10/22 04:46:50 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
15/10/22 04:46:50 INFO DAGScheduler: ResultStage 18 (collect at <ipython-input-17-ba9bc58c04b9>:5) finished in 0.052 s
15/10/22 04:46:50 INFO DAGScheduler: Job 12 finished: collect at <ipython-input-17-ba9bc58c04b9>:5, took 0.066173 s
[W 04:46:50.121 NotebookApp] zmq message arrived on closed channel
[W 04:46:50.121 NotebookApp] zmq message arrived on closed channel
[W 04:46:50.123 NotebookApp] zmq message arrived on closed channel
[W 04:46:50.124 NotebookApp] zmq message arrived on closed channel
[W 04:46:50.125 NotebookApp] zmq message arrived on closed channel
[W 04:46:50.125 NotebookApp] zmq message arrived on closed channel
[W 04:46:58.556 NotebookApp] zmq message arrived on closed channel
[W 04:46:58.557 NotebookApp] zmq message arrived on closed channel
[W 04:46:58.558 NotebookApp] zmq message arrived on closed channel
[W 04:46:58.558 NotebookApp] zmq message arrived on closed channel
[W 04:46:58.599 NotebookApp] zmq message arrived on closed channel
[W 04:46:58.599 NotebookApp] zmq message arrived on closed channel
[W 04:46:58.601 NotebookApp] zmq message arrived on closed channel
[W 04:46:58.601 NotebookApp] zmq message arrived on closed channel
[W 04:47:01.497 NotebookApp] zmq message arrived on closed channel
[W 04:47:01.497 NotebookApp] zmq message arrived on closed channel
[W 04:47:01.498 NotebookApp] zmq message arrived on closed channel
[W 04:47:01.499 NotebookApp] zmq message arrived on closed channel
15/10/22 04:47:01 INFO SparkContext: Starting job: collect at <ipython-input-19-fbbe55dea9b6>:1
15/10/22 04:47:01 INFO DAGScheduler: Got job 13 (collect at <ipython-input-19-fbbe55dea9b6>:1) with 2 output partitions (allowLocal=false)
15/10/22 04:47:01 INFO DAGScheduler: Final stage: ResultStage 21(collect at <ipython-input-19-fbbe55dea9b6>:1)
15/10/22 04:47:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19, ShuffleMapStage 20)
15/10/22 04:47:01 INFO DAGScheduler: Missing parents: List()
15/10/22 04:47:01 INFO DAGScheduler: Submitting ResultStage 21 (PythonRDD[27] at RDD at PythonRDD.scala:43), which has no missing parents
15/10/22 04:47:01 INFO MemoryStore: ensureFreeSpace(12576) called with curMem=593332, maxMem=278302556
15/10/22 04:47:01 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 12.3 KB, free 264.8 MB)
15/10/22 04:47:01 INFO MemoryStore: ensureFreeSpace(5827) called with curMem=605908, maxMem=278302556
15/10/22 04:47:01 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.7 KB, free 264.8 MB)
15/10/22 04:47:01 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:34923 (size: 5.7 KB, free: 265.3 MB)
15/10/22 04:47:01 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:874
15/10/22 04:47:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 21 (PythonRDD[27] at RDD at PythonRDD.scala:43)
15/10/22 04:47:01 INFO TaskSchedulerImpl: Adding task set 21.0 with 2 tasks
15/10/22 04:47:01 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 30, localhost, PROCESS_LOCAL, 1365 bytes)
15/10/22 04:47:01 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 31, localhost, PROCESS_LOCAL, 1365 bytes)
15/10/22 04:47:01 INFO Executor: Running task 0.0 in stage 21.0 (TID 30)
15/10/22 04:47:01 INFO Executor: Running task 1.0 in stage 21.0 (TID 31)
15/10/22 04:47:01 INFO CacheManager: Partition rdd_27_0 not found, computing it
15/10/22 04:47:01 INFO CacheManager: Partition rdd_27_1 not found, computing it
15/10/22 04:47:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/10/22 04:47:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/10/22 04:47:01 INFO PythonRDD: Times: total = 74, boot = 67, init = 4, finish = 3
15/10/22 04:47:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/10/22 04:47:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/10/22 04:47:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/10/22 04:47:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/10/22 04:47:01 INFO PythonRDD: Times: total = 130, boot = 123, init = 4, finish = 3
15/10/22 04:47:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/10/22 04:47:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/10/22 04:47:01 INFO PythonRDD: Times: total = 39, boot = 18, init = 20, finish = 1
15/10/22 04:47:01 INFO PythonRDD: Times: total = 166, boot = -11430, init = 11594, finish = 2
15/10/22 04:47:01 INFO MemoryStore: ensureFreeSpace(246) called with curMem=611735, maxMem=278302556
15/10/22 04:47:01 INFO MemoryStore: Block rdd_27_1 stored as bytes in memory (estimated size 246.0 B, free 264.8 MB)
15/10/22 04:47:01 INFO BlockManagerInfo: Added rdd_27_1 in memory on localhost:34923 (size: 246.0 B, free: 265.3 MB)
15/10/22 04:47:01 INFO Executor: Finished task 1.0 in stage 21.0 (TID 31). 1788 bytes result sent to driver
15/10/22 04:47:01 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 31) in 188 ms on localhost (1/2)
15/10/22 04:47:01 INFO PythonRDD: Times: total = 65, boot = 64, init = 0, finish = 1
15/10/22 04:47:01 INFO PythonRDD: Times: total = 200, boot = -11431, init = 11629, finish = 2
15/10/22 04:47:01 INFO MemoryStore: ensureFreeSpace(395) called with curMem=611981, maxMem=278302556
15/10/22 04:47:01 INFO MemoryStore: Block rdd_27_0 stored as bytes in memory (estimated size 395.0 B, free 264.8 MB)
15/10/22 04:47:01 INFO BlockManagerInfo: Added rdd_27_0 in memory on localhost:34923 (size: 395.0 B, free: 265.3 MB)
15/10/22 04:47:01 INFO Executor: Finished task 0.0 in stage 21.0 (TID 30). 1983 bytes result sent to driver
15/10/22 04:47:01 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 30) in 221 ms on localhost (2/2)
15/10/22 04:47:01 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
15/10/22 04:47:01 INFO DAGScheduler: ResultStage 21 (collect at <ipython-input-19-fbbe55dea9b6>:1) finished in 0.222 s
15/10/22 04:47:01 INFO DAGScheduler: Job 13 finished: collect at <ipython-input-19-fbbe55dea9b6>:1, took 0.250106 s
[W 04:47:01.776 NotebookApp] zmq message arrived on closed channel
[W 04:47:01.776 NotebookApp] zmq message arrived on closed channel
[W 04:47:01.778 NotebookApp] zmq message arrived on closed channel
[W 04:47:01.778 NotebookApp] zmq message arrived on closed channel
[W 04:47:06.224 NotebookApp] zmq message arrived on closed channel
[W 04:47:06.224 NotebookApp] zmq message arrived on closed channel
[W 04:47:06.225 NotebookApp] zmq message arrived on closed channel
[W 04:47:06.225 NotebookApp] zmq message arrived on closed channel
[W 04:47:06.228 NotebookApp] zmq message arrived on closed channel
[W 04:47:06.228 NotebookApp] zmq message arrived on closed channel
[W 04:47:07.779 NotebookApp] zmq message arrived on closed channel
[W 04:47:07.779 NotebookApp] zmq message arrived on closed channel
[W 04:47:07.780 NotebookApp] zmq message arrived on closed channel
[W 04:47:07.780 NotebookApp] zmq message arrived on closed channel
15/10/22 04:47:07 INFO SparkContext: Starting job: runJob at PythonRDD.scala:366
15/10/22 04:47:07 INFO DAGScheduler: Got job 14 (runJob at PythonRDD.scala:366) with 1 output partitions (allowLocal=true)
15/10/22 04:47:07 INFO DAGScheduler: Final stage: ResultStage 24(runJob at PythonRDD.scala:366)
15/10/22 04:47:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22, ShuffleMapStage 23)
15/10/22 04:47:07 INFO DAGScheduler: Missing parents: List()
15/10/22 04:47:07 INFO DAGScheduler: Submitting ResultStage 24 (PythonRDD[28] at RDD at PythonRDD.scala:43), which has no missing parents
15/10/22 04:47:07 INFO MemoryStore: ensureFreeSpace(13352) called with curMem=612376, maxMem=278302556
15/10/22 04:47:07 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 13.0 KB, free 264.8 MB)
15/10/22 04:47:07 INFO MemoryStore: ensureFreeSpace(6117) called with curMem=625728, maxMem=278302556
15/10/22 04:47:07 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 6.0 KB, free 264.8 MB)
15/10/22 04:47:07 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:34923 (size: 6.0 KB, free: 265.3 MB)
15/10/22 04:47:07 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:874
15/10/22 04:47:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (PythonRDD[28] at RDD at PythonRDD.scala:43)
15/10/22 04:47:07 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
15/10/22 04:47:07 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 32, localhost, PROCESS_LOCAL, 1365 bytes)
15/10/22 04:47:07 INFO Executor: Running task 0.0 in stage 24.0 (TID 32)
15/10/22 04:47:07 INFO BlockManager: Found block rdd_27_0 locally
15/10/22 04:47:07 INFO PythonRDD: Times: total = 40, boot = -6083, init = 6123, finish = 0
15/10/22 04:47:07 INFO Executor: Finished task 0.0 in stage 24.0 (TID 32). 1988 bytes result sent to driver
15/10/22 04:47:07 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 32) in 53 ms on localhost (1/1)
15/10/22 04:47:07 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
15/10/22 04:47:07 INFO DAGScheduler: ResultStage 24 (runJob at PythonRDD.scala:366) finished in 0.053 s
15/10/22 04:47:07 INFO DAGScheduler: Job 14 finished: runJob at PythonRDD.scala:366, took 0.076318 s
15/10/22 04:47:07 INFO SparkContext: Starting job: runJob at PythonRDD.scala:366
15/10/22 04:47:07 INFO DAGScheduler: Got job 15 (runJob at PythonRDD.scala:366) with 1 output partitions (allowLocal=true)
15/10/22 04:47:07 INFO DAGScheduler: Final stage: ResultStage 27(runJob at PythonRDD.scala:366)
15/10/22 04:47:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25, ShuffleMapStage 26)
15/10/22 04:47:07 INFO DAGScheduler: Missing parents: List()
15/10/22 04:47:07 INFO DAGScheduler: Submitting ResultStage 27 (PythonRDD[29] at RDD at PythonRDD.scala:43), which has no missing parents
15/10/22 04:47:07 INFO MemoryStore: ensureFreeSpace(13896) called with curMem=631845, maxMem=278302556
15/10/22 04:47:07 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 13.6 KB, free 264.8 MB)
15/10/22 04:47:07 INFO MemoryStore: ensureFreeSpace(6320) called with curMem=645741, maxMem=278302556
15/10/22 04:47:07 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 6.2 KB, free 264.8 MB)
15/10/22 04:47:07 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:34923 (size: 6.2 KB, free: 265.3 MB)
15/10/22 04:47:07 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:874
15/10/22 04:47:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (PythonRDD[29] at RDD at PythonRDD.scala:43)
15/10/22 04:47:07 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
15/10/22 04:47:07 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 33, localhost, PROCESS_LOCAL, 1365 bytes)
15/10/22 04:47:07 INFO Executor: Running task 0.0 in stage 27.0 (TID 33)
15/10/22 04:47:07 INFO BlockManager: Found block rdd_27_0 locally
15/10/22 04:47:07 INFO PythonRDD: Times: total = 39, boot = -6158, init = 6197, finish = 0
15/10/22 04:47:07 INFO Executor: Finished task 0.0 in stage 27.0 (TID 33). 1981 bytes result sent to driver
15/10/22 04:47:07 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 33) in 49 ms on localhost (1/1)
15/10/22 04:47:07 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
15/10/22 04:47:07 INFO DAGScheduler: ResultStage 27 (runJob at PythonRDD.scala:366) finished in 0.051 s
15/10/22 04:47:07 INFO DAGScheduler: Job 15 finished: runJob at PythonRDD.scala:366, took 0.067189 s
[W 04:47:07.953 NotebookApp] zmq message arrived on closed channel
[W 04:47:07.953 NotebookApp] zmq message arrived on closed channel
[W 04:47:07.955 NotebookApp] zmq message arrived on closed channel
[W 04:47:07.955 NotebookApp] zmq message arrived on closed channel
[W 04:47:15.043 NotebookApp] zmq message arrived on closed channel
[W 04:47:15.043 NotebookApp] zmq message arrived on closed channel
[W 04:47:15.044 NotebookApp] zmq message arrived on closed channel
[W 04:47:15.044 NotebookApp] zmq message arrived on closed channel
15/10/22 04:47:15 INFO SparkContext: Starting job: runJob at PythonRDD.scala:366
15/10/22 04:47:15 INFO DAGScheduler: Got job 16 (runJob at PythonRDD.scala:366) with 1 output partitions (allowLocal=true)
15/10/22 04:47:15 INFO DAGScheduler: Final stage: ResultStage 30(runJob at PythonRDD.scala:366)
15/10/22 04:47:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28, ShuffleMapStage 29)
15/10/22 04:47:15 INFO DAGScheduler: Missing parents: List()
15/10/22 04:47:15 INFO DAGScheduler: Submitting ResultStage 30 (PythonRDD[30] at RDD at PythonRDD.scala:43), which has no missing parents
15/10/22 04:47:15 INFO MemoryStore: ensureFreeSpace(13352) called with curMem=652061, maxMem=278302556
15/10/22 04:47:15 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 13.0 KB, free 264.8 MB)
15/10/22 04:47:15 INFO MemoryStore: ensureFreeSpace(6117) called with curMem=665413, maxMem=278302556
15/10/22 04:47:15 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 6.0 KB, free 264.8 MB)
15/10/22 04:47:15 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on localhost:34923 (size: 6.0 KB, free: 265.3 MB)
15/10/22 04:47:15 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:874
15/10/22 04:47:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (PythonRDD[30] at RDD at PythonRDD.scala:43)
15/10/22 04:47:15 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
15/10/22 04:47:15 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 34, localhost, PROCESS_LOCAL, 1365 bytes)
15/10/22 04:47:15 INFO Executor: Running task 0.0 in stage 30.0 (TID 34)
15/10/22 04:47:15 INFO BlockManager: Found block rdd_27_0 locally
15/10/22 04:47:15 INFO PythonRDD: Times: total = 41, boot = -13303, init = 13344, finish = 0
15/10/22 04:47:15 INFO Executor: Finished task 0.0 in stage 30.0 (TID 34). 1988 bytes result sent to driver
15/10/22 04:47:15 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 34) in 51 ms on localhost (1/1)
15/10/22 04:47:15 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
15/10/22 04:47:15 INFO DAGScheduler: ResultStage 30 (runJob at PythonRDD.scala:366) finished in 0.053 s
15/10/22 04:47:15 INFO DAGScheduler: Job 16 finished: runJob at PythonRDD.scala:366, took 0.069432 s
15/10/22 04:47:15 INFO SparkContext: Starting job: runJob at PythonRDD.scala:366
15/10/22 04:47:15 INFO DAGScheduler: Got job 17 (runJob at PythonRDD.scala:366) with 1 output partitions (allowLocal=true)
15/10/22 04:47:15 INFO DAGScheduler: Final stage: ResultStage 33(runJob at PythonRDD.scala:366)
15/10/22 04:47:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31, ShuffleMapStage 32)
15/10/22 04:47:15 INFO DAGScheduler: Missing parents: List()
15/10/22 04:47:15 INFO DAGScheduler: Submitting ResultStage 33 (PythonRDD[31] at RDD at PythonRDD.scala:43), which has no missing parents
15/10/22 04:47:15 INFO MemoryStore: ensureFreeSpace(13896) called with curMem=671530, maxMem=278302556
15/10/22 04:47:15 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 13.6 KB, free 264.8 MB)
15/10/22 04:47:15 INFO MemoryStore: ensureFreeSpace(6320) called with curMem=685426, maxMem=278302556
15/10/22 04:47:15 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 6.2 KB, free 264.8 MB)
15/10/22 04:47:15 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on localhost:34923 (size: 6.2 KB, free: 265.3 MB)
15/10/22 04:47:15 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:874
15/10/22 04:47:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (PythonRDD[31] at RDD at PythonRDD.scala:43)
15/10/22 04:47:15 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
15/10/22 04:47:15 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 35, localhost, PROCESS_LOCAL, 1365 bytes)
15/10/22 04:47:15 INFO Executor: Running task 0.0 in stage 33.0 (TID 35)
15/10/22 04:47:15 INFO BlockManager: Found block rdd_27_0 locally
15/10/22 04:47:15 INFO PythonRDD: Times: total = 40, boot = -13380, init = 13420, finish = 0
15/10/22 04:47:15 INFO Executor: Finished task 0.0 in stage 33.0 (TID 35). 1981 bytes result sent to driver
15/10/22 04:47:15 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 35) in 50 ms on localhost (1/1)
15/10/22 04:47:15 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
15/10/22 04:47:15 INFO DAGScheduler: ResultStage 33 (runJob at PythonRDD.scala:366) finished in 0.051 s
15/10/22 04:47:15 INFO DAGScheduler: Job 17 finished: runJob at PythonRDD.scala:366, took 0.066615 s
[W 04:47:15.208 NotebookApp] zmq message arrived on closed channel
[W 04:47:15.208 NotebookApp] zmq message arrived on closed channel
[W 04:47:15.209 NotebookApp] zmq message arrived on closed channel
[W 04:47:15.210 NotebookApp] zmq message arrived on closed channel
[W 04:47:15.211 NotebookApp] zmq message arrived on closed channel
[W 04:47:15.211 NotebookApp] zmq message arrived on closed channel
[W 04:47:45.837 NotebookApp] zmq message arrived on closed channel
[W 04:47:45.838 NotebookApp] zmq message arrived on closed channel
[W 04:47:45.839 NotebookApp] zmq message arrived on closed channel
[W 04:47:45.839 NotebookApp] zmq message arrived on closed channel
15/10/22 04:47:45 INFO SparkContext: Starting job: runJob at PythonRDD.scala:366
15/10/22 04:47:45 INFO DAGScheduler: Got job 18 (runJob at PythonRDD.scala:366) with 1 output partitions (allowLocal=true)
15/10/22 04:47:45 INFO DAGScheduler: Final stage: ResultStage 36(runJob at PythonRDD.scala:366)
15/10/22 04:47:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34, ShuffleMapStage 35)
15/10/22 04:47:45 INFO DAGScheduler: Missing parents: List()
15/10/22 04:47:45 INFO DAGScheduler: Submitting ResultStage 36 (PythonRDD[32] at RDD at PythonRDD.scala:43), which has no missing parents
15/10/22 04:47:45 INFO MemoryStore: ensureFreeSpace(13352) called with curMem=691746, maxMem=278302556
15/10/22 04:47:45 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 13.0 KB, free 264.7 MB)
15/10/22 04:47:45 INFO MemoryStore: ensureFreeSpace(6117) called with curMem=705098, maxMem=278302556
15/10/22 04:47:45 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 6.0 KB, free 264.7 MB)
15/10/22 04:47:45 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on localhost:34923 (size: 6.0 KB, free: 265.3 MB)
15/10/22 04:47:45 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:874
15/10/22 04:47:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (PythonRDD[32] at RDD at PythonRDD.scala:43)
15/10/22 04:47:45 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
15/10/22 04:47:45 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 36, localhost, PROCESS_LOCAL, 1365 bytes)
15/10/22 04:47:45 INFO Executor: Running task 0.0 in stage 36.0 (TID 36)
15/10/22 04:47:45 INFO BlockManager: Found block rdd_27_0 locally
15/10/22 04:47:45 INFO PythonRDD: Times: total = 68, boot = 65, init = 2, finish = 1
15/10/22 04:47:45 INFO Executor: Finished task 0.0 in stage 36.0 (TID 36). 1988 bytes result sent to driver
15/10/22 04:47:45 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 36) in 78 ms on localhost (1/1)
15/10/22 04:47:45 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
15/10/22 04:47:45 INFO DAGScheduler: ResultStage 36 (runJob at PythonRDD.scala:366) finished in 0.079 s
15/10/22 04:47:45 INFO DAGScheduler: Job 18 finished: runJob at PythonRDD.scala:366, took 0.096708 s
[W 04:47:45.950 NotebookApp] zmq message arrived on closed channel
[W 04:47:45.950 NotebookApp] zmq message arrived on closed channel
15/10/22 04:47:45 INFO SparkContext: Starting job: runJob at PythonRDD.scala:366
15/10/22 04:47:45 INFO DAGScheduler: Got job 19 (runJob at PythonRDD.scala:366) with 1 output partitions (allowLocal=true)
15/10/22 04:47:45 INFO DAGScheduler: Final stage: ResultStage 39(runJob at PythonRDD.scala:366)
15/10/22 04:47:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37, ShuffleMapStage 38)
15/10/22 04:47:45 INFO DAGScheduler: Missing parents: List()
15/10/22 04:47:45 INFO DAGScheduler: Submitting ResultStage 39 (PythonRDD[33] at RDD at PythonRDD.scala:43), which has no missing parents
15/10/22 04:47:45 INFO MemoryStore: ensureFreeSpace(13896) called with curMem=711215, maxMem=278302556
15/10/22 04:47:45 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 13.6 KB, free 264.7 MB)
15/10/22 04:47:45 INFO MemoryStore: ensureFreeSpace(6320) called with curMem=725111, maxMem=278302556
15/10/22 04:47:45 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 6.2 KB, free 264.7 MB)
15/10/22 04:47:45 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on localhost:34923 (size: 6.2 KB, free: 265.3 MB)
15/10/22 04:47:45 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:874
15/10/22 04:47:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (PythonRDD[33] at RDD at PythonRDD.scala:43)
15/10/22 04:47:45 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
15/10/22 04:47:45 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 37, localhost, PROCESS_LOCAL, 1365 bytes)
15/10/22 04:47:45 INFO Executor: Running task 0.0 in stage 39.0 (TID 37)
15/10/22 04:47:46 INFO BlockManager: Found block rdd_27_0 locally
15/10/22 04:47:46 INFO PythonRDD: Times: total = 63, boot = 60, init = 2, finish = 1
15/10/22 04:47:46 INFO Executor: Finished task 0.0 in stage 39.0 (TID 37). 1981 bytes result sent to driver
15/10/22 04:47:46 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 37) in 72 ms on localhost (1/1)
15/10/22 04:47:46 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
15/10/22 04:47:46 INFO DAGScheduler: ResultStage 39 (runJob at PythonRDD.scala:366) finished in 0.073 s
15/10/22 04:47:46 INFO DAGScheduler: Job 19 finished: runJob at PythonRDD.scala:366, took 0.088123 s
[W 04:47:46.049 NotebookApp] zmq message arrived on closed channel
[W 04:47:46.049 NotebookApp] zmq message arrived on closed channel
[W 04:47:46.050 NotebookApp] zmq message arrived on closed channel
[W 04:47:46.050 NotebookApp] zmq message arrived on closed channel
[W 04:47:46.051 NotebookApp] zmq message arrived on closed channel
[W 04:47:46.051 NotebookApp] zmq message arrived on closed channel
[I 04:48:22.566 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[I 04:48:27.092 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[I 04:48:31.399 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[I 04:48:37.221 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[I 04:50:49.495 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[W 04:52:21.112 NotebookApp] zmq message arrived on closed channel
[W 04:52:21.112 NotebookApp] zmq message arrived on closed channel
[W 04:52:21.113 NotebookApp] zmq message arrived on closed channel
[W 04:52:21.113 NotebookApp] zmq message arrived on closed channel
15/10/22 04:52:21 INFO MemoryStore: ensureFreeSpace(288) called with curMem=731431, maxMem=278302556
15/10/22 04:52:21 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 288.0 B, free 264.7 MB)
15/10/22 04:52:21 INFO MemoryStore: ensureFreeSpace(101) called with curMem=731719, maxMem=278302556
15/10/22 04:52:21 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 101.0 B, free 264.7 MB)
15/10/22 04:52:21 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on localhost:34923 (size: 101.0 B, free: 265.3 MB)
15/10/22 04:52:21 INFO SparkContext: Created broadcast 25 from broadcast at PythonRDD.scala:403
[W 04:52:21.130 NotebookApp] zmq message arrived on closed channel
[W 04:52:21.130 NotebookApp] zmq message arrived on closed channel
[W 04:52:22.703 NotebookApp] zmq message arrived on closed channel
[W 04:52:22.703 NotebookApp] zmq message arrived on closed channel
[W 04:52:22.704 NotebookApp] zmq message arrived on closed channel
[W 04:52:22.705 NotebookApp] zmq message arrived on closed channel
[W 04:52:22.705 NotebookApp] zmq message arrived on closed channel
[W 04:52:22.706 NotebookApp] zmq message arrived on closed channel
[W 04:52:22.708 NotebookApp] zmq message arrived on closed channel
[W 04:52:22.708 NotebookApp] zmq message arrived on closed channel
[I 04:52:27.125 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 04:52:31.249 NotebookApp] zmq message arrived on closed channel
[W 04:52:31.250 NotebookApp] zmq message arrived on closed channel
[W 04:52:31.251 NotebookApp] zmq message arrived on closed channel
[W 04:52:31.251 NotebookApp] zmq message arrived on closed channel
[W 04:52:31.253 NotebookApp] zmq message arrived on closed channel
[W 04:52:31.253 NotebookApp] zmq message arrived on closed channel
[W 04:52:33.380 NotebookApp] zmq message arrived on closed channel
[W 04:52:33.381 NotebookApp] zmq message arrived on closed channel
[W 04:52:33.382 NotebookApp] zmq message arrived on closed channel
[W 04:52:33.382 NotebookApp] zmq message arrived on closed channel
[W 04:52:33.392 NotebookApp] zmq message arrived on closed channel
[W 04:52:33.393 NotebookApp] zmq message arrived on closed channel
[W 04:52:34.911 NotebookApp] zmq message arrived on closed channel
[W 04:52:34.911 NotebookApp] zmq message arrived on closed channel
[W 04:52:34.912 NotebookApp] zmq message arrived on closed channel
[W 04:52:34.912 NotebookApp] zmq message arrived on closed channel
15/10/22 04:52:34 INFO SparkContext: Starting job: foreach at <ipython-input-28-0ae69f9e253f>:1
15/10/22 04:52:34 INFO DAGScheduler: Got job 20 (foreach at <ipython-input-28-0ae69f9e253f>:1) with 8 output partitions (allowLocal=false)
15/10/22 04:52:34 INFO DAGScheduler: Final stage: ResultStage 40(foreach at <ipython-input-28-0ae69f9e253f>:1)
15/10/22 04:52:34 INFO DAGScheduler: Parents of final stage: List()
15/10/22 04:52:34 INFO DAGScheduler: Missing parents: List()
15/10/22 04:52:34 INFO DAGScheduler: Submitting ResultStage 40 (PythonRDD[35] at foreach at <ipython-input-28-0ae69f9e253f>:1), which has no missing parents
15/10/22 04:52:34 INFO MemoryStore: ensureFreeSpace(5000) called with curMem=731820, maxMem=278302556
15/10/22 04:52:34 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 4.9 KB, free 264.7 MB)
15/10/22 04:52:34 INFO MemoryStore: ensureFreeSpace(3091) called with curMem=736820, maxMem=278302556
15/10/22 04:52:34 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.0 KB, free 264.7 MB)
15/10/22 04:52:34 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on localhost:34923 (size: 3.0 KB, free: 265.3 MB)
15/10/22 04:52:34 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:874
15/10/22 04:52:34 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 40 (PythonRDD[35] at foreach at <ipython-input-28-0ae69f9e253f>:1)
15/10/22 04:52:34 INFO TaskSchedulerImpl: Adding task set 40.0 with 8 tasks
15/10/22 04:52:34 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 38, localhost, PROCESS_LOCAL, 1355 bytes)
15/10/22 04:52:34 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 39, localhost, PROCESS_LOCAL, 1374 bytes)
15/10/22 04:52:34 INFO TaskSetManager: Starting task 2.0 in stage 40.0 (TID 40, localhost, PROCESS_LOCAL, 1355 bytes)
15/10/22 04:52:34 INFO TaskSetManager: Starting task 3.0 in stage 40.0 (TID 41, localhost, PROCESS_LOCAL, 1374 bytes)
15/10/22 04:52:34 INFO TaskSetManager: Starting task 4.0 in stage 40.0 (TID 42, localhost, PROCESS_LOCAL, 1355 bytes)
15/10/22 04:52:34 INFO TaskSetManager: Starting task 5.0 in stage 40.0 (TID 43, localhost, PROCESS_LOCAL, 1374 bytes)
15/10/22 04:52:34 INFO TaskSetManager: Starting task 6.0 in stage 40.0 (TID 44, localhost, PROCESS_LOCAL, 1355 bytes)
15/10/22 04:52:34 INFO TaskSetManager: Starting task 7.0 in stage 40.0 (TID 45, localhost, PROCESS_LOCAL, 1374 bytes)
15/10/22 04:52:34 INFO Executor: Running task 0.0 in stage 40.0 (TID 38)
15/10/22 04:52:34 INFO Executor: Running task 1.0 in stage 40.0 (TID 39)
15/10/22 04:52:34 INFO Executor: Running task 2.0 in stage 40.0 (TID 40)
15/10/22 04:52:34 INFO Executor: Running task 3.0 in stage 40.0 (TID 41)
15/10/22 04:52:34 INFO Executor: Running task 4.0 in stage 40.0 (TID 42)
15/10/22 04:52:34 INFO Executor: Running task 5.0 in stage 40.0 (TID 43)
15/10/22 04:52:34 INFO Executor: Running task 6.0 in stage 40.0 (TID 44)
15/10/22 04:52:34 INFO Executor: Running task 7.0 in stage 40.0 (TID 45)
15/10/22 04:52:35 INFO PythonRDD: Times: total = 66, boot = 63, init = 2, finish = 1
15/10/22 04:52:35 INFO PythonRDD: Times: total = 125, boot = 122, init = 3, finish = 0
15/10/22 04:52:35 INFO PythonRDD: Times: total = 185, boot = 182, init = 2, finish = 1
15/10/22 04:52:35 INFO PythonRDD: Times: total = 246, boot = 243, init = 3, finish = 0
15/10/22 04:52:35 INFO PythonRDD: Times: total = 306, boot = 303, init = 3, finish = 0
15/10/22 04:52:35 INFO PythonRDD: Times: total = 369, boot = 366, init = 3, finish = 0
15/10/22 04:52:35 INFO PythonRDD: Times: total = 440, boot = 429, init = 11, finish = 0
15/10/22 04:52:35 INFO Executor: Finished task 4.0 in stage 40.0 (TID 42). 731 bytes result sent to driver
15/10/22 04:52:35 INFO Executor: Finished task 3.0 in stage 40.0 (TID 41). 731 bytes result sent to driver
15/10/22 04:52:35 INFO Executor: Finished task 6.0 in stage 40.0 (TID 44). 731 bytes result sent to driver
15/10/22 04:52:35 INFO Executor: Finished task 5.0 in stage 40.0 (TID 43). 731 bytes result sent to driver
15/10/22 04:52:35 INFO Executor: Finished task 7.0 in stage 40.0 (TID 45). 731 bytes result sent to driver
15/10/22 04:52:35 INFO Executor: Finished task 2.0 in stage 40.0 (TID 40). 731 bytes result sent to driver
15/10/22 04:52:35 INFO Executor: Finished task 1.0 in stage 40.0 (TID 39). 731 bytes result sent to driver
15/10/22 04:52:35 INFO TaskSetManager: Finished task 4.0 in stage 40.0 (TID 42) in 500 ms on localhost (1/8)
15/10/22 04:52:35 INFO TaskSetManager: Finished task 3.0 in stage 40.0 (TID 41) in 502 ms on localhost (2/8)
15/10/22 04:52:35 INFO TaskSetManager: Finished task 6.0 in stage 40.0 (TID 44) in 502 ms on localhost (3/8)
15/10/22 04:52:35 INFO TaskSetManager: Finished task 2.0 in stage 40.0 (TID 40) in 504 ms on localhost (4/8)
15/10/22 04:52:35 INFO TaskSetManager: Finished task 5.0 in stage 40.0 (TID 43) in 502 ms on localhost (5/8)
15/10/22 04:52:35 INFO TaskSetManager: Finished task 7.0 in stage 40.0 (TID 45) in 502 ms on localhost (6/8)
15/10/22 04:52:35 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 39) in 506 ms on localhost (7/8)
15/10/22 04:52:35 INFO PythonRDD: Times: total = 526, boot = 488, init = 38, finish = 0
15/10/22 04:52:35 INFO Executor: Finished task 0.0 in stage 40.0 (TID 38). 731 bytes result sent to driver
15/10/22 04:52:35 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 38) in 542 ms on localhost (8/8)
15/10/22 04:52:35 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
15/10/22 04:52:35 INFO DAGScheduler: ResultStage 40 (foreach at <ipython-input-28-0ae69f9e253f>:1) finished in 0.543 s
15/10/22 04:52:35 INFO DAGScheduler: Job 20 finished: foreach at <ipython-input-28-0ae69f9e253f>:1, took 0.555794 s
[W 04:52:35.496 NotebookApp] zmq message arrived on closed channel
[W 04:52:35.496 NotebookApp] zmq message arrived on closed channel
[W 04:52:43.389 NotebookApp] zmq message arrived on closed channel
[W 04:52:43.389 NotebookApp] zmq message arrived on closed channel
[W 04:52:43.390 NotebookApp] zmq message arrived on closed channel
[W 04:52:43.391 NotebookApp] zmq message arrived on closed channel
[W 04:52:43.391 NotebookApp] zmq message arrived on closed channel
[W 04:52:43.392 NotebookApp] zmq message arrived on closed channel
[W 04:52:43.394 NotebookApp] zmq message arrived on closed channel
[W 04:52:43.394 NotebookApp] zmq message arrived on closed channel
[I 04:52:48.959 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[W 04:52:58.327 NotebookApp] zmq message arrived on closed channel
[W 04:52:58.328 NotebookApp] zmq message arrived on closed channel
[W 04:52:58.329 NotebookApp] zmq message arrived on closed channel
[W 04:52:58.329 NotebookApp] zmq message arrived on closed channel
[W 04:52:58.331 NotebookApp] zmq message arrived on closed channel
[W 04:52:58.331 NotebookApp] zmq message arrived on closed channel
[W 04:53:01.587 NotebookApp] zmq message arrived on closed channel
[W 04:53:01.588 NotebookApp] zmq message arrived on closed channel
[W 04:53:01.589 NotebookApp] zmq message arrived on closed channel
[W 04:53:01.589 NotebookApp] zmq message arrived on closed channel
[W 04:53:01.590 NotebookApp] zmq message arrived on closed channel
[W 04:53:01.590 NotebookApp] zmq message arrived on closed channel
[W 04:53:01.592 NotebookApp] zmq message arrived on closed channel
[W 04:53:01.592 NotebookApp] zmq message arrived on closed channel
[W 04:53:07.287 NotebookApp] zmq message arrived on closed channel
[W 04:53:07.287 NotebookApp] zmq message arrived on closed channel
[W 04:53:07.288 NotebookApp] zmq message arrived on closed channel
[W 04:53:07.289 NotebookApp] zmq message arrived on closed channel
[W 04:53:07.289 NotebookApp] zmq message arrived on closed channel
[W 04:53:07.290 NotebookApp] zmq message arrived on closed channel
[W 04:53:07.291 NotebookApp] zmq message arrived on closed channel
[W 04:53:07.291 NotebookApp] zmq message arrived on closed channel
[I 04:53:12.642 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[I 04:56:28.504 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[I 04:58:28.800 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 05:13:41.364 NotebookApp] zmq message arrived on closed channel
[W 05:13:41.365 NotebookApp] zmq message arrived on closed channel
[W 05:13:41.365 NotebookApp] zmq message arrived on closed channel
[W 05:13:41.366 NotebookApp] zmq message arrived on closed channel
[W 05:13:41.366 NotebookApp] zmq message arrived on closed channel
[W 05:13:41.366 NotebookApp] zmq message arrived on closed channel
[W 05:13:41.367 NotebookApp] zmq message arrived on closed channel
[W 05:13:41.367 NotebookApp] zmq message arrived on closed channel
[W 05:13:41.367 NotebookApp] zmq message arrived on closed channel
[W 05:13:41.367 NotebookApp] zmq message arrived on closed channel
[W 05:13:41.368 NotebookApp] zmq message arrived on closed channel
[W 05:13:41.368 NotebookApp] zmq message arrived on closed channel
taxi: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[43] at textFile at <console>:15
<console>:2: error: ';' expected but ',' found.
       To view the five rows of content, invoke the take function. Type in:
                                       ^
[W 05:13:41.585 NotebookApp] zmq message arrived on closed channel
[W 05:13:41.586 NotebookApp] zmq message arrived on closed channel
[W 05:13:41.586 NotebookApp] zmq message arrived on closed channel
[W 05:13:41.587 NotebookApp] zmq message arrived on closed channel
[W 05:13:41.587 NotebookApp] zmq message arrived on closed channel
[W 05:13:41.588 NotebookApp] zmq message arrived on closed channel
[W 05:13:41.588 NotebookApp] zmq message arrived on closed channel
[W 05:13:41.588 NotebookApp] zmq message arrived on closed channel
[W 05:13:41.588 NotebookApp] zmq message arrived on closed channel
[W 05:13:41.589 NotebookApp] zmq message arrived on closed channel
[W 05:13:41.589 NotebookApp] zmq message arrived on closed channel
[W 05:13:41.589 NotebookApp] zmq message arrived on closed channel
[I 05:14:59.107 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
<console>:1: error: ';' expected but '.' found.
       Remember that sc is the existing SparkContext that is created when the shell started.
                                                                                           ^
[W 05:15:34.220 NotebookApp] zmq message arrived on closed channel
[W 05:15:34.220 NotebookApp] zmq message arrived on closed channel
[W 05:15:34.220 NotebookApp] zmq message arrived on closed channel
[W 05:15:34.221 NotebookApp] zmq message arrived on closed channel
[W 05:15:34.221 NotebookApp] zmq message arrived on closed channel
[W 05:15:34.221 NotebookApp] zmq message arrived on closed channel
[W 05:15:34.221 NotebookApp] zmq message arrived on closed channel
[W 05:15:34.222 NotebookApp] zmq message arrived on closed channel
[W 05:15:34.222 NotebookApp] zmq message arrived on closed channel
[W 05:15:34.222 NotebookApp] zmq message arrived on closed channel
[W 05:15:34.223 NotebookApp] zmq message arrived on closed channel
[W 05:15:34.223 NotebookApp] zmq message arrived on closed channel
[W 05:15:34.226 NotebookApp] zmq message arrived on closed channel
[W 05:15:34.226 NotebookApp] zmq message arrived on closed channel
[W 05:15:34.226 NotebookApp] zmq message arrived on closed channel
[W 05:15:34.227 NotebookApp] zmq message arrived on closed channel
[W 05:15:34.227 NotebookApp] zmq message arrived on closed channel
[W 05:15:34.227 NotebookApp] zmq message arrived on closed channel
[W 05:15:34.228 NotebookApp] zmq message arrived on closed channel
[W 05:15:34.228 NotebookApp] zmq message arrived on closed channel
[W 05:15:34.228 NotebookApp] zmq message arrived on closed channel
[W 05:15:34.228 NotebookApp] zmq message arrived on closed channel
[W 05:15:34.229 NotebookApp] zmq message arrived on closed channel
[W 05:15:34.229 NotebookApp] zmq message arrived on closed channel
[I 05:16:59.533 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[I 05:17:03.050 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
<console>:1: error: ';' expected but string literal found.
       !cat "/resources/nycweather.csv"
            ^
[W 05:17:29.997 NotebookApp] zmq message arrived on closed channel
[W 05:17:29.998 NotebookApp] zmq message arrived on closed channel
[W 05:17:29.998 NotebookApp] zmq message arrived on closed channel
[W 05:17:29.998 NotebookApp] zmq message arrived on closed channel
[W 05:17:29.999 NotebookApp] zmq message arrived on closed channel
[W 05:17:29.999 NotebookApp] zmq message arrived on closed channel
[W 05:17:29.999 NotebookApp] zmq message arrived on closed channel
[W 05:17:29.999 NotebookApp] zmq message arrived on closed channel
[W 05:17:30.000 NotebookApp] zmq message arrived on closed channel
[W 05:17:30.000 NotebookApp] zmq message arrived on closed channel
[W 05:17:30.001 NotebookApp] zmq message arrived on closed channel
[W 05:17:30.001 NotebookApp] zmq message arrived on closed channel
[W 05:17:30.002 NotebookApp] zmq message arrived on closed channel
[W 05:17:30.003 NotebookApp] zmq message arrived on closed channel
[W 05:17:30.003 NotebookApp] zmq message arrived on closed channel
[W 05:17:30.003 NotebookApp] zmq message arrived on closed channel
[W 05:17:30.003 NotebookApp] zmq message arrived on closed channel
[W 05:17:30.004 NotebookApp] zmq message arrived on closed channel
[W 05:17:30.005 NotebookApp] zmq message arrived on closed channel
[W 05:17:30.005 NotebookApp] zmq message arrived on closed channel
[W 05:17:30.005 NotebookApp] zmq message arrived on closed channel
[W 05:17:30.006 NotebookApp] zmq message arrived on closed channel
[W 05:17:30.006 NotebookApp] zmq message arrived on closed channel
[W 05:17:30.006 NotebookApp] zmq message arrived on closed channel
[W 05:17:34.910 NotebookApp] zmq message arrived on closed channel
[W 05:17:34.910 NotebookApp] zmq message arrived on closed channel
[W 05:17:34.910 NotebookApp] zmq message arrived on closed channel
[W 05:17:34.911 NotebookApp] zmq message arrived on closed channel
[W 05:17:34.911 NotebookApp] zmq message arrived on closed channel
[W 05:17:34.911 NotebookApp] zmq message arrived on closed channel
[W 05:17:34.911 NotebookApp] zmq message arrived on closed channel
[W 05:17:34.912 NotebookApp] zmq message arrived on closed channel
[W 05:17:34.913 NotebookApp] zmq message arrived on closed channel
[W 05:17:34.913 NotebookApp] zmq message arrived on closed channel
[W 05:17:34.913 NotebookApp] zmq message arrived on closed channel
[W 05:17:34.913 NotebookApp] zmq message arrived on closed channel
<console>:14: error: not found: value cat
              !cat /resources/nycweather.csv
               ^
[W 05:17:34.939 NotebookApp] zmq message arrived on closed channel
[W 05:17:34.940 NotebookApp] zmq message arrived on closed channel
[W 05:17:34.940 NotebookApp] zmq message arrived on closed channel
[W 05:17:34.940 NotebookApp] zmq message arrived on closed channel
[W 05:17:34.940 NotebookApp] zmq message arrived on closed channel
[W 05:17:34.941 NotebookApp] zmq message arrived on closed channel
[W 05:17:34.941 NotebookApp] zmq message arrived on closed channel
[W 05:17:34.941 NotebookApp] zmq message arrived on closed channel
[W 05:17:34.941 NotebookApp] zmq message arrived on closed channel
[W 05:17:34.942 NotebookApp] zmq message arrived on closed channel
[W 05:17:34.942 NotebookApp] zmq message arrived on closed channel
[W 05:17:34.942 NotebookApp] zmq message arrived on closed channel
[W 05:18:22.349 NotebookApp] zmq message arrived on closed channel
[W 05:18:22.349 NotebookApp] zmq message arrived on closed channel
[W 05:18:22.349 NotebookApp] zmq message arrived on closed channel
[W 05:18:22.350 NotebookApp] zmq message arrived on closed channel
[W 05:18:22.350 NotebookApp] zmq message arrived on closed channel
[W 05:18:22.350 NotebookApp] zmq message arrived on closed channel
[W 05:18:22.350 NotebookApp] zmq message arrived on closed channel
[W 05:18:22.351 NotebookApp] zmq message arrived on closed channel
[W 05:18:22.352 NotebookApp] zmq message arrived on closed channel
[W 05:18:22.352 NotebookApp] zmq message arrived on closed channel
[W 05:18:22.352 NotebookApp] zmq message arrived on closed channel
[W 05:18:22.352 NotebookApp] zmq message arrived on closed channel
lines: String = 
""2013-01-01",1,0
"2013-01-02",-2,0
"2013-01-03",-2,0
"2013-01-04",1,0
"2013-01-05",3,0
"2013-01-06",4,0
"2013-01-07",5,0
"2013-01-08",6,0
"2013-01-09",7,0
"2013-01-10",7,0
"2013-01-11",6,13.97
"2013-01-12",7,0.51
"2013-01-13",8,0
"2013-01-14",8,2.29
"2013-01-15",3,3.05
"2013-01-16",2,17.53
"2013-01-17",4,0
"2013-01-18",-1,0
"2013-01-19",5,0
"2013-01-20",6,0
"2013-01-21",-2,0
"2013-01-22",-7,0
"2013-01-23",-9,0
"2013-01-24",-8,0
"2013-01-25",-7,1.78
"2013-01-26",-6,0
"2013-01-27",-3,0
"2013-01-28",1,5.59
"2013-01-29",6,1.52
"2013-01-30",9,1.02
"2013-01-31",8,22.86
"2013-02-01",-2,0
"2013-02-02",-4,0.51
"2013-02-03",-3,0.51
"2013-02-04",-3,0
"2013-02-05",-1,0.51
"2013-02-06",1,0
"2013-02-07",-2,0
"2013-02-08",-1,29.21
"2013-02-09",-3,9.65
"2013-02-10",-3,0
"2013-02-11",4...[W 05:18:22.561 NotebookApp] zmq message arrived on closed channel
[W 05:18:22.562 NotebookApp] zmq message arrived on closed channel
[W 05:18:22.562 NotebookApp] zmq message arrived on closed channel
[W 05:18:22.562 NotebookApp] zmq message arrived on closed channel
[W 05:18:22.563 NotebookApp] zmq message arrived on closed channel
[W 05:18:22.563 NotebookApp] zmq message arrived on closed channel
[W 05:18:27.756 NotebookApp] zmq message arrived on closed channel
[W 05:18:27.757 NotebookApp] zmq message arrived on closed channel
[W 05:18:27.757 NotebookApp] zmq message arrived on closed channel
[W 05:18:27.757 NotebookApp] zmq message arrived on closed channel
[W 05:18:27.758 NotebookApp] zmq message arrived on closed channel
[W 05:18:27.758 NotebookApp] zmq message arrived on closed channel
[W 05:18:27.758 NotebookApp] zmq message arrived on closed channel
[W 05:18:27.759 NotebookApp] zmq message arrived on closed channel
[W 05:18:27.759 NotebookApp] zmq message arrived on closed channel
[W 05:18:27.759 NotebookApp] zmq message arrived on closed channel
[W 05:18:27.760 NotebookApp] zmq message arrived on closed channel
[W 05:18:27.760 NotebookApp] zmq message arrived on closed channel
lines: String = 
""2013-01-01",1,0
"2013-01-02",-2,0
"2013-01-03",-2,0
"2013-01-04",1,0
"2013-01-05",3,0
"2013-01-06",4,0
"2013-01-07",5,0
"2013-01-08",6,0
"2013-01-09",7,0
"2013-01-10",7,0
"2013-01-11",6,13.97
"2013-01-12",7,0.51
"2013-01-13",8,0
"2013-01-14",8,2.29
"2013-01-15",3,3.05
"2013-01-16",2,17.53
"2013-01-17",4,0
"2013-01-18",-1,0
"2013-01-19",5,0
"2013-01-20",6,0
"2013-01-21",-2,0
"2013-01-22",-7,0
"2013-01-23",-9,0
"2013-01-24",-8,0
"2013-01-25",-7,1.78
"2013-01-26",-6,0
"2013-01-27",-3,0
"2013-01-28",1,5.59
"2013-01-29",6,1.52
"2013-01-30",9,1.02
"2013-01-31",8,22.86
"2013-02-01",-2,0
"2013-02-02",-4,0.51
"2013-02-03",-3,0.51
"2013-02-04",-3,0
"2013-02-05",-1,0.51
"2013-02-06",1,0
"2013-02-07",-2,0
"2013-02-08",-1,29.21
"2013-02-09",-3,9.65
"2013-02-10",-3,0
"2013-02-11",4...[W 05:18:28.014 NotebookApp] zmq message arrived on closed channel
[W 05:18:28.014 NotebookApp] zmq message arrived on closed channel
[W 05:18:28.014 NotebookApp] zmq message arrived on closed channel
[W 05:18:28.014 NotebookApp] zmq message arrived on closed channel
[W 05:18:28.015 NotebookApp] zmq message arrived on closed channel
[W 05:18:28.015 NotebookApp] zmq message arrived on closed channel
[W 05:18:28.023 NotebookApp] zmq message arrived on closed channel
[W 05:18:28.024 NotebookApp] zmq message arrived on closed channel
[W 05:18:28.024 NotebookApp] zmq message arrived on closed channel
[W 05:18:28.024 NotebookApp] zmq message arrived on closed channel
[W 05:18:28.024 NotebookApp] zmq message arrived on closed channel
[W 05:18:28.024 NotebookApp] zmq message arrived on closed channel
[W 05:18:43.872 NotebookApp] zmq message arrived on closed channel
[W 05:18:43.872 NotebookApp] zmq message arrived on closed channel
[W 05:18:43.873 NotebookApp] zmq message arrived on closed channel
[W 05:18:43.873 NotebookApp] zmq message arrived on closed channel
[W 05:18:43.873 NotebookApp] zmq message arrived on closed channel
[W 05:18:43.873 NotebookApp] zmq message arrived on closed channel
[W 05:18:43.874 NotebookApp] zmq message arrived on closed channel
[W 05:18:43.874 NotebookApp] zmq message arrived on closed channel
[W 05:18:43.875 NotebookApp] zmq message arrived on closed channel
[W 05:18:43.875 NotebookApp] zmq message arrived on closed channel
[W 05:18:43.875 NotebookApp] zmq message arrived on closed channel
[W 05:18:43.875 NotebookApp] zmq message arrived on closed channel
res112: org.apache.spark.SparkContext = org.apache.spark.SparkContext@176734ca
[W 05:18:43.996 NotebookApp] zmq message arrived on closed channel
[W 05:18:43.996 NotebookApp] zmq message arrived on closed channel
[W 05:18:43.996 NotebookApp] zmq message arrived on closed channel
[W 05:18:43.997 NotebookApp] zmq message arrived on closed channel
[W 05:18:43.997 NotebookApp] zmq message arrived on closed channel
[W 05:18:43.998 NotebookApp] zmq message arrived on closed channel
[W 05:18:43.998 NotebookApp] zmq message arrived on closed channel
[W 05:18:43.998 NotebookApp] zmq message arrived on closed channel
[W 05:18:43.998 NotebookApp] zmq message arrived on closed channel
[W 05:18:43.999 NotebookApp] zmq message arrived on closed channel
[W 05:18:43.999 NotebookApp] zmq message arrived on closed channel
[W 05:18:43.999 NotebookApp] zmq message arrived on closed channel
[W 05:18:45.981 NotebookApp] zmq message arrived on closed channel
[W 05:18:45.981 NotebookApp] zmq message arrived on closed channel
[W 05:18:45.982 NotebookApp] zmq message arrived on closed channel
[W 05:18:45.982 NotebookApp] zmq message arrived on closed channel
[W 05:18:45.982 NotebookApp] zmq message arrived on closed channel
[W 05:18:45.983 NotebookApp] zmq message arrived on closed channel
[W 05:18:45.983 NotebookApp] zmq message arrived on closed channel
[W 05:18:45.983 NotebookApp] zmq message arrived on closed channel
[W 05:18:45.984 NotebookApp] zmq message arrived on closed channel
[W 05:18:45.984 NotebookApp] zmq message arrived on closed channel
[W 05:18:45.984 NotebookApp] zmq message arrived on closed channel
[W 05:18:45.984 NotebookApp] zmq message arrived on closed channel
<console>:14: error: not found: value sqlContext
              sqlContext
              ^
[W 05:18:46.007 NotebookApp] zmq message arrived on closed channel
[W 05:18:46.007 NotebookApp] zmq message arrived on closed channel
[W 05:18:46.007 NotebookApp] zmq message arrived on closed channel
[W 05:18:46.008 NotebookApp] zmq message arrived on closed channel
[W 05:18:46.008 NotebookApp] zmq message arrived on closed channel
[W 05:18:46.009 NotebookApp] zmq message arrived on closed channel
[W 05:18:46.009 NotebookApp] zmq message arrived on closed channel
[W 05:18:46.010 NotebookApp] zmq message arrived on closed channel
[W 05:18:46.010 NotebookApp] zmq message arrived on closed channel
[W 05:18:46.010 NotebookApp] zmq message arrived on closed channel
[W 05:18:46.011 NotebookApp] zmq message arrived on closed channel
[W 05:18:46.011 NotebookApp] zmq message arrived on closed channel
[W 05:18:53.086 NotebookApp] zmq message arrived on closed channel
[W 05:18:53.086 NotebookApp] zmq message arrived on closed channel
[W 05:18:53.087 NotebookApp] zmq message arrived on closed channel
[W 05:18:53.087 NotebookApp] zmq message arrived on closed channel
[W 05:18:53.087 NotebookApp] zmq message arrived on closed channel
[W 05:18:53.087 NotebookApp] zmq message arrived on closed channel
[W 05:18:53.088 NotebookApp] zmq message arrived on closed channel
[W 05:18:53.088 NotebookApp] zmq message arrived on closed channel
[W 05:18:53.088 NotebookApp] zmq message arrived on closed channel
[W 05:18:53.089 NotebookApp] zmq message arrived on closed channel
[W 05:18:53.089 NotebookApp] zmq message arrived on closed channel
[W 05:18:53.089 NotebookApp] zmq message arrived on closed channel
sqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@55d47e95
[W 05:18:53.395 NotebookApp] zmq message arrived on closed channel
[W 05:18:53.396 NotebookApp] zmq message arrived on closed channel
[W 05:18:53.396 NotebookApp] zmq message arrived on closed channel
[W 05:18:53.396 NotebookApp] zmq message arrived on closed channel
[W 05:18:53.396 NotebookApp] zmq message arrived on closed channel
[W 05:18:53.396 NotebookApp] zmq message arrived on closed channel
[W 05:18:54.820 NotebookApp] zmq message arrived on closed channel
[W 05:18:54.820 NotebookApp] zmq message arrived on closed channel
[W 05:18:54.820 NotebookApp] zmq message arrived on closed channel
[W 05:18:54.820 NotebookApp] zmq message arrived on closed channel
[W 05:18:54.821 NotebookApp] zmq message arrived on closed channel
[W 05:18:54.821 NotebookApp] zmq message arrived on closed channel
[W 05:18:54.821 NotebookApp] zmq message arrived on closed channel
[W 05:18:54.822 NotebookApp] zmq message arrived on closed channel
[W 05:18:54.822 NotebookApp] zmq message arrived on closed channel
[W 05:18:54.823 NotebookApp] zmq message arrived on closed channel
[W 05:18:54.823 NotebookApp] zmq message arrived on closed channel
[W 05:18:54.823 NotebookApp] zmq message arrived on closed channel
<console>:17: error: value createSchemaRDD is not a member of org.apache.spark.sql.SQLContext
       import sqlContext.createSchemaRDD
              ^
[W 05:18:54.849 NotebookApp] zmq message arrived on closed channel
[W 05:18:54.850 NotebookApp] zmq message arrived on closed channel
[W 05:18:54.850 NotebookApp] zmq message arrived on closed channel
[W 05:18:54.850 NotebookApp] zmq message arrived on closed channel
[W 05:18:54.851 NotebookApp] zmq message arrived on closed channel
[W 05:18:54.851 NotebookApp] zmq message arrived on closed channel
[W 05:18:54.852 NotebookApp] zmq message arrived on closed channel
[W 05:18:54.852 NotebookApp] zmq message arrived on closed channel
[W 05:18:54.852 NotebookApp] zmq message arrived on closed channel
[W 05:18:54.853 NotebookApp] zmq message arrived on closed channel
[W 05:18:54.853 NotebookApp] zmq message arrived on closed channel
[W 05:18:54.853 NotebookApp] zmq message arrived on closed channel
[I 05:19:00.021 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 05:19:01.729 NotebookApp] zmq message arrived on closed channel
[W 05:19:01.730 NotebookApp] zmq message arrived on closed channel
[W 05:19:01.730 NotebookApp] zmq message arrived on closed channel
[W 05:19:01.730 NotebookApp] zmq message arrived on closed channel
[W 05:19:01.731 NotebookApp] zmq message arrived on closed channel
[W 05:19:01.731 NotebookApp] zmq message arrived on closed channel
[W 05:19:01.731 NotebookApp] zmq message arrived on closed channel
[W 05:19:01.732 NotebookApp] zmq message arrived on closed channel
[W 05:19:01.732 NotebookApp] zmq message arrived on closed channel
[W 05:19:01.732 NotebookApp] zmq message arrived on closed channel
[W 05:19:01.732 NotebookApp] zmq message arrived on closed channel
[W 05:19:01.733 NotebookApp] zmq message arrived on closed channel
defined class Weather
[W 05:19:02.211 NotebookApp] zmq message arrived on closed channel
[W 05:19:02.212 NotebookApp] zmq message arrived on closed channel
[W 05:19:02.212 NotebookApp] zmq message arrived on closed channel
[W 05:19:02.212 NotebookApp] zmq message arrived on closed channel
[W 05:19:02.213 NotebookApp] zmq message arrived on closed channel
[W 05:19:02.213 NotebookApp] zmq message arrived on closed channel
[W 05:19:05.573 NotebookApp] zmq message arrived on closed channel
[W 05:19:05.573 NotebookApp] zmq message arrived on closed channel
[W 05:19:05.573 NotebookApp] zmq message arrived on closed channel
[W 05:19:05.574 NotebookApp] zmq message arrived on closed channel
[W 05:19:05.574 NotebookApp] zmq message arrived on closed channel
[W 05:19:05.574 NotebookApp] zmq message arrived on closed channel
[W 05:19:05.574 NotebookApp] zmq message arrived on closed channel
[W 05:19:05.575 NotebookApp] zmq message arrived on closed channel
[W 05:19:05.575 NotebookApp] zmq message arrived on closed channel
[W 05:19:05.575 NotebookApp] zmq message arrived on closed channel
[W 05:19:05.576 NotebookApp] zmq message arrived on closed channel
[W 05:19:05.576 NotebookApp] zmq message arrived on closed channel
weather: org.apache.spark.rdd.RDD[Weather] = MapPartitionsRDD[47] at map at <console>:17
[W 05:19:05.847 NotebookApp] zmq message arrived on closed channel
[W 05:19:05.847 NotebookApp] zmq message arrived on closed channel
[W 05:19:05.847 NotebookApp] zmq message arrived on closed channel
[W 05:19:05.848 NotebookApp] zmq message arrived on closed channel
[W 05:19:05.848 NotebookApp] zmq message arrived on closed channel
[W 05:19:05.849 NotebookApp] zmq message arrived on closed channel
[W 05:19:08.939 NotebookApp] zmq message arrived on closed channel
[W 05:19:08.939 NotebookApp] zmq message arrived on closed channel
[W 05:19:08.940 NotebookApp] zmq message arrived on closed channel
[W 05:19:08.940 NotebookApp] zmq message arrived on closed channel
[W 05:19:08.940 NotebookApp] zmq message arrived on closed channel
[W 05:19:08.941 NotebookApp] zmq message arrived on closed channel
[W 05:19:08.941 NotebookApp] zmq message arrived on closed channel
[W 05:19:08.941 NotebookApp] zmq message arrived on closed channel
[W 05:19:08.941 NotebookApp] zmq message arrived on closed channel
[W 05:19:08.942 NotebookApp] zmq message arrived on closed channel
[W 05:19:08.942 NotebookApp] zmq message arrived on closed channel
[W 05:19:08.942 NotebookApp] zmq message arrived on closed channel
<console>:20: error: value registerTempTable is not a member of org.apache.spark.rdd.RDD[Weather]
              weather.registerTempTable("weather")
                      ^
[W 05:19:09.003 NotebookApp] zmq message arrived on closed channel
[W 05:19:09.003 NotebookApp] zmq message arrived on closed channel
[W 05:19:09.004 NotebookApp] zmq message arrived on closed channel
[W 05:19:09.004 NotebookApp] zmq message arrived on closed channel
[W 05:19:09.004 NotebookApp] zmq message arrived on closed channel
[W 05:19:09.005 NotebookApp] zmq message arrived on closed channel
[W 05:19:09.005 NotebookApp] zmq message arrived on closed channel
[W 05:19:09.006 NotebookApp] zmq message arrived on closed channel
[W 05:19:09.006 NotebookApp] zmq message arrived on closed channel
[W 05:19:09.006 NotebookApp] zmq message arrived on closed channel
[W 05:19:09.006 NotebookApp] zmq message arrived on closed channel
[W 05:19:09.007 NotebookApp] zmq message arrived on closed channel
[W 05:19:23.380 NotebookApp] zmq message arrived on closed channel
[W 05:19:23.381 NotebookApp] zmq message arrived on closed channel
[W 05:19:23.381 NotebookApp] zmq message arrived on closed channel
[W 05:19:23.381 NotebookApp] zmq message arrived on closed channel
[W 05:19:23.382 NotebookApp] zmq message arrived on closed channel
[W 05:19:23.382 NotebookApp] zmq message arrived on closed channel
[W 05:19:23.382 NotebookApp] zmq message arrived on closed channel
[W 05:19:23.382 NotebookApp] zmq message arrived on closed channel
[W 05:19:23.382 NotebookApp] zmq message arrived on closed channel
[W 05:19:23.383 NotebookApp] zmq message arrived on closed channel
[W 05:19:23.384 NotebookApp] zmq message arrived on closed channel
[W 05:19:23.384 NotebookApp] zmq message arrived on closed channel
<console>:17: error: value createSchemaRDD is not a member of org.apache.spark.sql.SQLContext
       import sqlContext.createSchemaRDD
              ^
[W 05:19:23.413 NotebookApp] zmq message arrived on closed channel
[W 05:19:23.413 NotebookApp] zmq message arrived on closed channel
[W 05:19:23.413 NotebookApp] zmq message arrived on closed channel
[W 05:19:23.413 NotebookApp] zmq message arrived on closed channel
[W 05:19:23.414 NotebookApp] zmq message arrived on closed channel
[W 05:19:23.415 NotebookApp] zmq message arrived on closed channel
[W 05:19:23.415 NotebookApp] zmq message arrived on closed channel
[W 05:19:23.416 NotebookApp] zmq message arrived on closed channel
[W 05:19:23.416 NotebookApp] zmq message arrived on closed channel
[W 05:19:23.416 NotebookApp] zmq message arrived on closed channel
[W 05:19:23.416 NotebookApp] zmq message arrived on closed channel
[W 05:19:23.416 NotebookApp] zmq message arrived on closed channel
[W 05:19:59.894 NotebookApp] zmq message arrived on closed channel
[W 05:19:59.894 NotebookApp] zmq message arrived on closed channel
[W 05:19:59.894 NotebookApp] zmq message arrived on closed channel
[W 05:19:59.895 NotebookApp] zmq message arrived on closed channel
[W 05:19:59.895 NotebookApp] zmq message arrived on closed channel
[W 05:19:59.895 NotebookApp] zmq message arrived on closed channel
[W 05:19:59.896 NotebookApp] zmq message arrived on closed channel
[W 05:19:59.896 NotebookApp] zmq message arrived on closed channel
[W 05:19:59.897 NotebookApp] zmq message arrived on closed channel
[W 05:19:59.897 NotebookApp] zmq message arrived on closed channel
[W 05:19:59.897 NotebookApp] zmq message arrived on closed channel
[W 05:19:59.897 NotebookApp] zmq message arrived on closed channel
import sqlContext._
[W 05:20:00.018 NotebookApp] zmq message arrived on closed channel
[W 05:20:00.018 NotebookApp] zmq message arrived on closed channel
[W 05:20:00.018 NotebookApp] zmq message arrived on closed channel
[W 05:20:00.019 NotebookApp] zmq message arrived on closed channel
[W 05:20:00.019 NotebookApp] zmq message arrived on closed channel
[W 05:20:00.019 NotebookApp] zmq message arrived on closed channel
[W 05:20:03.452 NotebookApp] zmq message arrived on closed channel
[W 05:20:03.452 NotebookApp] zmq message arrived on closed channel
[W 05:20:03.452 NotebookApp] zmq message arrived on closed channel
[W 05:20:03.452 NotebookApp] zmq message arrived on closed channel
[W 05:20:03.453 NotebookApp] zmq message arrived on closed channel
[W 05:20:03.453 NotebookApp] zmq message arrived on closed channel
[W 05:20:03.454 NotebookApp] zmq message arrived on closed channel
[W 05:20:03.454 NotebookApp] zmq message arrived on closed channel
[W 05:20:03.454 NotebookApp] zmq message arrived on closed channel
[W 05:20:03.454 NotebookApp] zmq message arrived on closed channel
[W 05:20:03.455 NotebookApp] zmq message arrived on closed channel
[W 05:20:03.455 NotebookApp] zmq message arrived on closed channel
<console>:25: error: value registerTempTable is not a member of org.apache.spark.rdd.RDD[Weather]
              weather.registerTempTable("weather")
                      ^
[W 05:20:03.964 NotebookApp] zmq message arrived on closed channel
[W 05:20:03.964 NotebookApp] zmq message arrived on closed channel
[W 05:20:03.964 NotebookApp] zmq message arrived on closed channel
[W 05:20:03.965 NotebookApp] zmq message arrived on closed channel
[W 05:20:03.965 NotebookApp] zmq message arrived on closed channel
[W 05:20:03.965 NotebookApp] zmq message arrived on closed channel
[W 05:20:03.966 NotebookApp] zmq message arrived on closed channel
[W 05:20:03.966 NotebookApp] zmq message arrived on closed channel
[W 05:20:03.966 NotebookApp] zmq message arrived on closed channel
[W 05:20:03.967 NotebookApp] zmq message arrived on closed channel
[W 05:20:03.967 NotebookApp] zmq message arrived on closed channel
[W 05:20:03.967 NotebookApp] zmq message arrived on closed channel
[I 05:21:00.465 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 05:21:02.258 NotebookApp] zmq message arrived on closed channel
[W 05:21:02.259 NotebookApp] zmq message arrived on closed channel
[W 05:21:02.259 NotebookApp] zmq message arrived on closed channel
[W 05:21:02.259 NotebookApp] zmq message arrived on closed channel
[W 05:21:02.259 NotebookApp] zmq message arrived on closed channel
[W 05:21:02.260 NotebookApp] zmq message arrived on closed channel
[W 05:21:02.260 NotebookApp] zmq message arrived on closed channel
[W 05:21:02.260 NotebookApp] zmq message arrived on closed channel
[W 05:21:02.260 NotebookApp] zmq message arrived on closed channel
[W 05:21:02.261 NotebookApp] zmq message arrived on closed channel
[W 05:21:02.261 NotebookApp] zmq message arrived on closed channel
[W 05:21:02.261 NotebookApp] zmq message arrived on closed channel
<console>:25: error: value toDF is not a member of org.apache.spark.rdd.RDD[Weather]
              weather.toDF().registerTempTable("weather")
                      ^
[W 05:21:02.310 NotebookApp] zmq message arrived on closed channel
[W 05:21:02.310 NotebookApp] zmq message arrived on closed channel
[W 05:21:02.310 NotebookApp] zmq message arrived on closed channel
[W 05:21:02.311 NotebookApp] zmq message arrived on closed channel
[W 05:21:02.311 NotebookApp] zmq message arrived on closed channel
[W 05:21:02.312 NotebookApp] zmq message arrived on closed channel
[W 05:21:02.312 NotebookApp] zmq message arrived on closed channel
[W 05:21:02.313 NotebookApp] zmq message arrived on closed channel
[W 05:21:02.313 NotebookApp] zmq message arrived on closed channel
[W 05:21:02.313 NotebookApp] zmq message arrived on closed channel
[W 05:21:02.314 NotebookApp] zmq message arrived on closed channel
[W 05:21:02.314 NotebookApp] zmq message arrived on closed channel
[W 05:21:14.906 NotebookApp] zmq message arrived on closed channel
[W 05:21:14.906 NotebookApp] zmq message arrived on closed channel
[W 05:21:14.907 NotebookApp] zmq message arrived on closed channel
[W 05:21:14.907 NotebookApp] zmq message arrived on closed channel
[W 05:21:14.907 NotebookApp] zmq message arrived on closed channel
[W 05:21:14.907 NotebookApp] zmq message arrived on closed channel
[W 05:21:14.908 NotebookApp] zmq message arrived on closed channel
[W 05:21:14.908 NotebookApp] zmq message arrived on closed channel
[W 05:21:14.909 NotebookApp] zmq message arrived on closed channel
[W 05:21:14.909 NotebookApp] zmq message arrived on closed channel
[W 05:21:14.909 NotebookApp] zmq message arrived on closed channel
[W 05:21:14.909 NotebookApp] zmq message arrived on closed channel
res117: org.apache.spark.rdd.RDD[Weather] = MapPartitionsRDD[47] at map at <console>:17
[W 05:21:15.077 NotebookApp] zmq message arrived on closed channel
[W 05:21:15.077 NotebookApp] zmq message arrived on closed channel
[W 05:21:15.078 NotebookApp] zmq message arrived on closed channel
[W 05:21:15.078 NotebookApp] zmq message arrived on closed channel
[W 05:21:15.078 NotebookApp] zmq message arrived on closed channel
[W 05:21:15.079 NotebookApp] zmq message arrived on closed channel
[W 05:21:15.079 NotebookApp] zmq message arrived on closed channel
[W 05:21:15.080 NotebookApp] zmq message arrived on closed channel
[W 05:21:15.080 NotebookApp] zmq message arrived on closed channel
[W 05:21:15.081 NotebookApp] zmq message arrived on closed channel
[W 05:21:15.081 NotebookApp] zmq message arrived on closed channel
[W 05:21:15.081 NotebookApp] zmq message arrived on closed channel
[W 05:21:21.614 NotebookApp] zmq message arrived on closed channel
[W 05:21:21.615 NotebookApp] zmq message arrived on closed channel
[W 05:21:21.615 NotebookApp] zmq message arrived on closed channel
[W 05:21:21.615 NotebookApp] zmq message arrived on closed channel
[W 05:21:21.616 NotebookApp] zmq message arrived on closed channel
[W 05:21:21.616 NotebookApp] zmq message arrived on closed channel
[W 05:21:22.085 NotebookApp] zmq message arrived on closed channel
[W 05:21:22.085 NotebookApp] zmq message arrived on closed channel
[W 05:21:22.085 NotebookApp] zmq message arrived on closed channel
[W 05:21:22.085 NotebookApp] zmq message arrived on closed channel
[W 05:21:22.085 NotebookApp] zmq message arrived on closed channel
[W 05:21:22.086 NotebookApp] zmq message arrived on closed channel
[W 05:21:23.185 NotebookApp] zmq message arrived on closed channel
[W 05:21:23.186 NotebookApp] zmq message arrived on closed channel
[W 05:21:23.186 NotebookApp] zmq message arrived on closed channel
[W 05:21:23.186 NotebookApp] zmq message arrived on closed channel
[W 05:21:23.187 NotebookApp] zmq message arrived on closed channel
[W 05:21:23.187 NotebookApp] zmq message arrived on closed channel
[W 05:21:23.661 NotebookApp] zmq message arrived on closed channel
[W 05:21:23.662 NotebookApp] zmq message arrived on closed channel
[W 05:21:23.662 NotebookApp] zmq message arrived on closed channel
[W 05:21:23.662 NotebookApp] zmq message arrived on closed channel
[W 05:21:23.663 NotebookApp] zmq message arrived on closed channel
[W 05:21:23.663 NotebookApp] zmq message arrived on closed channel
[W 05:21:23.914 NotebookApp] zmq message arrived on closed channel
[W 05:21:23.914 NotebookApp] zmq message arrived on closed channel
[W 05:21:23.915 NotebookApp] zmq message arrived on closed channel
[W 05:21:23.915 NotebookApp] zmq message arrived on closed channel
[W 05:21:23.915 NotebookApp] zmq message arrived on closed channel
[W 05:21:23.915 NotebookApp] zmq message arrived on closed channel
[W 05:21:24.374 NotebookApp] zmq message arrived on closed channel
[W 05:21:24.374 NotebookApp] zmq message arrived on closed channel
[W 05:21:24.375 NotebookApp] zmq message arrived on closed channel
[W 05:21:24.375 NotebookApp] zmq message arrived on closed channel
[W 05:21:24.375 NotebookApp] zmq message arrived on closed channel
[W 05:21:24.375 NotebookApp] zmq message arrived on closed channel
[W 05:21:24.376 NotebookApp] zmq message arrived on closed channel
[W 05:21:24.376 NotebookApp] zmq message arrived on closed channel
[W 05:21:24.376 NotebookApp] zmq message arrived on closed channel
[W 05:21:24.376 NotebookApp] zmq message arrived on closed channel
[W 05:21:24.377 NotebookApp] zmq message arrived on closed channel
[W 05:21:24.377 NotebookApp] zmq message arrived on closed channel
[W 05:21:24.812 NotebookApp] zmq message arrived on closed channel
[W 05:21:24.812 NotebookApp] zmq message arrived on closed channel
[W 05:21:24.812 NotebookApp] zmq message arrived on closed channel
[W 05:21:24.812 NotebookApp] zmq message arrived on closed channel
[W 05:21:24.813 NotebookApp] zmq message arrived on closed channel
[W 05:21:24.814 NotebookApp] zmq message arrived on closed channel
[W 05:21:35.508 NotebookApp] zmq message arrived on closed channel
[W 05:21:35.509 NotebookApp] zmq message arrived on closed channel
[W 05:21:35.509 NotebookApp] zmq message arrived on closed channel
[W 05:21:35.509 NotebookApp] zmq message arrived on closed channel
[W 05:21:35.509 NotebookApp] zmq message arrived on closed channel
[W 05:21:35.510 NotebookApp] zmq message arrived on closed channel
[W 05:21:35.510 NotebookApp] zmq message arrived on closed channel
[W 05:21:35.511 NotebookApp] zmq message arrived on closed channel
[W 05:21:35.511 NotebookApp] zmq message arrived on closed channel
[W 05:21:35.511 NotebookApp] zmq message arrived on closed channel
[W 05:21:35.511 NotebookApp] zmq message arrived on closed channel
[W 05:21:35.512 NotebookApp] zmq message arrived on closed channel
<console>:25: error: value toDF is not a member of org.apache.spark.api.java.JavaRDD[Weather]
              weather.toJavaRDD().toDF().registerTempTable("weather")
                                  ^
[W 05:21:35.561 NotebookApp] zmq message arrived on closed channel
[W 05:21:35.561 NotebookApp] zmq message arrived on closed channel
[W 05:21:35.562 NotebookApp] zmq message arrived on closed channel
[W 05:21:35.562 NotebookApp] zmq message arrived on closed channel
[W 05:21:35.562 NotebookApp] zmq message arrived on closed channel
[W 05:21:35.563 NotebookApp] zmq message arrived on closed channel
[W 05:21:35.564 NotebookApp] zmq message arrived on closed channel
[W 05:21:35.564 NotebookApp] zmq message arrived on closed channel
[W 05:21:35.564 NotebookApp] zmq message arrived on closed channel
[W 05:21:35.565 NotebookApp] zmq message arrived on closed channel
[W 05:21:35.565 NotebookApp] zmq message arrived on closed channel
[W 05:21:35.565 NotebookApp] zmq message arrived on closed channel
[W 05:21:42.805 NotebookApp] zmq message arrived on closed channel
[W 05:21:42.806 NotebookApp] zmq message arrived on closed channel
[W 05:21:42.806 NotebookApp] zmq message arrived on closed channel
[W 05:21:42.806 NotebookApp] zmq message arrived on closed channel
[W 05:21:42.807 NotebookApp] zmq message arrived on closed channel
[W 05:21:42.807 NotebookApp] zmq message arrived on closed channel
[W 05:21:42.807 NotebookApp] zmq message arrived on closed channel
[W 05:21:42.808 NotebookApp] zmq message arrived on closed channel
[W 05:21:42.808 NotebookApp] zmq message arrived on closed channel
[W 05:21:42.808 NotebookApp] zmq message arrived on closed channel
[W 05:21:42.809 NotebookApp] zmq message arrived on closed channel
[W 05:21:42.809 NotebookApp] zmq message arrived on closed channel
<console>:25: error: value registerTempTable is not a member of org.apache.spark.api.java.JavaRDD[Weather]
              weather.toJavaRDD().registerTempTable("weather")
                                  ^
[W 05:21:42.853 NotebookApp] zmq message arrived on closed channel
[W 05:21:42.853 NotebookApp] zmq message arrived on closed channel
[W 05:21:42.853 NotebookApp] zmq message arrived on closed channel
[W 05:21:42.854 NotebookApp] zmq message arrived on closed channel
[W 05:21:42.854 NotebookApp] zmq message arrived on closed channel
[W 05:21:42.855 NotebookApp] zmq message arrived on closed channel
[W 05:21:42.855 NotebookApp] zmq message arrived on closed channel
[W 05:21:42.856 NotebookApp] zmq message arrived on closed channel
[W 05:21:42.856 NotebookApp] zmq message arrived on closed channel
[W 05:21:42.856 NotebookApp] zmq message arrived on closed channel
[W 05:21:42.857 NotebookApp] zmq message arrived on closed channel
[W 05:21:42.857 NotebookApp] zmq message arrived on closed channel
[W 05:21:48.829 NotebookApp] zmq message arrived on closed channel
[W 05:21:48.829 NotebookApp] zmq message arrived on closed channel
[W 05:21:48.829 NotebookApp] zmq message arrived on closed channel
[W 05:21:48.830 NotebookApp] zmq message arrived on closed channel
[W 05:21:48.830 NotebookApp] zmq message arrived on closed channel
[W 05:21:48.830 NotebookApp] zmq message arrived on closed channel
[W 05:21:48.830 NotebookApp] zmq message arrived on closed channel
[W 05:21:48.831 NotebookApp] zmq message arrived on closed channel
[W 05:21:48.831 NotebookApp] zmq message arrived on closed channel
[W 05:21:48.832 NotebookApp] zmq message arrived on closed channel
[W 05:21:48.832 NotebookApp] zmq message arrived on closed channel
[W 05:21:48.832 NotebookApp] zmq message arrived on closed channel
<console>:25: error: value registerTempTable is not a member of org.apache.spark.rdd.RDD[Weather]
              weather.registerTempTable("weather")
                      ^
[W 05:21:48.875 NotebookApp] zmq message arrived on closed channel
[W 05:21:48.875 NotebookApp] zmq message arrived on closed channel
[W 05:21:48.875 NotebookApp] zmq message arrived on closed channel
[W 05:21:48.876 NotebookApp] zmq message arrived on closed channel
[W 05:21:48.876 NotebookApp] zmq message arrived on closed channel
[W 05:21:48.876 NotebookApp] zmq message arrived on closed channel
[W 05:21:48.877 NotebookApp] zmq message arrived on closed channel
[W 05:21:48.878 NotebookApp] zmq message arrived on closed channel
[W 05:21:48.878 NotebookApp] zmq message arrived on closed channel
[W 05:21:48.878 NotebookApp] zmq message arrived on closed channel
[W 05:21:48.879 NotebookApp] zmq message arrived on closed channel
[W 05:21:48.879 NotebookApp] zmq message arrived on closed channel
[W 05:21:53.612 NotebookApp] zmq message arrived on closed channel
[W 05:21:53.612 NotebookApp] zmq message arrived on closed channel
[W 05:21:53.612 NotebookApp] zmq message arrived on closed channel
[W 05:21:53.613 NotebookApp] zmq message arrived on closed channel
[W 05:21:53.613 NotebookApp] zmq message arrived on closed channel
[W 05:21:53.613 NotebookApp] zmq message arrived on closed channel
[W 05:21:54.058 NotebookApp] zmq message arrived on closed channel
[W 05:21:54.059 NotebookApp] zmq message arrived on closed channel
[W 05:21:54.059 NotebookApp] zmq message arrived on closed channel
[W 05:21:54.059 NotebookApp] zmq message arrived on closed channel
[W 05:21:54.060 NotebookApp] zmq message arrived on closed channel
[W 05:21:54.060 NotebookApp] zmq message arrived on closed channel
[W 05:21:58.431 NotebookApp] zmq message arrived on closed channel
[W 05:21:58.432 NotebookApp] zmq message arrived on closed channel
[W 05:21:58.432 NotebookApp] zmq message arrived on closed channel
[W 05:21:58.432 NotebookApp] zmq message arrived on closed channel
[W 05:21:58.433 NotebookApp] zmq message arrived on closed channel
[W 05:21:58.433 NotebookApp] zmq message arrived on closed channel
[W 05:21:58.862 NotebookApp] zmq message arrived on closed channel
[W 05:21:58.862 NotebookApp] zmq message arrived on closed channel
[W 05:21:58.862 NotebookApp] zmq message arrived on closed channel
[W 05:21:58.863 NotebookApp] zmq message arrived on closed channel
[W 05:21:58.863 NotebookApp] zmq message arrived on closed channel
[W 05:21:58.864 NotebookApp] zmq message arrived on closed channel
[W 05:22:34.142 NotebookApp] zmq message arrived on closed channel
[W 05:22:34.142 NotebookApp] zmq message arrived on closed channel
[W 05:22:34.142 NotebookApp] zmq message arrived on closed channel
[W 05:22:34.143 NotebookApp] zmq message arrived on closed channel
[W 05:22:34.143 NotebookApp] zmq message arrived on closed channel
[W 05:22:34.143 NotebookApp] zmq message arrived on closed channel
[W 05:22:34.143 NotebookApp] zmq message arrived on closed channel
[W 05:22:34.144 NotebookApp] zmq message arrived on closed channel
[W 05:22:34.144 NotebookApp] zmq message arrived on closed channel
[W 05:22:34.145 NotebookApp] zmq message arrived on closed channel
[W 05:22:34.145 NotebookApp] zmq message arrived on closed channel
[W 05:22:34.145 NotebookApp] zmq message arrived on closed channel
import sqlContext._
import sqlContext.implicits
[W 05:22:34.865 NotebookApp] zmq message arrived on closed channel
[W 05:22:34.865 NotebookApp] zmq message arrived on closed channel
[W 05:22:34.866 NotebookApp] zmq message arrived on closed channel
[W 05:22:34.866 NotebookApp] zmq message arrived on closed channel
[W 05:22:34.866 NotebookApp] zmq message arrived on closed channel
[W 05:22:34.867 NotebookApp] zmq message arrived on closed channel
[W 05:22:36.543 NotebookApp] zmq message arrived on closed channel
[W 05:22:36.543 NotebookApp] zmq message arrived on closed channel
[W 05:22:36.544 NotebookApp] zmq message arrived on closed channel
[W 05:22:36.544 NotebookApp] zmq message arrived on closed channel
[W 05:22:36.544 NotebookApp] zmq message arrived on closed channel
[W 05:22:36.545 NotebookApp] zmq message arrived on closed channel
[W 05:22:36.545 NotebookApp] zmq message arrived on closed channel
[W 05:22:36.546 NotebookApp] zmq message arrived on closed channel
[W 05:22:36.546 NotebookApp] zmq message arrived on closed channel
[W 05:22:36.546 NotebookApp] zmq message arrived on closed channel
[W 05:22:36.546 NotebookApp] zmq message arrived on closed channel
[W 05:22:36.547 NotebookApp] zmq message arrived on closed channel
<console>:29: error: value registerTempTable is not a member of org.apache.spark.rdd.RDD[Weather]
              weather.registerTempTable("weather")
                      ^
[W 05:22:36.595 NotebookApp] zmq message arrived on closed channel
[W 05:22:36.595 NotebookApp] zmq message arrived on closed channel
[W 05:22:36.595 NotebookApp] zmq message arrived on closed channel
[W 05:22:36.596 NotebookApp] zmq message arrived on closed channel
[W 05:22:36.596 NotebookApp] zmq message arrived on closed channel
[W 05:22:36.596 NotebookApp] zmq message arrived on closed channel
[W 05:22:36.597 NotebookApp] zmq message arrived on closed channel
[W 05:22:36.597 NotebookApp] zmq message arrived on closed channel
[W 05:22:36.598 NotebookApp] zmq message arrived on closed channel
[W 05:22:36.598 NotebookApp] zmq message arrived on closed channel
[W 05:22:36.598 NotebookApp] zmq message arrived on closed channel
[W 05:22:36.598 NotebookApp] zmq message arrived on closed channel
[W 05:22:44.809 NotebookApp] zmq message arrived on closed channel
[W 05:22:44.810 NotebookApp] zmq message arrived on closed channel
[W 05:22:44.810 NotebookApp] zmq message arrived on closed channel
[W 05:22:44.810 NotebookApp] zmq message arrived on closed channel
[W 05:22:44.811 NotebookApp] zmq message arrived on closed channel
[W 05:22:44.811 NotebookApp] zmq message arrived on closed channel
[W 05:22:44.812 NotebookApp] zmq message arrived on closed channel
[W 05:22:44.812 NotebookApp] zmq message arrived on closed channel
[W 05:22:44.812 NotebookApp] zmq message arrived on closed channel
[W 05:22:44.812 NotebookApp] zmq message arrived on closed channel
[W 05:22:44.813 NotebookApp] zmq message arrived on closed channel
[W 05:22:44.813 NotebookApp] zmq message arrived on closed channel
<console>:29: error: value toDf is not a member of org.apache.spark.rdd.RDD[Weather]
              weather.toDf().registerTempTable("weather")
                      ^
[W 05:22:44.860 NotebookApp] zmq message arrived on closed channel
[W 05:22:44.861 NotebookApp] zmq message arrived on closed channel
[W 05:22:44.861 NotebookApp] zmq message arrived on closed channel
[W 05:22:44.861 NotebookApp] zmq message arrived on closed channel
[W 05:22:44.862 NotebookApp] zmq message arrived on closed channel
[W 05:22:44.862 NotebookApp] zmq message arrived on closed channel
[W 05:22:44.863 NotebookApp] zmq message arrived on closed channel
[W 05:22:44.863 NotebookApp] zmq message arrived on closed channel
[W 05:22:44.863 NotebookApp] zmq message arrived on closed channel
[W 05:22:44.864 NotebookApp] zmq message arrived on closed channel
[W 05:22:44.864 NotebookApp] zmq message arrived on closed channel
[W 05:22:44.864 NotebookApp] zmq message arrived on closed channel
[W 05:22:52.763 NotebookApp] zmq message arrived on closed channel
[W 05:22:52.763 NotebookApp] zmq message arrived on closed channel
[W 05:22:52.764 NotebookApp] zmq message arrived on closed channel
[W 05:22:52.764 NotebookApp] zmq message arrived on closed channel
[W 05:22:52.764 NotebookApp] zmq message arrived on closed channel
[W 05:22:52.765 NotebookApp] zmq message arrived on closed channel
[W 05:22:52.765 NotebookApp] zmq message arrived on closed channel
[W 05:22:52.766 NotebookApp] zmq message arrived on closed channel
[W 05:22:52.766 NotebookApp] zmq message arrived on closed channel
[W 05:22:52.766 NotebookApp] zmq message arrived on closed channel
[W 05:22:52.766 NotebookApp] zmq message arrived on closed channel
[W 05:22:52.766 NotebookApp] zmq message arrived on closed channel
<console>:29: error: value toDF is not a member of org.apache.spark.rdd.RDD[Weather]
              weather.toDF().registerTempTable("weather")
                      ^
[W 05:22:52.822 NotebookApp] zmq message arrived on closed channel
[W 05:22:52.823 NotebookApp] zmq message arrived on closed channel
[W 05:22:52.823 NotebookApp] zmq message arrived on closed channel
[W 05:22:52.823 NotebookApp] zmq message arrived on closed channel
[W 05:22:52.824 NotebookApp] zmq message arrived on closed channel
[W 05:22:52.824 NotebookApp] zmq message arrived on closed channel
[W 05:22:52.824 NotebookApp] zmq message arrived on closed channel
[W 05:22:52.824 NotebookApp] zmq message arrived on closed channel
[W 05:22:52.825 NotebookApp] zmq message arrived on closed channel
[W 05:22:52.825 NotebookApp] zmq message arrived on closed channel
[W 05:22:52.825 NotebookApp] zmq message arrived on closed channel
[W 05:22:52.826 NotebookApp] zmq message arrived on closed channel
[W 05:22:58.767 NotebookApp] zmq message arrived on closed channel
[W 05:22:58.767 NotebookApp] zmq message arrived on closed channel
[W 05:22:58.767 NotebookApp] zmq message arrived on closed channel
[W 05:22:58.768 NotebookApp] zmq message arrived on closed channel
[W 05:22:58.768 NotebookApp] zmq message arrived on closed channel
[W 05:22:58.768 NotebookApp] zmq message arrived on closed channel
[W 05:22:59.414 NotebookApp] zmq message arrived on closed channel
[W 05:22:59.415 NotebookApp] zmq message arrived on closed channel
[W 05:22:59.415 NotebookApp] zmq message arrived on closed channel
[W 05:22:59.415 NotebookApp] zmq message arrived on closed channel
[W 05:22:59.415 NotebookApp] zmq message arrived on closed channel
[W 05:22:59.415 NotebookApp] zmq message arrived on closed channel
[I 05:22:59.991 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 05:23:00.804 NotebookApp] zmq message arrived on closed channel
[W 05:23:00.804 NotebookApp] zmq message arrived on closed channel
[W 05:23:00.804 NotebookApp] zmq message arrived on closed channel
[W 05:23:00.805 NotebookApp] zmq message arrived on closed channel
[W 05:23:00.805 NotebookApp] zmq message arrived on closed channel
[W 05:23:00.805 NotebookApp] zmq message arrived on closed channel
[W 05:23:01.420 NotebookApp] zmq message arrived on closed channel
[W 05:23:01.420 NotebookApp] zmq message arrived on closed channel
[W 05:23:01.421 NotebookApp] zmq message arrived on closed channel
[W 05:23:01.421 NotebookApp] zmq message arrived on closed channel
[W 05:23:01.421 NotebookApp] zmq message arrived on closed channel
[W 05:23:01.422 NotebookApp] zmq message arrived on closed channel
[W 05:23:01.799 NotebookApp] zmq message arrived on closed channel
[W 05:23:01.800 NotebookApp] zmq message arrived on closed channel
[W 05:23:01.800 NotebookApp] zmq message arrived on closed channel
[W 05:23:01.800 NotebookApp] zmq message arrived on closed channel
[W 05:23:01.800 NotebookApp] zmq message arrived on closed channel
[W 05:23:01.801 NotebookApp] zmq message arrived on closed channel
[W 05:23:02.360 NotebookApp] zmq message arrived on closed channel
[W 05:23:02.361 NotebookApp] zmq message arrived on closed channel
[W 05:23:02.361 NotebookApp] zmq message arrived on closed channel
[W 05:23:02.362 NotebookApp] zmq message arrived on closed channel
[W 05:23:02.362 NotebookApp] zmq message arrived on closed channel
[W 05:23:02.362 NotebookApp] zmq message arrived on closed channel
[W 05:23:07.870 NotebookApp] zmq message arrived on closed channel
[W 05:23:07.870 NotebookApp] zmq message arrived on closed channel
[W 05:23:07.870 NotebookApp] zmq message arrived on closed channel
[W 05:23:07.871 NotebookApp] zmq message arrived on closed channel
[W 05:23:07.871 NotebookApp] zmq message arrived on closed channel
[W 05:23:07.871 NotebookApp] zmq message arrived on closed channel
[W 05:23:07.871 NotebookApp] zmq message arrived on closed channel
[W 05:23:07.872 NotebookApp] zmq message arrived on closed channel
[W 05:23:07.872 NotebookApp] zmq message arrived on closed channel
[W 05:23:07.873 NotebookApp] zmq message arrived on closed channel
[W 05:23:07.873 NotebookApp] zmq message arrived on closed channel
[W 05:23:07.873 NotebookApp] zmq message arrived on closed channel
weather: org.apache.spark.rdd.RDD[Weather] = MapPartitionsRDD[51] at map at <console>:26
[W 05:23:08.100 NotebookApp] zmq message arrived on closed channel
[W 05:23:08.100 NotebookApp] zmq message arrived on closed channel
[W 05:23:08.100 NotebookApp] zmq message arrived on closed channel
[W 05:23:08.100 NotebookApp] zmq message arrived on closed channel
[W 05:23:08.101 NotebookApp] zmq message arrived on closed channel
[W 05:23:08.101 NotebookApp] zmq message arrived on closed channel
[W 05:23:09.371 NotebookApp] zmq message arrived on closed channel
[W 05:23:09.372 NotebookApp] zmq message arrived on closed channel
[W 05:23:09.372 NotebookApp] zmq message arrived on closed channel
[W 05:23:09.372 NotebookApp] zmq message arrived on closed channel
[W 05:23:09.372 NotebookApp] zmq message arrived on closed channel
[W 05:23:09.373 NotebookApp] zmq message arrived on closed channel
[W 05:23:09.373 NotebookApp] zmq message arrived on closed channel
[W 05:23:09.373 NotebookApp] zmq message arrived on closed channel
[W 05:23:09.373 NotebookApp] zmq message arrived on closed channel
[W 05:23:09.374 NotebookApp] zmq message arrived on closed channel
[W 05:23:09.374 NotebookApp] zmq message arrived on closed channel
[W 05:23:09.375 NotebookApp] zmq message arrived on closed channel
<console>:29: error: value registerTempTable is not a member of org.apache.spark.rdd.RDD[Weather]
              weather.registerTempTable("weather")
                      ^
[W 05:23:09.417 NotebookApp] zmq message arrived on closed channel
[W 05:23:09.417 NotebookApp] zmq message arrived on closed channel
[W 05:23:09.417 NotebookApp] zmq message arrived on closed channel
[W 05:23:09.417 NotebookApp] zmq message arrived on closed channel
[W 05:23:09.418 NotebookApp] zmq message arrived on closed channel
[W 05:23:09.418 NotebookApp] zmq message arrived on closed channel
[W 05:23:09.419 NotebookApp] zmq message arrived on closed channel
[W 05:23:09.419 NotebookApp] zmq message arrived on closed channel
[W 05:23:09.420 NotebookApp] zmq message arrived on closed channel
[W 05:23:09.420 NotebookApp] zmq message arrived on closed channel
[W 05:23:09.420 NotebookApp] zmq message arrived on closed channel
[W 05:23:09.420 NotebookApp] zmq message arrived on closed channel
[W 05:23:13.129 NotebookApp] zmq message arrived on closed channel
[W 05:23:13.129 NotebookApp] zmq message arrived on closed channel
[W 05:23:13.130 NotebookApp] zmq message arrived on closed channel
[W 05:23:13.130 NotebookApp] zmq message arrived on closed channel
[W 05:23:13.130 NotebookApp] zmq message arrived on closed channel
[W 05:23:13.130 NotebookApp] zmq message arrived on closed channel
[W 05:23:13.131 NotebookApp] zmq message arrived on closed channel
[W 05:23:13.131 NotebookApp] zmq message arrived on closed channel
[W 05:23:13.132 NotebookApp] zmq message arrived on closed channel
[W 05:23:13.132 NotebookApp] zmq message arrived on closed channel
[W 05:23:13.132 NotebookApp] zmq message arrived on closed channel
[W 05:23:13.132 NotebookApp] zmq message arrived on closed channel
<console>:29: error: value toDF is not a member of org.apache.spark.rdd.RDD[Weather]
              weather.toDF().registerTempTable("weather")
                      ^
[W 05:23:13.174 NotebookApp] zmq message arrived on closed channel
[W 05:23:13.175 NotebookApp] zmq message arrived on closed channel
[W 05:23:13.175 NotebookApp] zmq message arrived on closed channel
[W 05:23:13.175 NotebookApp] zmq message arrived on closed channel
[W 05:23:13.176 NotebookApp] zmq message arrived on closed channel
[W 05:23:13.176 NotebookApp] zmq message arrived on closed channel
[W 05:23:13.176 NotebookApp] zmq message arrived on closed channel
[W 05:23:13.177 NotebookApp] zmq message arrived on closed channel
[W 05:23:13.177 NotebookApp] zmq message arrived on closed channel
[W 05:23:13.177 NotebookApp] zmq message arrived on closed channel
[W 05:23:13.178 NotebookApp] zmq message arrived on closed channel
[W 05:23:13.178 NotebookApp] zmq message arrived on closed channel
[W 05:23:15.762 NotebookApp] zmq message arrived on closed channel
[W 05:23:15.762 NotebookApp] zmq message arrived on closed channel
[W 05:23:15.762 NotebookApp] zmq message arrived on closed channel
[W 05:23:15.763 NotebookApp] zmq message arrived on closed channel
[W 05:23:15.763 NotebookApp] zmq message arrived on closed channel
[W 05:23:15.763 NotebookApp] zmq message arrived on closed channel
[W 05:23:15.764 NotebookApp] zmq message arrived on closed channel
[W 05:23:15.764 NotebookApp] zmq message arrived on closed channel
[W 05:23:15.765 NotebookApp] zmq message arrived on closed channel
[W 05:23:15.765 NotebookApp] zmq message arrived on closed channel
[W 05:23:15.765 NotebookApp] zmq message arrived on closed channel
[W 05:23:15.765 NotebookApp] zmq message arrived on closed channel
<console>:29: error: value toDF is not a member of org.apache.spark.rdd.RDD[Weather]
              weather.toDF.registerTempTable("weather")
                      ^
[W 05:23:15.806 NotebookApp] zmq message arrived on closed channel
[W 05:23:15.806 NotebookApp] zmq message arrived on closed channel
[W 05:23:15.806 NotebookApp] zmq message arrived on closed channel
[W 05:23:15.807 NotebookApp] zmq message arrived on closed channel
[W 05:23:15.807 NotebookApp] zmq message arrived on closed channel
[W 05:23:15.808 NotebookApp] zmq message arrived on closed channel
[W 05:23:15.809 NotebookApp] zmq message arrived on closed channel
[W 05:23:15.809 NotebookApp] zmq message arrived on closed channel
[W 05:23:15.809 NotebookApp] zmq message arrived on closed channel
[W 05:23:15.810 NotebookApp] zmq message arrived on closed channel
[W 05:23:15.810 NotebookApp] zmq message arrived on closed channel
[W 05:23:15.810 NotebookApp] zmq message arrived on closed channel
[W 05:23:18.726 NotebookApp] zmq message arrived on closed channel
[W 05:23:18.727 NotebookApp] zmq message arrived on closed channel
[W 05:23:18.727 NotebookApp] zmq message arrived on closed channel
[W 05:23:18.727 NotebookApp] zmq message arrived on closed channel
[W 05:23:18.727 NotebookApp] zmq message arrived on closed channel
[W 05:23:18.728 NotebookApp] zmq message arrived on closed channel
[W 05:23:18.728 NotebookApp] zmq message arrived on closed channel
[W 05:23:18.728 NotebookApp] zmq message arrived on closed channel
[W 05:23:18.729 NotebookApp] zmq message arrived on closed channel
[W 05:23:18.729 NotebookApp] zmq message arrived on closed channel
[W 05:23:18.729 NotebookApp] zmq message arrived on closed channel
[W 05:23:18.730 NotebookApp] zmq message arrived on closed channel
<console>:29: error: value registerTempTable is not a member of org.apache.spark.rdd.RDD[Weather]
              weather.registerTempTable("weather")
                      ^
[W 05:23:18.771 NotebookApp] zmq message arrived on closed channel
[W 05:23:18.771 NotebookApp] zmq message arrived on closed channel
[W 05:23:18.772 NotebookApp] zmq message arrived on closed channel
[W 05:23:18.772 NotebookApp] zmq message arrived on closed channel
[W 05:23:18.772 NotebookApp] zmq message arrived on closed channel
[W 05:23:18.773 NotebookApp] zmq message arrived on closed channel
[W 05:23:18.773 NotebookApp] zmq message arrived on closed channel
[W 05:23:18.774 NotebookApp] zmq message arrived on closed channel
[W 05:23:18.774 NotebookApp] zmq message arrived on closed channel
[W 05:23:18.775 NotebookApp] zmq message arrived on closed channel
[W 05:23:18.775 NotebookApp] zmq message arrived on closed channel
[W 05:23:18.775 NotebookApp] zmq message arrived on closed channel
[W 05:23:20.870 NotebookApp] zmq message arrived on closed channel
[W 05:23:20.870 NotebookApp] zmq message arrived on closed channel
[W 05:23:20.870 NotebookApp] zmq message arrived on closed channel
[W 05:23:20.870 NotebookApp] zmq message arrived on closed channel
[W 05:23:20.871 NotebookApp] zmq message arrived on closed channel
[W 05:23:20.871 NotebookApp] zmq message arrived on closed channel
[W 05:23:20.871 NotebookApp] zmq message arrived on closed channel
[W 05:23:20.871 NotebookApp] zmq message arrived on closed channel
[W 05:23:20.872 NotebookApp] zmq message arrived on closed channel
[W 05:23:20.873 NotebookApp] zmq message arrived on closed channel
[W 05:23:20.873 NotebookApp] zmq message arrived on closed channel
[W 05:23:20.873 NotebookApp] zmq message arrived on closed channel
java.lang.RuntimeException: Table Not Found: weather
	at scala.sys.package$.error(package.scala:27)
	at org.apache.spark.sql.catalyst.analysis.SimpleCatalog$$anonfun$1.apply(Catalog.scala:115)
	at org.apache.spark.sql.catalyst.analysis.SimpleCatalog$$anonfun$1.apply(Catalog.scala:115)
	at scala.collection.MapLike$class.getOrElse(MapLike.scala:128)
	at scala.collection.AbstractMap.getOrElse(Map.scala:58)
	at org.apache.spark.sql.catalyst.analysis.SimpleCatalog.lookupRelation(Catalog.scala:115)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.getTable(Analyzer.scala:222)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$7.applyOrElse(Analyzer.scala:233)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$7.applyOrElse(Analyzer.scala:229)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:222)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:222)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:51)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:221)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:242)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformChildrenDown(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:227)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:242)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformChildrenDown(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:227)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:242)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformChildrenDown(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:227)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transform(TreeNode.scala:212)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:229)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:219)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:61)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:59)
	at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:111)
	at scala.collection.immutable.List.foldLeft(List.scala:84)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:59)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:51)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:51)
	at org.apache.spark.sql.SQLContext$QueryExecution.analyzed$lzycompute(SQLContext.scala:933)
	at org.apache.spark.sql.SQLContext$QueryExecution.analyzed(SQLContext.scala:933)
	at org.apache.spark.sql.SQLContext$QueryExecution.assertAnalyzed(SQLContext.scala:931)
	at org.apache.spark.sql.DataFrame.<init>(DataFrame.scala:131)
	at org.apache.spark.sql.DataFrame$.apply(DataFrame.scala:51)
	at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:755)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:24)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:29)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)
	at $iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)
	at $iwC$$iwC$$iwC$$iwC.<init>(<console>:35)
	at $iwC$$iwC$$iwC.<init>(<console>:37)
	at $iwC$$iwC.<init>(<console>:39)
	at $iwC.<init>(<console>:41)
	at <init>(<console>:43)
	at .<init>(<console>:47)
	at .<clinit>(<console>)
	at .<init>(<console>:7)
	at .<clinit>(<console>)
	at $print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	at com.ibm.spark.interpreter.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:296)
	at com.ibm.spark.interpreter.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:291)
	at com.ibm.spark.global.StreamState$.withStreams(StreamState.scala:80)
	at com.ibm.spark.interpreter.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:290)
	at com.ibm.spark.interpreter.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:290)
	at com.ibm.spark.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

lastException: Throwable = null
[W 05:23:21.968 NotebookApp] zmq message arrived on closed channel
[W 05:23:21.968 NotebookApp] zmq message arrived on closed channel
[W 05:23:21.968 NotebookApp] zmq message arrived on closed channel
[W 05:23:21.969 NotebookApp] zmq message arrived on closed channel
[W 05:23:21.970 NotebookApp] zmq message arrived on closed channel
[W 05:23:21.970 NotebookApp] zmq message arrived on closed channel
[W 05:23:21.971 NotebookApp] zmq message arrived on closed channel
[W 05:23:21.971 NotebookApp] zmq message arrived on closed channel
[W 05:23:21.971 NotebookApp] zmq message arrived on closed channel
[W 05:23:21.971 NotebookApp] zmq message arrived on closed channel
[W 05:23:21.971 NotebookApp] zmq message arrived on closed channel
[W 05:23:21.972 NotebookApp] zmq message arrived on closed channel
[I 05:25:00.707 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 05:25:44.803 NotebookApp] zmq message arrived on closed channel
[W 05:25:44.803 NotebookApp] zmq message arrived on closed channel
[W 05:25:44.803 NotebookApp] zmq message arrived on closed channel
[W 05:25:44.803 NotebookApp] zmq message arrived on closed channel
[W 05:25:44.804 NotebookApp] zmq message arrived on closed channel
[W 05:25:44.804 NotebookApp] zmq message arrived on closed channel
[W 05:25:44.804 NotebookApp] zmq message arrived on closed channel
[W 05:25:44.805 NotebookApp] zmq message arrived on closed channel
[W 05:25:44.805 NotebookApp] zmq message arrived on closed channel
[W 05:25:44.805 NotebookApp] zmq message arrived on closed channel
[W 05:25:44.806 NotebookApp] zmq message arrived on closed channel
[W 05:25:44.806 NotebookApp] zmq message arrived on closed channel
<console>:26: error: value toDF is not a member of org.apache.spark.rdd.RDD[Weather]
       val weather = sc.textFile("/resources/nycweather.csv").map(_.split(",")). map(w => Weather(w(0), w(1).trim.toInt, w(2).trim.toDouble)).toDF()
                                                                                                                                              ^
[W 05:25:44.872 NotebookApp] zmq message arrived on closed channel
[W 05:25:44.872 NotebookApp] zmq message arrived on closed channel
[W 05:25:44.872 NotebookApp] zmq message arrived on closed channel
[W 05:25:44.873 NotebookApp] zmq message arrived on closed channel
[W 05:25:44.873 NotebookApp] zmq message arrived on closed channel
[W 05:25:44.874 NotebookApp] zmq message arrived on closed channel
[W 05:25:44.874 NotebookApp] zmq message arrived on closed channel
[W 05:25:44.875 NotebookApp] zmq message arrived on closed channel
[W 05:25:44.875 NotebookApp] zmq message arrived on closed channel
[W 05:25:44.875 NotebookApp] zmq message arrived on closed channel
[W 05:25:44.875 NotebookApp] zmq message arrived on closed channel
[W 05:25:44.875 NotebookApp] zmq message arrived on closed channel
[W 05:25:53.438 NotebookApp] zmq message arrived on closed channel
[W 05:25:53.438 NotebookApp] zmq message arrived on closed channel
[W 05:25:53.438 NotebookApp] zmq message arrived on closed channel
[W 05:25:53.439 NotebookApp] zmq message arrived on closed channel
[W 05:25:53.439 NotebookApp] zmq message arrived on closed channel
[W 05:25:53.439 NotebookApp] zmq message arrived on closed channel
[W 05:25:53.439 NotebookApp] zmq message arrived on closed channel
[W 05:25:53.440 NotebookApp] zmq message arrived on closed channel
[W 05:25:53.440 NotebookApp] zmq message arrived on closed channel
[W 05:25:53.440 NotebookApp] zmq message arrived on closed channel
[W 05:25:53.441 NotebookApp] zmq message arrived on closed channel
[W 05:25:53.441 NotebookApp] zmq message arrived on closed channel
weather: org.apache.spark.rdd.RDD[Weather] = MapPartitionsRDD[55] at map at <console>:26
[W 05:25:53.679 NotebookApp] zmq message arrived on closed channel
[W 05:25:53.679 NotebookApp] zmq message arrived on closed channel
[W 05:25:53.680 NotebookApp] zmq message arrived on closed channel
[W 05:25:53.680 NotebookApp] zmq message arrived on closed channel
[W 05:25:53.680 NotebookApp] zmq message arrived on closed channel
[W 05:25:53.680 NotebookApp] zmq message arrived on closed channel
[W 05:25:57.971 NotebookApp] zmq message arrived on closed channel
[W 05:25:57.971 NotebookApp] zmq message arrived on closed channel
[W 05:25:57.971 NotebookApp] zmq message arrived on closed channel
[W 05:25:57.972 NotebookApp] zmq message arrived on closed channel
[W 05:25:57.972 NotebookApp] zmq message arrived on closed channel
[W 05:25:57.972 NotebookApp] zmq message arrived on closed channel
[W 05:25:57.972 NotebookApp] zmq message arrived on closed channel
[W 05:25:57.973 NotebookApp] zmq message arrived on closed channel
[W 05:25:57.973 NotebookApp] zmq message arrived on closed channel
[W 05:25:57.973 NotebookApp] zmq message arrived on closed channel
[W 05:25:57.974 NotebookApp] zmq message arrived on closed channel
[W 05:25:57.974 NotebookApp] zmq message arrived on closed channel
weather: org.apache.spark.rdd.RDD[Weather] = MapPartitionsRDD[59] at map at <console>:26
[W 05:25:58.197 NotebookApp] zmq message arrived on closed channel
[W 05:25:58.198 NotebookApp] zmq message arrived on closed channel
[W 05:25:58.198 NotebookApp] zmq message arrived on closed channel
[W 05:25:58.198 NotebookApp] zmq message arrived on closed channel
[W 05:25:58.199 NotebookApp] zmq message arrived on closed channel
[W 05:25:58.199 NotebookApp] zmq message arrived on closed channel
[W 05:26:06.522 NotebookApp] zmq message arrived on closed channel
[W 05:26:06.522 NotebookApp] zmq message arrived on closed channel
[W 05:26:06.522 NotebookApp] zmq message arrived on closed channel
[W 05:26:06.523 NotebookApp] zmq message arrived on closed channel
[W 05:26:06.523 NotebookApp] zmq message arrived on closed channel
[W 05:26:06.523 NotebookApp] zmq message arrived on closed channel
[W 05:26:06.523 NotebookApp] zmq message arrived on closed channel
[W 05:26:06.524 NotebookApp] zmq message arrived on closed channel
[W 05:26:06.524 NotebookApp] zmq message arrived on closed channel
[W 05:26:06.525 NotebookApp] zmq message arrived on closed channel
[W 05:26:06.525 NotebookApp] zmq message arrived on closed channel
[W 05:26:06.525 NotebookApp] zmq message arrived on closed channel
weather: org.apache.spark.rdd.RDD[Weather] = MapPartitionsRDD[63] at map at <console>:26
<console>:29: error: value toDF is not a member of org.apache.spark.rdd.RDD[Weather]
              weather.toDF()
                      ^
[W 05:26:06.770 NotebookApp] zmq message arrived on closed channel
[W 05:26:06.771 NotebookApp] zmq message arrived on closed channel
[W 05:26:06.771 NotebookApp] zmq message arrived on closed channel
[W 05:26:06.771 NotebookApp] zmq message arrived on closed channel
[W 05:26:06.771 NotebookApp] zmq message arrived on closed channel
[W 05:26:06.771 NotebookApp] zmq message arrived on closed channel
[W 05:26:06.772 NotebookApp] zmq message arrived on closed channel
[W 05:26:06.773 NotebookApp] zmq message arrived on closed channel
[W 05:26:06.773 NotebookApp] zmq message arrived on closed channel
[W 05:26:06.773 NotebookApp] zmq message arrived on closed channel
[W 05:26:06.773 NotebookApp] zmq message arrived on closed channel
[W 05:26:06.773 NotebookApp] zmq message arrived on closed channel
[W 05:26:24.048 NotebookApp] zmq message arrived on closed channel
[W 05:26:24.049 NotebookApp] zmq message arrived on closed channel
[W 05:26:24.049 NotebookApp] zmq message arrived on closed channel
[W 05:26:24.049 NotebookApp] zmq message arrived on closed channel
[W 05:26:24.049 NotebookApp] zmq message arrived on closed channel
[W 05:26:24.050 NotebookApp] zmq message arrived on closed channel
[W 05:26:24.050 NotebookApp] zmq message arrived on closed channel
[W 05:26:24.051 NotebookApp] zmq message arrived on closed channel
[W 05:26:24.051 NotebookApp] zmq message arrived on closed channel
[W 05:26:24.051 NotebookApp] zmq message arrived on closed channel
[W 05:26:24.051 NotebookApp] zmq message arrived on closed channel
[W 05:26:24.052 NotebookApp] zmq message arrived on closed channel
import sqlContext.implicits._
[W 05:26:24.171 NotebookApp] zmq message arrived on closed channel
[W 05:26:24.172 NotebookApp] zmq message arrived on closed channel
[W 05:26:24.172 NotebookApp] zmq message arrived on closed channel
[W 05:26:24.172 NotebookApp] zmq message arrived on closed channel
[W 05:26:24.173 NotebookApp] zmq message arrived on closed channel
[W 05:26:24.173 NotebookApp] zmq message arrived on closed channel
[W 05:26:26.468 NotebookApp] zmq message arrived on closed channel
[W 05:26:26.468 NotebookApp] zmq message arrived on closed channel
[W 05:26:26.468 NotebookApp] zmq message arrived on closed channel
[W 05:26:26.469 NotebookApp] zmq message arrived on closed channel
[W 05:26:26.469 NotebookApp] zmq message arrived on closed channel
[W 05:26:26.469 NotebookApp] zmq message arrived on closed channel
[W 05:26:26.469 NotebookApp] zmq message arrived on closed channel
[W 05:26:26.470 NotebookApp] zmq message arrived on closed channel
[W 05:26:26.470 NotebookApp] zmq message arrived on closed channel
[W 05:26:26.471 NotebookApp] zmq message arrived on closed channel
[W 05:26:26.471 NotebookApp] zmq message arrived on closed channel
[W 05:26:26.471 NotebookApp] zmq message arrived on closed channel
defined class Weather
[W 05:26:27.045 NotebookApp] zmq message arrived on closed channel
[W 05:26:27.046 NotebookApp] zmq message arrived on closed channel
[W 05:26:27.046 NotebookApp] zmq message arrived on closed channel
[W 05:26:27.047 NotebookApp] zmq message arrived on closed channel
[W 05:26:27.047 NotebookApp] zmq message arrived on closed channel
[W 05:26:27.047 NotebookApp] zmq message arrived on closed channel
[W 05:26:27.623 NotebookApp] zmq message arrived on closed channel
[W 05:26:27.623 NotebookApp] zmq message arrived on closed channel
[W 05:26:27.623 NotebookApp] zmq message arrived on closed channel
[W 05:26:27.624 NotebookApp] zmq message arrived on closed channel
[W 05:26:27.624 NotebookApp] zmq message arrived on closed channel
[W 05:26:27.624 NotebookApp] zmq message arrived on closed channel
[W 05:26:27.625 NotebookApp] zmq message arrived on closed channel
[W 05:26:27.625 NotebookApp] zmq message arrived on closed channel
[W 05:26:27.625 NotebookApp] zmq message arrived on closed channel
[W 05:26:27.625 NotebookApp] zmq message arrived on closed channel
[W 05:26:27.626 NotebookApp] zmq message arrived on closed channel
[W 05:26:27.626 NotebookApp] zmq message arrived on closed channel
weather: org.apache.spark.rdd.RDD[Weather] = MapPartitionsRDD[67] at map at <console>:29
res129: org.apache.spark.sql.DataFrame = [date: string, temp: int, precipitation: double]
[W 05:26:28.981 NotebookApp] zmq message arrived on closed channel
[W 05:26:28.981 NotebookApp] zmq message arrived on closed channel
[W 05:26:28.982 NotebookApp] zmq message arrived on closed channel
[W 05:26:28.982 NotebookApp] zmq message arrived on closed channel
[W 05:26:28.982 NotebookApp] zmq message arrived on closed channel
[W 05:26:28.983 NotebookApp] zmq message arrived on closed channel
[W 05:26:28.983 NotebookApp] zmq message arrived on closed channel
[W 05:26:28.984 NotebookApp] zmq message arrived on closed channel
[W 05:26:28.984 NotebookApp] zmq message arrived on closed channel
[W 05:26:28.984 NotebookApp] zmq message arrived on closed channel
[W 05:26:28.984 NotebookApp] zmq message arrived on closed channel
[W 05:26:28.985 NotebookApp] zmq message arrived on closed channel
[W 05:26:38.601 NotebookApp] zmq message arrived on closed channel
[W 05:26:38.601 NotebookApp] zmq message arrived on closed channel
[W 05:26:38.602 NotebookApp] zmq message arrived on closed channel
[W 05:26:38.602 NotebookApp] zmq message arrived on closed channel
[W 05:26:38.602 NotebookApp] zmq message arrived on closed channel
[W 05:26:38.603 NotebookApp] zmq message arrived on closed channel
[W 05:26:38.604 NotebookApp] zmq message arrived on closed channel
[W 05:26:38.604 NotebookApp] zmq message arrived on closed channel
[W 05:26:38.604 NotebookApp] zmq message arrived on closed channel
[W 05:26:38.604 NotebookApp] zmq message arrived on closed channel
[W 05:26:38.604 NotebookApp] zmq message arrived on closed channel
[W 05:26:38.605 NotebookApp] zmq message arrived on closed channel
weather: org.apache.spark.rdd.RDD[Weather] = MapPartitionsRDD[72] at map at <console>:29
<console>:31: error: reassignment to val
       weather = weather.toDF()
               ^
[W 05:26:39.002 NotebookApp] zmq message arrived on closed channel
[W 05:26:39.003 NotebookApp] zmq message arrived on closed channel
[W 05:26:39.003 NotebookApp] zmq message arrived on closed channel
[W 05:26:39.003 NotebookApp] zmq message arrived on closed channel
[W 05:26:39.004 NotebookApp] zmq message arrived on closed channel
[W 05:26:39.004 NotebookApp] zmq message arrived on closed channel
[W 05:26:39.004 NotebookApp] zmq message arrived on closed channel
[W 05:26:39.004 NotebookApp] zmq message arrived on closed channel
[W 05:26:39.004 NotebookApp] zmq message arrived on closed channel
[W 05:26:39.005 NotebookApp] zmq message arrived on closed channel
[W 05:26:39.005 NotebookApp] zmq message arrived on closed channel
[W 05:26:39.005 NotebookApp] zmq message arrived on closed channel
[W 05:26:49.072 NotebookApp] zmq message arrived on closed channel
[W 05:26:49.073 NotebookApp] zmq message arrived on closed channel
[W 05:26:49.073 NotebookApp] zmq message arrived on closed channel
[W 05:26:49.073 NotebookApp] zmq message arrived on closed channel
[W 05:26:49.074 NotebookApp] zmq message arrived on closed channel
[W 05:26:49.074 NotebookApp] zmq message arrived on closed channel
[W 05:26:49.074 NotebookApp] zmq message arrived on closed channel
[W 05:26:49.075 NotebookApp] zmq message arrived on closed channel
[W 05:26:49.075 NotebookApp] zmq message arrived on closed channel
[W 05:26:49.075 NotebookApp] zmq message arrived on closed channel
[W 05:26:49.076 NotebookApp] zmq message arrived on closed channel
[W 05:26:49.076 NotebookApp] zmq message arrived on closed channel
weather: org.apache.spark.sql.DataFrame = [date: string, temp: int, precipitation: double]
[W 05:26:49.500 NotebookApp] zmq message arrived on closed channel
[W 05:26:49.501 NotebookApp] zmq message arrived on closed channel
[W 05:26:49.501 NotebookApp] zmq message arrived on closed channel
[W 05:26:49.502 NotebookApp] zmq message arrived on closed channel
[W 05:26:49.502 NotebookApp] zmq message arrived on closed channel
[W 05:26:49.502 NotebookApp] zmq message arrived on closed channel
[W 05:26:51.388 NotebookApp] zmq message arrived on closed channel
[W 05:26:51.388 NotebookApp] zmq message arrived on closed channel
[W 05:26:51.388 NotebookApp] zmq message arrived on closed channel
[W 05:26:51.389 NotebookApp] zmq message arrived on closed channel
[W 05:26:51.389 NotebookApp] zmq message arrived on closed channel
[W 05:26:51.389 NotebookApp] zmq message arrived on closed channel
[W 05:26:51.389 NotebookApp] zmq message arrived on closed channel
[W 05:26:51.390 NotebookApp] zmq message arrived on closed channel
[W 05:26:51.391 NotebookApp] zmq message arrived on closed channel
[W 05:26:51.391 NotebookApp] zmq message arrived on closed channel
[W 05:26:51.391 NotebookApp] zmq message arrived on closed channel
[W 05:26:51.391 NotebookApp] zmq message arrived on closed channel
[W 05:26:51.571 NotebookApp] zmq message arrived on closed channel
[W 05:26:51.571 NotebookApp] zmq message arrived on closed channel
[W 05:26:51.571 NotebookApp] zmq message arrived on closed channel
[W 05:26:51.572 NotebookApp] zmq message arrived on closed channel
[W 05:26:51.572 NotebookApp] zmq message arrived on closed channel
[W 05:26:51.572 NotebookApp] zmq message arrived on closed channel
[W 05:26:53.786 NotebookApp] zmq message arrived on closed channel
[W 05:26:53.786 NotebookApp] zmq message arrived on closed channel
[W 05:26:53.786 NotebookApp] zmq message arrived on closed channel
[W 05:26:53.786 NotebookApp] zmq message arrived on closed channel
[W 05:26:53.787 NotebookApp] zmq message arrived on closed channel
[W 05:26:53.787 NotebookApp] zmq message arrived on closed channel
[W 05:26:53.787 NotebookApp] zmq message arrived on closed channel
[W 05:26:53.788 NotebookApp] zmq message arrived on closed channel
[W 05:26:53.788 NotebookApp] zmq message arrived on closed channel
[W 05:26:53.789 NotebookApp] zmq message arrived on closed channel
[W 05:26:53.789 NotebookApp] zmq message arrived on closed channel
[W 05:26:53.789 NotebookApp] zmq message arrived on closed channel
hottest_with_precip: org.apache.spark.sql.DataFrame = [date: string, temp: int, precipitation: double]
[W 05:26:54.116 NotebookApp] zmq message arrived on closed channel
[W 05:26:54.116 NotebookApp] zmq message arrived on closed channel
[W 05:26:54.116 NotebookApp] zmq message arrived on closed channel
[W 05:26:54.116 NotebookApp] zmq message arrived on closed channel
[W 05:26:54.117 NotebookApp] zmq message arrived on closed channel
[W 05:26:54.117 NotebookApp] zmq message arrived on closed channel
[W 05:26:57.655 NotebookApp] zmq message arrived on closed channel
[W 05:26:57.656 NotebookApp] zmq message arrived on closed channel
[W 05:26:57.656 NotebookApp] zmq message arrived on closed channel
[W 05:26:57.656 NotebookApp] zmq message arrived on closed channel
[W 05:26:57.657 NotebookApp] zmq message arrived on closed channel
[W 05:26:57.657 NotebookApp] zmq message arrived on closed channel
[W 05:26:57.657 NotebookApp] zmq message arrived on closed channel
[W 05:26:57.658 NotebookApp] zmq message arrived on closed channel
[W 05:26:57.658 NotebookApp] zmq message arrived on closed channel
[W 05:26:57.658 NotebookApp] zmq message arrived on closed channel
[W 05:26:57.659 NotebookApp] zmq message arrived on closed channel
[W 05:26:57.659 NotebookApp] zmq message arrived on closed channel
[W 05:26:58.678 NotebookApp] zmq message arrived on closed channel
[W 05:26:58.679 NotebookApp] zmq message arrived on closed channel
[W 05:26:58.680 NotebookApp] zmq message arrived on closed channel
[W 05:26:58.680 NotebookApp] zmq message arrived on closed channel
[W 05:26:58.680 NotebookApp] zmq message arrived on closed channel
[W 05:26:58.680 NotebookApp] zmq message arrived on closed channel
[W 05:26:58.686 NotebookApp] zmq message arrived on closed channel
[W 05:26:58.686 NotebookApp] zmq message arrived on closed channel
[W 05:26:58.687 NotebookApp] zmq message arrived on closed channel
[W 05:26:58.687 NotebookApp] zmq message arrived on closed channel
[W 05:26:58.687 NotebookApp] zmq message arrived on closed channel
[W 05:26:58.687 NotebookApp] zmq message arrived on closed channel
[I 05:27:00.190 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
15/10/22 05:30:04 INFO BlockManagerInfo: Removed broadcast_26_piece0 on localhost:34923 in memory (size: 3.0 KB, free: 265.3 MB)
15/10/22 05:30:04 INFO BlockManagerInfo: Removed broadcast_24_piece0 on localhost:34923 in memory (size: 6.2 KB, free: 265.3 MB)
15/10/22 05:30:04 INFO BlockManagerInfo: Removed broadcast_23_piece0 on localhost:34923 in memory (size: 6.0 KB, free: 265.3 MB)
15/10/22 05:30:04 INFO BlockManagerInfo: Removed broadcast_22_piece0 on localhost:34923 in memory (size: 6.2 KB, free: 265.3 MB)
15/10/22 05:30:04 INFO BlockManagerInfo: Removed broadcast_21_piece0 on localhost:34923 in memory (size: 6.0 KB, free: 265.3 MB)
15/10/22 05:30:04 INFO BlockManagerInfo: Removed broadcast_20_piece0 on localhost:34923 in memory (size: 6.2 KB, free: 265.3 MB)
15/10/22 05:30:04 INFO BlockManagerInfo: Removed broadcast_19_piece0 on localhost:34923 in memory (size: 6.0 KB, free: 265.3 MB)
15/10/22 05:30:04 INFO BlockManagerInfo: Removed broadcast_18_piece0 on localhost:34923 in memory (size: 5.7 KB, free: 265.3 MB)
15/10/22 05:30:04 INFO BlockManagerInfo: Removed broadcast_17_piece0 on localhost:34923 in memory (size: 3.0 KB, free: 265.3 MB)
15/10/22 05:30:04 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:34923 in memory (size: 3.0 KB, free: 265.3 MB)
15/10/22 05:30:04 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:34923 in memory (size: 3.0 KB, free: 265.3 MB)
15/10/22 05:30:04 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:34923 in memory (size: 3.0 KB, free: 265.3 MB)
15/10/22 05:30:04 INFO BlockManagerInfo: Removed broadcast_13_piece0 on localhost:34923 in memory (size: 3.0 KB, free: 265.4 MB)
15/10/22 05:30:04 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:34923 in memory (size: 5.1 KB, free: 265.4 MB)
15/10/22 05:30:04 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:34923 in memory (size: 3.0 KB, free: 265.4 MB)
[I 05:31:08.489 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[I 05:33:08.875 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[I 05:35:08.912 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 05:35:15.756 NotebookApp] zmq message arrived on closed channel
[W 05:35:15.756 NotebookApp] zmq message arrived on closed channel
[W 05:35:15.757 NotebookApp] zmq message arrived on closed channel
[W 05:35:15.757 NotebookApp] zmq message arrived on closed channel
[W 05:35:15.757 NotebookApp] zmq message arrived on closed channel
[W 05:35:15.758 NotebookApp] zmq message arrived on closed channel
[W 05:35:15.758 NotebookApp] zmq message arrived on closed channel
[W 05:35:15.758 NotebookApp] zmq message arrived on closed channel
[W 05:35:15.759 NotebookApp] zmq message arrived on closed channel
[W 05:35:15.759 NotebookApp] zmq message arrived on closed channel
[W 05:35:15.759 NotebookApp] zmq message arrived on closed channel
[W 05:35:15.760 NotebookApp] zmq message arrived on closed channel
[W 05:35:15.764 NotebookApp] zmq message arrived on closed channel
[W 05:35:15.764 NotebookApp] zmq message arrived on closed channel
[W 05:35:15.765 NotebookApp] zmq message arrived on closed channel
[W 05:35:15.765 NotebookApp] zmq message arrived on closed channel
[W 05:35:15.766 NotebookApp] zmq message arrived on closed channel
[W 05:35:15.766 NotebookApp] zmq message arrived on closed channel
[W 05:35:15.767 NotebookApp] zmq message arrived on closed channel
[W 05:35:15.767 NotebookApp] zmq message arrived on closed channel
[W 05:35:15.767 NotebookApp] zmq message arrived on closed channel
[W 05:35:15.768 NotebookApp] zmq message arrived on closed channel
[W 05:35:15.768 NotebookApp] zmq message arrived on closed channel
[W 05:35:15.768 NotebookApp] zmq message arrived on closed channel
[W 05:35:27.280 NotebookApp] zmq message arrived on closed channel
[W 05:35:27.280 NotebookApp] zmq message arrived on closed channel
[W 05:35:27.281 NotebookApp] zmq message arrived on closed channel
[W 05:35:27.281 NotebookApp] zmq message arrived on closed channel
[W 05:35:27.714 NotebookApp] zmq message arrived on closed channel
[W 05:35:27.714 NotebookApp] zmq message arrived on closed channel
[W 05:35:27.765 NotebookApp] zmq message arrived on closed channel
[W 05:35:27.765 NotebookApp] zmq message arrived on closed channel
[W 05:35:27.816 NotebookApp] zmq message arrived on closed channel
[W 05:35:27.816 NotebookApp] zmq message arrived on closed channel
[W 05:35:27.967 NotebookApp] zmq message arrived on closed channel
[W 05:35:27.967 NotebookApp] zmq message arrived on closed channel
[W 05:35:28.018 NotebookApp] zmq message arrived on closed channel
[W 05:35:28.018 NotebookApp] zmq message arrived on closed channel
[W 05:35:28.119 NotebookApp] zmq message arrived on closed channel
[W 05:35:28.119 NotebookApp] zmq message arrived on closed channel
[W 05:35:28.169 NotebookApp] zmq message arrived on closed channel
[W 05:35:28.170 NotebookApp] zmq message arrived on closed channel
[W 05:35:28.321 NotebookApp] zmq message arrived on closed channel
[W 05:35:28.321 NotebookApp] zmq message arrived on closed channel
[W 05:35:28.573 NotebookApp] zmq message arrived on closed channel
[W 05:35:28.573 NotebookApp] zmq message arrived on closed channel
[W 05:35:28.674 NotebookApp] zmq message arrived on closed channel
[W 05:35:28.674 NotebookApp] zmq message arrived on closed channel
[W 05:35:28.724 NotebookApp] zmq message arrived on closed channel
[W 05:35:28.725 NotebookApp] zmq message arrived on closed channel
[W 05:35:28.825 NotebookApp] zmq message arrived on closed channel
[W 05:35:28.826 NotebookApp] zmq message arrived on closed channel
[W 05:35:28.977 NotebookApp] zmq message arrived on closed channel
[W 05:35:28.977 NotebookApp] zmq message arrived on closed channel
[W 05:35:29.228 NotebookApp] zmq message arrived on closed channel
[W 05:35:29.229 NotebookApp] zmq message arrived on closed channel
[W 05:35:29.480 NotebookApp] zmq message arrived on closed channel
[W 05:35:29.481 NotebookApp] zmq message arrived on closed channel
[W 05:35:29.732 NotebookApp] zmq message arrived on closed channel
[W 05:35:29.733 NotebookApp] zmq message arrived on closed channel
[W 05:35:29.984 NotebookApp] zmq message arrived on closed channel
[W 05:35:29.984 NotebookApp] zmq message arrived on closed channel
[W 05:35:30.237 NotebookApp] zmq message arrived on closed channel
[W 05:35:30.237 NotebookApp] zmq message arrived on closed channel
[W 05:35:30.488 NotebookApp] zmq message arrived on closed channel
[W 05:35:30.489 NotebookApp] zmq message arrived on closed channel
[W 05:35:30.740 NotebookApp] zmq message arrived on closed channel
[W 05:35:30.740 NotebookApp] zmq message arrived on closed channel
[W 05:35:30.992 NotebookApp] zmq message arrived on closed channel
[W 05:35:30.993 NotebookApp] zmq message arrived on closed channel
[W 05:35:31.194 NotebookApp] zmq message arrived on closed channel
[W 05:35:31.194 NotebookApp] zmq message arrived on closed channel
[W 05:35:31.396 NotebookApp] zmq message arrived on closed channel
[W 05:35:31.396 NotebookApp] zmq message arrived on closed channel
[W 05:35:31.648 NotebookApp] zmq message arrived on closed channel
[W 05:35:31.648 NotebookApp] zmq message arrived on closed channel
[W 05:35:31.849 NotebookApp] zmq message arrived on closed channel
[W 05:35:31.849 NotebookApp] zmq message arrived on closed channel
[W 05:35:32.051 NotebookApp] zmq message arrived on closed channel
[W 05:35:32.051 NotebookApp] zmq message arrived on closed channel
[W 05:35:32.252 NotebookApp] zmq message arrived on closed channel
[W 05:35:32.253 NotebookApp] zmq message arrived on closed channel
[W 05:35:32.454 NotebookApp] zmq message arrived on closed channel
[W 05:35:32.455 NotebookApp] zmq message arrived on closed channel
[W 05:35:32.656 NotebookApp] zmq message arrived on closed channel
[W 05:35:32.656 NotebookApp] zmq message arrived on closed channel
[W 05:35:33.561 NotebookApp] zmq message arrived on closed channel
[W 05:35:33.561 NotebookApp] zmq message arrived on closed channel
[W 05:35:33.813 NotebookApp] zmq message arrived on closed channel
[W 05:35:33.813 NotebookApp] zmq message arrived on closed channel
[W 05:35:34.065 NotebookApp] zmq message arrived on closed channel
[W 05:35:34.065 NotebookApp] zmq message arrived on closed channel
[W 05:35:34.317 NotebookApp] zmq message arrived on closed channel
[W 05:35:34.317 NotebookApp] zmq message arrived on closed channel
[W 05:35:34.569 NotebookApp] zmq message arrived on closed channel
[W 05:35:34.569 NotebookApp] zmq message arrived on closed channel
[W 05:35:34.820 NotebookApp] zmq message arrived on closed channel
[W 05:35:34.821 NotebookApp] zmq message arrived on closed channel
[W 05:35:35.072 NotebookApp] zmq message arrived on closed channel
[W 05:35:35.072 NotebookApp] zmq message arrived on closed channel
[W 05:35:35.274 NotebookApp] zmq message arrived on closed channel
[W 05:35:35.275 NotebookApp] zmq message arrived on closed channel
[W 05:35:35.526 NotebookApp] zmq message arrived on closed channel
[W 05:35:35.527 NotebookApp] zmq message arrived on closed channel
[W 05:35:35.727 NotebookApp] zmq message arrived on closed channel
[W 05:35:35.728 NotebookApp] zmq message arrived on closed channel
[W 05:35:35.929 NotebookApp] zmq message arrived on closed channel
[W 05:35:35.930 NotebookApp] zmq message arrived on closed channel
[W 05:35:36.181 NotebookApp] zmq message arrived on closed channel
[W 05:35:36.182 NotebookApp] zmq message arrived on closed channel
[W 05:35:36.383 NotebookApp] zmq message arrived on closed channel
[W 05:35:36.383 NotebookApp] zmq message arrived on closed channel
[I 05:35:36.403 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[W 05:35:36.634 NotebookApp] zmq message arrived on closed channel
[W 05:35:36.635 NotebookApp] zmq message arrived on closed channel
[W 05:35:36.836 NotebookApp] zmq message arrived on closed channel
[W 05:35:36.837 NotebookApp] zmq message arrived on closed channel
[W 05:35:37.037 NotebookApp] zmq message arrived on closed channel
[W 05:35:37.038 NotebookApp] zmq message arrived on closed channel
[W 05:35:37.289 NotebookApp] zmq message arrived on closed channel
[W 05:35:37.290 NotebookApp] zmq message arrived on closed channel
[W 05:35:37.491 NotebookApp] zmq message arrived on closed channel
[W 05:35:37.492 NotebookApp] zmq message arrived on closed channel
[W 05:35:37.743 NotebookApp] zmq message arrived on closed channel
[W 05:35:37.744 NotebookApp] zmq message arrived on closed channel
[W 05:35:37.945 NotebookApp] zmq message arrived on closed channel
[W 05:35:37.946 NotebookApp] zmq message arrived on closed channel
[W 05:35:38.197 NotebookApp] zmq message arrived on closed channel
[W 05:35:38.198 NotebookApp] zmq message arrived on closed channel
[W 05:35:38.398 NotebookApp] zmq message arrived on closed channel
[W 05:35:38.399 NotebookApp] zmq message arrived on closed channel
[W 05:35:38.650 NotebookApp] zmq message arrived on closed channel
[W 05:35:38.651 NotebookApp] zmq message arrived on closed channel
[W 05:35:38.852 NotebookApp] zmq message arrived on closed channel
[W 05:35:38.853 NotebookApp] zmq message arrived on closed channel
[W 05:35:39.104 NotebookApp] zmq message arrived on closed channel
[W 05:35:39.105 NotebookApp] zmq message arrived on closed channel
[W 05:35:39.305 NotebookApp] zmq message arrived on closed channel
[W 05:35:39.306 NotebookApp] zmq message arrived on closed channel
[W 05:35:39.557 NotebookApp] zmq message arrived on closed channel
[W 05:35:39.558 NotebookApp] zmq message arrived on closed channel
[W 05:35:39.759 NotebookApp] zmq message arrived on closed channel
[W 05:35:39.760 NotebookApp] zmq message arrived on closed channel
[W 05:35:39.960 NotebookApp] zmq message arrived on closed channel
[W 05:35:39.961 NotebookApp] zmq message arrived on closed channel
[W 05:35:40.212 NotebookApp] zmq message arrived on closed channel
[W 05:35:40.213 NotebookApp] zmq message arrived on closed channel
[W 05:35:40.414 NotebookApp] zmq message arrived on closed channel
[W 05:35:40.415 NotebookApp] zmq message arrived on closed channel
[W 05:35:40.666 NotebookApp] zmq message arrived on closed channel
[W 05:35:40.667 NotebookApp] zmq message arrived on closed channel
[W 05:35:40.867 NotebookApp] zmq message arrived on closed channel
[W 05:35:40.868 NotebookApp] zmq message arrived on closed channel
[W 05:35:41.069 NotebookApp] zmq message arrived on closed channel
[W 05:35:41.070 NotebookApp] zmq message arrived on closed channel
[W 05:35:41.321 NotebookApp] zmq message arrived on closed channel
[W 05:35:41.322 NotebookApp] zmq message arrived on closed channel
[W 05:35:41.523 NotebookApp] zmq message arrived on closed channel
[W 05:35:41.524 NotebookApp] zmq message arrived on closed channel
[W 05:35:41.775 NotebookApp] zmq message arrived on closed channel
[W 05:35:41.776 NotebookApp] zmq message arrived on closed channel
[W 05:35:41.976 NotebookApp] zmq message arrived on closed channel
[W 05:35:41.977 NotebookApp] zmq message arrived on closed channel
[W 05:35:42.228 NotebookApp] zmq message arrived on closed channel
[W 05:35:42.229 NotebookApp] zmq message arrived on closed channel
[W 05:35:42.430 NotebookApp] zmq message arrived on closed channel
[W 05:35:42.431 NotebookApp] zmq message arrived on closed channel
[W 05:35:42.682 NotebookApp] zmq message arrived on closed channel
[W 05:35:42.683 NotebookApp] zmq message arrived on closed channel
[W 05:35:42.884 NotebookApp] zmq message arrived on closed channel
[W 05:35:42.885 NotebookApp] zmq message arrived on closed channel
[W 05:35:43.135 NotebookApp] zmq message arrived on closed channel
[W 05:35:43.136 NotebookApp] zmq message arrived on closed channel
[W 05:35:43.337 NotebookApp] zmq message arrived on closed channel
[W 05:35:43.338 NotebookApp] zmq message arrived on closed channel
[W 05:35:43.539 NotebookApp] zmq message arrived on closed channel
[W 05:35:43.540 NotebookApp] zmq message arrived on closed channel
[W 05:35:43.791 NotebookApp] zmq message arrived on closed channel
[W 05:35:43.792 NotebookApp] zmq message arrived on closed channel
[W 05:35:43.992 NotebookApp] zmq message arrived on closed channel
[W 05:35:43.993 NotebookApp] zmq message arrived on closed channel
[W 05:35:44.244 NotebookApp] zmq message arrived on closed channel
[W 05:35:44.245 NotebookApp] zmq message arrived on closed channel
[W 05:35:44.446 NotebookApp] zmq message arrived on closed channel
[W 05:35:44.447 NotebookApp] zmq message arrived on closed channel
[W 05:35:44.697 NotebookApp] zmq message arrived on closed channel
[W 05:35:44.698 NotebookApp] zmq message arrived on closed channel
[W 05:35:44.899 NotebookApp] zmq message arrived on closed channel
[W 05:35:44.900 NotebookApp] zmq message arrived on closed channel
[W 05:35:45.101 NotebookApp] zmq message arrived on closed channel
[W 05:35:45.101 NotebookApp] zmq message arrived on closed channel
[W 05:35:45.302 NotebookApp] zmq message arrived on closed channel
[W 05:35:45.303 NotebookApp] zmq message arrived on closed channel
[W 05:35:45.555 NotebookApp] zmq message arrived on closed channel
[W 05:35:45.555 NotebookApp] zmq message arrived on closed channel
[W 05:35:45.756 NotebookApp] zmq message arrived on closed channel
[W 05:35:45.757 NotebookApp] zmq message arrived on closed channel
[W 05:35:45.868 NotebookApp] zmq message arrived on closed channel
[W 05:35:45.868 NotebookApp] zmq message arrived on closed channel
[W 05:35:45.971 NotebookApp] zmq message arrived on closed channel
[W 05:35:45.972 NotebookApp] zmq message arrived on closed channel
[W 05:36:23.995 NotebookApp] zmq message arrived on closed channel
[W 05:36:23.995 NotebookApp] zmq message arrived on closed channel
[W 05:36:23.996 NotebookApp] zmq message arrived on closed channel
[W 05:36:23.996 NotebookApp] zmq message arrived on closed channel
[W 05:36:23.996 NotebookApp] zmq message arrived on closed channel
[W 05:36:23.996 NotebookApp] zmq message arrived on closed channel
[W 05:36:23.997 NotebookApp] zmq message arrived on closed channel
[W 05:36:23.997 NotebookApp] zmq message arrived on closed channel
[W 05:36:23.998 NotebookApp] zmq message arrived on closed channel
[W 05:36:23.998 NotebookApp] zmq message arrived on closed channel
[W 05:36:23.998 NotebookApp] zmq message arrived on closed channel
[W 05:36:23.998 NotebookApp] zmq message arrived on closed channel
import org.apache.spark.mllib.clustering.KMeans
import org.apache.spark.mllib.linalg.Vectors
[W 05:36:24.331 NotebookApp] zmq message arrived on closed channel
[W 05:36:24.331 NotebookApp] zmq message arrived on closed channel
[W 05:36:24.332 NotebookApp] zmq message arrived on closed channel
[W 05:36:24.332 NotebookApp] zmq message arrived on closed channel
[W 05:36:24.333 NotebookApp] zmq message arrived on closed channel
[W 05:36:24.333 NotebookApp] zmq message arrived on closed channel
[W 05:36:25.891 NotebookApp] zmq message arrived on closed channel
[W 05:36:25.891 NotebookApp] zmq message arrived on closed channel
[W 05:36:25.892 NotebookApp] zmq message arrived on closed channel
[W 05:36:25.892 NotebookApp] zmq message arrived on closed channel
[W 05:36:25.892 NotebookApp] zmq message arrived on closed channel
[W 05:36:25.892 NotebookApp] zmq message arrived on closed channel
[W 05:36:25.893 NotebookApp] zmq message arrived on closed channel
[W 05:36:25.894 NotebookApp] zmq message arrived on closed channel
[W 05:36:25.894 NotebookApp] zmq message arrived on closed channel
[W 05:36:25.894 NotebookApp] zmq message arrived on closed channel
[W 05:36:25.894 NotebookApp] zmq message arrived on closed channel
[W 05:36:25.894 NotebookApp] zmq message arrived on closed channel
taxiFile: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[90] at textFile at <console>:29
[W 05:36:26.175 NotebookApp] zmq message arrived on closed channel
[W 05:36:26.176 NotebookApp] zmq message arrived on closed channel
[W 05:36:26.176 NotebookApp] zmq message arrived on closed channel
[W 05:36:26.176 NotebookApp] zmq message arrived on closed channel
[W 05:36:26.177 NotebookApp] zmq message arrived on closed channel
[W 05:36:26.177 NotebookApp] zmq message arrived on closed channel
[W 05:36:27.486 NotebookApp] zmq message arrived on closed channel
[W 05:36:27.487 NotebookApp] zmq message arrived on closed channel
[W 05:36:27.487 NotebookApp] zmq message arrived on closed channel
[W 05:36:27.488 NotebookApp] zmq message arrived on closed channel
[W 05:36:27.488 NotebookApp] zmq message arrived on closed channel
[W 05:36:27.488 NotebookApp] zmq message arrived on closed channel
[W 05:36:27.488 NotebookApp] zmq message arrived on closed channel
[W 05:36:27.488 NotebookApp] zmq message arrived on closed channel
[W 05:36:27.489 NotebookApp] zmq message arrived on closed channel
[W 05:36:27.489 NotebookApp] zmq message arrived on closed channel
[W 05:36:27.490 NotebookApp] zmq message arrived on closed channel
[W 05:36:27.490 NotebookApp] zmq message arrived on closed channel
res132: Long = 250000
[W 05:36:27.892 NotebookApp] zmq message arrived on closed channel
[W 05:36:27.893 NotebookApp] zmq message arrived on closed channel
[W 05:36:27.893 NotebookApp] zmq message arrived on closed channel
[W 05:36:27.893 NotebookApp] zmq message arrived on closed channel
[W 05:36:27.894 NotebookApp] zmq message arrived on closed channel
[W 05:36:27.894 NotebookApp] zmq message arrived on closed channel
[W 05:36:27.894 NotebookApp] zmq message arrived on closed channel
[W 05:36:27.895 NotebookApp] zmq message arrived on closed channel
[W 05:36:27.895 NotebookApp] zmq message arrived on closed channel
[W 05:36:27.895 NotebookApp] zmq message arrived on closed channel
[W 05:36:27.896 NotebookApp] zmq message arrived on closed channel
[W 05:36:27.896 NotebookApp] zmq message arrived on closed channel
[W 05:36:30.014 NotebookApp] zmq message arrived on closed channel
[W 05:36:30.014 NotebookApp] zmq message arrived on closed channel
[W 05:36:30.015 NotebookApp] zmq message arrived on closed channel
[W 05:36:30.015 NotebookApp] zmq message arrived on closed channel
[W 05:36:30.015 NotebookApp] zmq message arrived on closed channel
[W 05:36:30.015 NotebookApp] zmq message arrived on closed channel
[W 05:36:30.016 NotebookApp] zmq message arrived on closed channel
[W 05:36:30.016 NotebookApp] zmq message arrived on closed channel
[W 05:36:30.017 NotebookApp] zmq message arrived on closed channel
[W 05:36:30.017 NotebookApp] zmq message arrived on closed channel
[W 05:36:30.017 NotebookApp] zmq message arrived on closed channel
[W 05:36:30.017 NotebookApp] zmq message arrived on closed channel
taxiData: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[93] at filter at <console>:31
[W 05:36:30.248 NotebookApp] zmq message arrived on closed channel
[W 05:36:30.249 NotebookApp] zmq message arrived on closed channel
[W 05:36:30.249 NotebookApp] zmq message arrived on closed channel
[W 05:36:30.249 NotebookApp] zmq message arrived on closed channel
[W 05:36:30.250 NotebookApp] zmq message arrived on closed channel
[W 05:36:30.250 NotebookApp] zmq message arrived on closed channel
[W 05:36:43.774 NotebookApp] zmq message arrived on closed channel
[W 05:36:43.774 NotebookApp] zmq message arrived on closed channel
[W 05:36:43.775 NotebookApp] zmq message arrived on closed channel
[W 05:36:43.775 NotebookApp] zmq message arrived on closed channel
[W 05:36:43.775 NotebookApp] zmq message arrived on closed channel
[W 05:36:43.775 NotebookApp] zmq message arrived on closed channel
[W 05:36:43.776 NotebookApp] zmq message arrived on closed channel
[W 05:36:43.776 NotebookApp] zmq message arrived on closed channel
[W 05:36:43.777 NotebookApp] zmq message arrived on closed channel
[W 05:36:43.777 NotebookApp] zmq message arrived on closed channel
[W 05:36:43.777 NotebookApp] zmq message arrived on closed channel
[W 05:36:43.777 NotebookApp] zmq message arrived on closed channel
res133: Long = 250000
[W 05:36:44.121 NotebookApp] zmq message arrived on closed channel
[W 05:36:44.122 NotebookApp] zmq message arrived on closed channel
[W 05:36:44.122 NotebookApp] zmq message arrived on closed channel
[W 05:36:44.122 NotebookApp] zmq message arrived on closed channel
[W 05:36:44.122 NotebookApp] zmq message arrived on closed channel
[W 05:36:44.123 NotebookApp] zmq message arrived on closed channel
[W 05:36:44.123 NotebookApp] zmq message arrived on closed channel
[W 05:36:44.123 NotebookApp] zmq message arrived on closed channel
[W 05:36:44.123 NotebookApp] zmq message arrived on closed channel
[W 05:36:44.124 NotebookApp] zmq message arrived on closed channel
[W 05:36:44.124 NotebookApp] zmq message arrived on closed channel
[W 05:36:44.124 NotebookApp] zmq message arrived on closed channel
[W 05:36:53.957 NotebookApp] zmq message arrived on closed channel
[W 05:36:53.958 NotebookApp] zmq message arrived on closed channel
[W 05:36:53.958 NotebookApp] zmq message arrived on closed channel
[W 05:36:53.959 NotebookApp] zmq message arrived on closed channel
[W 05:36:53.959 NotebookApp] zmq message arrived on closed channel
[W 05:36:53.959 NotebookApp] zmq message arrived on closed channel
[W 05:36:53.960 NotebookApp] zmq message arrived on closed channel
[W 05:36:53.960 NotebookApp] zmq message arrived on closed channel
[W 05:36:53.960 NotebookApp] zmq message arrived on closed channel
[W 05:36:53.960 NotebookApp] zmq message arrived on closed channel
[W 05:36:53.961 NotebookApp] zmq message arrived on closed channel
[W 05:36:53.961 NotebookApp] zmq message arrived on closed channel
taxiData: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[96] at filter at <console>:31
[W 05:36:54.179 NotebookApp] zmq message arrived on closed channel
[W 05:36:54.180 NotebookApp] zmq message arrived on closed channel
[W 05:36:54.180 NotebookApp] zmq message arrived on closed channel
[W 05:36:54.181 NotebookApp] zmq message arrived on closed channel
[W 05:36:54.181 NotebookApp] zmq message arrived on closed channel
[W 05:36:54.181 NotebookApp] zmq message arrived on closed channel
[W 05:36:55.358 NotebookApp] zmq message arrived on closed channel
[W 05:36:55.359 NotebookApp] zmq message arrived on closed channel
[W 05:36:55.359 NotebookApp] zmq message arrived on closed channel
[W 05:36:55.359 NotebookApp] zmq message arrived on closed channel
[W 05:36:55.360 NotebookApp] zmq message arrived on closed channel
[W 05:36:55.360 NotebookApp] zmq message arrived on closed channel
[W 05:36:55.361 NotebookApp] zmq message arrived on closed channel
[W 05:36:55.361 NotebookApp] zmq message arrived on closed channel
[W 05:36:55.361 NotebookApp] zmq message arrived on closed channel
[W 05:36:55.361 NotebookApp] zmq message arrived on closed channel
[W 05:36:55.361 NotebookApp] zmq message arrived on closed channel
[W 05:36:55.361 NotebookApp] zmq message arrived on closed channel
res134: Long = 250000
[W 05:36:55.712 NotebookApp] zmq message arrived on closed channel
[W 05:36:55.712 NotebookApp] zmq message arrived on closed channel
[W 05:36:55.713 NotebookApp] zmq message arrived on closed channel
[W 05:36:55.713 NotebookApp] zmq message arrived on closed channel
[W 05:36:55.713 NotebookApp] zmq message arrived on closed channel
[W 05:36:55.714 NotebookApp] zmq message arrived on closed channel
[W 05:36:55.714 NotebookApp] zmq message arrived on closed channel
[W 05:36:55.714 NotebookApp] zmq message arrived on closed channel
[W 05:36:55.714 NotebookApp] zmq message arrived on closed channel
[W 05:36:55.714 NotebookApp] zmq message arrived on closed channel
[W 05:36:55.715 NotebookApp] zmq message arrived on closed channel
[W 05:36:55.715 NotebookApp] zmq message arrived on closed channel
[W 05:37:04.386 NotebookApp] zmq message arrived on closed channel
[W 05:37:04.386 NotebookApp] zmq message arrived on closed channel
[W 05:37:04.387 NotebookApp] zmq message arrived on closed channel
[W 05:37:04.387 NotebookApp] zmq message arrived on closed channel
[W 05:37:04.387 NotebookApp] zmq message arrived on closed channel
[W 05:37:04.388 NotebookApp] zmq message arrived on closed channel
[W 05:37:04.388 NotebookApp] zmq message arrived on closed channel
[W 05:37:04.389 NotebookApp] zmq message arrived on closed channel
[W 05:37:04.389 NotebookApp] zmq message arrived on closed channel
[W 05:37:04.389 NotebookApp] zmq message arrived on closed channel
[W 05:37:04.389 NotebookApp] zmq message arrived on closed channel
[W 05:37:04.389 NotebookApp] zmq message arrived on closed channel
res135: Long = 249999
[W 05:37:05.160 NotebookApp] zmq message arrived on closed channel
[W 05:37:05.160 NotebookApp] zmq message arrived on closed channel
[W 05:37:05.161 NotebookApp] zmq message arrived on closed channel
[W 05:37:05.161 NotebookApp] zmq message arrived on closed channel
[W 05:37:05.161 NotebookApp] zmq message arrived on closed channel
[W 05:37:05.162 NotebookApp] zmq message arrived on closed channel
[W 05:37:05.162 NotebookApp] zmq message arrived on closed channel
[W 05:37:05.162 NotebookApp] zmq message arrived on closed channel
[W 05:37:05.162 NotebookApp] zmq message arrived on closed channel
[W 05:37:05.163 NotebookApp] zmq message arrived on closed channel
[W 05:37:05.163 NotebookApp] zmq message arrived on closed channel
[W 05:37:05.163 NotebookApp] zmq message arrived on closed channel
[I 05:37:08.917 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[I 05:37:36.352 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[W 05:37:45.102 NotebookApp] zmq message arrived on closed channel
[W 05:37:45.104 NotebookApp] zmq message arrived on closed channel
[W 05:37:45.104 NotebookApp] zmq message arrived on closed channel
[W 05:37:45.105 NotebookApp] zmq message arrived on closed channel
[W 05:37:45.105 NotebookApp] zmq message arrived on closed channel
[W 05:37:45.105 NotebookApp] zmq message arrived on closed channel
[W 05:37:45.105 NotebookApp] zmq message arrived on closed channel
[W 05:37:45.106 NotebookApp] zmq message arrived on closed channel
[W 05:37:45.106 NotebookApp] zmq message arrived on closed channel
[W 05:37:45.107 NotebookApp] zmq message arrived on closed channel
[W 05:37:45.107 NotebookApp] zmq message arrived on closed channel
[W 05:37:45.107 NotebookApp] zmq message arrived on closed channel
taxiFence: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[100] at filter at <console>:36
[W 05:37:45.363 NotebookApp] zmq message arrived on closed channel
[W 05:37:45.363 NotebookApp] zmq message arrived on closed channel
[W 05:37:45.363 NotebookApp] zmq message arrived on closed channel
[W 05:37:45.363 NotebookApp] zmq message arrived on closed channel
[W 05:37:45.364 NotebookApp] zmq message arrived on closed channel
[W 05:37:45.364 NotebookApp] zmq message arrived on closed channel
[W 05:37:47.809 NotebookApp] zmq message arrived on closed channel
[W 05:37:47.809 NotebookApp] zmq message arrived on closed channel
[W 05:37:47.810 NotebookApp] zmq message arrived on closed channel
[W 05:37:47.810 NotebookApp] zmq message arrived on closed channel
[W 05:37:47.810 NotebookApp] zmq message arrived on closed channel
[W 05:37:47.810 NotebookApp] zmq message arrived on closed channel
[W 05:37:47.811 NotebookApp] zmq message arrived on closed channel
[W 05:37:47.811 NotebookApp] zmq message arrived on closed channel
[W 05:37:47.812 NotebookApp] zmq message arrived on closed channel
[W 05:37:47.812 NotebookApp] zmq message arrived on closed channel
[W 05:37:47.812 NotebookApp] zmq message arrived on closed channel
[W 05:37:47.812 NotebookApp] zmq message arrived on closed channel
res136: Long = 206646
[W 05:37:49.115 NotebookApp] zmq message arrived on closed channel
[W 05:37:49.115 NotebookApp] zmq message arrived on closed channel
[W 05:37:49.116 NotebookApp] zmq message arrived on closed channel
[W 05:37:49.116 NotebookApp] zmq message arrived on closed channel
[W 05:37:49.116 NotebookApp] zmq message arrived on closed channel
[W 05:37:49.116 NotebookApp] zmq message arrived on closed channel
[W 05:37:49.117 NotebookApp] zmq message arrived on closed channel
[W 05:37:49.117 NotebookApp] zmq message arrived on closed channel
[W 05:37:49.117 NotebookApp] zmq message arrived on closed channel
[W 05:37:49.118 NotebookApp] zmq message arrived on closed channel
[W 05:37:49.118 NotebookApp] zmq message arrived on closed channel
[W 05:37:49.118 NotebookApp] zmq message arrived on closed channel
[W 05:37:49.122 NotebookApp] zmq message arrived on closed channel
[W 05:37:49.122 NotebookApp] zmq message arrived on closed channel
[W 05:37:49.122 NotebookApp] zmq message arrived on closed channel
[W 05:37:49.122 NotebookApp] zmq message arrived on closed channel
[W 05:37:49.123 NotebookApp] zmq message arrived on closed channel
[W 05:37:49.123 NotebookApp] zmq message arrived on closed channel
[W 05:38:16.051 NotebookApp] zmq message arrived on closed channel
[W 05:38:16.052 NotebookApp] zmq message arrived on closed channel
[W 05:38:16.052 NotebookApp] zmq message arrived on closed channel
[W 05:38:16.052 NotebookApp] zmq message arrived on closed channel
[W 05:38:16.052 NotebookApp] zmq message arrived on closed channel
[W 05:38:16.053 NotebookApp] zmq message arrived on closed channel
[W 05:38:16.054 NotebookApp] zmq message arrived on closed channel
[W 05:38:16.054 NotebookApp] zmq message arrived on closed channel
[W 05:38:16.054 NotebookApp] zmq message arrived on closed channel
[W 05:38:16.054 NotebookApp] zmq message arrived on closed channel
[W 05:38:16.054 NotebookApp] zmq message arrived on closed channel
[W 05:38:16.055 NotebookApp] zmq message arrived on closed channel
taxiFence: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[101] at filter at <console>:33
<console>:1: error: illegal start of definition
           .filter(_.split(",")(3).toDouble<40.86)
           ^
[W 05:38:16.248 NotebookApp] zmq message arrived on closed channel
[W 05:38:16.248 NotebookApp] zmq message arrived on closed channel
[W 05:38:16.249 NotebookApp] zmq message arrived on closed channel
[W 05:38:16.249 NotebookApp] zmq message arrived on closed channel
[W 05:38:16.249 NotebookApp] zmq message arrived on closed channel
[W 05:38:16.250 NotebookApp] zmq message arrived on closed channel
[W 05:38:16.250 NotebookApp] zmq message arrived on closed channel
[W 05:38:16.251 NotebookApp] zmq message arrived on closed channel
[W 05:38:16.251 NotebookApp] zmq message arrived on closed channel
[W 05:38:16.251 NotebookApp] zmq message arrived on closed channel
[W 05:38:16.251 NotebookApp] zmq message arrived on closed channel
[W 05:38:16.251 NotebookApp] zmq message arrived on closed channel
[W 05:38:20.358 NotebookApp] zmq message arrived on closed channel
[W 05:38:20.358 NotebookApp] zmq message arrived on closed channel
[W 05:38:20.359 NotebookApp] zmq message arrived on closed channel
[W 05:38:20.359 NotebookApp] zmq message arrived on closed channel
[W 05:38:20.359 NotebookApp] zmq message arrived on closed channel
[W 05:38:20.359 NotebookApp] zmq message arrived on closed channel
[W 05:38:20.360 NotebookApp] zmq message arrived on closed channel
[W 05:38:20.360 NotebookApp] zmq message arrived on closed channel
[W 05:38:20.361 NotebookApp] zmq message arrived on closed channel
[W 05:38:20.361 NotebookApp] zmq message arrived on closed channel
[W 05:38:20.361 NotebookApp] zmq message arrived on closed channel
[W 05:38:20.361 NotebookApp] zmq message arrived on closed channel
taxiFence: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[105] at filter at <console>:36
[W 05:38:20.606 NotebookApp] zmq message arrived on closed channel
[W 05:38:20.607 NotebookApp] zmq message arrived on closed channel
[W 05:38:20.607 NotebookApp] zmq message arrived on closed channel
[W 05:38:20.608 NotebookApp] zmq message arrived on closed channel
[W 05:38:20.608 NotebookApp] zmq message arrived on closed channel
[W 05:38:20.608 NotebookApp] zmq message arrived on closed channel
[W 05:38:22.233 NotebookApp] zmq message arrived on closed channel
[W 05:38:22.234 NotebookApp] zmq message arrived on closed channel
[W 05:38:22.234 NotebookApp] zmq message arrived on closed channel
[W 05:38:22.234 NotebookApp] zmq message arrived on closed channel
[W 05:38:22.235 NotebookApp] zmq message arrived on closed channel
[W 05:38:22.235 NotebookApp] zmq message arrived on closed channel
[W 05:38:22.235 NotebookApp] zmq message arrived on closed channel
[W 05:38:22.236 NotebookApp] zmq message arrived on closed channel
[W 05:38:22.236 NotebookApp] zmq message arrived on closed channel
[W 05:38:22.236 NotebookApp] zmq message arrived on closed channel
[W 05:38:22.236 NotebookApp] zmq message arrived on closed channel
[W 05:38:22.237 NotebookApp] zmq message arrived on closed channel
[Stage 89:===================>                                      (1 + 2) / 3][Stage 90:===================>                res137: Long = 206646
[W 05:38:23.511 NotebookApp] zmq message arrived on closed channel
[W 05:38:23.512 NotebookApp] zmq message arrived on closed channel
[W 05:38:23.512 NotebookApp] zmq message arrived on closed channel
[W 05:38:23.512 NotebookApp] zmq message arrived on closed channel
[W 05:38:23.513 NotebookApp] zmq message arrived on closed channel
[W 05:38:23.513 NotebookApp] zmq message arrived on closed channel
[W 05:38:23.514 NotebookApp] zmq message arrived on closed channel
[W 05:38:23.514 NotebookApp] zmq message arrived on closed channel
[W 05:38:23.514 NotebookApp] zmq message arrived on closed channel
[W 05:38:23.514 NotebookApp] zmq message arrived on closed channel
[W 05:38:23.514 NotebookApp] zmq message arrived on closed channel
[W 05:38:23.515 NotebookApp] zmq message arrived on closed channel
[W 05:38:23.515 NotebookApp] zmq message arrived on closed channel
[W 05:38:23.516 NotebookApp] zmq message arrived on closed channel
[W 05:38:23.516 NotebookApp] zmq message arrived on closed channel
[W 05:38:23.516 NotebookApp] zmq message arrived on closed channel
[W 05:38:23.516 NotebookApp] zmq message arrived on closed channel
[W 05:38:23.517 NotebookApp] zmq message arrived on closed channel
[W 05:38:38.181 NotebookApp] zmq message arrived on closed channel
[W 05:38:38.181 NotebookApp] zmq message arrived on closed channel
[W 05:38:38.181 NotebookApp] zmq message arrived on closed channel
[W 05:38:38.181 NotebookApp] zmq message arrived on closed channel
[W 05:38:38.182 NotebookApp] zmq message arrived on closed channel
[W 05:38:38.182 NotebookApp] zmq message arrived on closed channel
[W 05:38:38.182 NotebookApp] zmq message arrived on closed channel
[W 05:38:38.182 NotebookApp] zmq message arrived on closed channel
[W 05:38:38.183 NotebookApp] zmq message arrived on closed channel
[W 05:38:38.183 NotebookApp] zmq message arrived on closed channel
[W 05:38:38.184 NotebookApp] zmq message arrived on closed channel
[W 05:38:38.184 NotebookApp] zmq message arrived on closed channel
taxi: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[106] at map at <console>:36
[W 05:38:38.570 NotebookApp] zmq message arrived on closed channel
[W 05:38:38.571 NotebookApp] zmq message arrived on closed channel
[W 05:38:38.571 NotebookApp] zmq message arrived on closed channel
[W 05:38:38.571 NotebookApp] zmq message arrived on closed channel
[W 05:38:38.572 NotebookApp] zmq message arrived on closed channel
[W 05:38:38.572 NotebookApp] zmq message arrived on closed channel
[W 05:38:51.304 NotebookApp] zmq message arrived on closed channel
[W 05:38:51.304 NotebookApp] zmq message arrived on closed channel
[W 05:38:51.305 NotebookApp] zmq message arrived on closed channel
[W 05:38:51.305 NotebookApp] zmq message arrived on closed channel
[W 05:38:51.305 NotebookApp] zmq message arrived on closed channel
[W 05:38:51.305 NotebookApp] zmq message arrived on closed channel
[W 05:38:51.306 NotebookApp] zmq message arrived on closed channel
[W 05:38:51.306 NotebookApp] zmq message arrived on closed channel
[W 05:38:51.306 NotebookApp] zmq message arrived on closed channel
[W 05:38:51.307 NotebookApp] zmq message arrived on closed channel
[W 05:38:51.307 NotebookApp] zmq message arrived on closed channel
[W 05:38:51.307 NotebookApp] zmq message arrived on closed channel
iterationCount: Int = 10
clusterCount: Int = 3
15/10/22 05:38:51 [WARN] o.a.s.m.c.KMeans - The input data is not directly cached, which may hurt performance if its parent RDDs are also uncached.
                      (1 + 2) / 3][Stage 91:>                                                         (0 + 3) / 3][Stage 91:==[W 05:38:55.152 NotebookApp] zmq message arrived on closed channel
[W 05:38:55.152 NotebookApp] zmq message arrived on closed channel
[W 05:38:55.152 NotebookApp] zmq message arrived on closed channel
[W 05:38:55.152 NotebookApp] zmq message arrived on closed channel
[W 05:38:55.153 NotebookApp] zmq message arrived on closed channel
[W 05:38:55.153 NotebookApp] zmq message arrived on closed channel
=================>                                      (1 + 2) / 3][Stage 92:===================>                             [W 05:38:56.665 NotebookApp] zmq message arrived on closed channel
[W 05:38:56.665 NotebookApp] zmq message arrived on closed channel
[W 05:38:56.665 NotebookApp] zmq message arrived on closed channel
[W 05:38:56.666 NotebookApp] zmq message arrived on closed channel
[W 05:38:56.666 NotebookApp] zmq message arrived on closed channel
[W 05:38:56.666 NotebookApp] zmq message arrived on closed channel
15/10/22 05:38:57 [WARN] c.g.f.n.BLAS - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
15/10/22 05:38:57 [WARN] c.g.f.n.BLAS - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
         (1 + 2) / 3][Stage 93:>                                                         (0 + 3) / 3][Stage 93:===============[W 05:39:00.179 NotebookApp] zmq message arrived on closed channel
[W 05:39:00.180 NotebookApp] zmq message arrived on closed channel
[W 05:39:00.180 NotebookApp] zmq message arrived on closed channel
[W 05:39:00.180 NotebookApp] zmq message arrived on closed channel
[W 05:39:00.180 NotebookApp] zmq message arrived on closed channel
[W 05:39:00.180 NotebookApp] zmq message arrived on closed channel
====>                                      (1 + 2) / 3][Stage 94:>                                                         (0 +[W 05:39:01.738 NotebookApp] zmq message arrived on closed channel
[W 05:39:01.738 NotebookApp] zmq message arrived on closed channel
[W 05:39:01.738 NotebookApp] zmq message arrived on closed channel
[W 05:39:01.738 NotebookApp] zmq message arrived on closed channel
[W 05:39:01.739 NotebookApp] zmq message arrived on closed channel
[W 05:39:01.739 NotebookApp] zmq message arrived on closed channel
 3) / 3][Stage 94:===================>                                      (1 + 2) / 3][Stage 95:===================>        [W 05:39:03.334 NotebookApp] zmq message arrived on closed channel
[W 05:39:03.334 NotebookApp] zmq message arrived on closed channel
[W 05:39:03.335 NotebookApp] zmq message arrived on closed channel
[W 05:39:03.335 NotebookApp] zmq message arrived on closed channel
[W 05:39:03.335 NotebookApp] zmq message arrived on closed channel
[W 05:39:03.336 NotebookApp] zmq message arrived on closed channel
[W 05:39:04.839 NotebookApp] zmq message arrived on closed channel
[W 05:39:04.840 NotebookApp] zmq message arrived on closed channel
[W 05:39:04.840 NotebookApp] zmq message arrived on closed channel
[W 05:39:04.840 NotebookApp] zmq message arrived on closed channel
[W 05:39:04.841 NotebookApp] zmq message arrived on closed channel
[W 05:39:04.841 NotebookApp] zmq message arrived on closed channel
                              (1 + 2) / 3][Stage 96:===================>                                      (1 + 2) / 3][Stage 97:>                                                         (0 + 3) / 3][Stage 97:===================>                     [W 05:39:06.448 NotebookApp] zmq message arrived on closed channel
[W 05:39:06.449 NotebookApp] zmq message arrived on closed channel
[W 05:39:06.449 NotebookApp] zmq message arrived on closed channel
[W 05:39:06.450 NotebookApp] zmq message arrived on closed channel
[W 05:39:06.450 NotebookApp] zmq message arrived on closed channel
[W 05:39:06.450 NotebookApp] zmq message arrived on closed channel
                 (1 + 2) / 3][Stage 98:>                                                         (0 + 3) / 3][Stage 98:=======[I 05:39:07.723 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 05:39:07.952 NotebookApp] zmq message arrived on closed channel
[W 05:39:07.952 NotebookApp] zmq message arrived on closed channel
[W 05:39:07.953 NotebookApp] zmq message arrived on closed channel
[W 05:39:07.953 NotebookApp] zmq message arrived on closed channel
[W 05:39:07.953 NotebookApp] zmq message arrived on closed channel
[W 05:39:07.953 NotebookApp] zmq message arrived on closed channel
============>                                      (1 + 2) / 3][Stage 99:===================>                                  [W 05:39:09.561 NotebookApp] zmq message arrived on closed channel
[W 05:39:09.561 NotebookApp] zmq message arrived on closed channel
[W 05:39:09.561 NotebookApp] zmq message arrived on closed channel
[W 05:39:09.561 NotebookApp] zmq message arrived on closed channel
[W 05:39:09.562 NotebookApp] zmq message arrived on closed channel
[W 05:39:09.562 NotebookApp] zmq message arrived on closed channel
[W 05:39:11.054 NotebookApp] zmq message arrived on closed channel
[W 05:39:11.054 NotebookApp] zmq message arrived on closed channel
[W 05:39:11.054 NotebookApp] zmq message arrived on closed channel
[W 05:39:11.054 NotebookApp] zmq message arrived on closed channel
[W 05:39:11.055 NotebookApp] zmq message arrived on closed channel
[W 05:39:11.055 NotebookApp] zmq message arrived on closed channel
    (1 + 2) / 3][Stage 100:===================>                                     (1 + 2) / 3][Stage 101:>                                                        (0 + 3) / 3][Stage 101:===================>                                     (1 + 2) /[W 05:39:12.719 NotebookApp] zmq message arrived on closed channel
[W 05:39:12.720 NotebookApp] zmq message arrived on closed channel
[W 05:39:12.720 NotebookApp] zmq message arrived on closed channel
[W 05:39:12.720 NotebookApp] zmq message arrived on closed channel
[W 05:39:12.721 NotebookApp] zmq message arrived on closed channel
[W 05:39:12.721 NotebookApp] zmq message arrived on closed channel
[W 05:39:14.254 NotebookApp] zmq message arrived on closed channel
[W 05:39:14.255 NotebookApp] zmq message arrived on closed channel
[W 05:39:14.255 NotebookApp] zmq message arrived on closed channel
[W 05:39:14.255 NotebookApp] zmq message arrived on closed channel
[W 05:39:14.256 NotebookApp] zmq message arrived on closed channel
[W 05:39:14.256 NotebookApp] zmq message arrived on closed channel
 3][Stage 102:===================>                                     (1 + 2) / 3][Stage 103:>                               [W 05:39:15.957 NotebookApp] zmq message arrived on closed channel
[W 05:39:15.958 NotebookApp] zmq message arrived on closed channel
[W 05:39:15.959 NotebookApp] zmq message arrived on closed channel
[W 05:39:15.959 NotebookApp] zmq message arrived on closed channel
[W 05:39:15.959 NotebookApp] zmq message arrived on closed channel
[W 05:39:15.959 NotebookApp] zmq message arrived on closed channel
                         (0 + 3) / 3][Stage 103:===================>                                     (1 + 2) / 3][Stage 10[W 05:39:17.682 NotebookApp] zmq message arrived on closed channel
[W 05:39:17.683 NotebookApp] zmq message arrived on closed channel
[W 05:39:17.683 NotebookApp] zmq message arrived on closed channel
[W 05:39:17.683 NotebookApp] zmq message arrived on closed channel
[W 05:39:17.683 NotebookApp] zmq message arrived on closed channel
[W 05:39:17.684 NotebookApp] zmq message arrived on closed channel
5:===================>                                     (1 + 2) / 3][Stage 107:===================>                         [W 05:39:19.237 NotebookApp] zmq message arrived on closed channel
[W 05:39:19.238 NotebookApp] zmq message arrived on closed channel
[W 05:39:19.238 NotebookApp] zmq message arrived on closed channel
[W 05:39:19.238 NotebookApp] zmq message arrived on closed channel
[W 05:39:19.238 NotebookApp] zmq message arrived on closed channel
[W 05:39:19.239 NotebookApp] zmq message arrived on closed channel
            (1 + 2) / 3][Stage 109:>                                                        (0 + 3) / 3][Stage 109:===========[W 05:39:20.756 NotebookApp] zmq message arrived on closed channel
[W 05:39:20.757 NotebookApp] zmq message arrived on closed channel
[W 05:39:20.757 NotebookApp] zmq message arrived on closed channel
[W 05:39:20.757 NotebookApp] zmq message arrived on closed channel
[W 05:39:20.757 NotebookApp] zmq message arrived on closed channel
[W 05:39:20.757 NotebookApp] zmq message arrived on closed channel
========>                                     (1 + 2) / 3][Stage 111:===================>                                     ([W 05:39:22.326 NotebookApp] zmq message arrived on closed channel
[W 05:39:22.327 NotebookApp] zmq message arrived on closed channel
[W 05:39:22.327 NotebookApp] zmq message arrived on closed channel
[W 05:39:22.327 NotebookApp] zmq message arrived on closed channel
[W 05:39:22.327 NotebookApp] zmq message arrived on closed channel
[W 05:39:22.327 NotebookApp] zmq message arrived on closed channel
[W 05:39:23.855 NotebookApp] zmq message arrived on closed channel
[W 05:39:23.855 NotebookApp] zmq message arrived on closed channel
[W 05:39:23.855 NotebookApp] zmq message arrived on closed channel
[W 05:39:23.855 NotebookApp] zmq message arrived on closed channel
[W 05:39:23.856 NotebookApp] zmq message arrived on closed channel
[W 05:39:23.856 NotebookApp] zmq message arrived on closed channel
1 + 2) / 3][Stage 113:===================>                                     (1 + 2) / 3][Stage 115:>                       [W 05:39:25.379 NotebookApp] zmq message arrived on closed channel
[W 05:39:25.379 NotebookApp] zmq message arrived on closed channel
[W 05:39:25.380 NotebookApp] zmq message arrived on closed channel
[W 05:39:25.380 NotebookApp] zmq message arrived on closed channel
[W 05:39:25.380 NotebookApp] zmq message arrived on closed channel
[W 05:39:25.380 NotebookApp] zmq message arrived on closed channel
                                 (0 + 3) / 3][Stage 115:===================>                                     (1 + 2) / 3][[W 05:39:26.921 NotebookApp] zmq message arrived on closed channel
[W 05:39:26.922 NotebookApp] zmq message arrived on closed channel
[W 05:39:26.922 NotebookApp] zmq message arrived on closed channel
[W 05:39:26.922 NotebookApp] zmq message arrived on closed channel
[W 05:39:26.922 NotebookApp] zmq message arrived on closed channel
[W 05:39:26.922 NotebookApp] zmq message arrived on closed channel
Stage 117:===================>                                     (1 + 2) / 3][Stage 119:===================>                 [W 05:39:28.435 NotebookApp] zmq message arrived on closed channel
[W 05:39:28.435 NotebookApp] zmq message arrived on closed channel
[W 05:39:28.435 NotebookApp] zmq message arrived on closed channel
[W 05:39:28.436 NotebookApp] zmq message arrived on closed channel
[W 05:39:28.436 NotebookApp] zmq message arrived on closed channel
[W 05:39:28.436 NotebookApp] zmq message arrived on closed channel
                    (1 + 2) / 3][Stage 121:>                                                        (0 + 3) / 3][Stage 121:===[W 05:39:29.957 NotebookApp] zmq message arrived on closed channel
[W 05:39:29.957 NotebookApp] zmq message arrived on closed channel
[W 05:39:29.957 NotebookApp] zmq message arrived on closed channel
[W 05:39:29.957 NotebookApp] zmq message arrived on closed channel
[W 05:39:29.957 NotebookApp] zmq message arrived on closed channel
[W 05:39:29.958 NotebookApp] zmq message arrived on closed channel
================>                                     (1 + 2) / 3][Stage 123:===================>                              15/10/22 05:39:31 [WARN] o.a.s.m.c.KMeans - The input data was not directly cached, which may hurt performance if its parent RDDs are also uncached.
model: org.apache.spark.mllib.clustering.KMeansModel = org.apache.spark.mllib.clustering.KMeansModel@573d591d
[W 05:39:31.484 NotebookApp] zmq message arrived on closed channel
[W 05:39:31.484 NotebookApp] zmq message arrived on closed channel
[W 05:39:31.484 NotebookApp] zmq message arrived on closed channel
[W 05:39:31.484 NotebookApp] zmq message arrived on closed channel
[W 05:39:31.485 NotebookApp] zmq message arrived on closed channel
[W 05:39:31.485 NotebookApp] zmq message arrived on closed channel
clusterCenters: Array[Array[Double]] = Array(Array(40.72539489084507, -73.99574932051978), Array(40.75754897430462, -73.98029654669773), Array(40.78790914440758, -73.9567216210427))
cost: Double = 63.28637438362519
[W 05:39:33.593 NotebookApp] zmq message arrived on closed channel
[W 05:39:33.593 NotebookApp] zmq message arrived on closed channel
[W 05:39:33.593 NotebookApp] zmq message arrived on closed channel
[W 05:39:33.593 NotebookApp] zmq message arrived on closed channel
[W 05:39:33.594 NotebookApp] zmq message arrived on closed channel
[W 05:39:33.594 NotebookApp] zmq message arrived on closed channel
[W 05:39:33.816 NotebookApp] zmq message arrived on closed channel
[W 05:39:33.816 NotebookApp] zmq message arrived on closed channel
[W 05:39:33.817 NotebookApp] zmq message arrived on closed channel
[W 05:39:33.817 NotebookApp] zmq message arrived on closed channel
[W 05:39:33.817 NotebookApp] zmq message arrived on closed channel
[W 05:39:33.817 NotebookApp] zmq message arrived on closed channel
[W 05:39:33.824 NotebookApp] zmq message arrived on closed channel
[W 05:39:33.824 NotebookApp] zmq message arrived on closed channel
[W 05:39:33.825 NotebookApp] zmq message arrived on closed channel
[W 05:39:33.825 NotebookApp] zmq message arrived on closed channel
[W 05:39:33.825 NotebookApp] zmq message arrived on closed channel
[W 05:39:33.826 NotebookApp] zmq message arrived on closed channel
[I 05:41:08.270 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 05:41:43.079 NotebookApp] zmq message arrived on closed channel
[W 05:41:43.079 NotebookApp] zmq message arrived on closed channel
[W 05:41:43.079 NotebookApp] zmq message arrived on closed channel
[W 05:41:43.080 NotebookApp] zmq message arrived on closed channel
[W 05:41:43.080 NotebookApp] zmq message arrived on closed channel
[W 05:41:43.081 NotebookApp] zmq message arrived on closed channel
[W 05:41:43.081 NotebookApp] zmq message arrived on closed channel
[W 05:41:43.082 NotebookApp] zmq message arrived on closed channel
[W 05:41:43.082 NotebookApp] zmq message arrived on closed channel
[W 05:41:43.082 NotebookApp] zmq message arrived on closed channel
[W 05:41:43.083 NotebookApp] zmq message arrived on closed channel
[W 05:41:43.083 NotebookApp] zmq message arrived on closed channel
[W 05:41:43.084 NotebookApp] zmq message arrived on closed channel
[W 05:41:43.084 NotebookApp] zmq message arrived on closed channel
[W 05:41:59.251 NotebookApp] zmq message arrived on closed channel
[W 05:41:59.252 NotebookApp] zmq message arrived on closed channel
[W 05:41:59.252 NotebookApp] zmq message arrived on closed channel
[W 05:41:59.253 NotebookApp] zmq message arrived on closed channel
[W 05:41:59.253 NotebookApp] zmq message arrived on closed channel
[W 05:41:59.253 NotebookApp] zmq message arrived on closed channel
[W 05:41:59.254 NotebookApp] zmq message arrived on closed channel
[W 05:41:59.254 NotebookApp] zmq message arrived on closed channel
[W 05:41:59.254 NotebookApp] zmq message arrived on closed channel
[W 05:41:59.254 NotebookApp] zmq message arrived on closed channel
[W 05:41:59.255 NotebookApp] zmq message arrived on closed channel
[W 05:41:59.255 NotebookApp] zmq message arrived on closed channel
[W 05:41:59.256 NotebookApp] zmq message arrived on closed channel
[W 05:41:59.256 NotebookApp] zmq message arrived on closed channel
[W 05:41:59.303 NotebookApp] zmq message arrived on closed channel
[W 05:41:59.303 NotebookApp] zmq message arrived on closed channel
[W 05:41:59.303 NotebookApp] zmq message arrived on closed channel
[W 05:41:59.304 NotebookApp] zmq message arrived on closed channel
[W 05:41:59.304 NotebookApp] zmq message arrived on closed channel
[W 05:41:59.304 NotebookApp] zmq message arrived on closed channel
[W 05:41:59.304 NotebookApp] zmq message arrived on closed channel
[I 05:42:05.568 NotebookApp] Request shutdown_kernel: d815d372-19b2-4620-80b3-1126c94b76ff, <IPython.kernel.ioloop.manager.IOLoopKernelManager object at 0x7fd6315a5250>
15/10/22 05:42:05 INFO SparkUI: Stopped Spark web UI at http://172.17.0.22:4043
15/10/22 05:42:05 INFO DAGScheduler: Stopping DAGScheduler
15/10/22 05:42:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/10/22 05:42:05 INFO Utils: path = /tmp/spark-682ea8cc-d28a-4715-be6e-9c2bdc684ba4/blockmgr-73dbe021-6e2b-43f9-9547-72004cf3a221, already present as root for deletion.
15/10/22 05:42:05 INFO MemoryStore: MemoryStore cleared
15/10/22 05:42:05 INFO BlockManager: BlockManager stopped
15/10/22 05:42:05 INFO BlockManagerMaster: BlockManagerMaster stopped
15/10/22 05:42:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/10/22 05:42:05 INFO SparkContext: Successfully stopped SparkContext
15/10/22 05:42:05 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/10/22 05:42:05 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/10/22 05:42:05 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
15/10/22 05:42:06 INFO Utils: Shutdown hook called
15/10/22 05:42:06 INFO Utils: Deleting directory /tmp/spark-682ea8cc-d28a-4715-be6e-9c2bdc684ba4
[I 05:42:06.571 NotebookApp] Kernel shutdown: d815d372-19b2-4620-80b3-1126c94b76ff
[W 05:42:06.575 NotebookApp] zmq message arrived on closed channel
[W 05:42:06.575 NotebookApp] zmq message arrived on closed channel
[W 05:42:06.576 NotebookApp] zmq message arrived on closed channel
[W 05:42:06.576 NotebookApp] zmq message arrived on closed channel
[W 05:42:06.576 NotebookApp] zmq message arrived on closed channel
[W 05:42:06.576 NotebookApp] zmq message arrived on closed channel
[W 05:42:06.576 NotebookApp] zmq message arrived on closed channel
[W 05:42:06.577 NotebookApp] zmq message arrived on closed channel
[W 05:42:06.577 NotebookApp] zmq message arrived on closed channel
[W 05:42:06.577 NotebookApp] zmq message arrived on closed channel
[W 05:42:06.577 NotebookApp] zmq message arrived on closed channel
[W 05:42:06.577 NotebookApp] zmq message arrived on closed channel
[W 05:42:06.578 NotebookApp] zmq message arrived on closed channel
[W 05:42:06.578 NotebookApp] zmq message arrived on closed channel
[W 05:42:06.578 NotebookApp] zmq message arrived on closed channel
[W 05:42:06.578 NotebookApp] zmq message arrived on closed channel
[W 05:42:06.578 NotebookApp] zmq message arrived on closed channel
[W 05:42:06.579 NotebookApp] zmq message arrived on closed channel
[W 05:42:06.579 NotebookApp] zmq message arrived on closed channel
[W 05:42:06.579 NotebookApp] zmq message arrived on closed channel
[W 05:42:06.579 NotebookApp] zmq message arrived on closed channel
[W 05:42:51.304 NotebookApp] Notebook RedRock Original0.ipynb is not trusted
[I 05:42:54.826 NotebookApp] Request start_kernel: kernel_id=None, kernel_name=None, path="", **kwargs={}
[I 05:42:54.826 NotebookApp] Provisioning local kernel: None
[I 05:42:54.880 NotebookApp] Kernel started: cc9df352-9d3c-48d4-9781-ebbf9d930af2
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/22 05:42:58 INFO SparkContext: Running Spark version 1.4.1
15/10/22 05:42:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/22 05:42:58 INFO SecurityManager: Changing view acls to: notebook
15/10/22 05:42:58 INFO SecurityManager: Changing modify acls to: notebook
15/10/22 05:42:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
15/10/22 05:42:59 INFO Slf4jLogger: Slf4jLogger started
15/10/22 05:42:59 INFO Remoting: Starting remoting
15/10/22 05:42:59 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.22:32997]
15/10/22 05:42:59 INFO Utils: Successfully started service 'sparkDriver' on port 32997.
15/10/22 05:42:59 INFO SparkEnv: Registering MapOutputTracker
15/10/22 05:42:59 INFO SparkEnv: Registering BlockManagerMaster
15/10/22 05:42:59 INFO DiskBlockManager: Created local directory at /tmp/spark-cf71c18f-eb1b-4344-8525-a2574c650a59/blockmgr-6da140df-5530-460e-a154-b780fb3839ff
15/10/22 05:42:59 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/10/22 05:43:00 INFO HttpFileServer: HTTP File server directory is /tmp/spark-cf71c18f-eb1b-4344-8525-a2574c650a59/httpd-5a4d1c53-dd5f-4d13-8f82-fb56ecc67896
15/10/22 05:43:00 INFO HttpServer: Starting HTTP Server
15/10/22 05:43:00 INFO Utils: Successfully started service 'HTTP file server' on port 58378.
15/10/22 05:43:00 INFO SparkEnv: Registering OutputCommitCoordinator
15/10/22 05:43:00 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/10/22 05:43:00 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
15/10/22 05:43:00 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
15/10/22 05:43:00 INFO Utils: Successfully started service 'SparkUI' on port 4043.
15/10/22 05:43:00 INFO SparkUI: Started SparkUI at http://172.17.0.22:4043
15/10/22 05:43:00 INFO Executor: Starting executor ID driver on host localhost
15/10/22 05:43:00 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39140.
15/10/22 05:43:00 INFO NettyBlockTransferService: Server created on 39140
15/10/22 05:43:00 INFO BlockManagerMaster: Trying to register BlockManager
15/10/22 05:43:00 INFO BlockManagerMasterEndpoint: Registering block manager localhost:39140 with 265.4 MB RAM, BlockManagerId(driver, localhost, 39140)
15/10/22 05:43:00 INFO BlockManagerMaster: Registered BlockManager
[I 05:44:02.338 NotebookApp] Request shutdown_kernel: cc9df352-9d3c-48d4-9781-ebbf9d930af2, <IPython.kernel.ioloop.manager.IOLoopKernelManager object at 0x7fd630c32910>
15/10/22 05:44:02 INFO SparkUI: Stopped Spark web UI at http://172.17.0.22:4043
15/10/22 05:44:02 INFO DAGScheduler: Stopping DAGScheduler
15/10/22 05:44:02 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/10/22 05:44:02 INFO Utils: path = /tmp/spark-cf71c18f-eb1b-4344-8525-a2574c650a59/blockmgr-6da140df-5530-460e-a154-b780fb3839ff, already present as root for deletion.
15/10/22 05:44:02 INFO MemoryStore: MemoryStore cleared
15/10/22 05:44:02 INFO BlockManager: BlockManager stopped
15/10/22 05:44:02 INFO BlockManagerMaster: BlockManagerMaster stopped
15/10/22 05:44:02 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/10/22 05:44:02 INFO SparkContext: Successfully stopped SparkContext
15/10/22 05:44:02 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/10/22 05:44:02 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/10/22 05:44:02 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
15/10/22 05:44:03 INFO Utils: Shutdown hook called
15/10/22 05:44:03 INFO Utils: Deleting directory /tmp/spark-cf71c18f-eb1b-4344-8525-a2574c650a59
[I 05:44:03.346 NotebookApp] Kernel shutdown: cc9df352-9d3c-48d4-9781-ebbf9d930af2
[W 05:44:16.517 NotebookApp] Notebook Old Test.ipynb is not trusted
[I 05:44:23.610 NotebookApp] Request shutdown_kernel: dd7acff1-b1b3-4bdc-821c-9bb42891498c, <IPython.kernel.ioloop.manager.IOLoopKernelManager object at 0x7fd6317cb510>
15/10/22 05:44:23 INFO SparkUI: Stopped Spark web UI at http://172.17.0.22:4046
15/10/22 05:44:23 INFO DAGScheduler: Stopping DAGScheduler
15/10/22 05:44:23 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/10/22 05:44:23 INFO Utils: path = /tmp/spark-b42d68f2-0d81-418e-bccc-425aa078bfd3/blockmgr-822dc396-71cd-4fe2-893d-9f536687422a, already present as root for deletion.
15/10/22 05:44:23 INFO MemoryStore: MemoryStore cleared
15/10/22 05:44:23 INFO BlockManager: BlockManager stopped
15/10/22 05:44:23 INFO BlockManagerMaster: BlockManagerMaster stopped
15/10/22 05:44:23 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/10/22 05:44:23 INFO SparkContext: Successfully stopped SparkContext
15/10/22 05:44:23 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/10/22 05:44:23 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/10/22 05:44:23 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
15/10/22 05:44:24 INFO Utils: Shutdown hook called
15/10/22 05:44:24 INFO Utils: Deleting directory /tmp/spark-b42d68f2-0d81-418e-bccc-425aa078bfd3
[I 05:44:24.213 NotebookApp] Kernel shutdown: dd7acff1-b1b3-4bdc-821c-9bb42891498c
[W 05:44:28.401 NotebookApp] zmq message arrived on closed channel
[W 05:44:28.402 NotebookApp] zmq message arrived on closed channel
[W 05:44:28.402 NotebookApp] zmq message arrived on closed channel
[W 05:44:28.402 NotebookApp] zmq message arrived on closed channel
[W 05:44:28.403 NotebookApp] zmq message arrived on closed channel
[W 05:44:28.404 NotebookApp] zmq message arrived on closed channel
[W 05:44:28.404 NotebookApp] zmq message arrived on closed channel
[W 05:44:28.405 NotebookApp] zmq message arrived on closed channel
[W 05:44:28.405 NotebookApp] zmq message arrived on closed channel
[W 05:44:28.405 NotebookApp] zmq message arrived on closed channel
[I 05:44:31.472 NotebookApp] Request shutdown_kernel: c7f66d04-76bc-4f9a-a9f8-a47936dc6ef0, <IPython.kernel.ioloop.manager.IOLoopKernelManager object at 0x7fd6315aee10>
15/10/22 05:44:31 INFO SparkUI: Stopped Spark web UI at http://172.17.0.22:4041
15/10/22 05:44:31 INFO DAGScheduler: Stopping DAGScheduler
15/10/22 05:44:31 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/10/22 05:44:31 INFO Utils: path = /tmp/spark-0f142b40-8af5-41a7-b3fc-b03c2392bf8f/blockmgr-fb8c79d9-cb49-4e14-9eae-02211819594f, already present as root for deletion.
15/10/22 05:44:31 INFO MemoryStore: MemoryStore cleared
15/10/22 05:44:31 INFO BlockManager: BlockManager stopped
15/10/22 05:44:31 INFO BlockManagerMaster: BlockManagerMaster stopped
15/10/22 05:44:31 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/10/22 05:44:31 INFO SparkContext: Successfully stopped SparkContext
15/10/22 05:44:31 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/10/22 05:44:31 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/10/22 05:44:31 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
15/10/22 05:44:32 INFO Utils: Shutdown hook called
15/10/22 05:44:32 INFO Utils: Deleting directory /tmp/spark-0f142b40-8af5-41a7-b3fc-b03c2392bf8f/pyspark-9e9ff3f6-2e32-4570-ae7a-22a651278319
15/10/22 05:44:32 INFO Utils: Deleting directory /tmp/spark-0f142b40-8af5-41a7-b3fc-b03c2392bf8f
[I 05:44:32.275 NotebookApp] Kernel shutdown: c7f66d04-76bc-4f9a-a9f8-a47936dc6ef0
[W 05:44:32.281 NotebookApp] zmq message arrived on closed channel
[W 05:44:32.281 NotebookApp] zmq message arrived on closed channel
[W 05:44:32.281 NotebookApp] zmq message arrived on closed channel
[W 05:44:32.281 NotebookApp] zmq message arrived on closed channel
[W 05:44:32.281 NotebookApp] zmq message arrived on closed channel
[W 05:44:32.282 NotebookApp] zmq message arrived on closed channel
[W 05:44:32.282 NotebookApp] zmq message arrived on closed channel
[W 05:44:32.283 NotebookApp] zmq message arrived on closed channel
[W 05:44:32.283 NotebookApp] zmq message arrived on closed channel
[W 05:44:32.283 NotebookApp] zmq message arrived on closed channel
[W 05:44:32.283 NotebookApp] zmq message arrived on closed channel
[W 05:44:32.284 NotebookApp] zmq message arrived on closed channel
[W 05:44:32.284 NotebookApp] zmq message arrived on closed channel
[W 05:44:32.284 NotebookApp] zmq message arrived on closed channel
[W 05:44:32.284 NotebookApp] zmq message arrived on closed channel
[W 05:44:38.297 NotebookApp] zmq message arrived on closed channel
[W 05:44:38.298 NotebookApp] zmq message arrived on closed channel
[I 05:44:42.493 NotebookApp] Request shutdown_kernel: 9ab2bb2a-9020-44b0-a340-2de993f0e0ea, <IPython.kernel.ioloop.manager.IOLoopKernelManager object at 0x7fd6315df0d0>
15/10/22 05:44:42 INFO SparkUI: Stopped Spark web UI at http://172.17.0.22:4050
15/10/22 05:44:42 INFO DAGScheduler: Stopping DAGScheduler
15/10/22 05:44:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/10/22 05:44:42 INFO Utils: path = /tmp/spark-9b53112a-7587-40b2-875d-52372b9f0213/blockmgr-ff3b1fac-22e5-4969-8e3a-2aecbf2c0dcc, already present as root for deletion.
15/10/22 05:44:42 INFO MemoryStore: MemoryStore cleared
15/10/22 05:44:42 INFO BlockManager: BlockManager stopped
15/10/22 05:44:42 INFO BlockManagerMaster: BlockManagerMaster stopped
15/10/22 05:44:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/10/22 05:44:42 INFO SparkContext: Successfully stopped SparkContext
15/10/22 05:44:42 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/10/22 05:44:42 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/10/22 05:44:42 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
15/10/22 05:44:43 INFO Utils: Shutdown hook called
15/10/22 05:44:43 INFO Utils: Deleting directory /tmp/spark-9b53112a-7587-40b2-875d-52372b9f0213/pyspark-00ef6c66-4db7-4741-b890-7647fc2d4f76
15/10/22 05:44:43 INFO Utils: Deleting directory /tmp/spark-9b53112a-7587-40b2-875d-52372b9f0213
[I 05:44:43.497 NotebookApp] Kernel shutdown: 9ab2bb2a-9020-44b0-a340-2de993f0e0ea
[W 05:44:43.502 NotebookApp] zmq message arrived on closed channel
[W 05:44:43.502 NotebookApp] zmq message arrived on closed channel
[W 05:44:43.502 NotebookApp] zmq message arrived on closed channel
[I 05:44:52.175 NotebookApp] Request start_kernel: kernel_id=None, kernel_name=python2, path="", **kwargs={}
[I 05:44:52.175 NotebookApp] Provisioning local kernel: python2
[I 05:44:52.228 NotebookApp] Kernel started: 6dc2a32e-e64f-496a-a422-867f81e85e82
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/22 05:44:55 INFO SparkContext: Running Spark version 1.4.1
15/10/22 05:44:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/22 05:44:55 INFO SecurityManager: Changing view acls to: notebook
15/10/22 05:44:55 INFO SecurityManager: Changing modify acls to: notebook
15/10/22 05:44:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
15/10/22 05:44:56 INFO Slf4jLogger: Slf4jLogger started
15/10/22 05:44:56 INFO Remoting: Starting remoting
15/10/22 05:44:57 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.22:46937]
15/10/22 05:44:57 INFO Utils: Successfully started service 'sparkDriver' on port 46937.
15/10/22 05:44:57 INFO SparkEnv: Registering MapOutputTracker
15/10/22 05:44:57 INFO SparkEnv: Registering BlockManagerMaster
15/10/22 05:44:57 INFO DiskBlockManager: Created local directory at /tmp/spark-a1ac4ef9-edbb-4d59-84b1-fb6158dd824f/blockmgr-e7a8bf00-0701-4cb7-a835-b8448d9fe79c
15/10/22 05:44:57 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/10/22 05:44:57 INFO HttpFileServer: HTTP File server directory is /tmp/spark-a1ac4ef9-edbb-4d59-84b1-fb6158dd824f/httpd-91230dd5-3f29-4655-906e-228bc7bde472
15/10/22 05:44:57 INFO HttpServer: Starting HTTP Server
15/10/22 05:44:57 INFO Utils: Successfully started service 'HTTP file server' on port 50791.
15/10/22 05:44:57 INFO SparkEnv: Registering OutputCommitCoordinator
15/10/22 05:44:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/10/22 05:44:57 INFO Utils: Successfully started service 'SparkUI' on port 4041.
15/10/22 05:44:57 INFO SparkUI: Started SparkUI at http://172.17.0.22:4041
15/10/22 05:44:57 INFO Executor: Starting executor ID driver on host localhost
15/10/22 05:44:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37166.
15/10/22 05:44:57 INFO NettyBlockTransferService: Server created on 37166
15/10/22 05:44:57 INFO BlockManagerMaster: Trying to register BlockManager
15/10/22 05:44:57 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37166 with 265.4 MB RAM, BlockManagerId(driver, localhost, 37166)
15/10/22 05:44:57 INFO BlockManagerMaster: Registered BlockManager
[I 05:45:01.477 NotebookApp] Request shutdown_kernel: 6dc2a32e-e64f-496a-a422-867f81e85e82, <IPython.kernel.ioloop.manager.IOLoopKernelManager object at 0x7fd631524410>
15/10/22 05:45:01 INFO SparkUI: Stopped Spark web UI at http://172.17.0.22:4041
15/10/22 05:45:01 INFO DAGScheduler: Stopping DAGScheduler
15/10/22 05:45:01 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/10/22 05:45:01 INFO Utils: path = /tmp/spark-a1ac4ef9-edbb-4d59-84b1-fb6158dd824f/blockmgr-e7a8bf00-0701-4cb7-a835-b8448d9fe79c, already present as root for deletion.
15/10/22 05:45:01 INFO MemoryStore: MemoryStore cleared
15/10/22 05:45:01 INFO BlockManager: BlockManager stopped
15/10/22 05:45:01 INFO BlockManagerMaster: BlockManagerMaster stopped
15/10/22 05:45:01 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/10/22 05:45:01 INFO SparkContext: Successfully stopped SparkContext
15/10/22 05:45:01 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/10/22 05:45:01 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/10/22 05:45:01 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
15/10/22 05:45:02 INFO Utils: Shutdown hook called
15/10/22 05:45:02 INFO Utils: Deleting directory /tmp/spark-a1ac4ef9-edbb-4d59-84b1-fb6158dd824f/pyspark-c5a99eda-9137-401b-99a1-ffeae801f695
15/10/22 05:45:02 INFO Utils: Deleting directory /tmp/spark-a1ac4ef9-edbb-4d59-84b1-fb6158dd824f
[I 05:45:02.480 NotebookApp] Kernel shutdown: 6dc2a32e-e64f-496a-a422-867f81e85e82
[W 05:45:11.654 NotebookApp] Deprecated files/ URL: files/map.html
[I 05:45:11.655 NotebookApp] 302 GET /notebooks/files/map.html (172.17.0.29) 1.57ms
[I 05:47:17.075 NotebookApp] Saving file at /RedRock Update.ipynb
[I 05:48:07.388 NotebookApp] Request shutdown_kernel: c3da83e4-da41-46b6-931e-b02641be0d98, <IPython.kernel.ioloop.manager.IOLoopKernelManager object at 0x7fd631719b10>
15/10/22 05:48:07 INFO SparkUI: Stopped Spark web UI at http://172.17.0.22:4044
15/10/22 05:48:07 INFO DAGScheduler: Stopping DAGScheduler
15/10/22 05:48:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/10/22 05:48:07 INFO Utils: path = /tmp/spark-087dfd65-e3af-498d-9d22-e35dd3d35ef5/blockmgr-22d08b29-3ede-43e5-b659-7938c320c115, already present as root for deletion.
15/10/22 05:48:07 INFO MemoryStore: MemoryStore cleared
15/10/22 05:48:07 INFO BlockManager: BlockManager stopped
15/10/22 05:48:07 INFO BlockManagerMaster: BlockManagerMaster stopped
15/10/22 05:48:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/10/22 05:48:07 INFO SparkContext: Successfully stopped SparkContext
15/10/22 05:48:07 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/10/22 05:48:07 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/10/22 05:48:07 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
[I 05:48:08.408 NotebookApp] Kernel shutdown: c3da83e4-da41-46b6-931e-b02641be0d98
15/10/22 05:48:08 INFO Utils: Shutdown hook called
15/10/22 05:48:08 INFO Utils: Deleting directory /tmp/spark-087dfd65-e3af-498d-9d22-e35dd3d35ef5
[I 05:49:13.148 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[I 05:49:27.437 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 05:52:48.119 NotebookApp] zmq message arrived on closed channel
[W 05:52:48.120 NotebookApp] zmq message arrived on closed channel
[W 05:52:48.120 NotebookApp] zmq message arrived on closed channel
[W 05:52:48.121 NotebookApp] zmq message arrived on closed channel
[W 05:52:48.551 NotebookApp] zmq message arrived on closed channel
[W 05:52:48.551 NotebookApp] zmq message arrived on closed channel
[W 05:52:48.602 NotebookApp] zmq message arrived on closed channel
[W 05:52:48.603 NotebookApp] zmq message arrived on closed channel
[W 05:52:48.652 NotebookApp] zmq message arrived on closed channel
[W 05:52:48.653 NotebookApp] zmq message arrived on closed channel
[W 05:52:48.803 NotebookApp] zmq message arrived on closed channel
[W 05:52:48.804 NotebookApp] zmq message arrived on closed channel
[W 05:52:48.854 NotebookApp] zmq message arrived on closed channel
[W 05:52:48.855 NotebookApp] zmq message arrived on closed channel
[W 05:52:48.905 NotebookApp] zmq message arrived on closed channel
[W 05:52:48.906 NotebookApp] zmq message arrived on closed channel
[W 05:52:48.956 NotebookApp] zmq message arrived on closed channel
[W 05:52:48.956 NotebookApp] zmq message arrived on closed channel
[W 05:52:49.107 NotebookApp] zmq message arrived on closed channel
[W 05:52:49.108 NotebookApp] zmq message arrived on closed channel
[W 05:52:49.359 NotebookApp] zmq message arrived on closed channel
[W 05:52:49.360 NotebookApp] zmq message arrived on closed channel
[W 05:52:49.410 NotebookApp] zmq message arrived on closed channel
[W 05:52:49.411 NotebookApp] zmq message arrived on closed channel
[W 05:52:49.460 NotebookApp] zmq message arrived on closed channel
[W 05:52:49.461 NotebookApp] zmq message arrived on closed channel
[W 05:52:49.612 NotebookApp] zmq message arrived on closed channel
[W 05:52:49.612 NotebookApp] zmq message arrived on closed channel
[W 05:52:49.763 NotebookApp] zmq message arrived on closed channel
[W 05:52:49.763 NotebookApp] zmq message arrived on closed channel
[W 05:52:50.015 NotebookApp] zmq message arrived on closed channel
[W 05:52:50.015 NotebookApp] zmq message arrived on closed channel
[W 05:52:50.266 NotebookApp] zmq message arrived on closed channel
[W 05:52:50.267 NotebookApp] zmq message arrived on closed channel
[W 05:52:50.518 NotebookApp] zmq message arrived on closed channel
[W 05:52:50.519 NotebookApp] zmq message arrived on closed channel
[W 05:52:50.720 NotebookApp] zmq message arrived on closed channel
[W 05:52:50.721 NotebookApp] zmq message arrived on closed channel
[W 05:52:50.972 NotebookApp] zmq message arrived on closed channel
[W 05:52:50.973 NotebookApp] zmq message arrived on closed channel
[W 05:52:51.174 NotebookApp] zmq message arrived on closed channel
[W 05:52:51.175 NotebookApp] zmq message arrived on closed channel
[W 05:52:51.426 NotebookApp] zmq message arrived on closed channel
[W 05:52:51.427 NotebookApp] zmq message arrived on closed channel
[W 05:52:51.628 NotebookApp] zmq message arrived on closed channel
[W 05:52:51.629 NotebookApp] zmq message arrived on closed channel
[W 05:52:51.830 NotebookApp] zmq message arrived on closed channel
[W 05:52:51.831 NotebookApp] zmq message arrived on closed channel
[W 05:52:52.031 NotebookApp] zmq message arrived on closed channel
[W 05:52:52.032 NotebookApp] zmq message arrived on closed channel
[W 05:52:52.283 NotebookApp] zmq message arrived on closed channel
[W 05:52:52.284 NotebookApp] zmq message arrived on closed channel
[W 05:52:52.485 NotebookApp] zmq message arrived on closed channel
[W 05:52:52.486 NotebookApp] zmq message arrived on closed channel
[W 05:52:52.636 NotebookApp] zmq message arrived on closed channel
[W 05:52:52.637 NotebookApp] zmq message arrived on closed channel
[W 05:52:52.888 NotebookApp] zmq message arrived on closed channel
[W 05:52:52.889 NotebookApp] zmq message arrived on closed channel
[W 05:52:53.090 NotebookApp] zmq message arrived on closed channel
[W 05:52:53.091 NotebookApp] zmq message arrived on closed channel
[W 05:52:53.292 NotebookApp] zmq message arrived on closed channel
[W 05:52:53.293 NotebookApp] zmq message arrived on closed channel
[W 05:52:53.494 NotebookApp] zmq message arrived on closed channel
[W 05:52:53.495 NotebookApp] zmq message arrived on closed channel
[W 05:52:53.696 NotebookApp] zmq message arrived on closed channel
[W 05:52:53.696 NotebookApp] zmq message arrived on closed channel
[W 05:52:53.897 NotebookApp] zmq message arrived on closed channel
[W 05:52:53.898 NotebookApp] zmq message arrived on closed channel
[W 05:52:54.099 NotebookApp] zmq message arrived on closed channel
[W 05:52:54.100 NotebookApp] zmq message arrived on closed channel
[W 05:52:54.301 NotebookApp] zmq message arrived on closed channel
[W 05:52:54.302 NotebookApp] zmq message arrived on closed channel
[W 05:52:54.502 NotebookApp] zmq message arrived on closed channel
[W 05:52:54.503 NotebookApp] zmq message arrived on closed channel
[W 05:52:54.704 NotebookApp] zmq message arrived on closed channel
[W 05:52:54.705 NotebookApp] zmq message arrived on closed channel
[W 05:52:54.906 NotebookApp] zmq message arrived on closed channel
[W 05:52:54.907 NotebookApp] zmq message arrived on closed channel
[W 05:52:55.108 NotebookApp] zmq message arrived on closed channel
[W 05:52:55.109 NotebookApp] zmq message arrived on closed channel
[W 05:52:55.309 NotebookApp] zmq message arrived on closed channel
[W 05:52:55.310 NotebookApp] zmq message arrived on closed channel
[W 05:52:55.511 NotebookApp] zmq message arrived on closed channel
[W 05:52:55.512 NotebookApp] zmq message arrived on closed channel
[W 05:52:55.713 NotebookApp] zmq message arrived on closed channel
[W 05:52:55.714 NotebookApp] zmq message arrived on closed channel
[W 05:52:55.915 NotebookApp] zmq message arrived on closed channel
[W 05:52:55.916 NotebookApp] zmq message arrived on closed channel
[W 05:52:56.116 NotebookApp] zmq message arrived on closed channel
[W 05:52:56.117 NotebookApp] zmq message arrived on closed channel
[W 05:52:56.318 NotebookApp] zmq message arrived on closed channel
[W 05:52:56.319 NotebookApp] zmq message arrived on closed channel
[W 05:52:56.520 NotebookApp] zmq message arrived on closed channel
[W 05:52:56.521 NotebookApp] zmq message arrived on closed channel
[W 05:52:56.722 NotebookApp] zmq message arrived on closed channel
[W 05:52:56.723 NotebookApp] zmq message arrived on closed channel
[W 05:52:56.924 NotebookApp] zmq message arrived on closed channel
[W 05:52:56.925 NotebookApp] zmq message arrived on closed channel
[W 05:52:57.126 NotebookApp] zmq message arrived on closed channel
[W 05:52:57.127 NotebookApp] zmq message arrived on closed channel
[W 05:52:57.327 NotebookApp] zmq message arrived on closed channel
[W 05:52:57.328 NotebookApp] zmq message arrived on closed channel
[W 05:52:57.529 NotebookApp] zmq message arrived on closed channel
[W 05:52:57.530 NotebookApp] zmq message arrived on closed channel
[W 05:52:57.730 NotebookApp] zmq message arrived on closed channel
[W 05:52:57.731 NotebookApp] zmq message arrived on closed channel
[W 05:52:57.932 NotebookApp] zmq message arrived on closed channel
[W 05:52:57.933 NotebookApp] zmq message arrived on closed channel
[W 05:52:58.134 NotebookApp] zmq message arrived on closed channel
[W 05:52:58.135 NotebookApp] zmq message arrived on closed channel
[W 05:52:58.336 NotebookApp] zmq message arrived on closed channel
[W 05:52:58.337 NotebookApp] zmq message arrived on closed channel
[W 05:52:58.537 NotebookApp] zmq message arrived on closed channel
[W 05:52:58.538 NotebookApp] zmq message arrived on closed channel
[W 05:52:58.739 NotebookApp] zmq message arrived on closed channel
[W 05:52:58.740 NotebookApp] zmq message arrived on closed channel
[W 05:52:58.941 NotebookApp] zmq message arrived on closed channel
[W 05:52:58.942 NotebookApp] zmq message arrived on closed channel
[W 05:52:59.143 NotebookApp] zmq message arrived on closed channel
[W 05:52:59.143 NotebookApp] zmq message arrived on closed channel
[W 05:52:59.344 NotebookApp] zmq message arrived on closed channel
[W 05:52:59.345 NotebookApp] zmq message arrived on closed channel
[W 05:52:59.546 NotebookApp] zmq message arrived on closed channel
[W 05:52:59.547 NotebookApp] zmq message arrived on closed channel
[W 05:52:59.748 NotebookApp] zmq message arrived on closed channel
[W 05:52:59.749 NotebookApp] zmq message arrived on closed channel
[W 05:52:59.899 NotebookApp] zmq message arrived on closed channel
[W 05:52:59.900 NotebookApp] zmq message arrived on closed channel
[W 05:53:00.101 NotebookApp] zmq message arrived on closed channel
[W 05:53:00.102 NotebookApp] zmq message arrived on closed channel
[W 05:53:00.303 NotebookApp] zmq message arrived on closed channel
[W 05:53:00.304 NotebookApp] zmq message arrived on closed channel
[W 05:53:00.504 NotebookApp] zmq message arrived on closed channel
[W 05:53:00.505 NotebookApp] zmq message arrived on closed channel
[W 05:53:00.706 NotebookApp] zmq message arrived on closed channel
[W 05:53:00.707 NotebookApp] zmq message arrived on closed channel
[W 05:53:00.908 NotebookApp] zmq message arrived on closed channel
[W 05:53:00.909 NotebookApp] zmq message arrived on closed channel
[W 05:53:01.110 NotebookApp] zmq message arrived on closed channel
[W 05:53:01.110 NotebookApp] zmq message arrived on closed channel
[W 05:53:01.311 NotebookApp] zmq message arrived on closed channel
[W 05:53:01.312 NotebookApp] zmq message arrived on closed channel
[W 05:53:01.513 NotebookApp] zmq message arrived on closed channel
[W 05:53:01.514 NotebookApp] zmq message arrived on closed channel
[W 05:53:01.715 NotebookApp] zmq message arrived on closed channel
[W 05:53:01.716 NotebookApp] zmq message arrived on closed channel
[W 05:53:01.917 NotebookApp] zmq message arrived on closed channel
[W 05:53:01.918 NotebookApp] zmq message arrived on closed channel
[W 05:53:02.119 NotebookApp] zmq message arrived on closed channel
[W 05:53:02.119 NotebookApp] zmq message arrived on closed channel
[W 05:53:02.320 NotebookApp] zmq message arrived on closed channel
[W 05:53:02.321 NotebookApp] zmq message arrived on closed channel
[W 05:53:02.522 NotebookApp] zmq message arrived on closed channel
[W 05:53:02.523 NotebookApp] zmq message arrived on closed channel
[W 05:53:02.724 NotebookApp] zmq message arrived on closed channel
[W 05:53:02.725 NotebookApp] zmq message arrived on closed channel
[W 05:53:02.926 NotebookApp] zmq message arrived on closed channel
[W 05:53:02.926 NotebookApp] zmq message arrived on closed channel
[W 05:53:03.127 NotebookApp] zmq message arrived on closed channel
[W 05:53:03.128 NotebookApp] zmq message arrived on closed channel
[W 05:53:03.329 NotebookApp] zmq message arrived on closed channel
[W 05:53:03.330 NotebookApp] zmq message arrived on closed channel
[W 05:53:03.531 NotebookApp] zmq message arrived on closed channel
[W 05:53:03.532 NotebookApp] zmq message arrived on closed channel
[W 05:53:03.732 NotebookApp] zmq message arrived on closed channel
[W 05:53:03.733 NotebookApp] zmq message arrived on closed channel
[W 05:53:03.934 NotebookApp] zmq message arrived on closed channel
[W 05:53:03.935 NotebookApp] zmq message arrived on closed channel
[W 05:53:04.135 NotebookApp] zmq message arrived on closed channel
[W 05:53:04.136 NotebookApp] zmq message arrived on closed channel
[W 05:53:04.337 NotebookApp] zmq message arrived on closed channel
[W 05:53:04.338 NotebookApp] zmq message arrived on closed channel
[W 05:53:04.539 NotebookApp] zmq message arrived on closed channel
[W 05:53:04.540 NotebookApp] zmq message arrived on closed channel
[W 05:53:04.741 NotebookApp] zmq message arrived on closed channel
[W 05:53:04.742 NotebookApp] zmq message arrived on closed channel
[W 05:53:04.942 NotebookApp] zmq message arrived on closed channel
[W 05:53:04.943 NotebookApp] zmq message arrived on closed channel
[W 05:53:05.144 NotebookApp] zmq message arrived on closed channel
[W 05:53:05.145 NotebookApp] zmq message arrived on closed channel
[W 05:53:05.346 NotebookApp] zmq message arrived on closed channel
[W 05:53:05.347 NotebookApp] zmq message arrived on closed channel
[W 05:53:05.548 NotebookApp] zmq message arrived on closed channel
[W 05:53:05.548 NotebookApp] zmq message arrived on closed channel
[W 05:53:05.749 NotebookApp] zmq message arrived on closed channel
[W 05:53:05.750 NotebookApp] zmq message arrived on closed channel
[W 05:53:05.951 NotebookApp] zmq message arrived on closed channel
[W 05:53:05.952 NotebookApp] zmq message arrived on closed channel
[W 05:53:06.153 NotebookApp] zmq message arrived on closed channel
[W 05:53:06.153 NotebookApp] zmq message arrived on closed channel
[W 05:53:06.354 NotebookApp] zmq message arrived on closed channel
[W 05:53:06.355 NotebookApp] zmq message arrived on closed channel
[W 05:53:06.556 NotebookApp] zmq message arrived on closed channel
[W 05:53:06.557 NotebookApp] zmq message arrived on closed channel
[W 05:53:06.757 NotebookApp] zmq message arrived on closed channel
[W 05:53:06.758 NotebookApp] zmq message arrived on closed channel
[W 05:53:06.959 NotebookApp] zmq message arrived on closed channel
[W 05:53:06.960 NotebookApp] zmq message arrived on closed channel
[W 05:53:07.161 NotebookApp] zmq message arrived on closed channel
[W 05:53:07.162 NotebookApp] zmq message arrived on closed channel
[W 05:53:07.363 NotebookApp] zmq message arrived on closed channel
[W 05:53:07.364 NotebookApp] zmq message arrived on closed channel
[W 05:53:07.564 NotebookApp] zmq message arrived on closed channel
[W 05:53:07.565 NotebookApp] zmq message arrived on closed channel
[W 05:53:07.766 NotebookApp] zmq message arrived on closed channel
[W 05:53:07.767 NotebookApp] zmq message arrived on closed channel
[W 05:53:07.968 NotebookApp] zmq message arrived on closed channel
[W 05:53:07.969 NotebookApp] zmq message arrived on closed channel
[W 05:53:08.170 NotebookApp] zmq message arrived on closed channel
[W 05:53:08.171 NotebookApp] zmq message arrived on closed channel
[W 05:53:08.371 NotebookApp] zmq message arrived on closed channel
[W 05:53:08.372 NotebookApp] zmq message arrived on closed channel
[W 05:53:08.523 NotebookApp] zmq message arrived on closed channel
[W 05:53:08.523 NotebookApp] zmq message arrived on closed channel
[W 05:53:08.724 NotebookApp] zmq message arrived on closed channel
[W 05:53:08.725 NotebookApp] zmq message arrived on closed channel
[W 05:53:08.926 NotebookApp] zmq message arrived on closed channel
[W 05:53:08.927 NotebookApp] zmq message arrived on closed channel
[W 05:53:09.127 NotebookApp] zmq message arrived on closed channel
[W 05:53:09.128 NotebookApp] zmq message arrived on closed channel
[W 05:53:09.329 NotebookApp] zmq message arrived on closed channel
[W 05:53:09.330 NotebookApp] zmq message arrived on closed channel
[W 05:53:09.531 NotebookApp] zmq message arrived on closed channel
[W 05:53:09.532 NotebookApp] zmq message arrived on closed channel
[W 05:53:09.732 NotebookApp] zmq message arrived on closed channel
[W 05:53:09.733 NotebookApp] zmq message arrived on closed channel
[W 05:53:09.934 NotebookApp] zmq message arrived on closed channel
[W 05:53:09.935 NotebookApp] zmq message arrived on closed channel
[W 05:53:10.136 NotebookApp] zmq message arrived on closed channel
[W 05:53:10.136 NotebookApp] zmq message arrived on closed channel
[W 05:53:10.337 NotebookApp] zmq message arrived on closed channel
[W 05:53:10.338 NotebookApp] zmq message arrived on closed channel
[W 05:53:10.539 NotebookApp] zmq message arrived on closed channel
[W 05:53:10.540 NotebookApp] zmq message arrived on closed channel
[W 05:53:10.741 NotebookApp] zmq message arrived on closed channel
[W 05:53:10.741 NotebookApp] zmq message arrived on closed channel
[W 05:53:10.942 NotebookApp] zmq message arrived on closed channel
[W 05:53:10.943 NotebookApp] zmq message arrived on closed channel
[W 05:53:11.144 NotebookApp] zmq message arrived on closed channel
[W 05:53:11.145 NotebookApp] zmq message arrived on closed channel
[W 05:53:11.346 NotebookApp] zmq message arrived on closed channel
[W 05:53:11.347 NotebookApp] zmq message arrived on closed channel
[W 05:53:11.547 NotebookApp] zmq message arrived on closed channel
[W 05:53:11.548 NotebookApp] zmq message arrived on closed channel
[W 05:53:11.749 NotebookApp] zmq message arrived on closed channel
[W 05:53:11.750 NotebookApp] zmq message arrived on closed channel
[W 05:53:11.951 NotebookApp] zmq message arrived on closed channel
[W 05:53:11.952 NotebookApp] zmq message arrived on closed channel
[W 05:53:12.152 NotebookApp] zmq message arrived on closed channel
[W 05:53:12.153 NotebookApp] zmq message arrived on closed channel
[W 05:53:12.354 NotebookApp] zmq message arrived on closed channel
[W 05:53:12.355 NotebookApp] zmq message arrived on closed channel
[W 05:53:12.556 NotebookApp] zmq message arrived on closed channel
[W 05:53:12.557 NotebookApp] zmq message arrived on closed channel
[W 05:53:12.758 NotebookApp] zmq message arrived on closed channel
[W 05:53:12.759 NotebookApp] zmq message arrived on closed channel
[W 05:53:12.959 NotebookApp] zmq message arrived on closed channel
[W 05:53:12.960 NotebookApp] zmq message arrived on closed channel
[W 05:53:13.161 NotebookApp] zmq message arrived on closed channel
[W 05:53:13.162 NotebookApp] zmq message arrived on closed channel
[W 05:53:13.363 NotebookApp] zmq message arrived on closed channel
[W 05:53:13.364 NotebookApp] zmq message arrived on closed channel
[W 05:53:13.564 NotebookApp] zmq message arrived on closed channel
[W 05:53:13.565 NotebookApp] zmq message arrived on closed channel
[W 05:53:13.766 NotebookApp] zmq message arrived on closed channel
[W 05:53:13.767 NotebookApp] zmq message arrived on closed channel
[W 05:53:13.968 NotebookApp] zmq message arrived on closed channel
[W 05:53:13.969 NotebookApp] zmq message arrived on closed channel
[W 05:53:14.170 NotebookApp] zmq message arrived on closed channel
[W 05:53:14.171 NotebookApp] zmq message arrived on closed channel
[W 05:53:14.371 NotebookApp] zmq message arrived on closed channel
[W 05:53:14.372 NotebookApp] zmq message arrived on closed channel
[W 05:53:14.573 NotebookApp] zmq message arrived on closed channel
[W 05:53:14.574 NotebookApp] zmq message arrived on closed channel
[W 05:53:14.775 NotebookApp] zmq message arrived on closed channel
[W 05:53:14.776 NotebookApp] zmq message arrived on closed channel
[W 05:53:14.977 NotebookApp] zmq message arrived on closed channel
[W 05:53:14.978 NotebookApp] zmq message arrived on closed channel
[W 05:53:15.178 NotebookApp] zmq message arrived on closed channel
[W 05:53:15.179 NotebookApp] zmq message arrived on closed channel
[W 05:53:15.380 NotebookApp] zmq message arrived on closed channel
[W 05:53:15.381 NotebookApp] zmq message arrived on closed channel
[W 05:53:15.581 NotebookApp] zmq message arrived on closed channel
[W 05:53:15.582 NotebookApp] zmq message arrived on closed channel
[W 05:53:15.783 NotebookApp] zmq message arrived on closed channel
[W 05:53:15.784 NotebookApp] zmq message arrived on closed channel
[W 05:53:15.985 NotebookApp] zmq message arrived on closed channel
[W 05:53:15.985 NotebookApp] zmq message arrived on closed channel
[W 05:53:16.186 NotebookApp] zmq message arrived on closed channel
[W 05:53:16.187 NotebookApp] zmq message arrived on closed channel
[W 05:53:16.388 NotebookApp] zmq message arrived on closed channel
[W 05:53:16.389 NotebookApp] zmq message arrived on closed channel
[W 05:53:16.590 NotebookApp] zmq message arrived on closed channel
[W 05:53:16.591 NotebookApp] zmq message arrived on closed channel
[W 05:53:16.791 NotebookApp] zmq message arrived on closed channel
[W 05:53:16.792 NotebookApp] zmq message arrived on closed channel
[W 05:53:16.993 NotebookApp] zmq message arrived on closed channel
[W 05:53:16.994 NotebookApp] zmq message arrived on closed channel
[W 05:53:17.195 NotebookApp] zmq message arrived on closed channel
[W 05:53:17.196 NotebookApp] zmq message arrived on closed channel
[W 05:53:17.346 NotebookApp] zmq message arrived on closed channel
[W 05:53:17.347 NotebookApp] zmq message arrived on closed channel
[W 05:53:17.548 NotebookApp] zmq message arrived on closed channel
[W 05:53:17.549 NotebookApp] zmq message arrived on closed channel
[W 05:53:17.750 NotebookApp] zmq message arrived on closed channel
[W 05:53:17.751 NotebookApp] zmq message arrived on closed channel
[W 05:53:17.952 NotebookApp] zmq message arrived on closed channel
[W 05:53:17.952 NotebookApp] zmq message arrived on closed channel
[W 05:53:18.153 NotebookApp] zmq message arrived on closed channel
[W 05:53:18.154 NotebookApp] zmq message arrived on closed channel
[W 05:53:18.355 NotebookApp] zmq message arrived on closed channel
[W 05:53:18.356 NotebookApp] zmq message arrived on closed channel
[W 05:53:18.557 NotebookApp] zmq message arrived on closed channel
[W 05:53:18.557 NotebookApp] zmq message arrived on closed channel
[W 05:53:18.758 NotebookApp] zmq message arrived on closed channel
[W 05:53:18.759 NotebookApp] zmq message arrived on closed channel
[W 05:53:18.960 NotebookApp] zmq message arrived on closed channel
[W 05:53:18.961 NotebookApp] zmq message arrived on closed channel
[W 05:53:19.162 NotebookApp] zmq message arrived on closed channel
[W 05:53:19.162 NotebookApp] zmq message arrived on closed channel
[W 05:53:19.363 NotebookApp] zmq message arrived on closed channel
[W 05:53:19.364 NotebookApp] zmq message arrived on closed channel
[W 05:53:19.565 NotebookApp] zmq message arrived on closed channel
[W 05:53:19.566 NotebookApp] zmq message arrived on closed channel
[W 05:53:19.767 NotebookApp] zmq message arrived on closed channel
[W 05:53:19.768 NotebookApp] zmq message arrived on closed channel
[W 05:53:19.968 NotebookApp] zmq message arrived on closed channel
[W 05:53:19.969 NotebookApp] zmq message arrived on closed channel
[W 05:53:20.170 NotebookApp] zmq message arrived on closed channel
[W 05:53:20.171 NotebookApp] zmq message arrived on closed channel
[W 05:53:20.372 NotebookApp] zmq message arrived on closed channel
[W 05:53:20.373 NotebookApp] zmq message arrived on closed channel
[W 05:53:20.573 NotebookApp] zmq message arrived on closed channel
[W 05:53:20.574 NotebookApp] zmq message arrived on closed channel
[W 05:53:20.775 NotebookApp] zmq message arrived on closed channel
[W 05:53:20.776 NotebookApp] zmq message arrived on closed channel
[W 05:53:20.977 NotebookApp] zmq message arrived on closed channel
[W 05:53:20.978 NotebookApp] zmq message arrived on closed channel
[W 05:53:21.178 NotebookApp] zmq message arrived on closed channel
[W 05:53:21.179 NotebookApp] zmq message arrived on closed channel
[W 05:53:21.380 NotebookApp] zmq message arrived on closed channel
[W 05:53:21.381 NotebookApp] zmq message arrived on closed channel
[W 05:53:21.582 NotebookApp] zmq message arrived on closed channel
[W 05:53:21.582 NotebookApp] zmq message arrived on closed channel
[W 05:53:21.783 NotebookApp] zmq message arrived on closed channel
[W 05:53:21.784 NotebookApp] zmq message arrived on closed channel
[W 05:53:21.985 NotebookApp] zmq message arrived on closed channel
[W 05:53:21.986 NotebookApp] zmq message arrived on closed channel
[W 05:53:22.187 NotebookApp] zmq message arrived on closed channel
[W 05:53:22.188 NotebookApp] zmq message arrived on closed channel
[W 05:53:22.389 NotebookApp] zmq message arrived on closed channel
[W 05:53:22.390 NotebookApp] zmq message arrived on closed channel
[W 05:53:22.590 NotebookApp] zmq message arrived on closed channel
[W 05:53:22.591 NotebookApp] zmq message arrived on closed channel
[W 05:53:22.792 NotebookApp] zmq message arrived on closed channel
[W 05:53:22.793 NotebookApp] zmq message arrived on closed channel
[W 05:53:22.994 NotebookApp] zmq message arrived on closed channel
[W 05:53:22.995 NotebookApp] zmq message arrived on closed channel
[W 05:53:23.196 NotebookApp] zmq message arrived on closed channel
[W 05:53:23.197 NotebookApp] zmq message arrived on closed channel
[W 05:53:23.397 NotebookApp] zmq message arrived on closed channel
[W 05:53:23.398 NotebookApp] zmq message arrived on closed channel
[W 05:53:23.599 NotebookApp] zmq message arrived on closed channel
[W 05:53:23.600 NotebookApp] zmq message arrived on closed channel
[W 05:53:23.801 NotebookApp] zmq message arrived on closed channel
[W 05:53:23.801 NotebookApp] zmq message arrived on closed channel
[W 05:53:24.002 NotebookApp] zmq message arrived on closed channel
[W 05:53:24.003 NotebookApp] zmq message arrived on closed channel
[W 05:53:24.204 NotebookApp] zmq message arrived on closed channel
[W 05:53:24.205 NotebookApp] zmq message arrived on closed channel
[W 05:53:24.406 NotebookApp] zmq message arrived on closed channel
[W 05:53:24.407 NotebookApp] zmq message arrived on closed channel
[W 05:53:24.607 NotebookApp] zmq message arrived on closed channel
[W 05:53:24.608 NotebookApp] zmq message arrived on closed channel
[W 05:53:24.809 NotebookApp] zmq message arrived on closed channel
[W 05:53:24.810 NotebookApp] zmq message arrived on closed channel
[W 05:53:25.011 NotebookApp] zmq message arrived on closed channel
[W 05:53:25.012 NotebookApp] zmq message arrived on closed channel
[W 05:53:25.213 NotebookApp] zmq message arrived on closed channel
[W 05:53:25.214 NotebookApp] zmq message arrived on closed channel
[W 05:53:25.414 NotebookApp] zmq message arrived on closed channel
[W 05:53:25.415 NotebookApp] zmq message arrived on closed channel
[W 05:53:25.616 NotebookApp] zmq message arrived on closed channel
[W 05:53:25.617 NotebookApp] zmq message arrived on closed channel
[W 05:53:25.767 NotebookApp] zmq message arrived on closed channel
[W 05:53:25.768 NotebookApp] zmq message arrived on closed channel
[W 05:53:25.969 NotebookApp] zmq message arrived on closed channel
[W 05:53:25.970 NotebookApp] zmq message arrived on closed channel
[W 05:53:26.171 NotebookApp] zmq message arrived on closed channel
[W 05:53:26.172 NotebookApp] zmq message arrived on closed channel
[W 05:53:26.372 NotebookApp] zmq message arrived on closed channel
[W 05:53:26.373 NotebookApp] zmq message arrived on closed channel
[W 05:53:26.441 NotebookApp] zmq message arrived on closed channel
[W 05:53:26.442 NotebookApp] zmq message arrived on closed channel
[W 05:53:26.545 NotebookApp] zmq message arrived on closed channel
[W 05:53:26.545 NotebookApp] zmq message arrived on closed channel
[I 05:53:44.867 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[I 05:55:22.783 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 05:57:15.990 NotebookApp] zmq message arrived on closed channel
[W 05:57:15.990 NotebookApp] zmq message arrived on closed channel
[W 05:57:15.990 NotebookApp] zmq message arrived on closed channel
[W 05:57:15.991 NotebookApp] zmq message arrived on closed channel
[W 05:57:15.991 NotebookApp] zmq message arrived on closed channel
[W 05:57:15.992 NotebookApp] zmq message arrived on closed channel
[W 05:57:15.992 NotebookApp] zmq message arrived on closed channel
[W 05:57:15.992 NotebookApp] zmq message arrived on closed channel
[W 05:57:15.993 NotebookApp] zmq message arrived on closed channel
[W 05:57:15.993 NotebookApp] zmq message arrived on closed channel
[W 05:57:15.993 NotebookApp] zmq message arrived on closed channel
[W 05:57:15.994 NotebookApp] zmq message arrived on closed channel
taxi: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[156] at textFile at <console>:29
[W 05:57:16.198 NotebookApp] zmq message arrived on closed channel
[W 05:57:16.198 NotebookApp] zmq message arrived on closed channel
[W 05:57:16.198 NotebookApp] zmq message arrived on closed channel
[W 05:57:16.199 NotebookApp] zmq message arrived on closed channel
[W 05:57:16.199 NotebookApp] zmq message arrived on closed channel
[W 05:57:16.199 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.427 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.427 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.428 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.428 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.428 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.428 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.429 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.429 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.430 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.430 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.430 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.430 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.676 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.677 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.677 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.677 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.677 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.678 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.685 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.685 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.685 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.686 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.686 NotebookApp] zmq message arrived on closed channel
[W 05:57:18.686 NotebookApp] zmq message arrived on closed channel
[I 05:57:22.704 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 05:57:24.714 NotebookApp] zmq message arrived on closed channel
[W 05:57:24.714 NotebookApp] zmq message arrived on closed channel
[W 05:57:24.715 NotebookApp] zmq message arrived on closed channel
[W 05:57:24.715 NotebookApp] zmq message arrived on closed channel
[W 05:57:24.715 NotebookApp] zmq message arrived on closed channel
[W 05:57:24.715 NotebookApp] zmq message arrived on closed channel
[W 05:57:24.716 NotebookApp] zmq message arrived on closed channel
[W 05:57:24.716 NotebookApp] zmq message arrived on closed channel
[W 05:57:24.717 NotebookApp] zmq message arrived on closed channel
[W 05:57:24.717 NotebookApp] zmq message arrived on closed channel
[W 05:57:24.717 NotebookApp] zmq message arrived on closed channel
[W 05:57:24.717 NotebookApp] zmq message arrived on closed channel
taxiParse: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[157] at map at <console>:31
[W 05:57:24.893 NotebookApp] zmq message arrived on closed channel
[W 05:57:24.893 NotebookApp] zmq message arrived on closed channel
[W 05:57:24.894 NotebookApp] zmq message arrived on closed channel
[W 05:57:24.894 NotebookApp] zmq message arrived on closed channel
[W 05:57:24.895 NotebookApp] zmq message arrived on closed channel
[W 05:57:24.895 NotebookApp] zmq message arrived on closed channel
[W 05:57:26.570 NotebookApp] zmq message arrived on closed channel
[W 05:57:26.571 NotebookApp] zmq message arrived on closed channel
[W 05:57:26.571 NotebookApp] zmq message arrived on closed channel
[W 05:57:26.571 NotebookApp] zmq message arrived on closed channel
[W 05:57:26.572 NotebookApp] zmq message arrived on closed channel
[W 05:57:26.572 NotebookApp] zmq message arrived on closed channel
[W 05:57:26.572 NotebookApp] zmq message arrived on closed channel
[W 05:57:26.573 NotebookApp] zmq message arrived on closed channel
[W 05:57:26.573 NotebookApp] zmq message arrived on closed channel
[W 05:57:26.573 NotebookApp] zmq message arrived on closed channel
[W 05:57:26.574 NotebookApp] zmq message arrived on closed channel
[W 05:57:26.574 NotebookApp] zmq message arrived on closed channel
taxiMedKey: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[158] at map at <console>:33
[W 05:57:26.753 NotebookApp] zmq message arrived on closed channel
[W 05:57:26.754 NotebookApp] zmq message arrived on closed channel
[W 05:57:26.754 NotebookApp] zmq message arrived on closed channel
[W 05:57:26.754 NotebookApp] zmq message arrived on closed channel
[W 05:57:26.755 NotebookApp] zmq message arrived on closed channel
[W 05:57:26.755 NotebookApp] zmq message arrived on closed channel
[W 05:57:29.385 NotebookApp] zmq message arrived on closed channel
[W 05:57:29.386 NotebookApp] zmq message arrived on closed channel
[W 05:57:29.386 NotebookApp] zmq message arrived on closed channel
[W 05:57:29.386 NotebookApp] zmq message arrived on closed channel
[W 05:57:29.386 NotebookApp] zmq message arrived on closed channel
[W 05:57:29.387 NotebookApp] zmq message arrived on closed channel
[W 05:57:29.387 NotebookApp] zmq message arrived on closed channel
[W 05:57:29.387 NotebookApp] zmq message arrived on closed channel
[W 05:57:29.387 NotebookApp] zmq message arrived on closed channel
[W 05:57:29.388 NotebookApp] zmq message arrived on closed channel
[W 05:57:29.388 NotebookApp] zmq message arrived on closed channel
[W 05:57:29.389 NotebookApp] zmq message arrived on closed channel
taxiMedCounts: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[159] at reduceByKey at <console>:35
[W 05:57:29.602 NotebookApp] zmq message arrived on closed channel
[W 05:57:29.602 NotebookApp] zmq message arrived on closed channel
[W 05:57:29.603 NotebookApp] zmq message arrived on closed channel
[W 05:57:29.603 NotebookApp] zmq message arrived on closed channel
[W 05:57:29.603 NotebookApp] zmq message arrived on closed channel
[W 05:57:29.603 NotebookApp] zmq message arrived on closed channel
[W 05:57:32.333 NotebookApp] zmq message arrived on closed channel
[W 05:57:32.333 NotebookApp] zmq message arrived on closed channel
[W 05:57:32.333 NotebookApp] zmq message arrived on closed channel
[W 05:57:32.334 NotebookApp] zmq message arrived on closed channel
[W 05:57:32.334 NotebookApp] zmq message arrived on closed channel
[W 05:57:32.334 NotebookApp] zmq message arrived on closed channel
[W 05:57:32.335 NotebookApp] zmq message arrived on closed channel
[W 05:57:32.335 NotebookApp] zmq message arrived on closed channel
[W 05:57:32.335 NotebookApp] zmq message arrived on closed channel
[W 05:57:32.336 NotebookApp] zmq message arrived on closed channel
[W 05:57:32.336 NotebookApp] zmq message arrived on closed channel
[W 05:57:32.336 NotebookApp] zmq message arrived on closed channel
       (1 + 2) / 3][Stage 125:===================>                                     (1 + 2) / 3][Stage 127:>                                                       (0 + 8) / 26][Stage 127:=================>                                      (8 + 8) / 26][Stage 127:===============================>                       (15 + 8) / 26][Stage 127:=================================>                     (16 + 8) / 26][Stage 127:==================================================>    (24 + 2) / 26][Stage[W 05:57:35.192 NotebookApp] zmq message arrived on closed channel
[W 05:57:35.192 NotebookApp] zmq message arrived on closed channel
[W 05:57:35.192 NotebookApp] zmq message arrived on closed channel
[W 05:57:35.193 NotebookApp] zmq message arrived on closed channel
[W 05:57:35.193 NotebookApp] zmq message arrived on closed channel
[W 05:57:35.193 NotebookApp] zmq message arrived on closed channel
[W 05:57:35.197 NotebookApp] zmq message arrived on closed channel
[W 05:57:35.198 NotebookApp] zmq message arrived on closed channel
[W 05:57:35.198 NotebookApp] zmq message arrived on closed channel
[W 05:57:35.198 NotebookApp] zmq message arrived on closed channel
[W 05:57:35.198 NotebookApp] zmq message arrived on closed channel
[W 05:57:35.198 NotebookApp] zmq message arrived on closed channel
[W 05:57:44.087 NotebookApp] zmq message arrived on closed channel
[W 05:57:44.087 NotebookApp] zmq message arrived on closed channel
[W 05:57:44.087 NotebookApp] zmq message arrived on closed channel
[W 05:57:44.088 NotebookApp] zmq message arrived on closed channel
[W 05:57:44.088 NotebookApp] zmq message arrived on closed channel
[W 05:57:44.088 NotebookApp] zmq message arrived on closed channel
[W 05:57:44.088 NotebookApp] zmq message arrived on closed channel
[W 05:57:44.089 NotebookApp] zmq message arrived on closed channel
[W 05:57:44.089 NotebookApp] zmq message arrived on closed channel
[W 05:57:44.089 NotebookApp] zmq message arrived on closed channel
[W 05:57:44.090 NotebookApp] zmq message arrived on closed channel
[W 05:57:44.090 NotebookApp] zmq message arrived on closed channel
taxiMedCountsOneLine: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[164] at reduceByKey at <console>:31
[W 05:57:44.340 NotebookApp] zmq message arrived on closed channel
[W 05:57:44.340 NotebookApp] zmq message arrived on closed channel
[W 05:57:44.340 NotebookApp] zmq message arrived on closed channel
[W 05:57:44.341 NotebookApp] zmq message arrived on closed channel
[W 05:57:44.341 NotebookApp] zmq message arrived on closed channel
[W 05:57:44.341 NotebookApp] zmq message arrived on closed channel
[W 05:57:46.118 NotebookApp] zmq message arrived on closed channel
[W 05:57:46.119 NotebookApp] zmq message arrived on closed channel
[W 05:57:46.119 NotebookApp] zmq message arrived on closed channel
[W 05:57:46.119 NotebookApp] zmq message arrived on closed channel
[W 05:57:46.119 NotebookApp] zmq message arrived on closed channel
[W 05:57:46.120 NotebookApp] zmq message arrived on closed channel
[W 05:57:46.120 NotebookApp] zmq message arrived on closed channel
[W 05:57:46.120 NotebookApp] zmq message arrived on closed channel
[W 05:57:46.120 NotebookApp] zmq message arrived on closed channel
[W 05:57:46.121 NotebookApp] zmq message arrived on closed channel
[W 05:57:46.121 NotebookApp] zmq message arrived on closed channel
[W 05:57:46.122 NotebookApp] zmq message arrived on closed channel
 127:====================================================>  (25 + 1) / 26][Stage 129:>                                                       (0 + 8) / 26][Stage 129:=================>                                      (8 + 8) / 26][Stage 129:=================================>                     (16 + 8) / 26][Stage 129:================================================>      (23 + 3) / 26][Stage 129:==================================================>    (24 + 2) / 26][Stage 129:=====================[W 05:57:49.846 NotebookApp] zmq message arrived on closed channel
[W 05:57:49.846 NotebookApp] zmq message arrived on closed channel
[W 05:57:49.847 NotebookApp] zmq message arrived on closed channel
[W 05:57:49.847 NotebookApp] zmq message arrived on closed channel
[W 05:57:49.847 NotebookApp] zmq message arrived on closed channel
[W 05:57:49.847 NotebookApp] zmq message arrived on closed channel
[W 05:57:49.851 NotebookApp] zmq message arrived on closed channel
[W 05:57:49.852 NotebookApp] zmq message arrived on closed channel
[W 05:57:49.852 NotebookApp] zmq message arrived on closed channel
[W 05:57:49.852 NotebookApp] zmq message arrived on closed channel
[W 05:57:49.852 NotebookApp] zmq message arrived on closed channel
[W 05:57:49.853 NotebookApp] zmq message arrived on closed channel
[W 05:58:05.068 NotebookApp] zmq message arrived on closed channel
[W 05:58:05.068 NotebookApp] zmq message arrived on closed channel
[W 05:58:05.068 NotebookApp] zmq message arrived on closed channel
[W 05:58:05.069 NotebookApp] zmq message arrived on closed channel
[W 05:58:05.069 NotebookApp] zmq message arrived on closed channel
[W 05:58:05.069 NotebookApp] zmq message arrived on closed channel
[W 05:58:05.070 NotebookApp] zmq message arrived on closed channel
[W 05:58:05.070 NotebookApp] zmq message arrived on closed channel
[W 05:58:05.070 NotebookApp] zmq message arrived on closed channel
[W 05:58:05.070 NotebookApp] zmq message arrived on closed channel
[W 05:58:05.071 NotebookApp] zmq message arrived on closed channel
[W 05:58:05.071 NotebookApp] zmq message arrived on closed channel
res144: taxiMedCountsOneLine.type = ShuffledRDD[164] at reduceByKey at <console>:31
[W 05:58:05.222 NotebookApp] zmq message arrived on closed channel
[W 05:58:05.222 NotebookApp] zmq message arrived on closed channel
[W 05:58:05.222 NotebookApp] zmq message arrived on closed channel
[W 05:58:05.223 NotebookApp] zmq message arrived on closed channel
[W 05:58:05.223 NotebookApp] zmq message arrived on closed channel
[W 05:58:05.223 NotebookApp] zmq message arrived on closed channel
[W 05:58:05.224 NotebookApp] zmq message arrived on closed channel
[W 05:58:05.224 NotebookApp] zmq message arrived on closed channel
[W 05:58:05.225 NotebookApp] zmq message arrived on closed channel
[W 05:58:05.225 NotebookApp] zmq message arrived on closed channel
[W 05:58:05.226 NotebookApp] zmq message arrived on closed channel
[W 05:58:05.226 NotebookApp] zmq message arrived on closed channel
[W 05:58:09.216 NotebookApp] zmq message arrived on closed channel
[W 05:58:09.216 NotebookApp] zmq message arrived on closed channel
[W 05:58:09.217 NotebookApp] zmq message arrived on closed channel
[W 05:58:09.217 NotebookApp] zmq message arrived on closed channel
[W 05:58:09.217 NotebookApp] zmq message arrived on closed channel
[W 05:58:09.217 NotebookApp] zmq message arrived on closed channel
[W 05:58:09.218 NotebookApp] zmq message arrived on closed channel
[W 05:58:09.219 NotebookApp] zmq message arrived on closed channel
[W 05:58:09.219 NotebookApp] zmq message arrived on closed channel
[W 05:58:09.219 NotebookApp] zmq message arrived on closed channel
[W 05:58:09.219 NotebookApp] zmq message arrived on closed channel
[W 05:58:09.219 NotebookApp] zmq message arrived on closed channel
res145: Long = 13464
[W 05:58:09.606 NotebookApp] zmq message arrived on closed channel
[W 05:58:09.606 NotebookApp] zmq message arrived on closed channel
[W 05:58:09.607 NotebookApp] zmq message arrived on closed channel
[W 05:58:09.607 NotebookApp] zmq message arrived on closed channel
[W 05:58:09.607 NotebookApp] zmq message arrived on closed channel
[W 05:58:09.607 NotebookApp] zmq message arrived on closed channel
[W 05:58:09.608 NotebookApp] zmq message arrived on closed channel
[W 05:58:09.608 NotebookApp] zmq message arrived on closed channel
[W 05:58:09.608 NotebookApp] zmq message arrived on closed channel
[W 05:58:09.608 NotebookApp] zmq message arrived on closed channel
[W 05:58:09.609 NotebookApp] zmq message arrived on closed channel
[W 05:58:09.609 NotebookApp] zmq message arrived on closed channel
[W 05:58:11.880 NotebookApp] zmq message arrived on closed channel
[W 05:58:11.881 NotebookApp] zmq message arrived on closed channel
[W 05:58:11.881 NotebookApp] zmq message arrived on closed channel
[W 05:58:11.881 NotebookApp] zmq message arrived on closed channel
[W 05:58:11.882 NotebookApp] zmq message arrived on closed channel
[W 05:58:11.882 NotebookApp] zmq message arrived on closed channel
[W 05:58:11.883 NotebookApp] zmq message arrived on closed channel
[W 05:58:11.883 NotebookApp] zmq message arrived on closed channel
[W 05:58:11.883 NotebookApp] zmq message arrived on closed channel
[W 05:58:11.883 NotebookApp] zmq message arrived on closed channel
[W 05:58:11.884 NotebookApp] zmq message arrived on closed channel
[W 05:58:11.884 NotebookApp] zmq message arrived on closed channel
res146: Long = 13464
[W 05:58:12.053 NotebookApp] zmq message arrived on closed channel
[W 05:58:12.053 NotebookApp] zmq message arrived on closed channel
[W 05:58:12.054 NotebookApp] zmq message arrived on closed channel
[W 05:58:12.054 NotebookApp] zmq message arrived on closed channel
[W 05:58:12.054 NotebookApp] zmq message arrived on closed channel
[W 05:58:12.054 NotebookApp] zmq message arrived on closed channel
[W 05:58:12.055 NotebookApp] zmq message arrived on closed channel
[W 05:58:12.055 NotebookApp] zmq message arrived on closed channel
[W 05:58:12.055 NotebookApp] zmq message arrived on closed channel
[W 05:58:12.056 NotebookApp] zmq message arrived on closed channel
[W 05:58:12.056 NotebookApp] zmq message arrived on closed channel
[W 05:58:12.057 NotebookApp] zmq message arrived on closed channel
[I 05:58:30.467 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 05:58:37.780 NotebookApp] zmq message arrived on closed channel
[W 05:58:37.781 NotebookApp] zmq message arrived on closed channel
[W 05:58:37.782 NotebookApp] zmq message arrived on closed channel
[W 05:58:37.782 NotebookApp] zmq message arrived on closed channel
[I 05:59:23.795 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[I 05:59:51.765 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[I 06:01:42.783 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[I 06:03:23.855 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[I 06:03:42.216 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[I 06:05:21.574 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[I 06:05:41.342 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[W 06:06:53.007 NotebookApp] zmq message arrived on closed channel
[W 06:06:53.008 NotebookApp] zmq message arrived on closed channel
[W 06:06:53.008 NotebookApp] zmq message arrived on closed channel
[W 06:06:53.008 NotebookApp] zmq message arrived on closed channel
[W 06:06:53.009 NotebookApp] zmq message arrived on closed channel
[W 06:06:53.009 NotebookApp] zmq message arrived on closed channel
[W 06:06:53.010 NotebookApp] zmq message arrived on closed channel
[W 06:06:53.010 NotebookApp] zmq message arrived on closed channel
[W 06:06:53.010 NotebookApp] zmq message arrived on closed channel
[W 06:06:53.010 NotebookApp] zmq message arrived on closed channel
[W 06:06:53.011 NotebookApp] zmq message arrived on closed channel
[W 06:06:53.011 NotebookApp] zmq message arrived on closed channel
java.io.FileNotFoundException: /resources/users.txt (No such file or directory)
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:146)
	at scala.io.Source$.fromFile(Source.scala:90)
	at scala.io.Source$.fromFile(Source.scala:75)
	at scala.io.Source$.fromFile(Source.scala:53)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:30)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:35)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:37)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:39)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:41)
	at $iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:43)
	at $iwC$$iwC$$iwC$$iwC.<init>(<console>:45)
	at $iwC$$iwC$$iwC.<init>(<console>:47)
	at $iwC$$iwC.<init>(<console>:49)
	at $iwC.<init>(<console>:51)
	at <init>(<console>:53)
	at .<init>(<console>:57)
	at .<clinit>(<console>)
	at .<init>(<console>:7)
	at .<clinit>(<console>)
	at $print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	at com.ibm.spark.interpreter.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:296)
	at com.ibm.spark.interpreter.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:291)
	at com.ibm.spark.global.StreamState$.withStreams(StreamState.scala:80)
	at com.ibm.spark.interpreter.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:290)
	at com.ibm.spark.interpreter.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:290)
	at com.ibm.spark.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

lastException: Throwable = null
[W 06:06:53.440 NotebookApp] zmq message arrived on closed channel
[W 06:06:53.440 NotebookApp] zmq message arrived on closed channel
[W 06:06:53.441 NotebookApp] zmq message arrived on closed channel
[W 06:06:53.441 NotebookApp] zmq message arrived on closed channel
[W 06:06:53.441 NotebookApp] zmq message arrived on closed channel
[W 06:06:53.442 NotebookApp] zmq message arrived on closed channel
[W 06:06:53.442 NotebookApp] zmq message arrived on closed channel
[W 06:06:53.443 NotebookApp] zmq message arrived on closed channel
[W 06:06:53.443 NotebookApp] zmq message arrived on closed channel
[W 06:06:53.443 NotebookApp] zmq message arrived on closed channel
[W 06:06:53.443 NotebookApp] zmq message arrived on closed channel
[W 06:06:53.444 NotebookApp] zmq message arrived on closed channel
[I 06:07:21.553 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 06:08:33.409 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.409 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.409 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.410 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.410 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.411 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.411 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.411 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.411 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.412 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.412 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.412 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.562 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.562 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.562 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.562 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.563 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.563 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.695 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.695 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.696 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.696 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.696 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.697 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.704 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.704 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.705 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.705 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.705 NotebookApp] zmq message arrived on closed channel
[W 06:08:33.705 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.537 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.537 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.537 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.538 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.538 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.538 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.538 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.539 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.540 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.540 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.540 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.540 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.684 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.684 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.684 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.684 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.685 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.685 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.812 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.812 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.812 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.812 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.813 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.813 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.935 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.935 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.936 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.936 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.936 NotebookApp] zmq message arrived on closed channel
[W 06:08:53.937 NotebookApp] zmq message arrived on closed channel
[W 06:08:54.054 NotebookApp] zmq message arrived on closed channel
[W 06:08:54.054 NotebookApp] zmq message arrived on closed channel
[W 06:08:54.054 NotebookApp] zmq message arrived on closed channel
[W 06:08:54.054 NotebookApp] zmq message arrived on closed channel
[W 06:08:54.055 NotebookApp] zmq message arrived on closed channel
[W 06:08:54.055 NotebookApp] zmq message arrived on closed channel
[W 06:08:54.063 NotebookApp] zmq message arrived on closed channel
[W 06:08:54.063 NotebookApp] zmq message arrived on closed channel
[W 06:08:54.063 NotebookApp] zmq message arrived on closed channel
[W 06:08:54.063 NotebookApp] zmq message arrived on closed channel
[W 06:08:54.063 NotebookApp] zmq message arrived on closed channel
[W 06:08:54.064 NotebookApp] zmq message arrived on closed channel
[W 06:08:58.718 NotebookApp] zmq message arrived on closed channel
[W 06:08:58.718 NotebookApp] zmq message arrived on closed channel
[W 06:08:58.719 NotebookApp] zmq message arrived on closed channel
[W 06:08:58.719 NotebookApp] zmq message arrived on closed channel
[W 06:08:58.719 NotebookApp] zmq message arrived on closed channel
[W 06:08:58.719 NotebookApp] zmq message arrived on closed channel
[W 06:08:58.720 NotebookApp] zmq message arrived on closed channel
[W 06:08:58.720 NotebookApp] zmq message arrived on closed channel
[W 06:08:58.720 NotebookApp] zmq message arrived on closed channel
[W 06:08:58.720 NotebookApp] zmq message arrived on closed channel
[W 06:08:58.721 NotebookApp] zmq message arrived on closed channel
[W 06:08:58.721 NotebookApp] zmq message arrived on closed channel
import org.apache.spark.graphx._
[W 06:08:58.854 NotebookApp] zmq message arrived on closed channel
[W 06:08:58.855 NotebookApp] zmq message arrived on closed channel
[W 06:08:58.855 NotebookApp] zmq message arrived on closed channel
[W 06:08:58.855 NotebookApp] zmq message arrived on closed channel
[W 06:08:58.856 NotebookApp] zmq message arrived on closed channel
[W 06:08:58.856 NotebookApp] zmq message arrived on closed channel
[W 06:09:01.418 NotebookApp] zmq message arrived on closed channel
[W 06:09:01.418 NotebookApp] zmq message arrived on closed channel
[W 06:09:01.418 NotebookApp] zmq message arrived on closed channel
[W 06:09:01.419 NotebookApp] zmq message arrived on closed channel
[W 06:09:01.419 NotebookApp] zmq message arrived on closed channel
[W 06:09:01.419 NotebookApp] zmq message arrived on closed channel
[W 06:09:01.419 NotebookApp] zmq message arrived on closed channel
[W 06:09:01.420 NotebookApp] zmq message arrived on closed channel
[W 06:09:01.420 NotebookApp] zmq message arrived on closed channel
[W 06:09:01.420 NotebookApp] zmq message arrived on closed channel
[W 06:09:01.421 NotebookApp] zmq message arrived on closed channel
[W 06:09:01.421 NotebookApp] zmq message arrived on closed channel
users: org.apache.spark.rdd.RDD[(Long, Array[String])] = MapPartitionsRDD[170] at map at <console>:32
[W 06:09:01.888 NotebookApp] zmq message arrived on closed channel
[W 06:09:01.888 NotebookApp] zmq message arrived on closed channel
[W 06:09:01.888 NotebookApp] zmq message arrived on closed channel
[W 06:09:01.888 NotebookApp] zmq message arrived on closed channel
[W 06:09:01.888 NotebookApp] zmq message arrived on closed channel
[W 06:09:01.889 NotebookApp] zmq message arrived on closed channel
[W 06:09:07.246 NotebookApp] zmq message arrived on closed channel
[W 06:09:07.247 NotebookApp] zmq message arrived on closed channel
[W 06:09:07.247 NotebookApp] zmq message arrived on closed channel
[W 06:09:07.248 NotebookApp] zmq message arrived on closed channel
[W 06:09:07.248 NotebookApp] zmq message arrived on closed channel
[W 06:09:07.248 NotebookApp] zmq message arrived on closed channel
[W 06:09:07.249 NotebookApp] zmq message arrived on closed channel
[W 06:09:07.249 NotebookApp] zmq message arrived on closed channel
[W 06:09:07.249 NotebookApp] zmq message arrived on closed channel
[W 06:09:07.250 NotebookApp] zmq message arrived on closed channel
[W 06:09:07.250 NotebookApp] zmq message arrived on closed channel
[W 06:09:07.250 NotebookApp] zmq message arrived on closed channel
followerGraph: org.apache.spark.graphx.Graph[Int,Int] = org.apache.spark.graphx.impl.GraphImpl@959dc2a
[W 06:09:07.552 NotebookApp] zmq message arrived on closed channel
[W 06:09:07.552 NotebookApp] zmq message arrived on closed channel
[W 06:09:07.553 NotebookApp] zmq message arrived on closed channel
[W 06:09:07.553 NotebookApp] zmq message arrived on closed channel
[W 06:09:07.554 NotebookApp] zmq message arrived on closed channel
[W 06:09:07.554 NotebookApp] zmq message arrived on closed channel
[W 06:09:09.922 NotebookApp] zmq message arrived on closed channel
[W 06:09:09.923 NotebookApp] zmq message arrived on closed channel
[W 06:09:09.923 NotebookApp] zmq message arrived on closed channel
[W 06:09:09.923 NotebookApp] zmq message arrived on closed channel
[W 06:09:09.924 NotebookApp] zmq message arrived on closed channel
[W 06:09:09.924 NotebookApp] zmq message arrived on closed channel
[W 06:09:09.925 NotebookApp] zmq message arrived on closed channel
[W 06:09:09.925 NotebookApp] zmq message arrived on closed channel
[W 06:09:09.925 NotebookApp] zmq message arrived on closed channel
[W 06:09:09.925 NotebookApp] zmq message arrived on closed channel
[W 06:09:09.926 NotebookApp] zmq message arrived on closed channel
[W 06:09:09.926 NotebookApp] zmq message arrived on closed channel
graph: org.apache.spark.graphx.Graph[Array[String],Int] = org.apache.spark.graphx.impl.GraphImpl@221c4d1e
[W 06:09:10.291 NotebookApp] zmq message arrived on closed channel
[W 06:09:10.291 NotebookApp] zmq message arrived on closed channel
[W 06:09:10.292 NotebookApp] zmq message arrived on closed channel
[W 06:09:10.292 NotebookApp] zmq message arrived on closed channel
[W 06:09:10.292 NotebookApp] zmq message arrived on closed channel
[W 06:09:10.292 NotebookApp] zmq message arrived on closed channel
[W 06:09:14.568 NotebookApp] zmq message arrived on closed channel
[W 06:09:14.569 NotebookApp] zmq message arrived on closed channel
[W 06:09:14.569 NotebookApp] zmq message arrived on closed channel
[W 06:09:14.569 NotebookApp] zmq message arrived on closed channel
[W 06:09:14.569 NotebookApp] zmq message arrived on closed channel
[W 06:09:14.570 NotebookApp] zmq message arrived on closed channel
[W 06:09:14.571 NotebookApp] zmq message arrived on closed channel
[W 06:09:14.571 NotebookApp] zmq message arrived on closed channel
[W 06:09:14.571 NotebookApp] zmq message arrived on closed channel
[W 06:09:14.571 NotebookApp] zmq message arrived on closed channel
[W 06:09:14.571 NotebookApp] zmq message arrived on closed channel
[W 06:09:14.572 NotebookApp] zmq message arrived on closed channel
graph: org.apache.spark.graphx.Graph[Array[String],Int] = org.apache.spark.graphx.impl.GraphImpl@5e79ad5
[W 06:09:14.849 NotebookApp] zmq message arrived on closed channel
[W 06:09:14.849 NotebookApp] zmq message arrived on closed channel
[W 06:09:14.849 NotebookApp] zmq message arrived on closed channel
[W 06:09:14.849 NotebookApp] zmq message arrived on closed channel
[W 06:09:14.850 NotebookApp] zmq message arrived on closed channel
[W 06:09:14.850 NotebookApp] zmq message arrived on closed channel
[W 06:09:16.914 NotebookApp] zmq message arrived on closed channel
[W 06:09:16.914 NotebookApp] zmq message arrived on closed channel
[W 06:09:16.914 NotebookApp] zmq message arrived on closed channel
[W 06:09:16.915 NotebookApp] zmq message arrived on closed channel
[W 06:09:16.915 NotebookApp] zmq message arrived on closed channel
[W 06:09:16.915 NotebookApp] zmq message arrived on closed channel
[W 06:09:16.916 NotebookApp] zmq message arrived on closed channel
[W 06:09:16.916 NotebookApp] zmq message arrived on closed channel
[W 06:09:16.916 NotebookApp] zmq message arrived on closed channel
[W 06:09:16.916 NotebookApp] zmq message arrived on closed channel
[W 06:09:16.917 NotebookApp] zmq message arrived on closed channel
[W 06:09:16.917 NotebookApp] zmq message arrived on closed channel
subgraph: org.apache.spark.graphx.Graph[Array[String],Int] = org.apache.spark.graphx.impl.GraphImpl@5ec170a1
[W 06:09:17.194 NotebookApp] zmq message arrived on closed channel
[W 06:09:17.195 NotebookApp] zmq message arrived on closed channel
[W 06:09:17.195 NotebookApp] zmq message arrived on closed channel
[W 06:09:17.195 NotebookApp] zmq message arrived on closed channel
[W 06:09:17.196 NotebookApp] zmq message arrived on closed channel
[W 06:09:17.196 NotebookApp] zmq message arrived on closed channel
[W 06:09:19.071 NotebookApp] zmq message arrived on closed channel
[W 06:09:19.071 NotebookApp] zmq message arrived on closed channel
[W 06:09:19.072 NotebookApp] zmq message arrived on closed channel
[W 06:09:19.072 NotebookApp] zmq message arrived on closed channel
[W 06:09:19.072 NotebookApp] zmq message arrived on closed channel
[W 06:09:19.072 NotebookApp] zmq message arrived on closed channel
[W 06:09:19.073 NotebookApp] zmq message arrived on closed channel
[W 06:09:19.073 NotebookApp] zmq message arrived on closed channel
[W 06:09:19.073 NotebookApp] zmq message arrived on closed channel
[W 06:09:19.074 NotebookApp] zmq message arrived on closed channel
[W 06:09:19.074 NotebookApp] zmq message arrived on closed channel
[W 06:09:19.074 NotebookApp] zmq message arrived on closed channel
[I 06:09:24.028 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
pagerankGraph: org.apache.spark.graphx.Graph[Double,Double] = org.apache.spark.graphx.impl.GraphImpl@3a95329a
[W 06:09:29.191 NotebookApp] zmq message arrived on closed channel
[W 06:09:29.192 NotebookApp] zmq message arrived on closed channel
[W 06:09:29.192 NotebookApp] zmq message arrived on closed channel
[W 06:09:29.193 NotebookApp] zmq message arrived on closed channel
[W 06:09:29.193 NotebookApp] zmq message arrived on closed channel
[W 06:09:29.193 NotebookApp] zmq message arrived on closed channel
[W 06:09:37.611 NotebookApp] zmq message arrived on closed channel
[W 06:09:37.612 NotebookApp] zmq message arrived on closed channel
[W 06:09:37.612 NotebookApp] zmq message arrived on closed channel
[W 06:09:37.612 NotebookApp] zmq message arrived on closed channel
[W 06:09:37.612 NotebookApp] zmq message arrived on closed channel
[W 06:09:37.613 NotebookApp] zmq message arrived on closed channel
[W 06:09:38.309 NotebookApp] zmq message arrived on closed channel
[W 06:09:38.310 NotebookApp] zmq message arrived on closed channel
[W 06:09:38.310 NotebookApp] zmq message arrived on closed channel
[W 06:09:38.311 NotebookApp] zmq message arrived on closed channel
[W 06:09:38.311 NotebookApp] zmq message arrived on closed channel
[W 06:09:38.311 NotebookApp] zmq message arrived on closed channel
[W 06:09:47.199 NotebookApp] zmq message arrived on closed channel
[W 06:09:47.199 NotebookApp] zmq message arrived on closed channel
[W 06:09:47.199 NotebookApp] zmq message arrived on closed channel
[W 06:09:47.200 NotebookApp] zmq message arrived on closed channel
[W 06:09:47.200 NotebookApp] zmq message arrived on closed channel
[W 06:09:47.200 NotebookApp] zmq message arrived on closed channel
[W 06:09:47.201 NotebookApp] zmq message arrived on closed channel
[W 06:09:47.201 NotebookApp] zmq message arrived on closed channel
[W 06:09:47.201 NotebookApp] zmq message arrived on closed channel
[W 06:09:47.201 NotebookApp] zmq message arrived on closed channel
[W 06:09:47.202 NotebookApp] zmq message arrived on closed channel
[W 06:09:47.202 NotebookApp] zmq message arrived on closed channel
userInfoWithPageRank: org.apache.spark.graphx.Graph[(Double, List[String]),Int] = org.apache.spark.graphx.impl.GraphImpl@27ca89fc
[W 06:09:47.575 NotebookApp] zmq message arrived on closed channel
[W 06:09:47.576 NotebookApp] zmq message arrived on closed channel
[W 06:09:47.576 NotebookApp] zmq message arrived on closed channel
[W 06:09:47.576 NotebookApp] zmq message arrived on closed channel
[W 06:09:47.577 NotebookApp] zmq message arrived on closed channel
[W 06:09:47.577 NotebookApp] zmq message arrived on closed channel
[W 06:09:49.717 NotebookApp] zmq message arrived on closed channel
[W 06:09:49.718 NotebookApp] zmq message arrived on closed channel
[W 06:09:49.718 NotebookApp] zmq message arrived on closed channel
[W 06:09:49.718 NotebookApp] zmq message arrived on closed channel
[W 06:09:49.718 NotebookApp] zmq message arrived on closed channel
[W 06:09:49.719 NotebookApp] zmq message arrived on closed channel
[W 06:09:49.719 NotebookApp] zmq message arrived on closed channel
[W 06:09:49.719 NotebookApp] zmq message arrived on closed channel
[W 06:09:49.719 NotebookApp] zmq message arrived on closed channel
[W 06:09:49.719 NotebookApp] zmq message arrived on closed channel
[W 06:09:49.720 NotebookApp] zmq message arrived on closed channel
[W 06:09:49.720 NotebookApp] zmq message arrived on closed channel
<console>:45: error: value mkSt is not a member of Array[(org.apache.spark.graphx.VertexId, (Double, List[String]))]
              println(userInfoWithPageRank.vertices.top(5)(Ordering.by(_._2._1)).mkSt ring("\n"))
                                                                                 ^
[W 06:09:49.853 NotebookApp] zmq message arrived on closed channel
[W 06:09:49.854 NotebookApp] zmq message arrived on closed channel
[W 06:09:49.854 NotebookApp] zmq message arrived on closed channel
[W 06:09:49.855 NotebookApp] zmq message arrived on closed channel
[W 06:09:49.855 NotebookApp] zmq message arrived on closed channel
[W 06:09:49.855 NotebookApp] zmq message arrived on closed channel
[W 06:09:49.856 NotebookApp] zmq message arrived on closed channel
[W 06:09:49.856 NotebookApp] zmq message arrived on closed channel
[W 06:09:49.856 NotebookApp] zmq message arrived on closed channel
[W 06:09:49.856 NotebookApp] zmq message arrived on closed channel
[W 06:09:49.856 NotebookApp] zmq message arrived on closed channel
[W 06:09:49.857 NotebookApp] zmq message arrived on closed channel
[W 06:09:56.722 NotebookApp] zmq message arrived on closed channel
[W 06:09:56.722 NotebookApp] zmq message arrived on closed channel
[W 06:09:56.723 NotebookApp] zmq message arrived on closed channel
[W 06:09:56.723 NotebookApp] zmq message arrived on closed channel
[W 06:09:56.723 NotebookApp] zmq message arrived on closed channel
[W 06:09:56.724 NotebookApp] zmq message arrived on closed channel
[W 06:09:56.724 NotebookApp] zmq message arrived on closed channel
[W 06:09:56.724 NotebookApp] zmq message arrived on closed channel
[W 06:09:56.725 NotebookApp] zmq message arrived on closed channel
[W 06:09:56.725 NotebookApp] zmq message arrived on closed channel
[W 06:09:56.725 NotebookApp] zmq message arrived on closed channel
[W 06:09:56.726 NotebookApp] zmq message arrived on closed channel
[W 06:09:57.291 NotebookApp] zmq message arrived on closed channel
[W 06:09:57.291 NotebookApp] zmq message arrived on closed channel
[W 06:09:57.291 NotebookApp] zmq message arrived on closed channel
[W 06:09:57.292 NotebookApp] zmq message arrived on closed channel
[W 06:09:57.292 NotebookApp] zmq message arrived on closed channel
[W 06:09:57.292 NotebookApp] zmq message arrived on closed channel
[W 06:09:57.298 NotebookApp] zmq message arrived on closed channel
[W 06:09:57.299 NotebookApp] zmq message arrived on closed channel
[W 06:09:57.299 NotebookApp] zmq message arrived on closed channel
[W 06:09:57.299 NotebookApp] zmq message arrived on closed channel
[W 06:09:57.299 NotebookApp] zmq message arrived on closed channel
[W 06:09:57.299 NotebookApp] zmq message arrived on closed channel
[I 06:10:32.443 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 06:12:27.424 NotebookApp] Notebook Untitled0.ipynb is not trusted
[I 06:12:27.786 NotebookApp] Request start_kernel: kernel_id=None, kernel_name=python2, path="", **kwargs={}
[I 06:12:27.787 NotebookApp] Provisioning local kernel: python2
[I 06:12:27.839 NotebookApp] Kernel started: 5f1ecd5c-9649-4b79-bf19-e6930fc86e23
WARNING: Attempting to work in a virtualenv. If you encounter problems, please install IPython inside the virtualenv.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/10/22 06:12:30 INFO SparkContext: Running Spark version 1.4.1
15/10/22 06:12:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/10/22 06:12:31 INFO SecurityManager: Changing view acls to: notebook
15/10/22 06:12:31 INFO SecurityManager: Changing modify acls to: notebook
15/10/22 06:12:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(notebook); users with modify permissions: Set(notebook)
15/10/22 06:12:32 INFO Slf4jLogger: Slf4jLogger started
15/10/22 06:12:32 INFO Remoting: Starting remoting
15/10/22 06:12:32 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.22:56255]
15/10/22 06:12:32 INFO Utils: Successfully started service 'sparkDriver' on port 56255.
15/10/22 06:12:32 INFO SparkEnv: Registering MapOutputTracker
15/10/22 06:12:32 INFO SparkEnv: Registering BlockManagerMaster
15/10/22 06:12:32 INFO DiskBlockManager: Created local directory at /tmp/spark-7ca4125c-fd13-4197-aa7f-9fe6163feca2/blockmgr-88b233e4-cd52-4810-b90f-fd20425e41c4
15/10/22 06:12:32 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/10/22 06:12:32 INFO HttpFileServer: HTTP File server directory is /tmp/spark-7ca4125c-fd13-4197-aa7f-9fe6163feca2/httpd-0f8a2ab5-bb96-4597-98e9-db0d62952c1f
15/10/22 06:12:32 INFO HttpServer: Starting HTTP Server
15/10/22 06:12:33 INFO Utils: Successfully started service 'HTTP file server' on port 53762.
15/10/22 06:12:33 INFO SparkEnv: Registering OutputCommitCoordinator
15/10/22 06:12:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/10/22 06:12:33 INFO Utils: Successfully started service 'SparkUI' on port 4041.
15/10/22 06:12:33 INFO SparkUI: Started SparkUI at http://172.17.0.22:4041
15/10/22 06:12:33 INFO Executor: Starting executor ID driver on host localhost
15/10/22 06:12:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34717.
15/10/22 06:12:33 INFO NettyBlockTransferService: Server created on 34717
15/10/22 06:12:33 INFO BlockManagerMaster: Trying to register BlockManager
15/10/22 06:12:33 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34717 with 265.4 MB RAM, BlockManagerId(driver, localhost, 34717)
15/10/22 06:12:33 INFO BlockManagerMaster: Registered BlockManager
[I 06:14:28.768 NotebookApp] Saving file at /Untitled0.ipynb
[I 06:15:42.867 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[W 06:17:03.206 NotebookApp] zmq message arrived on closed channel
[W 06:17:03.207 NotebookApp] zmq message arrived on closed channel
[W 06:17:03.207 NotebookApp] zmq message arrived on closed channel
[W 06:17:03.208 NotebookApp] zmq message arrived on closed channel
[W 06:17:03.211 NotebookApp] zmq message arrived on closed channel
[W 06:17:03.211 NotebookApp] zmq message arrived on closed channel
[W 06:17:03.214 NotebookApp] zmq message arrived on closed channel
[W 06:17:03.214 NotebookApp] zmq message arrived on closed channel
[W 06:17:09.081 NotebookApp] zmq message arrived on closed channel
[W 06:17:09.082 NotebookApp] zmq message arrived on closed channel
[W 06:17:09.083 NotebookApp] zmq message arrived on closed channel
[W 06:17:09.083 NotebookApp] zmq message arrived on closed channel
[W 06:17:09.099 NotebookApp] zmq message arrived on closed channel
[W 06:17:09.100 NotebookApp] zmq message arrived on closed channel
[W 06:17:09.102 NotebookApp] zmq message arrived on closed channel
[W 06:17:09.102 NotebookApp] zmq message arrived on closed channel
[W 06:17:15.155 NotebookApp] zmq message arrived on closed channel
[W 06:17:15.156 NotebookApp] zmq message arrived on closed channel
[W 06:17:15.156 NotebookApp] zmq message arrived on closed channel
[W 06:17:15.157 NotebookApp] zmq message arrived on closed channel
[W 06:17:15.348 NotebookApp] zmq message arrived on closed channel
[W 06:17:15.348 NotebookApp] zmq message arrived on closed channel
[W 06:17:15.350 NotebookApp] zmq message arrived on closed channel
[W 06:17:15.351 NotebookApp] zmq message arrived on closed channel
[W 06:17:23.808 NotebookApp] zmq message arrived on closed channel
[W 06:17:23.809 NotebookApp] zmq message arrived on closed channel
[W 06:17:23.809 NotebookApp] zmq message arrived on closed channel
[W 06:17:23.810 NotebookApp] zmq message arrived on closed channel
[W 06:17:23.823 NotebookApp] zmq message arrived on closed channel
[W 06:17:23.824 NotebookApp] zmq message arrived on closed channel
[W 06:17:23.826 NotebookApp] zmq message arrived on closed channel
[W 06:17:23.826 NotebookApp] zmq message arrived on closed channel
[I 06:17:43.284 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[W 06:18:12.849 NotebookApp] zmq message arrived on closed channel
[W 06:18:12.850 NotebookApp] zmq message arrived on closed channel
[W 06:18:12.850 NotebookApp] zmq message arrived on closed channel
[W 06:18:12.851 NotebookApp] zmq message arrived on closed channel
[W 06:18:12.851 NotebookApp] zmq message arrived on closed channel
[W 06:18:12.851 NotebookApp] zmq message arrived on closed channel
[W 06:18:12.852 NotebookApp] zmq message arrived on closed channel
[W 06:18:12.852 NotebookApp] zmq message arrived on closed channel
[W 06:18:12.852 NotebookApp] zmq message arrived on closed channel
[W 06:18:12.853 NotebookApp] zmq message arrived on closed channel
[W 06:18:12.853 NotebookApp] zmq message arrived on closed channel
[W 06:18:12.853 NotebookApp] zmq message arrived on closed channel
import org.apache.log4j.Logger
import org.apache.log4j.Level
import org.apache.spark._
import org.apache.spark.streaming._
import org.apache.spark.streaming.StreamingContext._
[W 06:18:14.286 NotebookApp] zmq message arrived on closed channel
[W 06:18:14.287 NotebookApp] zmq message arrived on closed channel
[W 06:18:14.287 NotebookApp] zmq message arrived on closed channel
[W 06:18:14.288 NotebookApp] zmq message arrived on closed channel
[W 06:18:14.288 NotebookApp] zmq message arrived on closed channel
[W 06:18:14.288 NotebookApp] zmq message arrived on closed channel
[I 06:19:23.904 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 06:19:40.992 NotebookApp] zmq message arrived on closed channel
[W 06:19:40.993 NotebookApp] zmq message arrived on closed channel
[W 06:19:40.993 NotebookApp] zmq message arrived on closed channel
[W 06:19:40.994 NotebookApp] zmq message arrived on closed channel
[W 06:19:40.994 NotebookApp] zmq message arrived on closed channel
[W 06:19:40.995 NotebookApp] zmq message arrived on closed channel
[W 06:19:40.995 NotebookApp] zmq message arrived on closed channel
[W 06:19:40.996 NotebookApp] zmq message arrived on closed channel
[W 06:19:40.996 NotebookApp] zmq message arrived on closed channel
[W 06:19:40.996 NotebookApp] zmq message arrived on closed channel
[W 06:19:40.997 NotebookApp] zmq message arrived on closed channel
[W 06:19:40.997 NotebookApp] zmq message arrived on closed channel
ssc: org.apache.spark.streaming.StreamingContext = org.apache.spark.streaming.StreamingContext@79fbebf7
[W 06:19:41.894 NotebookApp] zmq message arrived on closed channel
[W 06:19:41.894 NotebookApp] zmq message arrived on closed channel
[W 06:19:41.894 NotebookApp] zmq message arrived on closed channel
[W 06:19:41.895 NotebookApp] zmq message arrived on closed channel
[W 06:19:41.895 NotebookApp] zmq message arrived on closed channel
[W 06:19:41.895 NotebookApp] zmq message arrived on closed channel
[I 06:19:43.069 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[W 06:19:48.606 NotebookApp] zmq message arrived on closed channel
[W 06:19:48.606 NotebookApp] zmq message arrived on closed channel
[W 06:19:48.607 NotebookApp] zmq message arrived on closed channel
[W 06:19:48.607 NotebookApp] zmq message arrived on closed channel
[W 06:19:48.607 NotebookApp] zmq message arrived on closed channel
[W 06:19:48.608 NotebookApp] zmq message arrived on closed channel
[W 06:19:48.608 NotebookApp] zmq message arrived on closed channel
[W 06:19:48.609 NotebookApp] zmq message arrived on closed channel
[W 06:19:48.609 NotebookApp] zmq message arrived on closed channel
[W 06:19:48.609 NotebookApp] zmq message arrived on closed channel
[W 06:19:48.609 NotebookApp] zmq message arrived on closed channel
[W 06:19:48.610 NotebookApp] zmq message arrived on closed channel
lines: org.apache.spark.streaming.dstream.ReceiverInputDStream[String] = org.apache.spark.streaming.dstream.SocketInputDStream@6788da90
[W 06:19:48.853 NotebookApp] zmq message arrived on closed channel
[W 06:19:48.853 NotebookApp] zmq message arrived on closed channel
[W 06:19:48.853 NotebookApp] zmq message arrived on closed channel
[W 06:19:48.854 NotebookApp] zmq message arrived on closed channel
[W 06:19:48.854 NotebookApp] zmq message arrived on closed channel
[W 06:19:48.854 NotebookApp] zmq message arrived on closed channel
[W 06:19:51.566 NotebookApp] zmq message arrived on closed channel
[W 06:19:51.566 NotebookApp] zmq message arrived on closed channel
[W 06:19:51.566 NotebookApp] zmq message arrived on closed channel
[W 06:19:51.566 NotebookApp] zmq message arrived on closed channel
[W 06:19:51.567 NotebookApp] zmq message arrived on closed channel
[W 06:19:51.567 NotebookApp] zmq message arrived on closed channel
[W 06:19:51.568 NotebookApp] zmq message arrived on closed channel
[W 06:19:51.568 NotebookApp] zmq message arrived on closed channel
[W 06:19:51.568 NotebookApp] zmq message arrived on closed channel
[W 06:19:51.569 NotebookApp] zmq message arrived on closed channel
[W 06:19:51.569 NotebookApp] zmq message arrived on closed channel
[W 06:19:51.569 NotebookApp] zmq message arrived on closed channel
pass: org.apache.spark.streaming.dstream.DStream[(String, Int)] = org.apache.spark.streaming.dstream.ShuffledDStream@f747af2
[W 06:19:51.910 NotebookApp] zmq message arrived on closed channel
[W 06:19:51.910 NotebookApp] zmq message arrived on closed channel
[W 06:19:51.911 NotebookApp] zmq message arrived on closed channel
[W 06:19:51.911 NotebookApp] zmq message arrived on closed channel
[W 06:19:51.911 NotebookApp] zmq message arrived on closed channel
[W 06:19:51.912 NotebookApp] zmq message arrived on closed channel
[W 06:19:57.469 NotebookApp] zmq message arrived on closed channel
[W 06:19:57.470 NotebookApp] zmq message arrived on closed channel
[W 06:19:57.470 NotebookApp] zmq message arrived on closed channel
[W 06:19:57.470 NotebookApp] zmq message arrived on closed channel
[W 06:19:57.470 NotebookApp] zmq message arrived on closed channel
[W 06:19:57.471 NotebookApp] zmq message arrived on closed channel
[W 06:19:57.471 NotebookApp] zmq message arrived on closed channel
[W 06:19:57.472 NotebookApp] zmq message arrived on closed channel
[W 06:19:57.472 NotebookApp] zmq message arrived on closed channel
[W 06:19:57.472 NotebookApp] zmq message arrived on closed channel
[W 06:19:57.472 NotebookApp] zmq message arrived on closed channel
[W 06:19:57.472 NotebookApp] zmq message arrived on closed channel
[W 06:19:57.691 NotebookApp] zmq message arrived on closed channel
[W 06:19:57.692 NotebookApp] zmq message arrived on closed channel
[W 06:19:57.692 NotebookApp] zmq message arrived on closed channel
[W 06:19:57.692 NotebookApp] zmq message arrived on closed channel
[W 06:19:57.693 NotebookApp] zmq message arrived on closed channel
[W 06:19:57.693 NotebookApp] zmq message arrived on closed channel
[W 06:20:30.568 NotebookApp] zmq message arrived on closed channel
[W 06:20:30.569 NotebookApp] zmq message arrived on closed channel
[W 06:20:30.569 NotebookApp] zmq message arrived on closed channel
[W 06:20:30.569 NotebookApp] zmq message arrived on closed channel
[W 06:20:30.570 NotebookApp] zmq message arrived on closed channel
[W 06:20:30.570 NotebookApp] zmq message arrived on closed channel
[W 06:20:30.570 NotebookApp] zmq message arrived on closed channel
[W 06:20:30.570 NotebookApp] zmq message arrived on closed channel
[W 06:20:30.570 NotebookApp] zmq message arrived on closed channel
[W 06:20:30.571 NotebookApp] zmq message arrived on closed channel
[W 06:20:30.572 NotebookApp] zmq message arrived on closed channel
[W 06:20:30.572 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:31 [WARN] o.a.s.s.BlockManager - Block input-0-1445494830800 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:31.076 NotebookApp] zmq message arrived on closed channel
[W 06:20:31.076 NotebookApp] zmq message arrived on closed channel
[W 06:20:31.077 NotebookApp] zmq message arrived on closed channel
[W 06:20:31.077 NotebookApp] zmq message arrived on closed channel
[W 06:20:31.077 NotebookApp] zmq message arrived on closed channel
[W 06:20:31.077 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:31 [WARN] o.a.s.s.BlockManager - Block input-0-1445494831400 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:32 [WARN] o.a.s.s.BlockManager - Block input-0-1445494831800 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:32.078 NotebookApp] zmq message arrived on closed channel
[W 06:20:32.078 NotebookApp] zmq message arrived on closed channel
[W 06:20:32.078 NotebookApp] zmq message arrived on closed channel
[W 06:20:32.079 NotebookApp] zmq message arrived on closed channel
[W 06:20:32.079 NotebookApp] zmq message arrived on closed channel
[W 06:20:32.079 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:32 [WARN] o.a.s.s.BlockManager - Block input-0-1445494832400 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:33 [WARN] o.a.s.s.BlockManager - Block input-0-1445494832800 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:33.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:33.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:33.069 NotebookApp] zmq message arrived on closed channel
[W 06:20:33.069 NotebookApp] zmq message arrived on closed channel
[W 06:20:33.069 NotebookApp] zmq message arrived on closed channel
[W 06:20:33.070 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:33 [WARN] o.a.s.s.BlockManager - Block input-0-1445494833400 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:34 [WARN] o.a.s.s.BlockManager - Block input-0-1445494833800 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:34.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:34.069 NotebookApp] zmq message arrived on closed channel
[W 06:20:34.069 NotebookApp] zmq message arrived on closed channel
[W 06:20:34.069 NotebookApp] zmq message arrived on closed channel
[W 06:20:34.069 NotebookApp] zmq message arrived on closed channel
[W 06:20:34.069 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:34 [WARN] o.a.s.s.BlockManager - Block input-0-1445494834400 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:35 [WARN] o.a.s.s.BlockManager - Block input-0-1445494834800 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:35.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:35.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:35.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:35.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:35.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:35.068 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:35 [WARN] o.a.s.s.BlockManager - Block input-0-1445494835400 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:36 [WARN] o.a.s.s.BlockManager - Block input-0-1445494835800 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:36.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:36.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:36.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:36.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:36.069 NotebookApp] zmq message arrived on closed channel
[W 06:20:36.069 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:36 [WARN] o.a.s.s.BlockManager - Block input-0-1445494836400 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:37 [WARN] o.a.s.s.BlockManager - Block input-0-1445494836800 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:37.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:37.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:37.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:37.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:37.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:37.068 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:37 [WARN] o.a.s.s.BlockManager - Block input-0-1445494837400 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:38 [WARN] o.a.s.s.BlockManager - Block input-0-1445494837800 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:38.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:38.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:38.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:38.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:38.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:38.067 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:38 [WARN] o.a.s.s.BlockManager - Block input-0-1445494838400 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:39 [WARN] o.a.s.s.BlockManager - Block input-0-1445494838800 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:39.064 NotebookApp] zmq message arrived on closed channel
[W 06:20:39.065 NotebookApp] zmq message arrived on closed channel
[W 06:20:39.065 NotebookApp] zmq message arrived on closed channel
[W 06:20:39.065 NotebookApp] zmq message arrived on closed channel
[W 06:20:39.065 NotebookApp] zmq message arrived on closed channel
[W 06:20:39.066 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:39 [WARN] o.a.s.s.BlockManager - Block input-0-1445494839400 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:40.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:40.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:40.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:40.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:40.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:40.068 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:40 [WARN] o.a.s.s.BlockManager - Block input-0-1445494840000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:40 [WARN] o.a.s.s.BlockManager - Block input-0-1445494840400 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:41.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:41.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:41.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:41.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:41.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:41.069 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:41 [WARN] o.a.s.s.BlockManager - Block input-0-1445494841000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:41 [WARN] o.a.s.s.BlockManager - Block input-0-1445494841400 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:42.065 NotebookApp] zmq message arrived on closed channel
[W 06:20:42.065 NotebookApp] zmq message arrived on closed channel
[W 06:20:42.065 NotebookApp] zmq message arrived on closed channel
[W 06:20:42.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:42.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:42.067 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:42 [WARN] o.a.s.s.BlockManager - Block input-0-1445494842000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:42 [WARN] o.a.s.s.BlockManager - Block input-0-1445494842400 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:43.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:43.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:43.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:43.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:43.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:43.067 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:43 [WARN] o.a.s.s.BlockManager - Block input-0-1445494843000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:43 [WARN] o.a.s.s.BlockManager - Block input-0-1445494843400 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:44.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:44.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:44.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:44.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:44.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:44.068 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:44 [WARN] o.a.s.s.BlockManager - Block input-0-1445494844000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:44 [WARN] o.a.s.s.BlockManager - Block input-0-1445494844400 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:45.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:45.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:45.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:45.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:45.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:45.068 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:45 [WARN] o.a.s.s.BlockManager - Block input-0-1445494845000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:45 [WARN] o.a.s.s.BlockManager - Block input-0-1445494845400 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:46.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:46.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:46.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:46.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:46.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:46.067 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:46 [WARN] o.a.s.s.BlockManager - Block input-0-1445494846000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:46 [WARN] o.a.s.s.BlockManager - Block input-0-1445494846400 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:47.065 NotebookApp] zmq message arrived on closed channel
[W 06:20:47.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:47.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:47.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:47.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:47.067 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:47 [WARN] o.a.s.s.BlockManager - Block input-0-1445494847000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:47 [WARN] o.a.s.s.BlockManager - Block input-0-1445494847400 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:48.091 NotebookApp] zmq message arrived on closed channel
[W 06:20:48.091 NotebookApp] zmq message arrived on closed channel
[W 06:20:48.091 NotebookApp] zmq message arrived on closed channel
[W 06:20:48.092 NotebookApp] zmq message arrived on closed channel
[W 06:20:48.092 NotebookApp] zmq message arrived on closed channel
[W 06:20:48.092 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:48 [WARN] o.a.s.s.BlockManager - Block input-0-1445494848000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:48 [WARN] o.a.s.s.BlockManager - Block input-0-1445494848400 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:49.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:49.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:49.069 NotebookApp] zmq message arrived on closed channel
[W 06:20:49.069 NotebookApp] zmq message arrived on closed channel
[W 06:20:49.070 NotebookApp] zmq message arrived on closed channel
[W 06:20:49.070 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:49 [WARN] o.a.s.s.BlockManager - Block input-0-1445494849000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:49 [WARN] o.a.s.s.BlockManager - Block input-0-1445494849400 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:50.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:50.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:50.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:50.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:50.069 NotebookApp] zmq message arrived on closed channel
[W 06:20:50.069 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:50 [WARN] o.a.s.s.BlockManager - Block input-0-1445494850000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:50 [WARN] o.a.s.s.BlockManager - Block input-0-1445494850400 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:51.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:51.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:51.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:51.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:51.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:51.068 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:51 [WARN] o.a.s.s.BlockManager - Block input-0-1445494851000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:51 [WARN] o.a.s.s.BlockManager - Block input-0-1445494851400 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:52.065 NotebookApp] zmq message arrived on closed channel
[W 06:20:52.065 NotebookApp] zmq message arrived on closed channel
[W 06:20:52.065 NotebookApp] zmq message arrived on closed channel
[W 06:20:52.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:52.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:52.066 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:52 [WARN] o.a.s.s.BlockManager - Block input-0-1445494852000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:52 [WARN] o.a.s.s.BlockManager - Block input-0-1445494852400 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:53.065 NotebookApp] zmq message arrived on closed channel
[W 06:20:53.065 NotebookApp] zmq message arrived on closed channel
[W 06:20:53.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:53.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:53.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:53.066 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:53 [WARN] o.a.s.s.BlockManager - Block input-0-1445494853000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:53 [WARN] o.a.s.s.BlockManager - Block input-0-1445494853400 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:54.065 NotebookApp] zmq message arrived on closed channel
[W 06:20:54.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:54.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:54.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:54.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:54.067 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:54 [WARN] o.a.s.s.BlockManager - Block input-0-1445494854000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:54 [WARN] o.a.s.s.BlockManager - Block input-0-1445494854400 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:55.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:55.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:55.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:55.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:55.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:55.068 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:55 [WARN] o.a.s.s.BlockManager - Block input-0-1445494855000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:55 [WARN] o.a.s.s.BlockManager - Block input-0-1445494855400 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:56.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:56.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:56.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:56.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:56.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:56.069 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:56 [WARN] o.a.s.s.BlockManager - Block input-0-1445494856000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:56 [WARN] o.a.s.s.BlockManager - Block input-0-1445494856400 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:57.064 NotebookApp] zmq message arrived on closed channel
[W 06:20:57.065 NotebookApp] zmq message arrived on closed channel
[W 06:20:57.065 NotebookApp] zmq message arrived on closed channel
[W 06:20:57.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:57.066 NotebookApp] zmq message arrived on closed channel
[W 06:20:57.066 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:57 [WARN] o.a.s.s.BlockManager - Block input-0-1445494857000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:57 [WARN] o.a.s.s.BlockManager - Block input-0-1445494857400 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:58.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:58.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:58.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:58.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:58.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:58.069 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:58 [WARN] o.a.s.s.BlockManager - Block input-0-1445494858000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:58 [WARN] o.a.s.s.BlockManager - Block input-0-1445494858400 replicated to only 0 peer(s) instead of 1 peers
[W 06:20:59.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:59.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:59.067 NotebookApp] zmq message arrived on closed channel
[W 06:20:59.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:59.068 NotebookApp] zmq message arrived on closed channel
[W 06:20:59.069 NotebookApp] zmq message arrived on closed channel
15/10/22 06:20:59 [WARN] o.a.s.s.BlockManager - Block input-0-1445494859000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:20:59 [WARN] o.a.s.s.BlockManager - Block input-0-1445494859400 replicated to only 0 peer(s) instead of 1 peers
===============================>  (25 + 1) / 26][Stage 33611:>                                                      (0 + 0) / 2[W 06:21:00.043 NotebookApp] zmq message arrived on closed channel
[W 06:21:00.044 NotebookApp] zmq message arrived on closed channel
[W 06:21:00.044 NotebookApp] zmq message arrived on closed channel
[W 06:21:00.044 NotebookApp] zmq message arrived on closed channel
[W 06:21:00.045 NotebookApp] zmq message arrived on closed channel
[W 06:21:00.045 NotebookApp] zmq message arrived on closed channel
[W 06:21:00.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:00.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:00.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:00.068 NotebookApp] zmq message arrived on closed channel
[W 06:21:00.068 NotebookApp] zmq message arrived on closed channel
[W 06:21:00.068 NotebookApp] zmq message arrived on closed channel
15/10/22 06:21:00 [WARN] o.a.s.s.BlockManager - Block input-0-1445494860000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:21:00 [WARN] o.a.s.s.BlockManager - Block input-0-1445494860400 replicated to only 0 peer(s) instead of 1 peers
[W 06:21:01.065 NotebookApp] zmq message arrived on closed channel
[W 06:21:01.065 NotebookApp] zmq message arrived on closed channel
[W 06:21:01.065 NotebookApp] zmq message arrived on closed channel
[W 06:21:01.066 NotebookApp] zmq message arrived on closed channel
[W 06:21:01.066 NotebookApp] zmq message arrived on closed channel
[W 06:21:01.067 NotebookApp] zmq message arrived on closed channel
15/10/22 06:21:01 [WARN] o.a.s.s.BlockManager - Block input-0-1445494861000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:21:01 [WARN] o.a.s.s.BlockManager - Block input-0-1445494861400 replicated to only 0 peer(s) instead of 1 peers
[W 06:21:02.043 NotebookApp] zmq message arrived on closed channel
[W 06:21:02.043 NotebookApp] zmq message arrived on closed channel
[W 06:21:02.043 NotebookApp] zmq message arrived on closed channel
[W 06:21:02.044 NotebookApp] zmq message arrived on closed channel
[W 06:21:02.044 NotebookApp] zmq message arrived on closed channel
[W 06:21:02.044 NotebookApp] zmq message arrived on closed channel
[W 06:21:02.066 NotebookApp] zmq message arrived on closed channel
[W 06:21:02.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:02.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:02.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:02.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:02.067 NotebookApp] zmq message arrived on closed channel
15/10/22 06:21:02 [WARN] o.a.s.s.BlockManager - Block input-0-1445494862000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:21:02 [WARN] o.a.s.s.BlockManager - Block input-0-1445494862400 replicated to only 0 peer(s) instead of 1 peers
][Stage 33623:>                                                      (0 + 0) / 2][Stage 33629:>                               [W 06:21:03.043 NotebookApp] zmq message arrived on closed channel
[W 06:21:03.044 NotebookApp] zmq message arrived on closed channel
[W 06:21:03.044 NotebookApp] zmq message arrived on closed channel
[W 06:21:03.044 NotebookApp] zmq message arrived on closed channel
[W 06:21:03.045 NotebookApp] zmq message arrived on closed channel
[W 06:21:03.045 NotebookApp] zmq message arrived on closed channel
[W 06:21:03.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:03.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:03.068 NotebookApp] zmq message arrived on closed channel
[W 06:21:03.068 NotebookApp] zmq message arrived on closed channel
[W 06:21:03.068 NotebookApp] zmq message arrived on closed channel
[W 06:21:03.068 NotebookApp] zmq message arrived on closed channel
15/10/22 06:21:03 [WARN] o.a.s.s.BlockManager - Block input-0-1445494863000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:21:03 [WARN] o.a.s.s.BlockManager - Block input-0-1445494863400 replicated to only 0 peer(s) instead of 1 peers
[W 06:21:04.043 NotebookApp] zmq message arrived on closed channel
[W 06:21:04.044 NotebookApp] zmq message arrived on closed channel
[W 06:21:04.044 NotebookApp] zmq message arrived on closed channel
[W 06:21:04.044 NotebookApp] zmq message arrived on closed channel
[W 06:21:04.044 NotebookApp] zmq message arrived on closed channel
[W 06:21:04.045 NotebookApp] zmq message arrived on closed channel
[W 06:21:04.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:04.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:04.068 NotebookApp] zmq message arrived on closed channel
[W 06:21:04.068 NotebookApp] zmq message arrived on closed channel
[W 06:21:04.068 NotebookApp] zmq message arrived on closed channel
[W 06:21:04.068 NotebookApp] zmq message arrived on closed channel
15/10/22 06:21:04 [WARN] o.a.s.s.BlockManager - Block input-0-1445494864000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:21:04 [WARN] o.a.s.s.BlockManager - Block input-0-1445494864400 replicated to only 0 peer(s) instead of 1 peers
[W 06:21:05.066 NotebookApp] zmq message arrived on closed channel
[W 06:21:05.066 NotebookApp] zmq message arrived on closed channel
[W 06:21:05.066 NotebookApp] zmq message arrived on closed channel
[W 06:21:05.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:05.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:05.068 NotebookApp] zmq message arrived on closed channel
15/10/22 06:21:05 [WARN] o.a.s.s.BlockManager - Block input-0-1445494865000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:21:05 [WARN] o.a.s.s.BlockManager - Block input-0-1445494865400 replicated to only 0 peer(s) instead of 1 peers
[W 06:21:06.065 NotebookApp] zmq message arrived on closed channel
[W 06:21:06.065 NotebookApp] zmq message arrived on closed channel
[W 06:21:06.065 NotebookApp] zmq message arrived on closed channel
[W 06:21:06.065 NotebookApp] zmq message arrived on closed channel
[W 06:21:06.065 NotebookApp] zmq message arrived on closed channel
[W 06:21:06.066 NotebookApp] zmq message arrived on closed channel
15/10/22 06:21:06 [WARN] o.a.s.s.BlockManager - Block input-0-1445494866000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:21:06 [WARN] o.a.s.s.BlockManager - Block input-0-1445494866400 replicated to only 0 peer(s) instead of 1 peers
[W 06:21:07.064 NotebookApp] zmq message arrived on closed channel
[W 06:21:07.065 NotebookApp] zmq message arrived on closed channel
[W 06:21:07.065 NotebookApp] zmq message arrived on closed channel
[W 06:21:07.065 NotebookApp] zmq message arrived on closed channel
[W 06:21:07.066 NotebookApp] zmq message arrived on closed channel
[W 06:21:07.066 NotebookApp] zmq message arrived on closed channel
15/10/22 06:21:07 [WARN] o.a.s.s.BlockManager - Block input-0-1445494867000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:21:07 [WARN] o.a.s.s.BlockManager - Block input-0-1445494867400 replicated to only 0 peer(s) instead of 1 peers
[W 06:21:08.065 NotebookApp] zmq message arrived on closed channel
[W 06:21:08.065 NotebookApp] zmq message arrived on closed channel
[W 06:21:08.066 NotebookApp] zmq message arrived on closed channel
[W 06:21:08.066 NotebookApp] zmq message arrived on closed channel
[W 06:21:08.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:08.067 NotebookApp] zmq message arrived on closed channel
15/10/22 06:21:08 [WARN] o.a.s.s.BlockManager - Block input-0-1445494868000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:21:08 [WARN] o.a.s.s.BlockManager - Block input-0-1445494868400 replicated to only 0 peer(s) instead of 1 peers
[W 06:21:09.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:09.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:09.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:09.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:09.068 NotebookApp] zmq message arrived on closed channel
[W 06:21:09.068 NotebookApp] zmq message arrived on closed channel
15/10/22 06:21:09 [WARN] o.a.s.s.BlockManager - Block input-0-1445494869000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:21:09 [WARN] o.a.s.s.BlockManager - Block input-0-1445494869400 replicated to only 0 peer(s) instead of 1 peers
[W 06:21:10.065 NotebookApp] zmq message arrived on closed channel
[W 06:21:10.066 NotebookApp] zmq message arrived on closed channel
[W 06:21:10.066 NotebookApp] zmq message arrived on closed channel
[W 06:21:10.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:10.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:10.067 NotebookApp] zmq message arrived on closed channel
15/10/22 06:21:10 [WARN] o.a.s.s.BlockManager - Block input-0-1445494870000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:21:10 [WARN] o.a.s.s.BlockManager - Block input-0-1445494870400 replicated to only 0 peer(s) instead of 1 peers
[W 06:21:11.064 NotebookApp] zmq message arrived on closed channel
[W 06:21:11.064 NotebookApp] zmq message arrived on closed channel
[W 06:21:11.064 NotebookApp] zmq message arrived on closed channel
[W 06:21:11.065 NotebookApp] zmq message arrived on closed channel
[W 06:21:11.065 NotebookApp] zmq message arrived on closed channel
[W 06:21:11.065 NotebookApp] zmq message arrived on closed channel
15/10/22 06:21:11 [WARN] o.a.s.s.BlockManager - Block input-0-1445494871000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:21:11 [WARN] o.a.s.s.BlockManager - Block input-0-1445494871400 replicated to only 0 peer(s) instead of 1 peers
[W 06:21:12.065 NotebookApp] zmq message arrived on closed channel
[W 06:21:12.065 NotebookApp] zmq message arrived on closed channel
[W 06:21:12.065 NotebookApp] zmq message arrived on closed channel
[W 06:21:12.066 NotebookApp] zmq message arrived on closed channel
[W 06:21:12.066 NotebookApp] zmq message arrived on closed channel
[W 06:21:12.066 NotebookApp] zmq message arrived on closed channel
15/10/22 06:21:12 [WARN] o.a.s.s.BlockManager - Block input-0-1445494872000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:21:12 [WARN] o.a.s.s.BlockManager - Block input-0-1445494872400 replicated to only 0 peer(s) instead of 1 peers
[W 06:21:13.066 NotebookApp] zmq message arrived on closed channel
[W 06:21:13.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:13.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:13.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:13.068 NotebookApp] zmq message arrived on closed channel
[W 06:21:13.068 NotebookApp] zmq message arrived on closed channel
15/10/22 06:21:13 [WARN] o.a.s.s.BlockManager - Block input-0-1445494873000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:21:13 [WARN] o.a.s.s.BlockManager - Block input-0-1445494873400 replicated to only 0 peer(s) instead of 1 peers
[W 06:21:14.066 NotebookApp] zmq message arrived on closed channel
[W 06:21:14.066 NotebookApp] zmq message arrived on closed channel
[W 06:21:14.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:14.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:14.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:14.067 NotebookApp] zmq message arrived on closed channel
15/10/22 06:21:14 [WARN] o.a.s.s.BlockManager - Block input-0-1445494874000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:21:14 [WARN] o.a.s.s.BlockManager - Block input-0-1445494874400 replicated to only 0 peer(s) instead of 1 peers
[W 06:21:15.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:15.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:15.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:15.068 NotebookApp] zmq message arrived on closed channel
[W 06:21:15.068 NotebookApp] zmq message arrived on closed channel
[W 06:21:15.068 NotebookApp] zmq message arrived on closed channel
15/10/22 06:21:15 [WARN] o.a.s.s.BlockManager - Block input-0-1445494875000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:21:15 [WARN] o.a.s.s.BlockManager - Block input-0-1445494875400 replicated to only 0 peer(s) instead of 1 peers
[W 06:21:16.066 NotebookApp] zmq message arrived on closed channel
[W 06:21:16.066 NotebookApp] zmq message arrived on closed channel
[W 06:21:16.066 NotebookApp] zmq message arrived on closed channel
[W 06:21:16.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:16.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:16.067 NotebookApp] zmq message arrived on closed channel
15/10/22 06:21:16 [WARN] o.a.s.s.BlockManager - Block input-0-1445494876000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:21:16 [WARN] o.a.s.s.BlockManager - Block input-0-1445494876400 replicated to only 0 peer(s) instead of 1 peers
[W 06:21:17.066 NotebookApp] zmq message arrived on closed channel
[W 06:21:17.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:17.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:17.068 NotebookApp] zmq message arrived on closed channel
[W 06:21:17.068 NotebookApp] zmq message arrived on closed channel
[W 06:21:17.068 NotebookApp] zmq message arrived on closed channel
15/10/22 06:21:17 [WARN] o.a.s.s.BlockManager - Block input-0-1445494877000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:21:17 [WARN] o.a.s.s.BlockManager - Block input-0-1445494877400 replicated to only 0 peer(s) instead of 1 peers
[W 06:21:18.065 NotebookApp] zmq message arrived on closed channel
[W 06:21:18.065 NotebookApp] zmq message arrived on closed channel
[W 06:21:18.065 NotebookApp] zmq message arrived on closed channel
[W 06:21:18.066 NotebookApp] zmq message arrived on closed channel
[W 06:21:18.066 NotebookApp] zmq message arrived on closed channel
[W 06:21:18.067 NotebookApp] zmq message arrived on closed channel
15/10/22 06:21:18 [WARN] o.a.s.s.BlockManager - Block input-0-1445494878000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:21:18 [WARN] o.a.s.s.BlockManager - Block input-0-1445494878400 replicated to only 0 peer(s) instead of 1 peers
[W 06:21:19.066 NotebookApp] zmq message arrived on closed channel
[W 06:21:19.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:19.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:19.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:19.068 NotebookApp] zmq message arrived on closed channel
[W 06:21:19.068 NotebookApp] zmq message arrived on closed channel
15/10/22 06:21:19 [WARN] o.a.s.s.BlockManager - Block input-0-1445494879000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:21:19 [WARN] o.a.s.s.BlockManager - Block input-0-1445494879400 replicated to only 0 peer(s) instead of 1 peers
[W 06:21:20.067 NotebookApp] zmq message arrived on closed channel
[W 06:21:20.068 NotebookApp] zmq message arrived on closed channel
[W 06:21:20.068 NotebookApp] zmq message arrived on closed channel
[W 06:21:20.069 NotebookApp] zmq message arrived on closed channel
[W 06:21:20.069 NotebookApp] zmq message arrived on closed channel
[W 06:21:20.069 NotebookApp] zmq message arrived on closed channel
15/10/22 06:21:20 [WARN] o.a.s.s.BlockManager - Block input-0-1445494880000 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:21:20 [WARN] o.a.s.s.BlockManager - Block input-0-1445494880400 replicated to only 0 peer(s) instead of 1 peers
[I 06:21:20.815 NotebookApp] Kernel interrupted: e85064b7-a07a-452b-8f29-ac7f2b8cb557
15/10/22 06:21:20 [INFO] c.i.s.SparkKernel$$anon$1 - Resetting code execution!
15/10/22 06:21:20 [INFO] c.i.s.SparkKernel$$anon$1 - Enter Ctrl-C twice to shutdown!
[W 06:21:21.003 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.004 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.004 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.004 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.005 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.005 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.005 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.006 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.006 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.006 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.007 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.007 NotebookApp] zmq message arrived on closed channel
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2017)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2052)
	at org.apache.spark.streaming.ContextWaiter.waitForStopOrError(ContextWaiter.scala:63)
	at org.apache.spark.streaming.StreamingContext.awaitTermination(StreamingContext.scala:623)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:46)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:51)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:53)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:55)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:57)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:59)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:61)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:63)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:65)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:67)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:69)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:71)
	at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:73)
	at $iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:75)
	at $iwC$$iwC$$iwC$$iwC.<init>(<console>:77)
	at $iwC$$iwC$$iwC.<init>(<console>:79)
	at $iwC$$iwC.<init>(<console>:81)
	at $iwC.<init>(<console>:83)
	at <init>(<console>:85)
	at .<init>(<console>:89)
	at .<clinit>(<console>)
	at .<init>(<console>:7)
	at .<clinit>(<console>)
	at $print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1338)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	at com.ibm.spark.interpreter.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:296)
	at com.ibm.spark.interpreter.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:291)
	at com.ibm.spark.global.StreamState$.withStreams(StreamState.scala:80)
	at com.ibm.spark.interpreter.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:290)
	at com.ibm.spark.interpreter.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:290)
	at com.ibm.spark.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

[W 06:21:21.063 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.064 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.064 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.064 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.064 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.065 NotebookApp] zmq message arrived on closed channel
lastException: Throwable = null
[W 06:21:21.218 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.218 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.218 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.219 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.219 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.219 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.219 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.220 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.220 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.220 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.221 NotebookApp] zmq message arrived on closed channel
[W 06:21:21.221 NotebookApp] zmq message arrived on closed channel
[W 06:21:22.060 NotebookApp] zmq message arrived on closed channel
[W 06:21:22.060 NotebookApp] zmq message arrived on closed channel
[W 06:21:22.060 NotebookApp] zmq message arrived on closed channel
[W 06:21:22.061 NotebookApp] zmq message arrived on closed channel
[W 06:21:22.061 NotebookApp] zmq message arrived on closed channel
[W 06:21:22.061 NotebookApp] zmq message arrived on closed channel
[W 06:21:23.059 NotebookApp] zmq message arrived on closed channel
[W 06:21:23.059 NotebookApp] zmq message arrived on closed channel
[W 06:21:23.059 NotebookApp] zmq message arrived on closed channel
[W 06:21:23.059 NotebookApp] zmq message arrived on closed channel
[W 06:21:23.059 NotebookApp] zmq message arrived on closed channel
[W 06:21:23.060 NotebookApp] zmq message arrived on closed channel
[W 06:21:24.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:24.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:24.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:24.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:24.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:24.059 NotebookApp] zmq message arrived on closed channel
[I 06:21:24.586 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 06:21:25.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:25.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:25.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:25.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:25.059 NotebookApp] zmq message arrived on closed channel
[W 06:21:25.059 NotebookApp] zmq message arrived on closed channel
[W 06:21:26.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:26.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:26.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:26.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:26.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:26.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:27.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:27.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:27.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:27.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:27.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:27.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:28.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:28.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:28.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:28.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:28.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:28.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:29.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:29.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:29.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:29.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:29.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:29.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:30.073 NotebookApp] zmq message arrived on closed channel
[W 06:21:30.074 NotebookApp] zmq message arrived on closed channel
[W 06:21:30.074 NotebookApp] zmq message arrived on closed channel
[W 06:21:30.074 NotebookApp] zmq message arrived on closed channel
[W 06:21:30.074 NotebookApp] zmq message arrived on closed channel
[W 06:21:30.074 NotebookApp] zmq message arrived on closed channel
[W 06:21:31.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:31.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:31.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:31.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:31.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:31.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:32.054 NotebookApp] zmq message arrived on closed channel
[W 06:21:32.054 NotebookApp] zmq message arrived on closed channel
[W 06:21:32.054 NotebookApp] zmq message arrived on closed channel
[W 06:21:32.054 NotebookApp] zmq message arrived on closed channel
[W 06:21:32.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:32.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:33.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:33.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:33.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:33.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:33.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:33.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:34.054 NotebookApp] zmq message arrived on closed channel
[W 06:21:34.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:34.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:34.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:34.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:34.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:35.054 NotebookApp] zmq message arrived on closed channel
[W 06:21:35.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:35.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:35.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:35.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:35.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:36.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:36.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:36.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:36.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:36.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:36.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:37.053 NotebookApp] zmq message arrived on closed channel
[W 06:21:37.054 NotebookApp] zmq message arrived on closed channel
[W 06:21:37.054 NotebookApp] zmq message arrived on closed channel
[W 06:21:37.054 NotebookApp] zmq message arrived on closed channel
[W 06:21:37.054 NotebookApp] zmq message arrived on closed channel
[W 06:21:37.054 NotebookApp] zmq message arrived on closed channel
[W 06:21:38.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:38.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:38.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:38.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:38.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:38.059 NotebookApp] zmq message arrived on closed channel
[W 06:21:39.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:39.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:39.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:39.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:39.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:39.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:40.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:40.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:40.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:40.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:40.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:40.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:41.054 NotebookApp] zmq message arrived on closed channel
[W 06:21:41.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:41.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:41.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:41.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:41.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:42.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:42.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:42.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:42.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:42.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:42.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:43.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:43.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:43.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:43.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:43.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:43.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:44.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:44.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:44.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:44.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:44.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:44.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:45.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:45.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:45.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:45.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:45.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:45.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:46.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:46.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:46.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:46.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:46.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:46.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:47.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:47.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:47.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:47.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:47.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:47.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:48.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:48.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:48.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:48.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:48.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:48.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:49.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:49.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:49.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:49.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:49.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:49.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:50.054 NotebookApp] zmq message arrived on closed channel
[W 06:21:50.054 NotebookApp] zmq message arrived on closed channel
[W 06:21:50.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:50.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:50.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:50.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:51.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:51.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:51.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:51.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:51.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:51.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:52.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:52.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:52.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:52.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:52.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:52.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:53.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:53.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:53.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:53.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:53.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:53.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:54.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:54.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:54.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:54.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:54.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:54.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:55.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:55.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:55.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:55.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:55.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:55.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:56.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:56.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:56.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:56.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:56.056 NotebookApp] zmq message arrived on closed channel
[W 06:21:56.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:57.053 NotebookApp] zmq message arrived on closed channel
[W 06:21:57.054 NotebookApp] zmq message arrived on closed channel
[W 06:21:57.054 NotebookApp] zmq message arrived on closed channel
[W 06:21:57.054 NotebookApp] zmq message arrived on closed channel
[W 06:21:57.054 NotebookApp] zmq message arrived on closed channel
[W 06:21:57.054 NotebookApp] zmq message arrived on closed channel
[W 06:21:58.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:58.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:58.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:58.057 NotebookApp] zmq message arrived on closed channel
[W 06:21:58.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:58.058 NotebookApp] zmq message arrived on closed channel
[W 06:21:59.053 NotebookApp] zmq message arrived on closed channel
[W 06:21:59.053 NotebookApp] zmq message arrived on closed channel
[W 06:21:59.054 NotebookApp] zmq message arrived on closed channel
[W 06:21:59.054 NotebookApp] zmq message arrived on closed channel
[W 06:21:59.055 NotebookApp] zmq message arrived on closed channel
[W 06:21:59.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:00.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:00.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:00.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:00.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:00.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:00.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:01.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:01.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:01.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:01.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:01.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:01.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:02.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:02.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:02.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:02.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:02.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:02.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:03.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:03.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:03.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:03.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:03.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:03.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:04.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:04.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:04.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:04.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:04.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:04.057 NotebookApp] zmq message arrived on closed channel
[W 06:22:05.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:05.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:05.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:05.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:05.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:05.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:06.058 NotebookApp] zmq message arrived on closed channel
[W 06:22:06.059 NotebookApp] zmq message arrived on closed channel
[W 06:22:06.059 NotebookApp] zmq message arrived on closed channel
[W 06:22:06.059 NotebookApp] zmq message arrived on closed channel
[W 06:22:06.059 NotebookApp] zmq message arrived on closed channel
[W 06:22:06.060 NotebookApp] zmq message arrived on closed channel
[W 06:22:07.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:07.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:07.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:07.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:07.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:07.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:08.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:08.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:08.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:08.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:08.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:08.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:09.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:09.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:09.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:09.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:09.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:09.057 NotebookApp] zmq message arrived on closed channel
[W 06:22:10.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:10.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:10.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:10.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:10.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:10.057 NotebookApp] zmq message arrived on closed channel
[W 06:22:11.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:11.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:11.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:11.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:11.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:11.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:12.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:12.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:12.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:12.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:12.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:12.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:13.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:13.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:13.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:13.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:13.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:13.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:14.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:14.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:14.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:14.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:14.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:14.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:15.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:15.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:15.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:15.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:15.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:15.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:16.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:16.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:16.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:16.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:16.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:16.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:17.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:17.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:17.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:17.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:17.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:17.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:18.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:18.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:18.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:18.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:18.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:18.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:19.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:19.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:19.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:19.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:19.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:19.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:20.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:20.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:20.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:20.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:20.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:20.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:21.051 NotebookApp] zmq message arrived on closed channel
[W 06:22:21.052 NotebookApp] zmq message arrived on closed channel
[W 06:22:21.052 NotebookApp] zmq message arrived on closed channel
[W 06:22:21.052 NotebookApp] zmq message arrived on closed channel
[W 06:22:21.052 NotebookApp] zmq message arrived on closed channel
[W 06:22:21.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:22.052 NotebookApp] zmq message arrived on closed channel
[W 06:22:22.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:22.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:22.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:22.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:22.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:23.074 NotebookApp] zmq message arrived on closed channel
[W 06:22:23.074 NotebookApp] zmq message arrived on closed channel
[W 06:22:23.074 NotebookApp] zmq message arrived on closed channel
[W 06:22:23.074 NotebookApp] zmq message arrived on closed channel
[W 06:22:23.075 NotebookApp] zmq message arrived on closed channel
[W 06:22:23.075 NotebookApp] zmq message arrived on closed channel
[W 06:22:24.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:24.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:24.057 NotebookApp] zmq message arrived on closed channel
[W 06:22:24.057 NotebookApp] zmq message arrived on closed channel
[W 06:22:24.057 NotebookApp] zmq message arrived on closed channel
[W 06:22:24.057 NotebookApp] zmq message arrived on closed channel
[W 06:22:25.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:25.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:25.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:25.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:25.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:25.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:26.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:26.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:26.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:26.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:26.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:26.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:27.052 NotebookApp] zmq message arrived on closed channel
[W 06:22:27.052 NotebookApp] zmq message arrived on closed channel
[W 06:22:27.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:27.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:27.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:27.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:28.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:28.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:28.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:28.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:28.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:28.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:29.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:29.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:29.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:29.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:29.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:29.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:30.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:30.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:30.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:30.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:30.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:30.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:31.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:31.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:31.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:31.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:31.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:31.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:32.052 NotebookApp] zmq message arrived on closed channel
[W 06:22:32.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:32.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:32.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:32.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:32.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:33.052 NotebookApp] zmq message arrived on closed channel
[W 06:22:33.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:33.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:33.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:33.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:33.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:34.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:34.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:34.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:34.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:34.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:34.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:35.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:35.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:35.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:35.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:35.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:35.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:36.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:36.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:36.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:36.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:36.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:36.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:37.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:37.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:37.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:37.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:37.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:37.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:38.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:38.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:38.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:38.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:38.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:38.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:39.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:39.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:39.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:39.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:39.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:39.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:40.052 NotebookApp] zmq message arrived on closed channel
[W 06:22:40.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:40.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:40.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:40.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:40.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:41.057 NotebookApp] zmq message arrived on closed channel
[W 06:22:41.057 NotebookApp] zmq message arrived on closed channel
[W 06:22:41.057 NotebookApp] zmq message arrived on closed channel
[W 06:22:41.057 NotebookApp] zmq message arrived on closed channel
[W 06:22:41.058 NotebookApp] zmq message arrived on closed channel
[W 06:22:41.058 NotebookApp] zmq message arrived on closed channel
[W 06:22:42.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:42.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:42.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:42.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:42.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:42.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:43.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:43.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:43.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:43.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:43.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:43.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:44.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:44.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:44.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:44.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:44.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:44.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:45.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:45.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:45.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:45.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:45.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:45.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:46.052 NotebookApp] zmq message arrived on closed channel
[W 06:22:46.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:46.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:46.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:46.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:46.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:47.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:47.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:47.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:47.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:47.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:47.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:48.052 NotebookApp] zmq message arrived on closed channel
[W 06:22:48.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:48.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:48.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:48.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:48.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:49.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:49.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:49.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:49.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:49.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:49.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:50.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:50.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:50.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:50.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:50.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:50.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:51.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:51.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:51.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:51.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:51.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:51.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:52.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:52.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:52.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:52.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:52.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:52.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:53.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:53.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:53.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:53.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:53.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:53.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:54.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:54.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:54.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:54.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:54.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:54.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:55.052 NotebookApp] zmq message arrived on closed channel
[W 06:22:55.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:55.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:55.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:55.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:55.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:56.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:56.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:56.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:56.055 NotebookApp] zmq message arrived on closed channel
[W 06:22:56.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:56.056 NotebookApp] zmq message arrived on closed channel
[W 06:22:57.052 NotebookApp] zmq message arrived on closed channel
[W 06:22:57.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:57.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:57.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:57.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:57.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:58.051 NotebookApp] zmq message arrived on closed channel
[W 06:22:58.051 NotebookApp] zmq message arrived on closed channel
[W 06:22:58.051 NotebookApp] zmq message arrived on closed channel
[W 06:22:58.051 NotebookApp] zmq message arrived on closed channel
[W 06:22:58.052 NotebookApp] zmq message arrived on closed channel
[W 06:22:58.052 NotebookApp] zmq message arrived on closed channel
[W 06:22:59.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:59.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:59.053 NotebookApp] zmq message arrived on closed channel
[W 06:22:59.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:59.054 NotebookApp] zmq message arrived on closed channel
[W 06:22:59.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:00.056 NotebookApp] zmq message arrived on closed channel
[W 06:23:00.056 NotebookApp] zmq message arrived on closed channel
[W 06:23:00.057 NotebookApp] zmq message arrived on closed channel
[W 06:23:00.057 NotebookApp] zmq message arrived on closed channel
[W 06:23:00.057 NotebookApp] zmq message arrived on closed channel
[W 06:23:00.057 NotebookApp] zmq message arrived on closed channel
[W 06:23:01.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:01.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:02.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:02.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:02.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:02.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:02.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:03.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:03.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:03.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:03.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:03.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:03.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:04.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:04.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:04.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:04.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:04.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:04.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:05.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:05.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:05.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:05.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:05.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:05.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:06.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:06.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:06.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:06.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:06.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:06.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:07.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:07.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:07.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:07.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:07.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:07.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:08.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:08.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:08.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:08.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:08.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:08.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:09.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:09.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:09.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:09.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:09.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:09.055 NotebookApp] zmq message arrived on closed channel
[I 06:23:09.239 NotebookApp] Kernel interrupted: 5f1ecd5c-9649-4b79-bf19-e6930fc86e23
15/10/22 06:23:09 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Socket data stream had no more data
15/10/22 06:23:09 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Socket data stream had no more data
[W 06:23:10.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:10.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:10.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:10.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:10.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:10.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:11.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:11.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:11.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:11.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:11.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:11.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:11 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:11 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:23:12.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:12.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:12.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:12.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:12.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:12.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:13.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:13.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:13.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:13.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:13.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:13.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:13 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:13 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:23:14.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:14.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:14.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:14.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:14.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:14.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:15.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:15.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:15.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:15.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:15.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:15.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:15 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:15 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:23:16.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:16.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:16.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:16.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:16.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:16.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:17.072 NotebookApp] zmq message arrived on closed channel
[W 06:23:17.073 NotebookApp] zmq message arrived on closed channel
[W 06:23:17.073 NotebookApp] zmq message arrived on closed channel
[W 06:23:17.073 NotebookApp] zmq message arrived on closed channel
[W 06:23:17.073 NotebookApp] zmq message arrived on closed channel
[W 06:23:17.073 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:17 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:17 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:23:18.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:18.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:18.056 NotebookApp] zmq message arrived on closed channel
[W 06:23:18.056 NotebookApp] zmq message arrived on closed channel
[W 06:23:18.056 NotebookApp] zmq message arrived on closed channel
[W 06:23:18.056 NotebookApp] zmq message arrived on closed channel
[W 06:23:19.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:19.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:19.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:19.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:19.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:19.055 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:19 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:19 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:23:20.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:20.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:20.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:20.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:20.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:20.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:21.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:21.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:21.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:21.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:21.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:21.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:21 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:21 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:23:22.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:22.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:22.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:22.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:22.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:22.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:23.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:23.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:23.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:23.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:23.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:23.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:23 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:23 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[I 06:23:23.586 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 06:23:24.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:24.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:24.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:24.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:24.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:24.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:25.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:25.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:25.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:25.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:25.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:25.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:25 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:25 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:23:26.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:26.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:26.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:26.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:26.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:26.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:27.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:27.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:27.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:27.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:27.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:27.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:27 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:27 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:23:28.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:28.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:28.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:28.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:28.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:28.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:29.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:29.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:29.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:29.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:29.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:29.055 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:29 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:29 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:23:30.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:30.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:30.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:30.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:30.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:30.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:31.050 NotebookApp] zmq message arrived on closed channel
[W 06:23:31.050 NotebookApp] zmq message arrived on closed channel
[W 06:23:31.050 NotebookApp] zmq message arrived on closed channel
[W 06:23:31.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:31.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:31.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:31 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:31 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:23:32.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:32.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:32.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:32.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:32.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:32.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:33.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:33.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:33.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:33 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:33 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:23:34.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:34.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:34.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:34.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:34.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:34.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:35.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:35.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:35.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:35.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:35.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:35.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:35 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:35 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:23:36.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:36.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:36.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:36.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:36.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:36.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:37.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:37.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:37.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:37.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:37.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:37.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:37 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:37 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:23:38.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:38.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:38.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:38.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:38.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:38.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:39.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:39.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:39.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:39.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:39.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:39.055 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:39 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:39 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:23:40.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:40.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:40.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:40.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:40.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:40.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:41.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:41.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:41.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:41.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:41.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:41.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:41 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:41 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:23:42.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:42.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:42.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:42.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:42.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:42.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:43.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:43.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:43.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:43.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:43.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:43.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:43 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:43 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:23:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:23:44.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:44.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:44.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:44.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:44.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:45.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:45 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:45 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:23:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:46.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:46.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:46.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:46.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:47.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:47.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:47.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:47.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:47.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:47.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:47 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:47 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:23:48.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:48.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:48.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:48.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:48.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:48.055 NotebookApp] zmq message arrived on closed channel
[W 06:23:49.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:49.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:49.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:49.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:49.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:49.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:49 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:49 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:23:50.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:50.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:50.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:50.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:50.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:50.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:51.050 NotebookApp] zmq message arrived on closed channel
[W 06:23:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:51.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:51 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:51 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:23:52.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:52.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:52.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:52.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:52.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:52.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:53.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:53.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:53.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:53.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:53.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:53.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:53 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:53 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:23:54.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:54.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:54.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:54.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:54.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:54.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:55.050 NotebookApp] zmq message arrived on closed channel
[W 06:23:55.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:55.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:55.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:55.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:55.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:55 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:55 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:23:56.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:56.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:56.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:56.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:56.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:56.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:57.050 NotebookApp] zmq message arrived on closed channel
[W 06:23:57.050 NotebookApp] zmq message arrived on closed channel
[W 06:23:57.050 NotebookApp] zmq message arrived on closed channel
[W 06:23:57.050 NotebookApp] zmq message arrived on closed channel
[W 06:23:57.051 NotebookApp] zmq message arrived on closed channel
[W 06:23:57.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:57 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:57 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:23:58.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:58.053 NotebookApp] zmq message arrived on closed channel
[W 06:23:58.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:58.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:58.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:58.054 NotebookApp] zmq message arrived on closed channel
[W 06:23:59.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:59.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:59.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:59.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:59.052 NotebookApp] zmq message arrived on closed channel
[W 06:23:59.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:23:59 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:23:59 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:00.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:00.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:00.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:01.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:01.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:01.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:01 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:01 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:02.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:02.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:03.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:03.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:03.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:03.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:03.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:03.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:03 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:03 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:04.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:04.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:04.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:04.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:04.054 NotebookApp] zmq message arrived on closed channel
[W 06:24:04.054 NotebookApp] zmq message arrived on closed channel
[W 06:24:05.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:05.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:05.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:05.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:05.054 NotebookApp] zmq message arrived on closed channel
[W 06:24:05.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:05 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:05 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:06.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:06.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:06.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:06.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:06.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:06.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:07.048 NotebookApp] zmq message arrived on closed channel
[W 06:24:07.049 NotebookApp] zmq message arrived on closed channel
[W 06:24:07.049 NotebookApp] zmq message arrived on closed channel
[W 06:24:07.049 NotebookApp] zmq message arrived on closed channel
[W 06:24:07.049 NotebookApp] zmq message arrived on closed channel
[W 06:24:07.049 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:07 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:07 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:08.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:08.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:08.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:08.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:08.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:08.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:09.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:09.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:09.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:09.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:09.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:09.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:09 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:09 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:10.068 NotebookApp] zmq message arrived on closed channel
[W 06:24:10.069 NotebookApp] zmq message arrived on closed channel
[W 06:24:10.069 NotebookApp] zmq message arrived on closed channel
[W 06:24:10.069 NotebookApp] zmq message arrived on closed channel
[W 06:24:10.069 NotebookApp] zmq message arrived on closed channel
[W 06:24:10.070 NotebookApp] zmq message arrived on closed channel
[W 06:24:11.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:11.054 NotebookApp] zmq message arrived on closed channel
[W 06:24:11.054 NotebookApp] zmq message arrived on closed channel
[W 06:24:11.054 NotebookApp] zmq message arrived on closed channel
[W 06:24:11.054 NotebookApp] zmq message arrived on closed channel
[W 06:24:11.055 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:11 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:11 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:12.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:12.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:12.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:12.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:12.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:12.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:13.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:13.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:13.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:13.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:13.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:13.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:13 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:13 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:14.049 NotebookApp] zmq message arrived on closed channel
[W 06:24:14.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:14.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:14.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:14.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:14.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:15.049 NotebookApp] zmq message arrived on closed channel
[W 06:24:15.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:15.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:15.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:15.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:15.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:15 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:15 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:16.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:16.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:16.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:16.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:16.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:16.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:17.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:17.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:17.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:17.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:17.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:17.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:17 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:17 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:18.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:18.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:18.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:18.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:18.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:18.054 NotebookApp] zmq message arrived on closed channel
[W 06:24:19.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:19.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:19.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:19.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:19.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:19.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:19 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:19 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:20.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:20.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:20.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:20.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:20.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:20.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:21.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:21.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:21.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:21.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:21.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:21.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:21 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:21 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:22.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:22.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:22.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:22.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:22.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:22.054 NotebookApp] zmq message arrived on closed channel
[W 06:24:23.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:23.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:23.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:23.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:23.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:23.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:23 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:23 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:24.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:24.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:24.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:24.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:24.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:24.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:25.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:25.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:25.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:25.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:25.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:25.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:25 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:25 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:26.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:26.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:26.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:26.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:26.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:26.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:27.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:27.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:27.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:27.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:27.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:27.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:27 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:27 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:28.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:28.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:28.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:28.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:28.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:28.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:29.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:29.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:29.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:29.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:29.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:29 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:29 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:30.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:30.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:30.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:30.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:30.054 NotebookApp] zmq message arrived on closed channel
[W 06:24:30.054 NotebookApp] zmq message arrived on closed channel
[I 06:24:30.116 NotebookApp] Saving file at /Untitled0.ipynb
[W 06:24:31.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:31.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:31.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:31.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:31.054 NotebookApp] zmq message arrived on closed channel
[W 06:24:31.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:31 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:31 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:32.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:32.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:32.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:32.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:32.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:32.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:33.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:33.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:33.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:33.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:33.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:33 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:33 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:34.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:34.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:34.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:34.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:34.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:34.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:35.049 NotebookApp] zmq message arrived on closed channel
[W 06:24:35.049 NotebookApp] zmq message arrived on closed channel
[W 06:24:35.049 NotebookApp] zmq message arrived on closed channel
[W 06:24:35.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:35.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:35.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:35 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:35 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:36.048 NotebookApp] zmq message arrived on closed channel
[W 06:24:36.049 NotebookApp] zmq message arrived on closed channel
[W 06:24:36.049 NotebookApp] zmq message arrived on closed channel
[W 06:24:36.049 NotebookApp] zmq message arrived on closed channel
[W 06:24:36.049 NotebookApp] zmq message arrived on closed channel
[W 06:24:36.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:37.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:37 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:37 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:38.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:38.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:38.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:38.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:38.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:38.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:39.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:39.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:39.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:39.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:39 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:39 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:40.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:40.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:40.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:40.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:40.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:40.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:41.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:41.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:41.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:41.054 NotebookApp] zmq message arrived on closed channel
[W 06:24:41.054 NotebookApp] zmq message arrived on closed channel
[W 06:24:41.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:41 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:41 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:42.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:42.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:42.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:42.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:42.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:42.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:43.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:43.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:43.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:43.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:43.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:43.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:43 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:43 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:44.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:44.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:44.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:44.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:44.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:44.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:45.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:45 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:45 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:46.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:46.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:47.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:47.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:47.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:47.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:47.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:47.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:47 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:47 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:48.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:48.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:48.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:48.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:48.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:48.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:49.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:49.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:49.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:49.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:49.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:49.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:49 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:49 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:50.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:50.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:50.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:50.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:50.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:50.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:51.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:51.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:51.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:51 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:51 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:52.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:52.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:52.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:52.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:52.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:52.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:53.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:53.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:53.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:53.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:53.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:53.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:53 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:53 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:54.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:54.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:54.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:54.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:54.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:54.053 NotebookApp] zmq message arrived on closed channel
[W 06:24:55.049 NotebookApp] zmq message arrived on closed channel
[W 06:24:55.049 NotebookApp] zmq message arrived on closed channel
[W 06:24:55.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:55.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:55.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:55.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:55 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:55 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:56.049 NotebookApp] zmq message arrived on closed channel
[W 06:24:56.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:56.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:56.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:56.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:56.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:57.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:57.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:57.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:57.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:57.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:57.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:57 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:57 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:24:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:58.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:58.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:59.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:59.050 NotebookApp] zmq message arrived on closed channel
[W 06:24:59.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:59.051 NotebookApp] zmq message arrived on closed channel
[W 06:24:59.052 NotebookApp] zmq message arrived on closed channel
[W 06:24:59.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:24:59 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:24:59 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:00.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:00.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:00.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:00.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:00.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:00.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:01.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:01.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:01.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:01.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:01 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:01 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:02.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:02.047 NotebookApp] zmq message arrived on closed channel
[W 06:25:02.047 NotebookApp] zmq message arrived on closed channel
[W 06:25:02.047 NotebookApp] zmq message arrived on closed channel
[W 06:25:02.048 NotebookApp] zmq message arrived on closed channel
[W 06:25:02.048 NotebookApp] zmq message arrived on closed channel
[W 06:25:03.045 NotebookApp] zmq message arrived on closed channel
[W 06:25:03.045 NotebookApp] zmq message arrived on closed channel
[W 06:25:03.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:03.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:03.047 NotebookApp] zmq message arrived on closed channel
[W 06:25:03.047 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:03 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:03 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:04.063 NotebookApp] zmq message arrived on closed channel
[W 06:25:04.063 NotebookApp] zmq message arrived on closed channel
[W 06:25:04.063 NotebookApp] zmq message arrived on closed channel
[W 06:25:04.063 NotebookApp] zmq message arrived on closed channel
[W 06:25:04.064 NotebookApp] zmq message arrived on closed channel
[W 06:25:04.064 NotebookApp] zmq message arrived on closed channel
[W 06:25:05.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:05.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:05.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:05.047 NotebookApp] zmq message arrived on closed channel
[W 06:25:05.047 NotebookApp] zmq message arrived on closed channel
[W 06:25:05.047 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:05 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:05 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:06.045 NotebookApp] zmq message arrived on closed channel
[W 06:25:06.045 NotebookApp] zmq message arrived on closed channel
[W 06:25:06.045 NotebookApp] zmq message arrived on closed channel
[W 06:25:06.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:06.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:06.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:07.049 NotebookApp] zmq message arrived on closed channel
[W 06:25:07.049 NotebookApp] zmq message arrived on closed channel
[W 06:25:07.049 NotebookApp] zmq message arrived on closed channel
[W 06:25:07.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:07.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:07.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:07 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:07 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:08.044 NotebookApp] zmq message arrived on closed channel
[W 06:25:08.044 NotebookApp] zmq message arrived on closed channel
[W 06:25:08.045 NotebookApp] zmq message arrived on closed channel
[W 06:25:08.045 NotebookApp] zmq message arrived on closed channel
[W 06:25:08.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:08.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:09.044 NotebookApp] zmq message arrived on closed channel
[W 06:25:09.045 NotebookApp] zmq message arrived on closed channel
[W 06:25:09.045 NotebookApp] zmq message arrived on closed channel
[W 06:25:09.045 NotebookApp] zmq message arrived on closed channel
[W 06:25:09.045 NotebookApp] zmq message arrived on closed channel
[W 06:25:09.045 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:09 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:09 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:10.045 NotebookApp] zmq message arrived on closed channel
[W 06:25:10.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:10.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:10.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:10.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:10.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:11.045 NotebookApp] zmq message arrived on closed channel
[W 06:25:11.045 NotebookApp] zmq message arrived on closed channel
[W 06:25:11.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:11.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:11.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:11.046 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:11 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:11 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:12.045 NotebookApp] zmq message arrived on closed channel
[W 06:25:12.045 NotebookApp] zmq message arrived on closed channel
[W 06:25:12.045 NotebookApp] zmq message arrived on closed channel
[W 06:25:12.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:12.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:12.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:13.045 NotebookApp] zmq message arrived on closed channel
[W 06:25:13.045 NotebookApp] zmq message arrived on closed channel
[W 06:25:13.045 NotebookApp] zmq message arrived on closed channel
[W 06:25:13.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:13.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:13.046 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:13 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:13 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:14.047 NotebookApp] zmq message arrived on closed channel
[W 06:25:14.047 NotebookApp] zmq message arrived on closed channel
[W 06:25:14.048 NotebookApp] zmq message arrived on closed channel
[W 06:25:14.048 NotebookApp] zmq message arrived on closed channel
[W 06:25:14.048 NotebookApp] zmq message arrived on closed channel
[W 06:25:14.048 NotebookApp] zmq message arrived on closed channel
[W 06:25:15.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:15.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:15.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:15.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:15.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:15.047 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:15 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:15 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:16.045 NotebookApp] zmq message arrived on closed channel
[W 06:25:16.045 NotebookApp] zmq message arrived on closed channel
[W 06:25:16.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:16.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:16.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:16.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:17.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:17.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:17.047 NotebookApp] zmq message arrived on closed channel
[W 06:25:17.047 NotebookApp] zmq message arrived on closed channel
[W 06:25:17.047 NotebookApp] zmq message arrived on closed channel
[W 06:25:17.048 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:17 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:17 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:18.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:18.046 NotebookApp] zmq message arrived on closed channel
[W 06:25:18.047 NotebookApp] zmq message arrived on closed channel
[W 06:25:18.047 NotebookApp] zmq message arrived on closed channel
[W 06:25:18.047 NotebookApp] zmq message arrived on closed channel
[W 06:25:18.047 NotebookApp] zmq message arrived on closed channel
[W 06:25:19.047 NotebookApp] zmq message arrived on closed channel
[W 06:25:19.047 NotebookApp] zmq message arrived on closed channel
[W 06:25:19.047 NotebookApp] zmq message arrived on closed channel
[W 06:25:19.048 NotebookApp] zmq message arrived on closed channel
[W 06:25:19.048 NotebookApp] zmq message arrived on closed channel
[W 06:25:19.049 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:19 [WARN] o.a.s.s.BlockManager - Block input-0-1445495119400 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:25:20 [WARN] o.a.s.s.BlockManager - Block input-0-1445495119800 replicated to only 0 peer(s) instead of 1 peers
[W 06:25:20.056 NotebookApp] zmq message arrived on closed channel
[W 06:25:20.056 NotebookApp] zmq message arrived on closed channel
[W 06:25:20.056 NotebookApp] zmq message arrived on closed channel
[W 06:25:20.057 NotebookApp] zmq message arrived on closed channel
[W 06:25:20.057 NotebookApp] zmq message arrived on closed channel
[W 06:25:20.057 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:20 [WARN] o.a.s.s.BlockManager - Block input-0-1445495120400 replicated to only 0 peer(s) instead of 1 peers
15/10/22 06:25:21 [WARN] o.a.s.s.BlockManager - Block input-0-1445495120800 replicated to only 0 peer(s) instead of 1 peers
[W 06:25:21.054 NotebookApp] zmq message arrived on closed channel
[W 06:25:21.054 NotebookApp] zmq message arrived on closed channel
[W 06:25:21.055 NotebookApp] zmq message arrived on closed channel
[W 06:25:21.055 NotebookApp] zmq message arrived on closed channel
[W 06:25:21.055 NotebookApp] zmq message arrived on closed channel
[W 06:25:21.055 NotebookApp] zmq message arrived on closed channel
[I 06:25:21.572 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
15/10/22 06:25:21 [WARN] o.a.s.s.BlockManager - Block input-0-1445495121400 replicated to only 0 peer(s) instead of 1 peers
[I 06:25:21.860 NotebookApp] Kernel interrupted: 5f1ecd5c-9649-4b79-bf19-e6930fc86e23
15/10/22 06:25:21 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Socket data stream had no more data
15/10/22 06:25:21 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Socket data stream had no more data
[W 06:25:22.056 NotebookApp] zmq message arrived on closed channel
[W 06:25:22.057 NotebookApp] zmq message arrived on closed channel
[W 06:25:22.057 NotebookApp] zmq message arrived on closed channel
[W 06:25:22.057 NotebookApp] zmq message arrived on closed channel
[W 06:25:22.058 NotebookApp] zmq message arrived on closed channel
[W 06:25:22.058 NotebookApp] zmq message arrived on closed channel
[W 06:25:23.047 NotebookApp] zmq message arrived on closed channel
[W 06:25:23.047 NotebookApp] zmq message arrived on closed channel
[W 06:25:23.047 NotebookApp] zmq message arrived on closed channel
[W 06:25:23.048 NotebookApp] zmq message arrived on closed channel
[W 06:25:23.048 NotebookApp] zmq message arrived on closed channel
[W 06:25:23.048 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:23 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:23 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:24.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:24.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:24.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:24.054 NotebookApp] zmq message arrived on closed channel
[W 06:25:24.054 NotebookApp] zmq message arrived on closed channel
[W 06:25:24.054 NotebookApp] zmq message arrived on closed channel
[W 06:25:25.048 NotebookApp] zmq message arrived on closed channel
[W 06:25:25.049 NotebookApp] zmq message arrived on closed channel
[W 06:25:25.049 NotebookApp] zmq message arrived on closed channel
[W 06:25:25.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:25.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:25.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:25 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:25 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:26.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:26.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:26.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:26.054 NotebookApp] zmq message arrived on closed channel
[W 06:25:26.054 NotebookApp] zmq message arrived on closed channel
[W 06:25:26.055 NotebookApp] zmq message arrived on closed channel
[W 06:25:27.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:27.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:27.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:27.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:27.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:27.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:27 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:27 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:28.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:28.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:28.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:28.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:28.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:28.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:29.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:29.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:29.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:29.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:29.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:29 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:29 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:30.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:30.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:30.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:30.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:30.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:30.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:31.048 NotebookApp] zmq message arrived on closed channel
[W 06:25:31.049 NotebookApp] zmq message arrived on closed channel
[W 06:25:31.049 NotebookApp] zmq message arrived on closed channel
[W 06:25:31.049 NotebookApp] zmq message arrived on closed channel
[W 06:25:31.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:31.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:31 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:31 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:32.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:32.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:32.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:32.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:32.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:32.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:33.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:33.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:33.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:33.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:33 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:33 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:34.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:34.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:34.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:34.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:34.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:34.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:35.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:35.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:35.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:35.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:35.054 NotebookApp] zmq message arrived on closed channel
[W 06:25:35.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:35 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:35 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:36.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:36.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:36.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:36.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:36.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:36.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:37.049 NotebookApp] zmq message arrived on closed channel
[W 06:25:37.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:37.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:37.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:37 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:37 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:38.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:38.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:38.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:38.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:38.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:38.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:39.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:39.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:39.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:39.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:39 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:39 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:40.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:40.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:40.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:40.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:40.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:40.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:41.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:41.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:41.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:41.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:41.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:41.053 NotebookApp] zmq message arrived on closed channel
[I 06:25:41.400 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
15/10/22 06:25:41 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:41 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:42.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:42.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:42.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:42.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:42.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:42.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:43.049 NotebookApp] zmq message arrived on closed channel
[W 06:25:43.049 NotebookApp] zmq message arrived on closed channel
[W 06:25:43.049 NotebookApp] zmq message arrived on closed channel
[W 06:25:43.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:43.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:43.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:43 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:43 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:44.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:44.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:45.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:45 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:45 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:46.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:47.049 NotebookApp] zmq message arrived on closed channel
[W 06:25:47.049 NotebookApp] zmq message arrived on closed channel
[W 06:25:47.049 NotebookApp] zmq message arrived on closed channel
[W 06:25:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:47.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:47 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:47 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:48.049 NotebookApp] zmq message arrived on closed channel
[W 06:25:48.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:48.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:48.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:48.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:48.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:49.049 NotebookApp] zmq message arrived on closed channel
[W 06:25:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:49.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:49 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:49 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:50.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:50.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:50.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:50.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:50.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:50.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:51.049 NotebookApp] zmq message arrived on closed channel
[W 06:25:51.049 NotebookApp] zmq message arrived on closed channel
[W 06:25:51.049 NotebookApp] zmq message arrived on closed channel
[W 06:25:51.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:51.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:51.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:51 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:51 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:52.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:52.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:52.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:52.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:52.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:52.051 NotebookApp] zmq message arrived on closed channel
[I 06:25:52.719 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[W 06:25:53.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:53.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:53.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:53.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:53.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:53.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:53 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:53 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:54.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:54.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:54.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:54.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:54.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:54.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:55.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:55.052 NotebookApp] zmq message arrived on closed channel
[W 06:25:55.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:55.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:55.053 NotebookApp] zmq message arrived on closed channel
[W 06:25:55.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:55 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:55 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:56.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:56.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:56.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:56.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:56.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:56.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:57.070 NotebookApp] zmq message arrived on closed channel
[W 06:25:57.070 NotebookApp] zmq message arrived on closed channel
[W 06:25:57.071 NotebookApp] zmq message arrived on closed channel
[W 06:25:57.071 NotebookApp] zmq message arrived on closed channel
[W 06:25:57.072 NotebookApp] zmq message arrived on closed channel
[W 06:25:57.072 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:57 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:57 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:25:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:25:58.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:58.051 NotebookApp] zmq message arrived on closed channel
[W 06:25:59.048 NotebookApp] zmq message arrived on closed channel
[W 06:25:59.048 NotebookApp] zmq message arrived on closed channel
[W 06:25:59.049 NotebookApp] zmq message arrived on closed channel
[W 06:25:59.049 NotebookApp] zmq message arrived on closed channel
[W 06:25:59.049 NotebookApp] zmq message arrived on closed channel
[W 06:25:59.049 NotebookApp] zmq message arrived on closed channel
15/10/22 06:25:59 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:25:59 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:00.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:00.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:00.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:00.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:00.052 NotebookApp] zmq message arrived on closed channel
[I 06:26:00.275 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 06:26:01.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:01.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:01.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:01.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:01 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:01 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:02.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:02.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:02.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:03.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:03.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:03.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:03.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:03.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:03.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:03 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:03 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:04.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:04.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:04.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:04.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:04.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:04.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:05.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:05.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:05.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:05.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:05.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:05.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:05 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:05 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:06.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:06.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:06.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:06.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:06.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:06.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:07.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:07.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:07.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:07.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:07.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:07.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:07 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:07 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:08.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:08.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:08.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:08.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:08.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:08.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:09.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:09.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:09.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:09.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:09.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:09.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:09 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:09 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:10.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:10.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:10.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:10.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:10.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:10.051 NotebookApp] zmq message arrived on closed channel
[I 06:26:10.305 NotebookApp] Saving file at /Spark Fundamentals - Scala.ipynb
[W 06:26:11.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:11.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:11.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:11.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:11 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:11 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:12.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:12.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:12.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:12.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:12.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:12.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:13.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:13.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:13.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:13.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:13.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:13.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:13 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:13 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:14.048 NotebookApp] zmq message arrived on closed channel
[W 06:26:14.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:14.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:14.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:14.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:14.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:15.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:15.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:15.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:15.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:15.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:15.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:15 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:15 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:16.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:16.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:16.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:16.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:16.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:16.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:17.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:17.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:17.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:17.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:17.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:17.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:17 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:17 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:18.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:18.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:18.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:18.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:18.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:18.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:19.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:19.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:19.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:19.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:19.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:19.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:19 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:20 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:20.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:20.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:20.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:20.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:20.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:20.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:21.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:21.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:21.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:21.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:21.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:21.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:22 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:22 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:22.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:22.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:22.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:22.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:22.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:22.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:23.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:23.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:23.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:23.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:23.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:23.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:24 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:24 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:24.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:24.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:24.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:24.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:24.054 NotebookApp] zmq message arrived on closed channel
[W 06:26:24.054 NotebookApp] zmq message arrived on closed channel
[W 06:26:25.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:25.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:25.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:25.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:25.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:25.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:26 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:26 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:26.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:26.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:26.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:26.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:26.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:26.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:27.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:27.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:27.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:27.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:27.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:27.052 NotebookApp] zmq message arrived on closed channel
[I 06:26:27.639 NotebookApp] Saving file at /Untitled0.ipynb
15/10/22 06:26:28 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:28 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:28.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:28.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:28.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:28.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:28.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:28.054 NotebookApp] zmq message arrived on closed channel
[W 06:26:29.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:29.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:29.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:30 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:30 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:30.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:30.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:30.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:30.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:30.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:30.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:31.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:31.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:31.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:31.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:31.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:31.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:32 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:32 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:32.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:32.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:32.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:32.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:32.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:32.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:33.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:33.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:33.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:33.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:33.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:33.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:34 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:34 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:34.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:34.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:34.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:34.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:34.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:34.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:35.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:35.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:35.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:35.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:35.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:35.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:36 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:36 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:36.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:36.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:36.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:36.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:36.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:36.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:37.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:37.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:38 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:38 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:38.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:38.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:38.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:38.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:38.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:38.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:39.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:39.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:39.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:40 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:40 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:40.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:40.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:40.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:40.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:40.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:40.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:41.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:41.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:41.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:41.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:41.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:41.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:42 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:42 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:42.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:42.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:42.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:42.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:42.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:42.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:43.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:43.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:43.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:43.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:43.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:43.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:44 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:44 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:44.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:44.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:44.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:44.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:44.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:44.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:45.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:46 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:46 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:46.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:46.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:46.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:46.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:46.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:47.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:47.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:47.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:48 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:48 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:48.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:48.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:48.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:48.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:48.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:48.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:49.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:49.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:49.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:49.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:49.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:50 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:50 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:50.048 NotebookApp] zmq message arrived on closed channel
[W 06:26:50.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:50.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:50.049 NotebookApp] zmq message arrived on closed channel
[W 06:26:50.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:50.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:51.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:51.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:51.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:51.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:51.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:52 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:52 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:52.073 NotebookApp] zmq message arrived on closed channel
[W 06:26:52.074 NotebookApp] zmq message arrived on closed channel
[W 06:26:52.074 NotebookApp] zmq message arrived on closed channel
[W 06:26:52.074 NotebookApp] zmq message arrived on closed channel
[W 06:26:52.074 NotebookApp] zmq message arrived on closed channel
[W 06:26:52.075 NotebookApp] zmq message arrived on closed channel
[W 06:26:53.054 NotebookApp] zmq message arrived on closed channel
[W 06:26:53.054 NotebookApp] zmq message arrived on closed channel
[W 06:26:53.055 NotebookApp] zmq message arrived on closed channel
[W 06:26:53.055 NotebookApp] zmq message arrived on closed channel
[W 06:26:53.055 NotebookApp] zmq message arrived on closed channel
[W 06:26:53.055 NotebookApp] zmq message arrived on closed channel
[W 06:26:54.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:54.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:54.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:54.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:54 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
[W 06:26:54.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:54 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:54.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:55.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:55.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:55.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:55.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:55.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:55.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:56.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:56.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:56.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:56.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:56.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:56.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:56 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:56 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:57.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:57.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:57.053 NotebookApp] zmq message arrived on closed channel
[W 06:26:57.054 NotebookApp] zmq message arrived on closed channel
[W 06:26:57.054 NotebookApp] zmq message arrived on closed channel
[W 06:26:57.054 NotebookApp] zmq message arrived on closed channel
[W 06:26:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:26:58.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:58.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:26:58 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:26:58 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:26:59.051 NotebookApp] zmq message arrived on closed channel
[W 06:26:59.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:59.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:59.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:59.052 NotebookApp] zmq message arrived on closed channel
[W 06:26:59.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:00.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:00.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:00.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:00.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:00.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:00.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:00 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:00 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:01.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:01.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:01.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:01.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:02.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:02.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:02.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:02.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:02.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:02.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:02 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:02 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:03.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:03.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:03.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:03.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:03.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:03.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:04.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:04.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:04.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:04.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:04.054 NotebookApp] zmq message arrived on closed channel
[W 06:27:04.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:04 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:04 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:05.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:05.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:05.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:05.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:05.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:05.054 NotebookApp] zmq message arrived on closed channel
[W 06:27:06.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:06.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:06.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:06.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:06.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:06.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:06 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:06 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:07.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:07.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:07.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:07.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:07.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:07.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:08.049 NotebookApp] zmq message arrived on closed channel
[W 06:27:08.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:08.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:08.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:08.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:08.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:08 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:08 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:09.049 NotebookApp] zmq message arrived on closed channel
[W 06:27:09.049 NotebookApp] zmq message arrived on closed channel
[W 06:27:09.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:09.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:09.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:09.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:10.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:10.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:10.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:10.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:10.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:10.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:10 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:10 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:11.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:12.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:12.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:12.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:12.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:12.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:12.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:12 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:12 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:13.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:13.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:13.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:13.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:13.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:13.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:14.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:14.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:14.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:14.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:14.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:14.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:14 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:14 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:15.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:15.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:15.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:15.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:15.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:15.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:16.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:16.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:16.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:16.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:16.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:16.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:16 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:16 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:17.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:17.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:17.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:17.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:17.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:17.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:18.049 NotebookApp] zmq message arrived on closed channel
[W 06:27:18.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:18.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:18.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:18.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:18.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:18 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:18 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:19.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:19.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:19.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:19.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:19.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:19.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:20.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:20.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:20.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:20.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:20.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:20.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:20 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:20 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:21.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:21.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:21.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:21.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:21.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:21.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:22.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:22.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:22.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:22.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:22.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:22.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:22 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:22 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:23.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:23.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:23.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:23.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:23.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:23.054 NotebookApp] zmq message arrived on closed channel
[W 06:27:24.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:24.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:24.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:24.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:24.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:24.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:24 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:24 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:25.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:25.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:25.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:25.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:25.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:25.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:26.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:26.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:26.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:26.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:26.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:26.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:26 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:26 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:27.049 NotebookApp] zmq message arrived on closed channel
[W 06:27:27.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:27.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:27.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:27.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:27.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:28.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:28.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:28.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:28.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:28.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:28.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:28 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:28 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:29.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:29.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:29.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:30.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:30.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:30.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:30.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:30.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:30.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:30 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:30 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:31.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:31.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:31.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:31.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:31.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:31.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:32.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:32.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:32.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:32.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:32.054 NotebookApp] zmq message arrived on closed channel
[W 06:27:32.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:32 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:32 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:33.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:33.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:33.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:33.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:34.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:34.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:34.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:34.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:34.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:34.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:34 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:34 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:35.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:35.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:35.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:35.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:35.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:35.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:36.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:36.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:36.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:36.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:36.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:36.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:36 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:36 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:37.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:37.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:37.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:37.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:37.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:38.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:38.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:38.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:38.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:38.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:38.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:38 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:38 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:39.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:39.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:39.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:39.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:39.054 NotebookApp] zmq message arrived on closed channel
[W 06:27:40.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:40.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:40.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:40.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:40.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:40.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:40 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:40 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:41.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:41.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:41.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:41.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:41.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:41.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:42.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:42.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:42.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:42.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:42.054 NotebookApp] zmq message arrived on closed channel
[W 06:27:42.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:42 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:42 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:43.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:43.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:43.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:43.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:43.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:43.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:44.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:44.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:44.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:44.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:44.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:44.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:44 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:44 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:45.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:46.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:46.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:46 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:46 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:47.075 NotebookApp] zmq message arrived on closed channel
[W 06:27:47.076 NotebookApp] zmq message arrived on closed channel
[W 06:27:47.076 NotebookApp] zmq message arrived on closed channel
[W 06:27:47.076 NotebookApp] zmq message arrived on closed channel
[W 06:27:47.076 NotebookApp] zmq message arrived on closed channel
[W 06:27:47.077 NotebookApp] zmq message arrived on closed channel
[W 06:27:48.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:48.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:48.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:48.053 NotebookApp] zmq message arrived on closed channel
[W 06:27:48.054 NotebookApp] zmq message arrived on closed channel
[W 06:27:48.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:48 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:48 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:49.049 NotebookApp] zmq message arrived on closed channel
[W 06:27:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:49.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:49.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:49.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:49.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:50.049 NotebookApp] zmq message arrived on closed channel
[W 06:27:50.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:50.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:50.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:50.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:50.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:50 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:50 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:51.049 NotebookApp] zmq message arrived on closed channel
[W 06:27:51.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:51.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:52.048 NotebookApp] zmq message arrived on closed channel
[W 06:27:52.049 NotebookApp] zmq message arrived on closed channel
[W 06:27:52.049 NotebookApp] zmq message arrived on closed channel
[W 06:27:52.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:52.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:52.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:52 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:52 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:53.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:53.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:53.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:53.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:53.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:53.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:54.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:54.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:54.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:54.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:54.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:54.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:54 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:54 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:55.049 NotebookApp] zmq message arrived on closed channel
[W 06:27:55.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:55.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:55.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:55.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:55.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:56.049 NotebookApp] zmq message arrived on closed channel
[W 06:27:56.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:56.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:56.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:56.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:56.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:56 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:56 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:57.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:57.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:57.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:57.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:57.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:57.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:58.049 NotebookApp] zmq message arrived on closed channel
[W 06:27:58.049 NotebookApp] zmq message arrived on closed channel
[W 06:27:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:27:58.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:27:58 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:27:58 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:27:59.051 NotebookApp] zmq message arrived on closed channel
[W 06:27:59.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:59.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:59.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:59.052 NotebookApp] zmq message arrived on closed channel
[W 06:27:59.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:00.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:00.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:00.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:00 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:00 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:01.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:01.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:01.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:01.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:01.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:01.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:02.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:02.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:02.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:02 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:02 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:03.048 NotebookApp] zmq message arrived on closed channel
[W 06:28:03.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:03.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:03.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:03.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:03.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:04.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:04.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:04.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:04.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:04.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:04.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:04 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:04 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:05.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:05.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:05.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:05.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:05.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:05.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:06.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:06.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:06.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:06.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:06.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:06.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:06 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:06 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:07.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:07.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:07.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:07.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:07.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:07.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:08.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:08.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:08.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:08.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:08.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:08.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:08 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:08 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:09.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:09.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:09.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:09.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:09.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:09.053 NotebookApp] zmq message arrived on closed channel
[W 06:28:10.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:10.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:10.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:10.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:10.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:10.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:10 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:10 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:11.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:11.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:11.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:12.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:12.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:12.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:12.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:12.053 NotebookApp] zmq message arrived on closed channel
[W 06:28:12.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:12 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:12 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:13.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:13.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:13.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:13.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:13.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:13.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:14.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:14.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:14.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:14.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:14.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:14.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:14 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:14 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:15.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:15.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:15.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:15.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:15.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:15.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:16.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:16.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:16.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:16.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:16.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:16.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:16 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:16 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:17.053 NotebookApp] zmq message arrived on closed channel
[W 06:28:17.053 NotebookApp] zmq message arrived on closed channel
[W 06:28:17.053 NotebookApp] zmq message arrived on closed channel
[W 06:28:17.053 NotebookApp] zmq message arrived on closed channel
[W 06:28:17.054 NotebookApp] zmq message arrived on closed channel
[W 06:28:17.054 NotebookApp] zmq message arrived on closed channel
[W 06:28:17.229 NotebookApp] zmq message arrived on closed channel
[W 06:28:17.230 NotebookApp] zmq message arrived on closed channel
[W 06:28:17.230 NotebookApp] zmq message arrived on closed channel
[W 06:28:17.231 NotebookApp] zmq message arrived on closed channel
[W 06:28:17.661 NotebookApp] zmq message arrived on closed channel
[W 06:28:17.662 NotebookApp] zmq message arrived on closed channel
[W 06:28:17.813 NotebookApp] zmq message arrived on closed channel
[W 06:28:17.813 NotebookApp] zmq message arrived on closed channel
[W 06:28:17.863 NotebookApp] zmq message arrived on closed channel
[W 06:28:17.864 NotebookApp] zmq message arrived on closed channel
[W 06:28:18.015 NotebookApp] zmq message arrived on closed channel
[W 06:28:18.015 NotebookApp] zmq message arrived on closed channel
[W 06:28:18.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:18.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:18.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:18.053 NotebookApp] zmq message arrived on closed channel
[W 06:28:18.053 NotebookApp] zmq message arrived on closed channel
[W 06:28:18.054 NotebookApp] zmq message arrived on closed channel
[W 06:28:18.116 NotebookApp] zmq message arrived on closed channel
[W 06:28:18.117 NotebookApp] zmq message arrived on closed channel
[W 06:28:18.167 NotebookApp] zmq message arrived on closed channel
[W 06:28:18.167 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:18 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:18 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:18.217 NotebookApp] zmq message arrived on closed channel
[W 06:28:18.218 NotebookApp] zmq message arrived on closed channel
[W 06:28:18.368 NotebookApp] zmq message arrived on closed channel
[W 06:28:18.369 NotebookApp] zmq message arrived on closed channel
[W 06:28:18.721 NotebookApp] zmq message arrived on closed channel
[W 06:28:18.721 NotebookApp] zmq message arrived on closed channel
[W 06:28:18.922 NotebookApp] zmq message arrived on closed channel
[W 06:28:18.923 NotebookApp] zmq message arrived on closed channel
[W 06:28:18.973 NotebookApp] zmq message arrived on closed channel
[W 06:28:18.973 NotebookApp] zmq message arrived on closed channel
[W 06:28:19.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:19.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:19.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:19.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:19.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:19.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:19.124 NotebookApp] zmq message arrived on closed channel
[W 06:28:19.124 NotebookApp] zmq message arrived on closed channel
[W 06:28:19.325 NotebookApp] zmq message arrived on closed channel
[W 06:28:19.326 NotebookApp] zmq message arrived on closed channel
[W 06:28:19.577 NotebookApp] zmq message arrived on closed channel
[W 06:28:19.578 NotebookApp] zmq message arrived on closed channel
[W 06:28:19.779 NotebookApp] zmq message arrived on closed channel
[W 06:28:19.779 NotebookApp] zmq message arrived on closed channel
[W 06:28:19.981 NotebookApp] zmq message arrived on closed channel
[W 06:28:19.982 NotebookApp] zmq message arrived on closed channel
[W 06:28:20.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:20.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:20.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:20.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:20.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:20.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:20 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
[W 06:28:20.182 NotebookApp] zmq message arrived on closed channel
[W 06:28:20.183 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:20 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:20.435 NotebookApp] zmq message arrived on closed channel
[W 06:28:20.435 NotebookApp] zmq message arrived on closed channel
[W 06:28:20.636 NotebookApp] zmq message arrived on closed channel
[W 06:28:20.637 NotebookApp] zmq message arrived on closed channel
[W 06:28:20.838 NotebookApp] zmq message arrived on closed channel
[W 06:28:20.838 NotebookApp] zmq message arrived on closed channel
[W 06:28:21.039 NotebookApp] zmq message arrived on closed channel
[W 06:28:21.040 NotebookApp] zmq message arrived on closed channel
[W 06:28:21.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:21.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:21.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:21.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:21.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:21.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:21.292 NotebookApp] zmq message arrived on closed channel
[W 06:28:21.292 NotebookApp] zmq message arrived on closed channel
[W 06:28:21.494 NotebookApp] zmq message arrived on closed channel
[W 06:28:21.494 NotebookApp] zmq message arrived on closed channel
[W 06:28:21.695 NotebookApp] zmq message arrived on closed channel
[W 06:28:21.695 NotebookApp] zmq message arrived on closed channel
[W 06:28:21.897 NotebookApp] zmq message arrived on closed channel
[W 06:28:21.897 NotebookApp] zmq message arrived on closed channel
[W 06:28:22.047 NotebookApp] zmq message arrived on closed channel
[W 06:28:22.048 NotebookApp] zmq message arrived on closed channel
[W 06:28:22.048 NotebookApp] zmq message arrived on closed channel
[W 06:28:22.048 NotebookApp] zmq message arrived on closed channel
[W 06:28:22.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:22.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:22.098 NotebookApp] zmq message arrived on closed channel
[W 06:28:22.099 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:22 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:22 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:22.300 NotebookApp] zmq message arrived on closed channel
[W 06:28:22.301 NotebookApp] zmq message arrived on closed channel
[W 06:28:22.501 NotebookApp] zmq message arrived on closed channel
[W 06:28:22.502 NotebookApp] zmq message arrived on closed channel
[W 06:28:22.703 NotebookApp] zmq message arrived on closed channel
[W 06:28:22.704 NotebookApp] zmq message arrived on closed channel
[W 06:28:22.905 NotebookApp] zmq message arrived on closed channel
[W 06:28:22.906 NotebookApp] zmq message arrived on closed channel
[W 06:28:23.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:23.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:23.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:23.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:23.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:23.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:23.106 NotebookApp] zmq message arrived on closed channel
[W 06:28:23.107 NotebookApp] zmq message arrived on closed channel
[W 06:28:23.308 NotebookApp] zmq message arrived on closed channel
[W 06:28:23.308 NotebookApp] zmq message arrived on closed channel
[W 06:28:23.510 NotebookApp] zmq message arrived on closed channel
[W 06:28:23.510 NotebookApp] zmq message arrived on closed channel
[W 06:28:23.711 NotebookApp] zmq message arrived on closed channel
[W 06:28:23.712 NotebookApp] zmq message arrived on closed channel
[W 06:28:23.913 NotebookApp] zmq message arrived on closed channel
[W 06:28:23.914 NotebookApp] zmq message arrived on closed channel
[W 06:28:24.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:24.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:24.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:24.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:24.053 NotebookApp] zmq message arrived on closed channel
[W 06:28:24.053 NotebookApp] zmq message arrived on closed channel
[W 06:28:24.115 NotebookApp] zmq message arrived on closed channel
[W 06:28:24.116 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:24 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:24 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:24.367 NotebookApp] zmq message arrived on closed channel
[W 06:28:24.368 NotebookApp] zmq message arrived on closed channel
[W 06:28:24.568 NotebookApp] zmq message arrived on closed channel
[W 06:28:24.569 NotebookApp] zmq message arrived on closed channel
[W 06:28:24.770 NotebookApp] zmq message arrived on closed channel
[W 06:28:24.771 NotebookApp] zmq message arrived on closed channel
[W 06:28:24.922 NotebookApp] zmq message arrived on closed channel
[W 06:28:24.922 NotebookApp] zmq message arrived on closed channel
[W 06:28:25.048 NotebookApp] zmq message arrived on closed channel
[W 06:28:25.048 NotebookApp] zmq message arrived on closed channel
[W 06:28:25.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:25.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:25.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:25.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:25.123 NotebookApp] zmq message arrived on closed channel
[W 06:28:25.124 NotebookApp] zmq message arrived on closed channel
[W 06:28:25.376 NotebookApp] zmq message arrived on closed channel
[W 06:28:25.376 NotebookApp] zmq message arrived on closed channel
[W 06:28:25.577 NotebookApp] zmq message arrived on closed channel
[W 06:28:25.578 NotebookApp] zmq message arrived on closed channel
[W 06:28:25.779 NotebookApp] zmq message arrived on closed channel
[W 06:28:25.779 NotebookApp] zmq message arrived on closed channel
[W 06:28:25.981 NotebookApp] zmq message arrived on closed channel
[W 06:28:25.981 NotebookApp] zmq message arrived on closed channel
[W 06:28:26.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:26.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:26.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:26.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:26.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:26.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:26.184 NotebookApp] zmq message arrived on closed channel
[W 06:28:26.185 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:26 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:26 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:26.385 NotebookApp] zmq message arrived on closed channel
[W 06:28:26.385 NotebookApp] zmq message arrived on closed channel
[W 06:28:26.587 NotebookApp] zmq message arrived on closed channel
[W 06:28:26.588 NotebookApp] zmq message arrived on closed channel
[W 06:28:26.789 NotebookApp] zmq message arrived on closed channel
[W 06:28:26.790 NotebookApp] zmq message arrived on closed channel
[W 06:28:26.991 NotebookApp] zmq message arrived on closed channel
[W 06:28:26.991 NotebookApp] zmq message arrived on closed channel
[W 06:28:27.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:27.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:27.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:27.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:27.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:27.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:27.192 NotebookApp] zmq message arrived on closed channel
[W 06:28:27.193 NotebookApp] zmq message arrived on closed channel
[W 06:28:27.394 NotebookApp] zmq message arrived on closed channel
[W 06:28:27.395 NotebookApp] zmq message arrived on closed channel
[W 06:28:27.595 NotebookApp] zmq message arrived on closed channel
[W 06:28:27.596 NotebookApp] zmq message arrived on closed channel
[W 06:28:27.797 NotebookApp] zmq message arrived on closed channel
[W 06:28:27.798 NotebookApp] zmq message arrived on closed channel
[W 06:28:27.999 NotebookApp] zmq message arrived on closed channel
[W 06:28:28.000 NotebookApp] zmq message arrived on closed channel
[W 06:28:28.048 NotebookApp] zmq message arrived on closed channel
[W 06:28:28.048 NotebookApp] zmq message arrived on closed channel
[W 06:28:28.048 NotebookApp] zmq message arrived on closed channel
[W 06:28:28.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:28.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:28.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:28 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:28 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:28.201 NotebookApp] zmq message arrived on closed channel
[W 06:28:28.202 NotebookApp] zmq message arrived on closed channel
[W 06:28:28.403 NotebookApp] zmq message arrived on closed channel
[W 06:28:28.403 NotebookApp] zmq message arrived on closed channel
[W 06:28:28.604 NotebookApp] zmq message arrived on closed channel
[W 06:28:28.605 NotebookApp] zmq message arrived on closed channel
[W 06:28:28.806 NotebookApp] zmq message arrived on closed channel
[W 06:28:28.807 NotebookApp] zmq message arrived on closed channel
[W 06:28:29.008 NotebookApp] zmq message arrived on closed channel
[W 06:28:29.008 NotebookApp] zmq message arrived on closed channel
[W 06:28:29.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:29.209 NotebookApp] zmq message arrived on closed channel
[W 06:28:29.210 NotebookApp] zmq message arrived on closed channel
[W 06:28:29.411 NotebookApp] zmq message arrived on closed channel
[W 06:28:29.411 NotebookApp] zmq message arrived on closed channel
[W 06:28:29.613 NotebookApp] zmq message arrived on closed channel
[W 06:28:29.613 NotebookApp] zmq message arrived on closed channel
[W 06:28:29.815 NotebookApp] zmq message arrived on closed channel
[W 06:28:29.815 NotebookApp] zmq message arrived on closed channel
[W 06:28:30.016 NotebookApp] zmq message arrived on closed channel
[W 06:28:30.017 NotebookApp] zmq message arrived on closed channel
[W 06:28:30.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:30.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:30.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:30.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:30.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:30.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:30 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:30 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:30.218 NotebookApp] zmq message arrived on closed channel
[W 06:28:30.218 NotebookApp] zmq message arrived on closed channel
[W 06:28:30.420 NotebookApp] zmq message arrived on closed channel
[W 06:28:30.420 NotebookApp] zmq message arrived on closed channel
[W 06:28:30.622 NotebookApp] zmq message arrived on closed channel
[W 06:28:30.622 NotebookApp] zmq message arrived on closed channel
[W 06:28:30.823 NotebookApp] zmq message arrived on closed channel
[W 06:28:30.824 NotebookApp] zmq message arrived on closed channel
[W 06:28:31.025 NotebookApp] zmq message arrived on closed channel
[W 06:28:31.025 NotebookApp] zmq message arrived on closed channel
[W 06:28:31.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:31.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:31.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:31.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:31.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:31.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:31.227 NotebookApp] zmq message arrived on closed channel
[W 06:28:31.227 NotebookApp] zmq message arrived on closed channel
[W 06:28:31.428 NotebookApp] zmq message arrived on closed channel
[W 06:28:31.429 NotebookApp] zmq message arrived on closed channel
[W 06:28:31.630 NotebookApp] zmq message arrived on closed channel
[W 06:28:31.631 NotebookApp] zmq message arrived on closed channel
[W 06:28:31.832 NotebookApp] zmq message arrived on closed channel
[W 06:28:31.832 NotebookApp] zmq message arrived on closed channel
[W 06:28:32.034 NotebookApp] zmq message arrived on closed channel
[W 06:28:32.034 NotebookApp] zmq message arrived on closed channel
[W 06:28:32.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:32.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:32.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:32.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:32.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:32.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:32 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:32 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:32.236 NotebookApp] zmq message arrived on closed channel
[W 06:28:32.236 NotebookApp] zmq message arrived on closed channel
[W 06:28:32.437 NotebookApp] zmq message arrived on closed channel
[W 06:28:32.438 NotebookApp] zmq message arrived on closed channel
[W 06:28:32.639 NotebookApp] zmq message arrived on closed channel
[W 06:28:32.639 NotebookApp] zmq message arrived on closed channel
[W 06:28:32.841 NotebookApp] zmq message arrived on closed channel
[W 06:28:32.841 NotebookApp] zmq message arrived on closed channel
[W 06:28:33.042 NotebookApp] zmq message arrived on closed channel
[W 06:28:33.043 NotebookApp] zmq message arrived on closed channel
[W 06:28:33.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:33.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:33.244 NotebookApp] zmq message arrived on closed channel
[W 06:28:33.244 NotebookApp] zmq message arrived on closed channel
[W 06:28:33.496 NotebookApp] zmq message arrived on closed channel
[W 06:28:33.496 NotebookApp] zmq message arrived on closed channel
[W 06:28:33.698 NotebookApp] zmq message arrived on closed channel
[W 06:28:33.698 NotebookApp] zmq message arrived on closed channel
[W 06:28:33.900 NotebookApp] zmq message arrived on closed channel
[W 06:28:33.900 NotebookApp] zmq message arrived on closed channel
[W 06:28:34.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:34.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:34.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:34.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:34.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:34.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:34.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:34.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:34 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:34 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:34.253 NotebookApp] zmq message arrived on closed channel
[W 06:28:34.253 NotebookApp] zmq message arrived on closed channel
[W 06:28:34.505 NotebookApp] zmq message arrived on closed channel
[W 06:28:34.506 NotebookApp] zmq message arrived on closed channel
[W 06:28:34.707 NotebookApp] zmq message arrived on closed channel
[W 06:28:34.707 NotebookApp] zmq message arrived on closed channel
[W 06:28:34.875 NotebookApp] zmq message arrived on closed channel
[W 06:28:34.876 NotebookApp] zmq message arrived on closed channel
[W 06:28:34.979 NotebookApp] zmq message arrived on closed channel
[W 06:28:34.979 NotebookApp] zmq message arrived on closed channel
[W 06:28:35.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:35.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:35.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:35.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:35.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:35.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:36.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:36.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:36.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:36.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:36.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:36.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:36 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:36 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:37.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:37.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:37.053 NotebookApp] zmq message arrived on closed channel
[W 06:28:37.053 NotebookApp] zmq message arrived on closed channel
[W 06:28:37.053 NotebookApp] zmq message arrived on closed channel
[W 06:28:37.053 NotebookApp] zmq message arrived on closed channel
[W 06:28:38.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:38.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:38.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:38.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:38.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:38.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:38 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:38 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:39.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:39.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:39.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:39.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:39.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:40.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:40.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:40.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:40.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:40.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:40.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:40 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:40 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:41.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:41.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:41.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:41.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:41.053 NotebookApp] zmq message arrived on closed channel
[W 06:28:41.053 NotebookApp] zmq message arrived on closed channel
[W 06:28:42.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:42.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:42.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:42.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:42.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:42.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:42 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:42 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:43.053 NotebookApp] zmq message arrived on closed channel
[W 06:28:43.054 NotebookApp] zmq message arrived on closed channel
[W 06:28:43.054 NotebookApp] zmq message arrived on closed channel
[W 06:28:43.054 NotebookApp] zmq message arrived on closed channel
[W 06:28:43.055 NotebookApp] zmq message arrived on closed channel
[W 06:28:43.055 NotebookApp] zmq message arrived on closed channel
[W 06:28:44.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:44.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:44.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:44 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:44 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:46.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:46.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:46.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:46 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:46 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:47.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:48.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:48.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:48.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:48.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:48.053 NotebookApp] zmq message arrived on closed channel
[W 06:28:48.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:48 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:48 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:49.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:49.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:49.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:49.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:50.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:50.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:50.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:50.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:50.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:50.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:50 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:50 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:51.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:51.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:52.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:52.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:52.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:52.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:52.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:52.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:52 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:52 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:53.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:53.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:53.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:53.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:53.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:53.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:54.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:54.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:54.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:54.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:54.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:54.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:54 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:54 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:55.053 NotebookApp] zmq message arrived on closed channel
[W 06:28:55.054 NotebookApp] zmq message arrived on closed channel
[W 06:28:55.054 NotebookApp] zmq message arrived on closed channel
[W 06:28:55.054 NotebookApp] zmq message arrived on closed channel
[W 06:28:55.054 NotebookApp] zmq message arrived on closed channel
[W 06:28:55.055 NotebookApp] zmq message arrived on closed channel
[W 06:28:56.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:56.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:56.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:56.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:56.053 NotebookApp] zmq message arrived on closed channel
[W 06:28:56.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:56 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:56 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:57.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:57.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:57.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:57.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:57.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:57.052 NotebookApp] zmq message arrived on closed channel
[W 06:28:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:58.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:58.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:58.051 NotebookApp] zmq message arrived on closed channel
[W 06:28:58.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:28:58 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:28:58 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:28:59.049 NotebookApp] zmq message arrived on closed channel
[W 06:28:59.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:59.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:59.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:59.050 NotebookApp] zmq message arrived on closed channel
[W 06:28:59.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:00.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:00.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:00 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:00 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:01.053 NotebookApp] zmq message arrived on closed channel
[W 06:29:01.053 NotebookApp] zmq message arrived on closed channel
[W 06:29:01.053 NotebookApp] zmq message arrived on closed channel
[W 06:29:01.053 NotebookApp] zmq message arrived on closed channel
[W 06:29:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:02.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:02 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:02 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:03.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:03.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:03.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:03.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:03.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:03.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:04.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:04.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:04.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:04.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:04.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:04.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:04 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:04 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:05.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:05.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:05.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:05.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:05.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:05.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:06.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:06.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:06.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:06.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:06.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:06.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:06 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:06 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:07.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:07.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:07.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:07.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:07.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:07.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:08.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:08.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:08.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:08.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:08.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:08.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:08 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:08 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:09.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:09.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:09.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:09.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:09.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:09.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:10.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:10.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:10.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:10.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:10.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:10.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:10 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:10 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:11.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:11.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:11.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:12.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:12.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:12.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:12.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:12.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:12.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:12 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:12 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:13.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:13.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:13.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:13.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:13.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:13.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:14.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:14.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:14.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:14.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:14.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:14.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:14 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:14 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:15.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:15.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:15.053 NotebookApp] zmq message arrived on closed channel
[W 06:29:15.053 NotebookApp] zmq message arrived on closed channel
[W 06:29:15.053 NotebookApp] zmq message arrived on closed channel
[W 06:29:15.053 NotebookApp] zmq message arrived on closed channel
[W 06:29:16.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:16.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:16.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:16.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:16.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:16.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:16 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:16 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:17.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:17.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:17.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:17.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:17.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:17.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:18.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:18.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:18.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:18.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:18.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:18.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:18 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:18 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:19.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:19.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:19.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:19.053 NotebookApp] zmq message arrived on closed channel
[W 06:29:19.053 NotebookApp] zmq message arrived on closed channel
[W 06:29:19.053 NotebookApp] zmq message arrived on closed channel
[W 06:29:20.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:20.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:20.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:20.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:20.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:20.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:20 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:20 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:20.742 NotebookApp] zmq message arrived on closed channel
[W 06:29:20.743 NotebookApp] zmq message arrived on closed channel
[W 06:29:20.744 NotebookApp] zmq message arrived on closed channel
[W 06:29:20.744 NotebookApp] zmq message arrived on closed channel
[W 06:29:21.047 NotebookApp] zmq message arrived on closed channel
[W 06:29:21.048 NotebookApp] zmq message arrived on closed channel
[W 06:29:21.048 NotebookApp] zmq message arrived on closed channel
[W 06:29:21.048 NotebookApp] zmq message arrived on closed channel
[W 06:29:21.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:21.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:21.176 NotebookApp] zmq message arrived on closed channel
[W 06:29:21.176 NotebookApp] zmq message arrived on closed channel
[W 06:29:22.048 NotebookApp] zmq message arrived on closed channel
[W 06:29:22.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:22.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:22.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:22.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:22.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:22 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:22 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:23.048 NotebookApp] zmq message arrived on closed channel
[W 06:29:23.048 NotebookApp] zmq message arrived on closed channel
[W 06:29:23.048 NotebookApp] zmq message arrived on closed channel
[W 06:29:23.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:23.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:23.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:24.046 NotebookApp] zmq message arrived on closed channel
[W 06:29:24.046 NotebookApp] zmq message arrived on closed channel
[W 06:29:24.046 NotebookApp] zmq message arrived on closed channel
[W 06:29:24.047 NotebookApp] zmq message arrived on closed channel
[W 06:29:24.047 NotebookApp] zmq message arrived on closed channel
[W 06:29:24.047 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:24 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:24 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:25.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:25.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:25.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:25.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:25.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:25.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:26.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:26.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:26.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:26.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:26.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:26.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:26 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:26 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:27.046 NotebookApp] zmq message arrived on closed channel
[W 06:29:27.046 NotebookApp] zmq message arrived on closed channel
[W 06:29:27.046 NotebookApp] zmq message arrived on closed channel
[W 06:29:27.047 NotebookApp] zmq message arrived on closed channel
[W 06:29:27.047 NotebookApp] zmq message arrived on closed channel
[W 06:29:27.047 NotebookApp] zmq message arrived on closed channel
[W 06:29:28.048 NotebookApp] zmq message arrived on closed channel
[W 06:29:28.048 NotebookApp] zmq message arrived on closed channel
[W 06:29:28.048 NotebookApp] zmq message arrived on closed channel
[W 06:29:28.048 NotebookApp] zmq message arrived on closed channel
[W 06:29:28.048 NotebookApp] zmq message arrived on closed channel
[W 06:29:28.048 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:28 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:28 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:29.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:29.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:29.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:30.047 NotebookApp] zmq message arrived on closed channel
[W 06:29:30.047 NotebookApp] zmq message arrived on closed channel
[W 06:29:30.047 NotebookApp] zmq message arrived on closed channel
[W 06:29:30.048 NotebookApp] zmq message arrived on closed channel
[W 06:29:30.048 NotebookApp] zmq message arrived on closed channel
[W 06:29:30.048 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:30 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:30 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:31.048 NotebookApp] zmq message arrived on closed channel
[W 06:29:31.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:31.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:31.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:31.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:31.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:32.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:32.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:32.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:32.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:32.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:32.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:32 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:32 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:33.040 NotebookApp] zmq message arrived on closed channel
[W 06:29:33.041 NotebookApp] zmq message arrived on closed channel
[W 06:29:33.046 NotebookApp] zmq message arrived on closed channel
[W 06:29:33.046 NotebookApp] zmq message arrived on closed channel
[W 06:29:33.046 NotebookApp] zmq message arrived on closed channel
[W 06:29:33.046 NotebookApp] zmq message arrived on closed channel
[W 06:29:33.046 NotebookApp] zmq message arrived on closed channel
[W 06:29:33.047 NotebookApp] zmq message arrived on closed channel
[W 06:29:34.047 NotebookApp] zmq message arrived on closed channel
[W 06:29:34.047 NotebookApp] zmq message arrived on closed channel
[W 06:29:34.047 NotebookApp] zmq message arrived on closed channel
[W 06:29:34.048 NotebookApp] zmq message arrived on closed channel
[W 06:29:34.048 NotebookApp] zmq message arrived on closed channel
[W 06:29:34.048 NotebookApp] zmq message arrived on closed channel
[W 06:29:34.097 NotebookApp] zmq message arrived on closed channel
[W 06:29:34.097 NotebookApp] zmq message arrived on closed channel
[W 06:29:34.200 NotebookApp] zmq message arrived on closed channel
[W 06:29:34.200 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:34 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:34 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:35.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:35.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:35.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:35.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:35.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:35.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:36.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:36.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:36.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:36.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:36.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:36.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:36 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:36 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:37.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:37.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:37.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:37.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:37.053 NotebookApp] zmq message arrived on closed channel
[W 06:29:37.053 NotebookApp] zmq message arrived on closed channel
[W 06:29:38.075 NotebookApp] zmq message arrived on closed channel
[W 06:29:38.075 NotebookApp] zmq message arrived on closed channel
[W 06:29:38.076 NotebookApp] zmq message arrived on closed channel
[W 06:29:38.076 NotebookApp] zmq message arrived on closed channel
[W 06:29:38.076 NotebookApp] zmq message arrived on closed channel
[W 06:29:38.076 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:38 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:38 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:39.053 NotebookApp] zmq message arrived on closed channel
[W 06:29:39.053 NotebookApp] zmq message arrived on closed channel
[W 06:29:39.053 NotebookApp] zmq message arrived on closed channel
[W 06:29:40.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:40.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:40.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:40.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:40.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:40.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:40 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:40 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:41.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:41.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:41.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:41.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:41.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:41.053 NotebookApp] zmq message arrived on closed channel
[I 06:29:41.712 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[W 06:29:42.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:42.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:42.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:42.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:42.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:42.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:42 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:42 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:43.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:43.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:43.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:43.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:43.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:43.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:44.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:44.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:44.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:44.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:44.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:44 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:44 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:45.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:45.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:45.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:45.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:46.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:46.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:46.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:46.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:46.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:46 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:46 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:47.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:47.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:47.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:47.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:47.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:48.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:48.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:48.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:48.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:48.053 NotebookApp] zmq message arrived on closed channel
[W 06:29:48.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:48 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:48 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:49.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:50.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:50.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:50.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:50.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:50.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:50.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:50 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:50 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:50.555 NotebookApp] zmq message arrived on closed channel
[W 06:29:50.556 NotebookApp] zmq message arrived on closed channel
[W 06:29:50.556 NotebookApp] zmq message arrived on closed channel
[W 06:29:50.557 NotebookApp] zmq message arrived on closed channel
[W 06:29:50.947 NotebookApp] zmq message arrived on closed channel
[W 06:29:50.948 NotebookApp] zmq message arrived on closed channel
[W 06:29:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:51.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:51.053 NotebookApp] zmq message arrived on closed channel
[W 06:29:51.054 NotebookApp] zmq message arrived on closed channel
[W 06:29:51.054 NotebookApp] zmq message arrived on closed channel
[W 06:29:52.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:52.053 NotebookApp] zmq message arrived on closed channel
[W 06:29:52.053 NotebookApp] zmq message arrived on closed channel
[W 06:29:52.053 NotebookApp] zmq message arrived on closed channel
[W 06:29:52.053 NotebookApp] zmq message arrived on closed channel
[W 06:29:52.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:52 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:52 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:53.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:53.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:53.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:53.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:53.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:53.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:54.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:54.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:54.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:54.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:54.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:54.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:54 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:54 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:55.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:55.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:55.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:55.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:55.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:55.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:56.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:56.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:56.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:56.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:56.052 NotebookApp] zmq message arrived on closed channel
[W 06:29:56.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:56 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:56 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:57.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:57.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:57.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:57.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:57.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:57.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:58.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:58.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:58.051 NotebookApp] zmq message arrived on closed channel
[W 06:29:58.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:29:58 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:29:58 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:29:59.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:59.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:59.049 NotebookApp] zmq message arrived on closed channel
[W 06:29:59.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:59.050 NotebookApp] zmq message arrived on closed channel
[W 06:29:59.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:00.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:00.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:00.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:00 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:00 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:01.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:01.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:01.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:01.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:01.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:02.049 NotebookApp] zmq message arrived on closed channel
[W 06:30:02.049 NotebookApp] zmq message arrived on closed channel
[W 06:30:02.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:02.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:02.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:02.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:02 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:02 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:03.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:03.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:03.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:03.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:03.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:03.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:04.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:04.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:04.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:04.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:04.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:04.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:04 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:04 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:05.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:05.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:05.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:05.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:05.053 NotebookApp] zmq message arrived on closed channel
[W 06:30:05.053 NotebookApp] zmq message arrived on closed channel
[W 06:30:06.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:06.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:06.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:06.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:06.053 NotebookApp] zmq message arrived on closed channel
[W 06:30:06.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:06 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:06 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:07.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:07.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:07.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:07.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:07.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:07.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:08.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:08.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:08.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:08.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:08.053 NotebookApp] zmq message arrived on closed channel
[W 06:30:08.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:08 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:08 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:09.053 NotebookApp] zmq message arrived on closed channel
[W 06:30:09.054 NotebookApp] zmq message arrived on closed channel
[W 06:30:09.054 NotebookApp] zmq message arrived on closed channel
[W 06:30:09.054 NotebookApp] zmq message arrived on closed channel
[W 06:30:09.055 NotebookApp] zmq message arrived on closed channel
[W 06:30:09.055 NotebookApp] zmq message arrived on closed channel
[W 06:30:10.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:10.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:10.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:10.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:10.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:10.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:10 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:10 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:11.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:11.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:11.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:11.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:11.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:12.046 NotebookApp] zmq message arrived on closed channel
[W 06:30:12.047 NotebookApp] zmq message arrived on closed channel
[W 06:30:12.047 NotebookApp] zmq message arrived on closed channel
[W 06:30:12.047 NotebookApp] zmq message arrived on closed channel
[W 06:30:12.047 NotebookApp] zmq message arrived on closed channel
[W 06:30:12.047 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:12 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:12 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:13.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:13.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:13.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:13.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:13.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:13.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:14.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:14.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:14.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:14.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:14.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:14.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:14 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:14 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:15.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:15.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:15.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:15.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:15.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:15.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:16.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:16.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:16.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:16.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:16.053 NotebookApp] zmq message arrived on closed channel
[W 06:30:16.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:16 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:16 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:17.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:17.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:17.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:17.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:17.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:17.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:18.049 NotebookApp] zmq message arrived on closed channel
[W 06:30:18.049 NotebookApp] zmq message arrived on closed channel
[W 06:30:18.049 NotebookApp] zmq message arrived on closed channel
[W 06:30:18.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:18.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:18.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:18 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:18 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:19.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:19.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:19.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:19.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:19.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:19.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:20.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:20.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:20.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:20.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:20.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:20.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:20 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:20 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:21.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:21.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:21.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:21.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:21.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:21.053 NotebookApp] zmq message arrived on closed channel
[W 06:30:22.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:22.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:22.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:22.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:22.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:22.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:22 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:22 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:23.049 NotebookApp] zmq message arrived on closed channel
[W 06:30:23.049 NotebookApp] zmq message arrived on closed channel
[W 06:30:23.049 NotebookApp] zmq message arrived on closed channel
[W 06:30:23.049 NotebookApp] zmq message arrived on closed channel
[W 06:30:23.049 NotebookApp] zmq message arrived on closed channel
[W 06:30:23.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:24.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:24.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:24.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:24.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:24.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:24.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:24 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:24 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:25.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:25.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:25.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:25.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:25.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:25.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:26.054 NotebookApp] zmq message arrived on closed channel
[W 06:30:26.054 NotebookApp] zmq message arrived on closed channel
[W 06:30:26.054 NotebookApp] zmq message arrived on closed channel
[W 06:30:26.054 NotebookApp] zmq message arrived on closed channel
[W 06:30:26.055 NotebookApp] zmq message arrived on closed channel
[W 06:30:26.055 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:26 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:26 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:27.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:27.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:27.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:27.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:27.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:27.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:28.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:28.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:28.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:28.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:28.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:28.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:28 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:28 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:29.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:29.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:30.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:30.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:30.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:30.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:30.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:30.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:30 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:30 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:31.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:31.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:31.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:31.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:31.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:31.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:32.049 NotebookApp] zmq message arrived on closed channel
[W 06:30:32.049 NotebookApp] zmq message arrived on closed channel
[W 06:30:32.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:32.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:32.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:32.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:32 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:32 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:33.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:33.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:33.053 NotebookApp] zmq message arrived on closed channel
[W 06:30:34.071 NotebookApp] zmq message arrived on closed channel
[W 06:30:34.072 NotebookApp] zmq message arrived on closed channel
[W 06:30:34.072 NotebookApp] zmq message arrived on closed channel
[W 06:30:34.072 NotebookApp] zmq message arrived on closed channel
[W 06:30:34.072 NotebookApp] zmq message arrived on closed channel
[W 06:30:34.073 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:34 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:34 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:35.053 NotebookApp] zmq message arrived on closed channel
[W 06:30:35.053 NotebookApp] zmq message arrived on closed channel
[W 06:30:35.053 NotebookApp] zmq message arrived on closed channel
[W 06:30:35.053 NotebookApp] zmq message arrived on closed channel
[W 06:30:35.054 NotebookApp] zmq message arrived on closed channel
[W 06:30:35.054 NotebookApp] zmq message arrived on closed channel
[W 06:30:36.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:36.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:36.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:36.053 NotebookApp] zmq message arrived on closed channel
[W 06:30:36.053 NotebookApp] zmq message arrived on closed channel
[W 06:30:36.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:36 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:36 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:37.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:38.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:38.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:38.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:38.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:38.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:38.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:38 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:38 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:39.053 NotebookApp] zmq message arrived on closed channel
[W 06:30:39.053 NotebookApp] zmq message arrived on closed channel
[W 06:30:39.053 NotebookApp] zmq message arrived on closed channel
[W 06:30:39.053 NotebookApp] zmq message arrived on closed channel
[W 06:30:40.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:40.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:40.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:40.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:40.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:40.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:40 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:40 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:41.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:41.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:41.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:41.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:41.053 NotebookApp] zmq message arrived on closed channel
[W 06:30:41.053 NotebookApp] zmq message arrived on closed channel
[W 06:30:42.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:42.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:42.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:42.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:42.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:42.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:42 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:42 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:43.049 NotebookApp] zmq message arrived on closed channel
[W 06:30:43.049 NotebookApp] zmq message arrived on closed channel
[W 06:30:43.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:43.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:43.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:43.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:44.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:44.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:44.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:44.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:44 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:44 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:45.053 NotebookApp] zmq message arrived on closed channel
[W 06:30:46.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:46.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:46.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:46 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:46 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:47.049 NotebookApp] zmq message arrived on closed channel
[W 06:30:47.049 NotebookApp] zmq message arrived on closed channel
[W 06:30:47.049 NotebookApp] zmq message arrived on closed channel
[W 06:30:47.049 NotebookApp] zmq message arrived on closed channel
[W 06:30:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:48.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:48.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:48.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:48.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:48.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:48.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:48 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:48 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:49.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:49.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:50.049 NotebookApp] zmq message arrived on closed channel
[W 06:30:50.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:50.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:50.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:50.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:50.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:50 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:50 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:51.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:51.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:51.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:51.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:52.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:52.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:52.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:52.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:52.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:52.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:52 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:52 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:53.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:53.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:53.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:53.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:53.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:53.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:53.887 NotebookApp] zmq message arrived on closed channel
[W 06:30:53.887 NotebookApp] zmq message arrived on closed channel
[W 06:30:53.888 NotebookApp] zmq message arrived on closed channel
[W 06:30:53.889 NotebookApp] zmq message arrived on closed channel
[W 06:30:54.047 NotebookApp] zmq message arrived on closed channel
[W 06:30:54.048 NotebookApp] zmq message arrived on closed channel
[W 06:30:54.048 NotebookApp] zmq message arrived on closed channel
[W 06:30:54.048 NotebookApp] zmq message arrived on closed channel
[W 06:30:54.048 NotebookApp] zmq message arrived on closed channel
[W 06:30:54.049 NotebookApp] zmq message arrived on closed channel
[W 06:30:54.280 NotebookApp] zmq message arrived on closed channel
[W 06:30:54.280 NotebookApp] zmq message arrived on closed channel
[W 06:30:54.383 NotebookApp] zmq message arrived on closed channel
[W 06:30:54.384 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:54 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:54 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:55.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:55.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:55.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:55.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:55.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:55.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:56.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:56.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:56.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:56.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:56.052 NotebookApp] zmq message arrived on closed channel
[W 06:30:56.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:56 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:56 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:57.049 NotebookApp] zmq message arrived on closed channel
[W 06:30:57.049 NotebookApp] zmq message arrived on closed channel
[W 06:30:57.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:57.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:57.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:57.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:58.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:58.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:30:58 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:30:58 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:30:59.050 NotebookApp] zmq message arrived on closed channel
[W 06:30:59.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:59.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:59.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:59.051 NotebookApp] zmq message arrived on closed channel
[W 06:30:59.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:00.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:00.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:00 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:00 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:01.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:01.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:01.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:01.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:01.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:01.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:02.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:02.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:02 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:02 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:03.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:03.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:03.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:03.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:03.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:03.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:04.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:04.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:04.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:04.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:04.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:04.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:04 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:04 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:05.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:05.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:05.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:05.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:05.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:05.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:06.048 NotebookApp] zmq message arrived on closed channel
[W 06:31:06.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:06.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:06.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:06.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:06.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:06 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:06 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:07.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:07.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:07.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:07.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:07.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:07.053 NotebookApp] zmq message arrived on closed channel
[W 06:31:08.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:08.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:08.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:08.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:08.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:08.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:08 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:08 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:09.048 NotebookApp] zmq message arrived on closed channel
[W 06:31:09.048 NotebookApp] zmq message arrived on closed channel
[W 06:31:09.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:09.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:09.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:09.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:10.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:10.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:10.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:10.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:10.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:10.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:10 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:10 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:11.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:11.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:12.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:12.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:12.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:12.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:12.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:12.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:12 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:12 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:13.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:13.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:13.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:13.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:13.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:13.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:14.048 NotebookApp] zmq message arrived on closed channel
[W 06:31:14.048 NotebookApp] zmq message arrived on closed channel
[W 06:31:14.048 NotebookApp] zmq message arrived on closed channel
[W 06:31:14.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:14.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:14.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:14 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:14 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:15.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:15.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:15.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:15.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:15.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:15.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:16.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:16.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:16.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:16.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:16.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:16.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:16 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:16 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:17.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:17.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:17.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:17.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:17.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:17.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:18.048 NotebookApp] zmq message arrived on closed channel
[W 06:31:18.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:18.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:18.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:18.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:18.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:18 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:18 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[I 06:31:18.466 NotebookApp] Saving file at /Spark Fundamentals - Python.ipynb
[W 06:31:19.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:19.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:19.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:19.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:19.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:19.053 NotebookApp] zmq message arrived on closed channel
[W 06:31:20.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:20.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:20.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:20.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:20.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:20.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:20 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:20 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:21.053 NotebookApp] zmq message arrived on closed channel
[W 06:31:21.053 NotebookApp] zmq message arrived on closed channel
[W 06:31:21.053 NotebookApp] zmq message arrived on closed channel
[W 06:31:21.053 NotebookApp] zmq message arrived on closed channel
[W 06:31:21.054 NotebookApp] zmq message arrived on closed channel
[W 06:31:21.054 NotebookApp] zmq message arrived on closed channel
[W 06:31:22.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:22.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:22.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:22.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:22.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:22.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:22 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:22 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:23.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:23.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:23.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:23.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:23.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:23.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:24.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:24.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:24.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:24.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:24.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:24.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:24 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:24 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:25.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:25.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:25.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:25.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:25.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:25.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:26.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:26.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:26.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:26.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:26.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:26.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:26 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:26 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:27.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:27.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:27.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:27.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:27.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:27.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:28.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:28.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:28.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:28.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:28.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:28.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:28 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:28 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:29.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:29.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:29.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:29.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:29.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:30.076 NotebookApp] zmq message arrived on closed channel
[W 06:31:30.076 NotebookApp] zmq message arrived on closed channel
[W 06:31:30.076 NotebookApp] zmq message arrived on closed channel
[W 06:31:30.076 NotebookApp] zmq message arrived on closed channel
[W 06:31:30.077 NotebookApp] zmq message arrived on closed channel
[W 06:31:30.077 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:30 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:30 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:31.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:31.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:31.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:31.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:31.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:31.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:32.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:32.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:32.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:32.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:32.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:32.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:32 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:32 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:33.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:33.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:33.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:33.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:33.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:34.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:34.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:34.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:34.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:34.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:34.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:34 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:34 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:35.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:35.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:35.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:35.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:35.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:35.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:36.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:36.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:36.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:36.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:36.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:36.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:36 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:36 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:37.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:37.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:37.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:37.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:37.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:38.048 NotebookApp] zmq message arrived on closed channel
[W 06:31:38.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:38.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:38.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:38.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:38.049 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:38 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:38 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:39.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:39.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:39.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:39.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:39.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:40.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:40.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:40.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:40.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:40.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:40.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:40 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:40 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:41.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:41.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:41.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:41.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:41.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:41.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:42.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:42.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:42.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:42.053 NotebookApp] zmq message arrived on closed channel
[W 06:31:42.053 NotebookApp] zmq message arrived on closed channel
[W 06:31:42.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:42 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:42 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:43.048 NotebookApp] zmq message arrived on closed channel
[W 06:31:43.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:43.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:43.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:43.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:43.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:44.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:44.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:44 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:44 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:46.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:46.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:46.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:46.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:46.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:46.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:46 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:46 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:47.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:47.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:48.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:48.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:48.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:48.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:48.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:48.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:48 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:48 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:49.048 NotebookApp] zmq message arrived on closed channel
[W 06:31:49.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:49.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:49.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:49.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:49.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:50.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:50.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:50.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:50.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:50.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:50.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:50 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:50 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:51.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:51.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:51.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:51.052 NotebookApp] zmq message arrived on closed channel
[W 06:31:52.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:52.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:52.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:52.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:52.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:52.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:52 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:52 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:53.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:53.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:53.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:53.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:53.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:53.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:54.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:54.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:54.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:54.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:54.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:54.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:54 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:54 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:55.048 NotebookApp] zmq message arrived on closed channel
[W 06:31:55.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:55.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:55.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:55.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:55.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:56.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:56.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:56.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:56.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:56.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:56.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:56 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:56 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:57.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:57.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:57.049 NotebookApp] zmq message arrived on closed channel
[W 06:31:57.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:57.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:57.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:58.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:58.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:31:58 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:31:58 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:31:59.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:59.050 NotebookApp] zmq message arrived on closed channel
[W 06:31:59.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:59.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:59.051 NotebookApp] zmq message arrived on closed channel
[W 06:31:59.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:00.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:00.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:00.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:00 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:00 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:01.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:01.053 NotebookApp] zmq message arrived on closed channel
[W 06:32:02.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:02.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:02.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:02.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:02.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:02.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:02 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:02 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:03.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:03.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:03.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:03.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:03.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:03.053 NotebookApp] zmq message arrived on closed channel
[W 06:32:04.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:04.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:04.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:04.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:04.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:04.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:04 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:04 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:05.048 NotebookApp] zmq message arrived on closed channel
[W 06:32:05.048 NotebookApp] zmq message arrived on closed channel
[W 06:32:05.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:05.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:05.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:05.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:06.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:06.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:06.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:06.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:06.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:06.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:06 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:06 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:07.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:07.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:07.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:07.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:07.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:07.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:08.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:08.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:08.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:08.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:08.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:08.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:08 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:08 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:09.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:09.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:09.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:09.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:09.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:09.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:10.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:10.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:10.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:10.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:10.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:10.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:10 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:10 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:11.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:11.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:11.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:11.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:11.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:12.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:12.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:12.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:12.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:12.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:12.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:12 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:12 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:13.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:13.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:13.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:13.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:13.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:13.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:14.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:14.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:14.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:14.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:14.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:14.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:14 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:14 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:15.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:15.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:15.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:15.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:15.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:15.053 NotebookApp] zmq message arrived on closed channel
[W 06:32:16.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:16.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:16.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:16.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:16.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:16.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:16 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:16 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:17.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:17.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:17.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:17.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:17.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:17.053 NotebookApp] zmq message arrived on closed channel
[W 06:32:18.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:18.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:18.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:18.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:18.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:18.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:18 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:18 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:19.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:19.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:19.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:19.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:19.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:19.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:20.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:20.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:20.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:20.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:20.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:20.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:20 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:20 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:21.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:21.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:21.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:21.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:21.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:21.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:22.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:22.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:22.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:22.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:22.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:22.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:22 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:22 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:23.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:23.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:23.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:23.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:23.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:23.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:24.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:24.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:24.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:24.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:24.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:24.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:24 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:24 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:25.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:25.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:25.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:25.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:25.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:25.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:26.073 NotebookApp] zmq message arrived on closed channel
[W 06:32:26.074 NotebookApp] zmq message arrived on closed channel
[W 06:32:26.074 NotebookApp] zmq message arrived on closed channel
[W 06:32:26.074 NotebookApp] zmq message arrived on closed channel
[W 06:32:26.074 NotebookApp] zmq message arrived on closed channel
[W 06:32:26.074 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:26 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:26 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:27.053 NotebookApp] zmq message arrived on closed channel
[W 06:32:27.053 NotebookApp] zmq message arrived on closed channel
[W 06:32:27.053 NotebookApp] zmq message arrived on closed channel
[W 06:32:27.053 NotebookApp] zmq message arrived on closed channel
[W 06:32:27.054 NotebookApp] zmq message arrived on closed channel
[W 06:32:27.054 NotebookApp] zmq message arrived on closed channel
[W 06:32:28.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:28.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:28.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:28.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:28.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:28.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:28 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:28 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:29.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:29.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:29.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:29.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:29.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:30.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:30.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:30.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:30.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:30.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:30.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:30 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:30 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:31.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:31.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:31.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:31.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:31.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:31.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:32.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:32.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:32.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:32.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:32.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:32.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:32 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:32 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:33.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:33.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:33.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:34.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:34.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:34.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:34.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:34.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:34.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:34 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:34 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:35.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:35.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:35.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:35.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:35.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:35.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:36.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:36.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:36.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:36.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:36.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:36.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:36 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:36 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:37.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:37.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:37.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:38.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:38.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:38.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:38.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:38.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:38.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:38 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:38 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:39.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:39.053 NotebookApp] zmq message arrived on closed channel
[W 06:32:40.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:40.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:40.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:40.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:40.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:40.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:40 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:40 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:41.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:41.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:41.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:41.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:41.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:41.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:42.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:42.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:42.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:42.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:42.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:42.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:42 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:42 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:43.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:43.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:43.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:43.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:43.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:43.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:44.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:44.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:44.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:44.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:44 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:44 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:46.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:46.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:46 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:46 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:47.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:47.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:47.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:47.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:47.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:47.053 NotebookApp] zmq message arrived on closed channel
[W 06:32:48.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:48.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:48.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:48.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:48.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:48.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:48 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:48 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:49.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:50.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:50.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:50.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:50.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:50.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:50.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:50 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:50 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:51.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:51.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:51.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:51.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:52.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:52.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:52.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:52.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:52.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:52.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:52 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:52 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:53.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:53.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:53.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:53.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:53.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:53.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:54.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:54.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:54.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:54.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:54.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:54.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:54 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:54 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:55.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:55.049 NotebookApp] zmq message arrived on closed channel
[W 06:32:55.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:55.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:55.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:55.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:56.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:56.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:56.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:56.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:56.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:56.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:56 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:56 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:57.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:57.052 NotebookApp] zmq message arrived on closed channel
[W 06:32:57.053 NotebookApp] zmq message arrived on closed channel
[W 06:32:57.053 NotebookApp] zmq message arrived on closed channel
[W 06:32:57.053 NotebookApp] zmq message arrived on closed channel
[W 06:32:57.053 NotebookApp] zmq message arrived on closed channel
[W 06:32:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:58.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:58.051 NotebookApp] zmq message arrived on closed channel
[W 06:32:58.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:32:58 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:32:58 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:32:59.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:59.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:59.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:59.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:59.050 NotebookApp] zmq message arrived on closed channel
[W 06:32:59.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:00.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:00.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:00.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:00 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:00 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:01.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:02.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:02.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:02.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:02.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:02.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:02 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:02 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:03.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:03.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:03.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:03.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:03.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:03.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:04.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:04.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:04.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:04.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:04.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:04.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:04 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:04 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:05.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:05.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:05.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:05.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:05.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:05.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:06.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:06.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:06.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:06.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:06.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:06.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:06 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:06 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:07.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:07.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:07.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:07.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:07.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:07.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:08.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:08.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:08.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:08.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:08.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:08.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:08 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:08 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:09.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:09.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:09.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:09.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:09.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:09.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:10.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:10.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:10.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:10.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:10.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:10.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:10 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:10 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:11.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:11.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:12.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:12.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:12.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:12.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:12.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:12.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:12 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:12 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:13.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:13.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:13.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:13.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:13.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:13.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:14.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:14.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:14.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:14.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:14.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:14.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:14 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:14 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:15.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:15.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:15.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:15.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:15.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:15.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:16.048 NotebookApp] zmq message arrived on closed channel
[W 06:33:16.048 NotebookApp] zmq message arrived on closed channel
[W 06:33:16.048 NotebookApp] zmq message arrived on closed channel
[W 06:33:16.048 NotebookApp] zmq message arrived on closed channel
[W 06:33:16.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:16.049 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:16 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:16 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:17.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:17.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:17.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:17.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:17.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:17.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:18.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:18.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:18.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:18.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:18.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:18.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:18 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:18 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:19.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:19.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:19.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:19.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:19.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:19.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:20.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:20.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:20.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:20.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:20.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:20.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:20 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:20 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:21.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:21.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:21.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:21.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:21.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:21.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:22.076 NotebookApp] zmq message arrived on closed channel
[W 06:33:22.076 NotebookApp] zmq message arrived on closed channel
[W 06:33:22.076 NotebookApp] zmq message arrived on closed channel
[W 06:33:22.076 NotebookApp] zmq message arrived on closed channel
[W 06:33:22.077 NotebookApp] zmq message arrived on closed channel
[W 06:33:22.077 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:22 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:22 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:23.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:23.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:23.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:23.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:23.054 NotebookApp] zmq message arrived on closed channel
[W 06:33:23.054 NotebookApp] zmq message arrived on closed channel
[W 06:33:24.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:24.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:24.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:24.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:24.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:24.051 NotebookApp] zmq message arrived on closed channel
[I 06:33:24.364 NotebookApp] Request shutdown_kernel: 5f1ecd5c-9649-4b79-bf19-e6930fc86e23, <IPython.kernel.ioloop.manager.IOLoopKernelManager object at 0x7fd6316638d0>
15/10/22 06:33:24 INFO SparkUI: Stopped Spark web UI at http://172.17.0.22:4041
15/10/22 06:33:24 INFO DAGScheduler: Stopping DAGScheduler
15/10/22 06:33:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/10/22 06:33:24 INFO Utils: path = /tmp/spark-7ca4125c-fd13-4197-aa7f-9fe6163feca2/blockmgr-88b233e4-cd52-4810-b90f-fd20425e41c4, already present as root for deletion.
15/10/22 06:33:24 INFO MemoryStore: MemoryStore cleared
15/10/22 06:33:24 INFO BlockManager: BlockManager stopped
15/10/22 06:33:24 INFO BlockManagerMaster: BlockManagerMaster stopped
15/10/22 06:33:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/10/22 06:33:24 INFO SparkContext: Successfully stopped SparkContext
15/10/22 06:33:24 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:24 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

15/10/22 06:33:24 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/10/22 06:33:24 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/10/22 06:33:24 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
15/10/22 06:33:25 INFO Utils: Shutdown hook called
15/10/22 06:33:25 INFO Utils: Deleting directory /tmp/spark-7ca4125c-fd13-4197-aa7f-9fe6163feca2/pyspark-7fef74de-62da-4241-a21b-35d6b6075968
15/10/22 06:33:25 INFO Utils: Deleting directory /tmp/spark-7ca4125c-fd13-4197-aa7f-9fe6163feca2
[I 06:33:25.367 NotebookApp] Kernel shutdown: 5f1ecd5c-9649-4b79-bf19-e6930fc86e23
[W 06:33:25.371 NotebookApp] zmq message arrived on closed channel
[W 06:33:25.371 NotebookApp] zmq message arrived on closed channel
[W 06:33:25.372 NotebookApp] zmq message arrived on closed channel
[W 06:33:25.372 NotebookApp] zmq message arrived on closed channel
[W 06:33:25.372 NotebookApp] zmq message arrived on closed channel
[W 06:33:25.372 NotebookApp] zmq message arrived on closed channel
[W 06:33:26.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:26.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:26.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:26.054 NotebookApp] zmq message arrived on closed channel
[W 06:33:26.054 NotebookApp] zmq message arrived on closed channel
[W 06:33:26.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:26 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:26 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:27.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:27.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:27.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:27.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:27.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:27.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:28.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:28.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:28.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:28.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:28.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:28.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:28 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:28 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:29.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:29.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:29.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:29.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:30.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:30.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:30.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:30.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:30.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:30.050 NotebookApp] zmq message arrived on closed channel
[I 06:33:30.086 NotebookApp] Request shutdown_kernel: 12a23d72-5ba3-498c-88f5-bc362c8c5357, <IPython.kernel.ioloop.manager.IOLoopKernelManager object at 0x7fd632b44690>
15/10/22 06:33:30 INFO SparkUI: Stopped Spark web UI at http://172.17.0.22:4040
15/10/22 06:33:30 INFO DAGScheduler: Stopping DAGScheduler
15/10/22 06:33:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/10/22 06:33:30 INFO Utils: path = /tmp/spark-fe150378-7bad-42b6-876b-d14e2c193eb6/blockmgr-c142f2f1-ebb6-4612-945b-0a67d156230a, already present as root for deletion.
15/10/22 06:33:30 INFO MemoryStore: MemoryStore cleared
15/10/22 06:33:30 INFO BlockManager: BlockManager stopped
15/10/22 06:33:30 INFO BlockManagerMaster: BlockManagerMaster stopped
15/10/22 06:33:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/10/22 06:33:30 INFO SparkContext: Successfully stopped SparkContext
15/10/22 06:33:30 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/10/22 06:33:30 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/10/22 06:33:30 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
15/10/22 06:33:30 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:30 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

15/10/22 06:33:30 INFO Utils: Shutdown hook called
15/10/22 06:33:30 INFO Utils: Deleting directory /tmp/spark-fe150378-7bad-42b6-876b-d14e2c193eb6
[I 06:33:30.889 NotebookApp] Kernel shutdown: 12a23d72-5ba3-498c-88f5-bc362c8c5357
[W 06:33:31.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:31.054 NotebookApp] zmq message arrived on closed channel
[W 06:33:31.054 NotebookApp] zmq message arrived on closed channel
[W 06:33:31.055 NotebookApp] zmq message arrived on closed channel
[W 06:33:31.055 NotebookApp] zmq message arrived on closed channel
[W 06:33:31.055 NotebookApp] zmq message arrived on closed channel
[W 06:33:32.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:32.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:32.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:32.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:32.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:32.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:32 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:32 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:33.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:34.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:34.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:34.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:34.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:34.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:34.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:34 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:34 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[I 06:33:34.985 NotebookApp] Request shutdown_kernel: e5b46672-62e4-414d-a53c-36167c8a4c14, <IPython.kernel.ioloop.manager.IOLoopKernelManager object at 0x7fd6317c5bd0>
15/10/22 06:33:35 INFO SparkUI: Stopped Spark web UI at http://172.17.0.22:4047
15/10/22 06:33:35 INFO DAGScheduler: Stopping DAGScheduler
15/10/22 06:33:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/10/22 06:33:35 INFO Utils: path = /tmp/spark-0f1efbbf-1336-4e53-b9e1-c3a0b791b808/blockmgr-573c0859-eb51-466c-99b6-84c3311f512c, already present as root for deletion.
15/10/22 06:33:35 INFO MemoryStore: MemoryStore cleared
15/10/22 06:33:35 INFO BlockManager: BlockManager stopped
15/10/22 06:33:35 INFO BlockManagerMaster: BlockManagerMaster stopped
15/10/22 06:33:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/10/22 06:33:35 INFO SparkContext: Successfully stopped SparkContext
15/10/22 06:33:35 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/10/22 06:33:35 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/10/22 06:33:35 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
15/10/22 06:33:35 INFO Utils: Shutdown hook called
15/10/22 06:33:35 INFO Utils: Deleting directory /tmp/spark-0f1efbbf-1336-4e53-b9e1-c3a0b791b808/pyspark-56ef90f8-2b4f-43b5-a7e4-219c544e948e
15/10/22 06:33:35 INFO Utils: Deleting directory /tmp/spark-0f1efbbf-1336-4e53-b9e1-c3a0b791b808
[I 06:33:35.788 NotebookApp] Kernel shutdown: e5b46672-62e4-414d-a53c-36167c8a4c14
[W 06:33:35.792 NotebookApp] zmq message arrived on closed channel
[W 06:33:35.792 NotebookApp] zmq message arrived on closed channel
[W 06:33:35.792 NotebookApp] zmq message arrived on closed channel
[W 06:33:35.793 NotebookApp] zmq message arrived on closed channel
[W 06:33:35.793 NotebookApp] zmq message arrived on closed channel
[W 06:33:35.793 NotebookApp] zmq message arrived on closed channel
[W 06:33:35.793 NotebookApp] zmq message arrived on closed channel
[W 06:33:35.793 NotebookApp] zmq message arrived on closed channel
[W 06:33:35.794 NotebookApp] zmq message arrived on closed channel
[W 06:33:35.794 NotebookApp] zmq message arrived on closed channel
[W 06:33:35.794 NotebookApp] zmq message arrived on closed channel
[W 06:33:35.795 NotebookApp] zmq message arrived on closed channel
[W 06:33:35.795 NotebookApp] zmq message arrived on closed channel
[W 06:33:35.796 NotebookApp] zmq message arrived on closed channel
[W 06:33:35.796 NotebookApp] zmq message arrived on closed channel
[W 06:33:35.796 NotebookApp] zmq message arrived on closed channel
[W 06:33:35.797 NotebookApp] zmq message arrived on closed channel
[W 06:33:35.798 NotebookApp] zmq message arrived on closed channel
[W 06:33:35.798 NotebookApp] zmq message arrived on closed channel
[W 06:33:35.799 NotebookApp] zmq message arrived on closed channel
[W 06:33:35.799 NotebookApp] zmq message arrived on closed channel
[W 06:33:36.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:36.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:36.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:36.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:36.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:36.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:36 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:36 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:37.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:37.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:38.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:38.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:38.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:38.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:38.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:38.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:38 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:38 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:39.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:39.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:39.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:39.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:40.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:40.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:40.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:40.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:40.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:40.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:40 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:40 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:41.048 NotebookApp] zmq message arrived on closed channel
[W 06:33:41.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:41.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:41.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:41.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:41.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:42.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:42.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:42.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:42.054 NotebookApp] zmq message arrived on closed channel
[W 06:33:42.054 NotebookApp] zmq message arrived on closed channel
[W 06:33:42.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:42 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:42 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:43.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:43.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:43.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:43.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:43.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:43.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:44.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:44 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:44 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:45.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:45.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:45.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:46.047 NotebookApp] zmq message arrived on closed channel
[W 06:33:46.048 NotebookApp] zmq message arrived on closed channel
[W 06:33:46.048 NotebookApp] zmq message arrived on closed channel
[W 06:33:46.048 NotebookApp] zmq message arrived on closed channel
[W 06:33:46.048 NotebookApp] zmq message arrived on closed channel
[W 06:33:46.048 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:46 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:46 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:47.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:48.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:48.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:48.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:48.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:48.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:48.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:48 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:48 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:49.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:49.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:49.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:50.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:50.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:50.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:50.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:50.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:50.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:50 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:50 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:51.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:51.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:51.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:51.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:52.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:52.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:52.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:52.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:52.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:52.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:52 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:52 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:53.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:53.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:53.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:53.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:53.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:53.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:54.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:54.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:54.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:54.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:54.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:54.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:54 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:54 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:55.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:55.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:55.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:55.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:55.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:55.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:56.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:56.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:56.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:56.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:56.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:56.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:56 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:56 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:57.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:57.051 NotebookApp] zmq message arrived on closed channel
[W 06:33:57.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:57.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:57.052 NotebookApp] zmq message arrived on closed channel
[W 06:33:57.053 NotebookApp] zmq message arrived on closed channel
[W 06:33:58.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:58.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:58.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:58.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:33:58 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:33:58 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:33:59.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:59.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:59.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:59.049 NotebookApp] zmq message arrived on closed channel
[W 06:33:59.050 NotebookApp] zmq message arrived on closed channel
[W 06:33:59.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:00.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:00.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:00.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:00.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:00.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:00.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:00 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:00 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:01.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:01.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:01.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:01.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:01.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:02.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:02.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:02.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:02 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:02 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:03.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:03.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:03.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:03.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:03.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:03.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:04.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:04.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:04.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:04.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:04.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:04.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:04 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:04 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:05.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:05.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:05.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:05.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:05.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:05.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:06.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:06.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:06.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:06.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:06.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:06.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:06 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:06 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:07.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:07.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:07.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:07.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:07.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:07.053 NotebookApp] zmq message arrived on closed channel
[W 06:34:08.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:08.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:08.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:08.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:08.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:08.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:08 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:08 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:09.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:09.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:09.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:09.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:09.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:09.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:10.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:10.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:10.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:10.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:10.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:10.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:10 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:10 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:11.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:11.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:11.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:12.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:12.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:12.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:12.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:12.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:12.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:12 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:12 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:13.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:13.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:13.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:13.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:13.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:13.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:14.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:14.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:14.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:14.053 NotebookApp] zmq message arrived on closed channel
[W 06:34:14.053 NotebookApp] zmq message arrived on closed channel
[W 06:34:14.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:14 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:14 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:15.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:15.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:15.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:15.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:15.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:15.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:16.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:16.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:16.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:16.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:16.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:16.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:16 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:16 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:17.048 NotebookApp] zmq message arrived on closed channel
[W 06:34:17.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:17.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:17.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:17.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:17.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:18.077 NotebookApp] zmq message arrived on closed channel
[W 06:34:18.077 NotebookApp] zmq message arrived on closed channel
[W 06:34:18.077 NotebookApp] zmq message arrived on closed channel
[W 06:34:18.078 NotebookApp] zmq message arrived on closed channel
[W 06:34:18.078 NotebookApp] zmq message arrived on closed channel
[W 06:34:18.078 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:18 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:18 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:19.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:19.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:19.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:19.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:19.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:19.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:20.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:20.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:20.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:20.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:20.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:20.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:20 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:20 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:21.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:21.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:21.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:21.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:21.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:21.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:22.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:22.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:22.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:22.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:22.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:22.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:22 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:22 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:23.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:23.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:23.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:23.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:23.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:23.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:24.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:24.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:24.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:24.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:24.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:24.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:24 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:24 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:25.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:25.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:25.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:25.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:25.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:25.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:26.048 NotebookApp] zmq message arrived on closed channel
[W 06:34:26.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:26.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:26.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:26.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:26.050 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:26 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:26 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:27.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:27.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:27.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:27.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:27.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:27.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:28.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:28.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:28.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:28.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:28.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:28.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:28 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:28 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:29.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:29.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:29.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:29.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:29.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:29.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:30.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:30.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:30.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:30.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:30.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:30.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:30 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:30 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:31.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:31.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:31.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:31.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:31.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:31.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:32.048 NotebookApp] zmq message arrived on closed channel
[W 06:34:32.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:32.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:32.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:32.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:32.049 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:32 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:32 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:33.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:33.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:33.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:33.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:33.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:34.047 NotebookApp] zmq message arrived on closed channel
[W 06:34:34.048 NotebookApp] zmq message arrived on closed channel
[W 06:34:34.048 NotebookApp] zmq message arrived on closed channel
[W 06:34:34.048 NotebookApp] zmq message arrived on closed channel
[W 06:34:34.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:34.049 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:34 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:34 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:35.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:35.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:35.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:35.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:35.053 NotebookApp] zmq message arrived on closed channel
[W 06:34:35.053 NotebookApp] zmq message arrived on closed channel
[W 06:34:36.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:36.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:36.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:36.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:36.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:36.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:36 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:36 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:37.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:37.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:37.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:37.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:38.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:38.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:38.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:38.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:38.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:38.051 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:38 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:38 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:39.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:39.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:39.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:40.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:40.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:40.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:40.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:40.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:40.053 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:40 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:40 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:41.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:41.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:41.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:41.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:41.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:41.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:42.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:42.053 NotebookApp] zmq message arrived on closed channel
[W 06:34:42.053 NotebookApp] zmq message arrived on closed channel
[W 06:34:42.053 NotebookApp] zmq message arrived on closed channel
[W 06:34:42.054 NotebookApp] zmq message arrived on closed channel
[W 06:34:42.054 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:42 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:42 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:43.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:43.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:43.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:43.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:43.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:43.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:44.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:44.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:44.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:44.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:44.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:44 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:44 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:45.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:45.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:45.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:45.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:45.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:46.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:46.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:46.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:46.052 NotebookApp] zmq message arrived on closed channel
[W 06:34:46.052 NotebookApp] zmq message arrived on closed channel
15/10/22 06:34:46 [WARN] o.a.s.s.r.ReceiverSupervisorImpl - Restarting receiver with delay 2000 ms: Error connecting to localhost:7777
java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)
15/10/22 06:34:46 [ERROR] o.a.s.s.s.ReceiverTracker - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Error connecting to localhost:7777 - java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at java.net.Socket.connect(Socket.java:528)
	at java.net.Socket.<init>(Socket.java:425)
	at java.net.Socket.<init>(Socket.java:208)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:59)

[W 06:34:47.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:47.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:47.050 NotebookApp] zmq message arrived on closed channel
[W 06:34:47.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:47.051 NotebookApp] zmq message arrived on closed channel
[W 06:34:48.047 NotebookApp] zmq message arrived on closed channel
[W 06:34:48.048 NotebookApp] zmq message arrived on closed channel
[W 06:34:48.048 NotebookApp] zmq message arrived on closed channel
[W 06:34:48.048 NotebookApp] zmq message arrived on closed channel
[W 06:34:48.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:48.049 NotebookApp] zmq message arrived on closed channel
[W 06:34:48.193 NotebookApp] zmq message arrived on closed channel
[W 06:34:48.194 NotebookApp] zmq message arrived on closed channel
[W 06:34:48.194 NotebookApp] zmq message arrived on closed channel
[W 06:34:48.195 NotebookApp] zmq message arrived on closed channel
